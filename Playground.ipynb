{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load the training and test datasets\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainset_reduzido = torch.utils.data.random_split(trainset, [1000, len(trainset) - 1000])[0]\n",
    "# Create data loaders\n",
    "trainloader = DataLoader(trainset_reduzido, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parametro inicial, camada final: 0.04712291806936264\n",
      "parametros finais, camada final: 0.046314749866724014 gradi total: 0.08081717044115067\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "params_init = [param.clone().detach() for param in net.parameters()]\n",
    "for i, param in enumerate(net.parameters()):\n",
    "    if i == 9:\n",
    "        print(f'parametro inicial, camada final: {param[0]}')\n",
    "grads_acu = [torch.zeros_like(param) for param in net.parameters()]\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "net.train()\n",
    "for epoch in range(2):\n",
    "    for data in trainloader:\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        params_anterior = [param.clone().detach() for param in net.parameters()]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        for i, param in enumerate(net.parameters()):\n",
    "            grads_acu[i] += param.grad\n",
    "            # if i == 9:\n",
    "            #     print(f'parametro anterior: {params_anterior[i][0]}')\n",
    "            #     print(f'gradiente da iteracao: {param.grad[0]}')\n",
    "            #     print(f'parametro anterior - gradiente: {params_anterior[i][0] - 0.01*param.grad[0]}')\n",
    "            #     print(f'parametro atualizado: {param[0]}')\n",
    "gradients = [grad.cpu().numpy() for grad in grads_acu] \n",
    "for i, param in enumerate(net.parameters()):\n",
    "    if i == 9:\n",
    "        print(f'parametros finais, camada final: {param[0]} gradi total: {gradients[9][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.randint(1, 12000, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7084,   288,  2117,  4414,   567, 10940,  8444,  6988,  3009,\n",
       "        4693])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _try_inplace(x, y, np_binary_op):\n",
    "        return (  # type: ignore[no-any-return]\n",
    "            np_binary_op(x, y, out=x)\n",
    "            if np.can_cast(y, x.dtype, casting=\"same_kind\")\n",
    "            else np_binary_op(x, np.array(y, x.dtype), out=x)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "        _try_inplace(x, y[0], np_binary_op=np.multiply)\n",
    "        for x in gradients\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2, 4, 6]), array([ 8, 10, 12])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from functools import partial, reduce\n",
    "\n",
    "def _try_inplace(x, y, np_binary_op):\n",
    "    return np_binary_op(x, y, out=x)\n",
    "\n",
    "# Parâmetros e gradientes de exemplo\n",
    "params = [np.array([1, 2, 3]), np.array([4, 5, 6])]\n",
    "res = [np.array([1, 2, 3]), np.array([4, 5, 6])]\n",
    "\n",
    "# Atualização dos parâmetros\n",
    "params = [\n",
    "    reduce(partial(_try_inplace, np_binary_op=np.add), layer_updates)\n",
    "    for layer_updates in zip(params, res)\n",
    "]\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16123287671232875"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_ex = [0.01,0.02,0.3,0.04,0.05,0.06,0.07,0.08,0.09,0.010]\n",
    "scale = [0.1]*10\n",
    "scale = grad_ex/np.sum(grad_ex)\n",
    "np.sum(np.multiply(grad_ex, scale))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeraFed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
