{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version     Editable project location\n",
      "------------------------- ----------- ---------------------------------------------------\n",
      "aiohappyeyeballs          2.4.6\n",
      "aiohttp                   3.11.12\n",
      "aiosignal                 1.3.2\n",
      "alembic                   1.14.1\n",
      "asttokens                 3.0.0\n",
      "async-timeout             5.0.1\n",
      "attrs                     25.1.0\n",
      "certifi                   2025.1.31\n",
      "cffi                      1.17.1\n",
      "charset-normalizer        3.4.1\n",
      "click                     8.1.8\n",
      "colorlog                  6.9.0\n",
      "comm                      0.2.2\n",
      "contourpy                 1.3.1\n",
      "cryptography              43.0.3\n",
      "ctgan                     0.10.2\n",
      "cycler                    0.12.1\n",
      "datasets                  3.1.0\n",
      "debugpy                   1.8.12\n",
      "decorator                 5.2.0\n",
      "dill                      0.3.8\n",
      "exceptiongroup            1.2.2\n",
      "executing                 2.2.0\n",
      "Faker                     36.1.1\n",
      "filelock                  3.17.0\n",
      "flwr                      1.15.2\n",
      "flwr-datasets             0.5.0\n",
      "fonttools                 4.56.0\n",
      "frozenlist                1.5.0\n",
      "fsspec                    2024.9.0\n",
      "GeraFed                   1.0.0       /home/guaragna/Documents/Pesquisa/GeraFed/GeraFed-1\n",
      "greenlet                  3.1.1\n",
      "grpcio                    1.70.0\n",
      "huggingface-hub           0.29.1\n",
      "idna                      3.10\n",
      "ipykernel                 6.29.5\n",
      "ipython                   8.32.0\n",
      "iterators                 0.0.2\n",
      "jedi                      0.19.2\n",
      "Jinja2                    3.1.5\n",
      "joblib                    1.4.2\n",
      "jsonschema                4.23.0\n",
      "jsonschema-specifications 2024.10.1\n",
      "jupyter_client            8.6.3\n",
      "jupyter_core              5.7.2\n",
      "kiwisolver                1.4.8\n",
      "Mako                      1.3.9\n",
      "markdown-it-py            3.0.0\n",
      "MarkupSafe                3.0.2\n",
      "matplotlib                3.10.0\n",
      "matplotlib-inline         0.1.7\n",
      "mdurl                     0.1.2\n",
      "mpmath                    1.3.0\n",
      "msgpack                   1.1.0\n",
      "multidict                 6.1.0\n",
      "multiprocess              0.70.16\n",
      "nest-asyncio              1.6.0\n",
      "networkx                  3.4.2\n",
      "numpy                     1.26.4\n",
      "nvidia-cublas-cu12        12.1.3.1\n",
      "nvidia-cuda-cupti-cu12    12.1.105\n",
      "nvidia-cuda-nvrtc-cu12    12.1.105\n",
      "nvidia-cuda-runtime-cu12  12.1.105\n",
      "nvidia-cudnn-cu12         8.9.2.26\n",
      "nvidia-cufft-cu12         11.0.2.54\n",
      "nvidia-curand-cu12        10.3.2.106\n",
      "nvidia-cusolver-cu12      11.4.5.107\n",
      "nvidia-cusparse-cu12      12.1.0.106\n",
      "nvidia-cusparselt-cu12    0.6.2\n",
      "nvidia-nccl-cu12          2.19.3\n",
      "nvidia-nvjitlink-cu12     12.4.127\n",
      "nvidia-nvtx-cu12          12.1.105\n",
      "optuna                    4.2.1\n",
      "packaging                 24.2\n",
      "pandas                    2.2.3\n",
      "parso                     0.8.4\n",
      "pathspec                  0.12.1\n",
      "pexpect                   4.9.0\n",
      "pillow                    11.1.0\n",
      "pip                       23.0.1\n",
      "platformdirs              4.3.6\n",
      "prompt_toolkit            3.0.50\n",
      "propcache                 0.3.0\n",
      "protobuf                  4.25.6\n",
      "psutil                    7.0.0\n",
      "ptyprocess                0.7.0\n",
      "pure_eval                 0.2.3\n",
      "pyarrow                   19.0.1\n",
      "pycparser                 2.22\n",
      "pycryptodome              3.21.0\n",
      "Pygments                  2.19.1\n",
      "pyparsing                 3.2.1\n",
      "python-dateutil           2.9.0.post0\n",
      "pytz                      2025.1\n",
      "PyYAML                    6.0.2\n",
      "pyzmq                     26.2.1\n",
      "ray                       2.31.0\n",
      "rdt                       1.14.0\n",
      "referencing               0.36.2\n",
      "requests                  2.32.3\n",
      "rich                      13.9.4\n",
      "rpds-py                   0.23.1\n",
      "scikit-learn              1.6.1\n",
      "scipy                     1.15.2\n",
      "seaborn                   0.13.2\n",
      "setuptools                65.5.0\n",
      "shellingham               1.5.4\n",
      "six                       1.17.0\n",
      "SQLAlchemy                2.0.38\n",
      "stack-data                0.6.3\n",
      "sympy                     1.13.1\n",
      "threadpoolctl             3.5.0\n",
      "tomli                     2.2.1\n",
      "tomli_w                   1.2.0\n",
      "torch                     2.2.2\n",
      "torchvision               0.17.2\n",
      "tornado                   6.4.2\n",
      "tqdm                      4.67.1\n",
      "traitlets                 5.14.3\n",
      "triton                    2.2.0\n",
      "typer                     0.12.5\n",
      "typing_extensions         4.12.2\n",
      "tzdata                    2025.1\n",
      "urllib3                   2.3.0\n",
      "wcwidth                   0.2.13\n",
      "xgboost                   2.1.4\n",
      "xxhash                    3.5.0\n",
      "yarl                      1.18.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, seed=None):\n",
    "        if seed is not None:\n",
    "          torch.manual_seed(seed)\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16*4*4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F2U_GAN(nn.Module):\n",
    "    def __init__(self, dataset=\"mnist\", img_size=28, latent_dim=128, condition=True, seed=None):\n",
    "        if seed is not None:\n",
    "          torch.manual_seed(seed)\n",
    "        super(F2U_GAN, self).__init__()\n",
    "        if dataset == \"mnist\":\n",
    "            self.classes = 10\n",
    "            self.channels = 1\n",
    "        else:\n",
    "            raise NotImplementedError(\"Only MNIST is supported\")\n",
    "\n",
    "        self.condition = condition\n",
    "        self.label_embedding = nn.Embedding(self.classes, self.classes) if condition else None\n",
    "        #self.label_embedding_disc = nn.Embedding(self.classes, self.img_size*self.img_size) if condition else None\n",
    "        self.img_size = img_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
    "        self.input_shape_gen = self.latent_dim + self.label_embedding.embedding_dim if condition else self.latent_dim\n",
    "        self.input_shape_disc = self.channels + self.classes if condition else self.channels\n",
    "\n",
    "        self.adv_loss = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Generator (unchanged) To calculate output shape of convtranspose layers, we can use the formula:\n",
    "        # output_shape = (input_shape - 1) * stride - 2 * padding + kernel_size + output_padding (or dilation * (kernel_size - 1) + 1 inplace of kernel_size if using dilation)\n",
    "        self.generator = nn.Sequential(\n",
    "            nn.Linear(self.input_shape_gen, 256 * 7 * 7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Unflatten(1, (256, 7, 7)),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1), # (256,7,7) -> (128,14,14)\n",
    "            nn.BatchNorm2d(128, momentum=0.1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1), # (128,14,14) -> (64,28,28)\n",
    "            nn.BatchNorm2d(64, momentum=0.1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(64, self.channels, kernel_size=3, stride=1, padding=1), # (64,28,28) -> (1,28,28)\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        # Discriminator (corrected) To calculate output shape of conv layers, we can use the formula:\n",
    "        # output_shape = ⌊(input_shape - kernel_size + 2 * padding) / stride + 1⌋ (or (dilation * (kernel_size - 1) - 1) inplace of kernel_size if using dilation)\n",
    "        self.discriminator = nn.Sequential(\n",
    "        # Camada 1: (1,28,28) -> (32,13,13)\n",
    "        nn.utils.spectral_norm(nn.Conv2d(self.input_shape_disc, 32, kernel_size=3, stride=2, padding=0)),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "        # Camada 2: (32,14,14) -> (64,7,7)\n",
    "        nn.utils.spectral_norm(nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "        # Camada 3: (64,7,7) -> (128,3,3)\n",
    "        nn.utils.spectral_norm(nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=0)),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "        # Camada 4: (128,3,3) -> (256,1,1)\n",
    "        nn.utils.spectral_norm(nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=0)),  # Padding 0 aqui!\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "        # Achata e concatena com as labels\n",
    "        nn.Flatten(), # (256,1,1) -> (256*1*1,)\n",
    "        nn.utils.spectral_norm(nn.Linear(256 * 1 * 1, 1))  # 256 (features)\n",
    "        )\n",
    "\n",
    "    def forward(self, input, labels=None):\n",
    "        if input.dim() == 2:\n",
    "            # Generator forward pass (unchanged)\n",
    "            if self.condition:\n",
    "                embedded_labels = self.label_embedding(labels)\n",
    "                gen_input = torch.cat((input, embedded_labels), dim=1)\n",
    "                x = self.generator(gen_input)\n",
    "            else:\n",
    "                x = self.generator(input)\n",
    "            return x.view(-1, *self.img_shape)\n",
    "\n",
    "        elif input.dim() == 4:\n",
    "            # Discriminator forward pass\n",
    "            if self.condition:\n",
    "                embedded_labels = self.label_embedding(labels)\n",
    "                image_labels = embedded_labels.view(embedded_labels.size(0), self.label_embedding.embedding_dim, 1, 1).expand(-1, -1, self.img_size, self.img_size)\n",
    "                x = torch.cat((input, image_labels), dim=1)\n",
    "            else:\n",
    "                x = input\n",
    "            return self.discriminator(x)\n",
    "\n",
    "    def loss(self, output, label):\n",
    "        return self.adv_loss(output, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_net = Net()\n",
    "optims = [torch.optim.Adam(global_net.parameters())]\n",
    "gen = F2U_GAN()\n",
    "optim_G = torch.optim.Adam(gen.generator.parameters())\n",
    "models = [F2U_GAN() for _ in range(4)]\n",
    "optim_Ds = [torch.optim.Adam(disc.discriminator.parameters()) for disc in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "            'epoch': 0,  # número da última época concluída\n",
    "            'alvo_state_dict': global_net.state_dict(),\n",
    "            'optimizer_alvo_state_dict': [optim.state_dict() for optim in optims],\n",
    "            'gen_state_dict': gen.state_dict(),\n",
    "            'optim_G_state_dict': optim_G.state_dict(),\n",
    "            'discs_state_dict': [model.state_dict() for model in models],\n",
    "            'optim_Ds_state_dict:': [optim_d.state_dict() for optim_d in optim_Ds]\n",
    "          }\n",
    "checkpoint_file = f\"checkpoint_epoch{000}.pth\"\n",
    "torch.save(checkpoint, checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = torch.load(\"checkpoint_epoch0.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_net.load_state_dict(check['alvo_state_dict'])\n",
    "for optim, state in zip(optims, check['optimizer_alvo_state_dict']):\n",
    "    optim.load_state_dict(state)\n",
    "\n",
    "gen.load_state_dict(check[\"gen_state_dict\"])\n",
    "optim_G.load_state_dict(check[\"optim_G_state_dict\"])\n",
    "\n",
    "for model, optim_d, state_model, state_optim in zip(models, optim_Ds, check[\"discs_state_dict\"], check[\"optim_Ds_state_dict:\"]):\n",
    "    model.load_state_dict(state_model)\n",
    "    optim_d.load_state_dict(state_optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, 'v'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../Experimentos/NB_F2U/GeraFed_4c_01Dir/MNIST/checkpoint_epoch100.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Pesquisa/GeraFed/gerafed_env/lib/python3.10/site-packages/torch/serialization.py:1040\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1039\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_legacy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Pesquisa/GeraFed/gerafed_env/lib/python3.10/site-packages/torch/serialization.py:1258\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mversion_info \u001b[38;5;241m<\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1254\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1255\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived object of type \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1256\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctionality.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1258\u001b[0m magic_number \u001b[38;5;241m=\u001b[39m \u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic_number \u001b[38;5;241m!=\u001b[39m MAGIC_NUMBER:\n\u001b[1;32m   1260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid magic number; corrupt file?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, 'v'."
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"../Experimentos/NB_F2U/GeraFed_4c_01Dir/MNIST/checkpoint_epoch100.pth\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gerafed_env",
   "language": "python",
   "name": "gerafed_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
