{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "07f8307e",
      "metadata": {
        "id": "07f8307e"
      },
      "source": [
        "# Inicialização"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f47d1996",
      "metadata": {
        "id": "f47d1996"
      },
      "source": [
        "## Prepara o ambiente local ou colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "88a7ea1c",
      "metadata": {
        "id": "88a7ea1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Ambiente local detectado. Downloads automáticos desativados.\n"
          ]
        }
      ],
      "source": [
        "# --- Detectar Ambiente (Colab ou Local) ---\n",
        "IN_COLAB = False\n",
        "try:\n",
        "    # Tenta importar um módulo específico do Colab\n",
        "    from google.colab import drive\n",
        "    import shutil # Usaremos para copiar, se necessário, mas salvar direto é melhor\n",
        "    import os\n",
        "\n",
        "    try:\n",
        "        drive.mount('/content/drive')\n",
        "        # Crie um diretório específico para salvar os resultados desta execução\n",
        "        save_base_dir = \"/content/drive/MyDrive/GAN_Training_Results\" # Ajuste o caminho como desejar\n",
        "        os.makedirs(save_base_dir, exist_ok=True)\n",
        "        # Opcional: Crie um subdiretório único para esta execução específica (ex: baseado em timestamp)\n",
        "        # import datetime\n",
        "        # timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        # save_dir = os.path.join(save_base_dir, f\"run_{timestamp}\")\n",
        "        # os.makedirs(save_dir, exist_ok=True)\n",
        "        # Por simplicidade, vamos usar o diretório base diretamente por enquanto\n",
        "        save_dir = save_base_dir\n",
        "        print(f\"✅ Google Drive montado. Arquivos serão salvos em: {save_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Erro ao montar o Google Drive: {e}\")\n",
        "        print(\"   Downloads diretos serão tentados, mas podem atrasar.\")\n",
        "        save_dir = \".\" # Salvar localmente se o Drive falhar\n",
        "    IN_COLAB = True\n",
        "    print(\"✅ Ambiente Google Colab detectado. Downloads automáticos (a cada 2 épocas) ativados.\")\n",
        "except ImportError:\n",
        "    print(\"✅ Ambiente local detectado. Downloads automáticos desativados.\")\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08e68593",
      "metadata": {
        "id": "08e68593"
      },
      "source": [
        "## Importa Pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1e43ad3e",
      "metadata": {
        "id": "1e43ad3e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5df872b",
      "metadata": {
        "id": "b5df872b"
      },
      "source": [
        "## Modelo Classificador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4395f020",
      "metadata": {
        "id": "4395f020"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, seed=None):\n",
        "        if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(16*4*4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16*4*4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a98df505",
      "metadata": {
        "id": "a98df505"
      },
      "outputs": [],
      "source": [
        "class Net_Cifar(nn.Module):\n",
        "    def __init__(self,seed=None):\n",
        "        if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d8c276e",
      "metadata": {
        "id": "6d8c276e"
      },
      "source": [
        "## Carrega Dados MNIST centralizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a82cbfd1",
      "metadata": {
        "id": "a82cbfd1"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13ad4aaf",
      "metadata": {
        "id": "13ad4aaf"
      },
      "outputs": [],
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Load the training and test datasets\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "trainset_reduzido = torch.utils.data.random_split(trainset, [1000, len(trainset) - 1000])[0]\n",
        "# Create data loaders\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "trainloader_reduzido = DataLoader(trainset_reduzido, batch_size=BATCH_SIZE, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "\n",
        "dataset = \"mnist\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64be3f56",
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "# Define transform com ToTensor e Normalize para 3 canais\n",
        "transform_cifar = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),  # média por canal R,G,B\n",
        "                         (0.5, 0.5, 0.5))  # desvio padrão por canal\n",
        "])\n",
        "\n",
        "# Carrega os datasets de treino e teste\n",
        "trainset_cifar = datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform_cifar\n",
        ")\n",
        "testset_cifar = datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform_cifar\n",
        ")\n",
        "\n",
        "# Cria um subset reduzido de treino (por exemplo, 1000 amostras)\n",
        "#trainset_cifar_reduzido = random_split(trainset_cifar, [1000, len(trainset_cifar) - 1000])[0]\n",
        "\n",
        "# DataLoaders\n",
        "trainloader_cifar = DataLoader(\n",
        "    trainset_cifar,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "# trainloader_cifar_reduzido = DataLoader(\n",
        "#     trainset_cifar_reduzido,\n",
        "#     batch_size=BATCH_SIZE,\n",
        "#     shuffle=True,\n",
        "#     num_workers=2,\n",
        "#     pin_memory=True\n",
        "# )\n",
        "testloader_cifar = DataLoader(\n",
        "    testset_cifar,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "dataset = \"cifar\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c27cfeac",
      "metadata": {
        "id": "c27cfeac"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# parameters\n",
        "num_classes = 10\n",
        "samples_per_class = 5\n",
        "\n",
        "if dataset == \"cifar\":\n",
        "    class_names = [\n",
        "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "     'dog', 'frog', 'horse', 'ship', 'truck'\n",
        "    ]\n",
        "\n",
        "# containers\n",
        "class_counts = {i: 0 for i in range(num_classes)}\n",
        "class_images = {i: [] for i in range(num_classes)}\n",
        "\n",
        "# gather up to 5 images per class\n",
        "for img, label in trainset:\n",
        "    if class_counts[label] < samples_per_class:\n",
        "        class_images[label].append(img)\n",
        "        class_counts[label] += 1\n",
        "    # stop early once we have enough of every class\n",
        "    if all(count >= samples_per_class for count in class_counts.values()):\n",
        "        break\n",
        "\n",
        "# plot\n",
        "fig, axes = plt.subplots(num_classes, samples_per_class, figsize=(5, 9))\n",
        "for cls in range(num_classes):\n",
        "    for i in range(samples_per_class):\n",
        "        ax = axes[cls, i]\n",
        "        img = class_images[cls][i]\n",
        "        if dataset == \"mnist\":\n",
        "            ax.imshow(img.squeeze(), cmap='gray')\n",
        "        else:\n",
        "            img_denorm = (img * 0.5 + 0.5)  # denormalize for visualization\n",
        "            ax.imshow(img_denorm.permute(1, 2, 0).numpy())\n",
        "        ax.axis('off')\n",
        "    # label the rows on the leftmost subplot\n",
        "   # axes[cls, 0].set_ylabel(str(cls), rotation=0, labelpad=12, va='center', fontsize=12)\n",
        "\n",
        "# Ajustar o layout antes de calcular as posições\n",
        "plt.tight_layout(rect=[0.05, 0, 1, 0.96])\n",
        "\n",
        "# Adicionar os rótulos das classes corretamente alinhados\n",
        "fig.canvas.draw()  # Atualiza a renderização para obter posições corretas\n",
        "for row in range(num_classes):\n",
        "    # Obter posição do subplot em coordenadas da figura\n",
        "    bbox = axes[row, 0].get_window_extent(fig.canvas.get_renderer())\n",
        "    pos = fig.transFigure.inverted().transform([(bbox.x0, bbox.y0), (bbox.x1, bbox.y1)])\n",
        "    center_y = (pos[0, 1] + pos[1, 1]) / 2  # Centro exato da linha\n",
        "\n",
        "    # Adicionar o rótulo\n",
        "    fig.text(0.04, center_y, str(row), va='center', fontsize=12, color='black')\n",
        "\n",
        "plt.suptitle(\"Real\", fontsize=16)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54f6fbda",
      "metadata": {
        "id": "54f6fbda"
      },
      "source": [
        "## Modelo Generativo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ea03ea69",
      "metadata": {
        "id": "ea03ea69"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "314c3604",
      "metadata": {
        "id": "314c3604"
      },
      "source": [
        "### CGAN (simples, mlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23cfec37",
      "metadata": {
        "id": "23cfec37"
      },
      "outputs": [],
      "source": [
        "class CGAN(nn.Module):\n",
        "    def __init__(self, dataset=\"mnist\", img_size=28, latent_dim=100):\n",
        "        super(CGAN, self).__init__()\n",
        "        if dataset == \"mnist\":\n",
        "            self.classes = 10\n",
        "            self.channels = 1\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes)\n",
        "        self.adv_loss = torch.nn.BCELoss()\n",
        "\n",
        "\n",
        "        self.generator = nn.Sequential(\n",
        "            *self._create_layer_gen(self.latent_dim + self.classes, 128, False),\n",
        "            *self._create_layer_gen(128, 256),\n",
        "            *self._create_layer_gen(256, 512),\n",
        "            *self._create_layer_gen(512, 1024),\n",
        "            nn.Linear(1024, int(np.prod(self.img_shape))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.discriminator = nn.Sequential(\n",
        "            *self._create_layer_disc(self.classes + int(np.prod(self.img_shape)), 1024, False, True),\n",
        "            *self._create_layer_disc(1024, 512, True, True),\n",
        "            *self._create_layer_disc(512, 256, True, True),\n",
        "            *self._create_layer_disc(256, 128, False, False),\n",
        "            *self._create_layer_disc(128, 1, False, False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def _create_layer_gen(self, size_in, size_out, normalize=True):\n",
        "        layers = [nn.Linear(size_in, size_out)]\n",
        "        if normalize:\n",
        "            layers.append(nn.BatchNorm1d(size_out))\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return layers\n",
        "\n",
        "    def _create_layer_disc(self, size_in, size_out, drop_out=True, act_func=True):\n",
        "        layers = [nn.Linear(size_in, size_out)]\n",
        "        if drop_out:\n",
        "            layers.append(nn.Dropout(0.4))\n",
        "        if act_func:\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return layers\n",
        "\n",
        "    def forward(self, input, labels):\n",
        "        if input.dim() == 2:\n",
        "            z = torch.cat((self.label_embedding(labels), input), -1)\n",
        "            x = self.generator(z)\n",
        "            x = x.view(x.size(0), *self.img_shape) #Em\n",
        "            return x\n",
        "        elif input.dim() == 4:\n",
        "            x = torch.cat((input.view(input.size(0), -1), self.label_embedding(labels)), -1)\n",
        "            return self.discriminator(x)\n",
        "\n",
        "    def loss(self, output, label):\n",
        "        return self.adv_loss(output, label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f1a5b73",
      "metadata": {
        "id": "4f1a5b73"
      },
      "source": [
        "### Arquitetura do paper F2U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cbb8292a",
      "metadata": {
        "id": "cbb8292a"
      },
      "outputs": [],
      "source": [
        "class F2U_GAN(nn.Module):\n",
        "    def __init__(self, dataset=\"mnist\", img_size=28, latent_dim=128, condition=True, seed=None):\n",
        "        if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "        super(F2U_GAN, self).__init__()\n",
        "        if dataset == \"mnist\":\n",
        "            self.classes = 10\n",
        "            self.channels = 1\n",
        "        else:\n",
        "            raise NotImplementedError(\"Only MNIST is supported\")\n",
        "\n",
        "        self.condition = condition\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes) if condition else None\n",
        "        #self.label_embedding_disc = nn.Embedding(self.classes, self.img_size*self.img_size) if condition else None\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
        "        self.input_shape_gen = self.latent_dim + self.label_embedding.embedding_dim if condition else self.latent_dim\n",
        "        self.input_shape_disc = self.channels + self.classes if condition else self.channels\n",
        "\n",
        "        self.adv_loss = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "        # Generator (unchanged) To calculate output shape of convtranspose layers, we can use the formula:\n",
        "        # output_shape = (input_shape - 1) * stride - 2 * padding + kernel_size + output_padding (or dilation * (kernel_size - 1) + 1 inplace of kernel_size if using dilation)\n",
        "        self.generator = nn.Sequential(\n",
        "            nn.Linear(self.input_shape_gen, 256 * 7 * 7),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Unflatten(1, (256, 7, 7)),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1), # (256,7,7) -> (128,14,14)\n",
        "            nn.BatchNorm2d(128, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1), # (128,14,14) -> (64,28,28)\n",
        "            nn.BatchNorm2d(64, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64, self.channels, kernel_size=3, stride=1, padding=1), # (64,28,28) -> (1,28,28)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # Discriminator (corrected) To calculate output shape of conv layers, we can use the formula:\n",
        "        # output_shape = ⌊(input_shape - kernel_size + 2 * padding) / stride + 1⌋ (or (dilation * (kernel_size - 1) - 1) inplace of kernel_size if using dilation)\n",
        "        self.discriminator = nn.Sequential(\n",
        "        # Camada 1: (1,28,28) -> (32,13,13)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(self.input_shape_disc, 32, kernel_size=3, stride=2, padding=0)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Camada 2: (32,14,14) -> (64,7,7)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Camada 3: (64,7,7) -> (128,3,3)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=0)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Camada 4: (128,3,3) -> (256,1,1)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=0)),  # Padding 0 aqui!\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Achata e concatena com as labels\n",
        "        nn.Flatten(), # (256,1,1) -> (256*1*1,)\n",
        "        nn.utils.spectral_norm(nn.Linear(256 * 1 * 1, 1))  # 256 (features)\n",
        "        )\n",
        "\n",
        "    def forward(self, input, labels=None):\n",
        "        if input.dim() == 2:\n",
        "            # Generator forward pass (unchanged)\n",
        "            if self.condition:\n",
        "                embedded_labels = self.label_embedding(labels)\n",
        "                gen_input = torch.cat((input, embedded_labels), dim=1)\n",
        "                x = self.generator(gen_input)\n",
        "            else:\n",
        "                x = self.generator(input)\n",
        "            return x.view(-1, *self.img_shape)\n",
        "\n",
        "        elif input.dim() == 4:\n",
        "            # Discriminator forward pass\n",
        "            if self.condition:\n",
        "                embedded_labels = self.label_embedding(labels)\n",
        "                image_labels = embedded_labels.view(embedded_labels.size(0), self.label_embedding.embedding_dim, 1, 1).expand(-1, -1, self.img_size, self.img_size)\n",
        "                x = torch.cat((input, image_labels), dim=1)\n",
        "            else:\n",
        "                x = input\n",
        "            return self.discriminator(x)\n",
        "\n",
        "    def loss(self, output, label):\n",
        "        return self.adv_loss(output, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c52363e9",
      "metadata": {
        "id": "c52363e9"
      },
      "outputs": [],
      "source": [
        "class F2U_GAN_CIFAR(nn.Module):\n",
        "    def __init__(self, img_size=32, latent_dim=128, condition=True, seed=None):\n",
        "        if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "        super(F2U_GAN_CIFAR, self).__init__()\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.classes = 10\n",
        "        self.channels = 3\n",
        "        self.condition = condition\n",
        "\n",
        "        # Embedding para condicionamento\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes) if self.condition else None\n",
        "\n",
        "        # Shapes de entrada\n",
        "        self.input_shape_gen = self.latent_dim + (self.classes if self.condition else 0)\n",
        "        self.input_shape_disc = self.channels + (self.classes if self.condition else 0)\n",
        "\n",
        "        # -----------------\n",
        "        #  Generator\n",
        "        # -----------------\n",
        "        self.generator = nn.Sequential(\n",
        "            nn.Linear(self.input_shape_gen, 512 * 4 * 4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Unflatten(1, (512, 4, 4)),                  # → (512,4,4)\n",
        "\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),  # → (256,8,8)\n",
        "            nn.BatchNorm2d(256, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # → (128,16,16)\n",
        "            nn.BatchNorm2d(128, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(128,  64, kernel_size=4, stride=2, padding=1),  # → ( 64,32,32)\n",
        "            nn.BatchNorm2d(64,  momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d( 64,   self.channels, kernel_size=3, stride=1, padding=1),  # → (3,32,32)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # -----------------\n",
        "        #  Discriminator\n",
        "        # -----------------\n",
        "        layers = []\n",
        "        in_ch = self.input_shape_disc\n",
        "        cfg = [\n",
        "            ( 64, 3, 1),  # → spatial stays 32\n",
        "            ( 64, 4, 2),  # → 16\n",
        "            (128, 3, 1),  # → 16\n",
        "            (128, 4, 2),  # → 8\n",
        "            (256, 4, 2),  # → 4\n",
        "        ]\n",
        "        for out_ch, k, s in cfg:\n",
        "            layers += [\n",
        "                nn.utils.spectral_norm(\n",
        "                    nn.Conv2d(in_ch, out_ch, kernel_size=k, stride=s, padding=1)\n",
        "                ),\n",
        "                nn.LeakyReLU(0.1, inplace=True)\n",
        "            ]\n",
        "            in_ch = out_ch\n",
        "\n",
        "        layers += [\n",
        "            nn.Flatten(),\n",
        "            nn.utils.spectral_norm(\n",
        "                nn.Linear(256 * 4 * 4, 1)\n",
        "            )\n",
        "        ]\n",
        "        self.discriminator = nn.Sequential(*layers)\n",
        "\n",
        "        # adversarial loss\n",
        "        self.adv_loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, input, labels=None):\n",
        "        # Generator pass\n",
        "        if input.dim() == 2 and input.size(1) == self.latent_dim:\n",
        "            if self.condition:\n",
        "                if labels is None:\n",
        "                    raise ValueError(\"Labels must be provided for conditional generation\")\n",
        "                embedded = self.label_embedding(labels)\n",
        "                gen_input = torch.cat((input, embedded), dim=1)\n",
        "            else:\n",
        "                gen_input = input\n",
        "            img = self.generator(gen_input)\n",
        "            return img\n",
        "\n",
        "        # Discriminator pass\n",
        "        elif input.dim() == 4 and input.size(1) == self.channels:\n",
        "            x = input\n",
        "            if self.condition:\n",
        "                if labels is None:\n",
        "                    raise ValueError(\"Labels must be provided for conditional discrimination\")\n",
        "                embedded = self.label_embedding(labels)\n",
        "                # criar mapa de labels e concatenar\n",
        "                lbl_map = embedded.view(-1, self.classes, 1, 1).expand(-1, self.classes, self.img_size, self.img_size)\n",
        "                x = torch.cat((x, lbl_map), dim=1)\n",
        "            return self.discriminator(x)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Input shape not recognized\")\n",
        "\n",
        "    def loss(self, logits, targets):\n",
        "        return self.adv_loss(logits.view(-1), targets.float().view(-1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "144a24f4",
      "metadata": {
        "id": "144a24f4"
      },
      "source": [
        "## Funções para geração de dataset e imagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3487d31",
      "metadata": {
        "id": "b3487d31"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn.functional as F\n",
        "import random # Needed for handling remainders if samples aren't perfectly divisible\n",
        "\n",
        "class GeneratedDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 generator,\n",
        "                 num_samples,\n",
        "                 latent_dim=100,\n",
        "                 num_classes=10, # Total classes the generator model knows\n",
        "                 desired_classes=None, # Optional: List of specific class indices to generate\n",
        "                 device=\"cpu\",\n",
        "                 image_col_name=\"image\",\n",
        "                 label_col_name=\"label\"):\n",
        "        \"\"\"\n",
        "        Generates a dataset using a conditional generative model, potentially\n",
        "        focusing on a subset of classes.\n",
        "\n",
        "        Args:\n",
        "            generator: The pre-trained generative model.\n",
        "            num_samples (int): Total number of images to generate across the desired classes.\n",
        "            latent_dim (int): Dimension of the latent space vector (z).\n",
        "            num_classes (int): The total number of classes the generator was trained on.\n",
        "                               This is crucial for correct label conditioning (e.g., one-hot dim).\n",
        "            desired_classes (list[int], optional): A list of integer class indices to generate.\n",
        "                                                  If None or empty, images for all classes\n",
        "                                                  (from 0 to num_classes-1) will be generated,\n",
        "                                                  distributed as evenly as possible.\n",
        "                                                  Defaults to None.\n",
        "            device (str): Device to run generation on ('cpu' or 'cuda').\n",
        "            image_col_name (str): Name for the image column in the output dictionary.\n",
        "            label_col_name (str): Name for the label column in the output dictionary.\n",
        "        \"\"\"\n",
        "        self.generator = generator\n",
        "        self.num_samples = num_samples\n",
        "        self.latent_dim = latent_dim\n",
        "        # Store the total number of classes the generator understands\n",
        "        self.total_num_classes = num_classes\n",
        "        self.device = device\n",
        "        self.model_type = type(self.generator).__name__ # Get generator class name\n",
        "        self.image_col_name = image_col_name\n",
        "        self.label_col_name = label_col_name\n",
        "\n",
        "        # Determine the actual classes to generate based on desired_classes\n",
        "        if desired_classes is not None and len(desired_classes) > 0:\n",
        "            # Validate that desired classes are within the generator's known range\n",
        "            if not all(0 <= c < self.total_num_classes for c in desired_classes):\n",
        "                raise ValueError(f\"All desired classes must be integers between 0 and {self.total_num_classes - 1}\")\n",
        "            # Use only the unique desired classes, sorted for consistency\n",
        "            self._actual_classes_to_generate = sorted(list(set(desired_classes)))\n",
        "        else:\n",
        "            # If no specific classes desired, generate all classes\n",
        "            self._actual_classes_to_generate = list(range(self.total_num_classes))\n",
        "\n",
        "        # The 'classes' attribute of the dataset reflects only those generated\n",
        "        self.classes = self._actual_classes_to_generate\n",
        "        self.num_generated_classes = len(self.classes) # Number of classes being generated\n",
        "\n",
        "        if self.num_generated_classes == 0 and self.num_samples > 0:\n",
        "             raise ValueError(\"Cannot generate samples with an empty list of desired classes.\")\n",
        "        elif self.num_samples == 0:\n",
        "             print(\"Warning: num_samples is 0. Dataset will be empty.\")\n",
        "             self.images = torch.empty(0) # Adjust shape if known\n",
        "             self.labels = torch.empty(0, dtype=torch.long)\n",
        "        else:\n",
        "             # Generate the data only if needed\n",
        "             self.images, self.labels = self.generate_data()\n",
        "\n",
        "\n",
        "    def generate_data(self):\n",
        "        \"\"\"Generates images and corresponding labels for the specified classes.\"\"\"\n",
        "        self.generator.eval()\n",
        "        self.generator.to(self.device)\n",
        "\n",
        "        # --- Create Labels ---\n",
        "        generated_labels_list = []\n",
        "        if self.num_generated_classes > 0:\n",
        "            # Distribute samples as evenly as possible among the desired classes\n",
        "            samples_per_class = self.num_samples // self.num_generated_classes\n",
        "            for cls in self._actual_classes_to_generate:\n",
        "                generated_labels_list.extend([cls] * samples_per_class)\n",
        "\n",
        "            # Handle remaining samples if num_samples is not perfectly divisible\n",
        "            num_remaining = self.num_samples - len(generated_labels_list)\n",
        "            if num_remaining > 0:\n",
        "                # Add remaining samples by randomly choosing from the desired classes\n",
        "                remainder_labels = random.choices(self._actual_classes_to_generate, k=num_remaining)\n",
        "                generated_labels_list.extend(remainder_labels)\n",
        "\n",
        "            # Shuffle labels for better distribution in batches later\n",
        "            random.shuffle(generated_labels_list)\n",
        "\n",
        "        # Convert labels list to tensor\n",
        "        labels = torch.tensor(generated_labels_list, dtype=torch.long, device=self.device)\n",
        "\n",
        "        # Double check label count (should match num_samples due to logic above)\n",
        "        if len(labels) != self.num_samples:\n",
        "             # This indicates an unexpected issue, potentially if num_generated_classes was 0 initially\n",
        "             # but num_samples > 0. Raise error or adjust. Let's adjust defensively.\n",
        "             print(f\"Warning: Label count mismatch. Expected {self.num_samples}, got {len(labels)}. Adjusting size.\")\n",
        "             if len(labels) > self.num_samples:\n",
        "                 labels = labels[:self.num_samples]\n",
        "             else:\n",
        "                 # Pad if too few (less likely with current logic unless num_generated_classes=0)\n",
        "                 num_needed = self.num_samples - len(labels)\n",
        "                 if self.num_generated_classes > 0:\n",
        "                      padding = torch.tensor(random.choices(self._actual_classes_to_generate, k=num_needed), dtype=torch.long, device=self.device)\n",
        "                      labels = torch.cat((labels, padding))\n",
        "                 # If no classes to generate from, labels tensor might remain smaller\n",
        "\n",
        "        # --- Create Latent Noise ---\n",
        "        z = torch.randn(self.num_samples, self.latent_dim, device=self.device)\n",
        "\n",
        "        # --- Generate Images in Batches ---\n",
        "        generated_images_list = []\n",
        "        # Consider making batch_size configurable\n",
        "        batch_size = min(1024, self.num_samples) if self.num_samples > 0 else 1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, self.num_samples, batch_size):\n",
        "                z_batch = z[i : min(i + batch_size, self.num_samples)]\n",
        "                labels_batch = labels[i : min(i + batch_size, self.num_samples)]\n",
        "\n",
        "                # Skip if batch is empty (can happen if num_samples = 0)\n",
        "                if z_batch.shape[0] == 0:\n",
        "                    continue\n",
        "\n",
        "                # --- Condition the generator based on its type ---\n",
        "                if self.model_type == 'Generator': # Assumes input: concat(z, one_hot_label)\n",
        "                    # One-hot encode labels using the TOTAL number of classes the generator knows\n",
        "                    labels_one_hot_batch = F.one_hot(labels_batch, num_classes=self.total_num_classes).float()\n",
        "                    generator_input = torch.cat([z_batch, labels_one_hot_batch], dim=1)\n",
        "                    gen_imgs = self.generator(generator_input)\n",
        "                elif self.model_type in ('CGAN', 'F2U_GAN', 'F2U_GAN_CIFAR'): # Assumes input: z, label_index\n",
        "                    gen_imgs = self.generator(z_batch, labels_batch)\n",
        "                else:\n",
        "                    # Handle other potential generator architectures or raise an error\n",
        "                    raise NotImplementedError(f\"Generation logic not defined for model type: {self.model_type}\")\n",
        "\n",
        "                generated_images_list.append(gen_imgs.cpu()) # Move generated images to CPU\n",
        "\n",
        "        self.generator.cpu() # Move generator back to CPU after generation\n",
        "\n",
        "        # Concatenate all generated image batches\n",
        "        if generated_images_list:\n",
        "            all_gen_imgs = torch.cat(generated_images_list, dim=0)\n",
        "        else:\n",
        "            # If no images were generated (e.g., num_samples = 0)\n",
        "            # Create an empty tensor. Shape needs care - determine from generator or use placeholder.\n",
        "            # Let's attempt a placeholder [0, C, H, W] - requires knowing C, H, W.\n",
        "            # For now, a simple empty tensor. User might need to handle this downstream.\n",
        "            print(\"Warning: No images generated. Returning empty tensor for images.\")\n",
        "            all_gen_imgs = torch.empty(0)\n",
        "\n",
        "        return all_gen_imgs, labels.cpu() # Return images and labels (on CPU)\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the actual number of samples generated\n",
        "        return self.images.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= len(self):\n",
        "            raise IndexError(\"Dataset index out of range\")\n",
        "        return {\n",
        "            self.image_col_name: self.images[idx],\n",
        "            self.label_col_name: int(self.labels[idx]) # Return label as standard Python int\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1c3d341",
      "metadata": {
        "id": "b1c3d341"
      },
      "outputs": [],
      "source": [
        "class UnconditionalGeneratedDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 generator,\n",
        "                 num_samples,\n",
        "                 latent_dim=128,\n",
        "                 device=\"cpu\",\n",
        "                 image_col_name=\"image\"):\n",
        "        \"\"\"\n",
        "        Generates a dataset using an unconditional generative model.\n",
        "\n",
        "        Args:\n",
        "            generator: The pre-trained unconditional generative model.\n",
        "            num_samples (int): Total number of images to generate.\n",
        "            latent_dim (int): Dimension of the latent space vector (z).\n",
        "            device (str): Device to run generation on ('cpu' or 'cuda').\n",
        "            image_col_name (str): Name for the image column in the output dictionary.\n",
        "        \"\"\"\n",
        "        self.generator = generator\n",
        "        self.num_samples = num_samples\n",
        "        self.latent_dim = latent_dim\n",
        "        self.device = device\n",
        "        self.image_col_name = image_col_name\n",
        "\n",
        "        if self.num_samples < 0:\n",
        "            raise ValueError(\"num_samples must be non-negative\")\n",
        "        elif self.num_samples == 0:\n",
        "            print(\"Warning: num_samples is 0. Dataset will be empty.\")\n",
        "            self.images = torch.empty(0)\n",
        "        else:\n",
        "            self.images = self._generate_images()\n",
        "\n",
        "    def _generate_images(self):\n",
        "        self.generator.eval()\n",
        "        self.generator.to(self.device)\n",
        "\n",
        "        # Create latent noise\n",
        "        z = torch.randn(self.num_samples, self.latent_dim, device=self.device)\n",
        "\n",
        "        # Generate images in batches\n",
        "        generated_images = []\n",
        "        batch_size = min(1024, self.num_samples)\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, self.num_samples, batch_size):\n",
        "                z_batch = z[i : min(i + batch_size, self.num_samples)]\n",
        "                gen_imgs = self.generator(z_batch)\n",
        "                generated_images.append(gen_imgs.cpu())\n",
        "\n",
        "        self.generator.cpu()\n",
        "        return torch.cat(generated_images, dim=0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= len(self):\n",
        "            raise IndexError(\"Dataset index out of range\")\n",
        "        return { self.image_col_name: self.images[idx] }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9452cf54",
      "metadata": {
        "id": "9452cf54"
      },
      "outputs": [],
      "source": [
        "def generate_plot(net, device, round_number, client_id = None, examples_per_class: int=5, classes: int=10, latent_dim: int=100):\n",
        "    \"\"\"Gera plot de imagens de cada classe\"\"\"\n",
        "\n",
        "    net_type = type(net).__name__\n",
        "    net.to(device)\n",
        "    net.eval()\n",
        "    batch_size = examples_per_class * classes\n",
        "    dataset = \"mnist\" if  not net_type == \"F2U_GAN_CIFAR\" else \"cifar10\"\n",
        "\n",
        "    latent_vectors = torch.randn(batch_size, latent_dim, device=device)\n",
        "    labels = torch.tensor([i for i in range(classes) for _ in range(examples_per_class)], device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if net_type == \"Generator\":\n",
        "            labels_one_hot = torch.nn.functional.one_hot(labels, 10).float().to(device)\n",
        "            generated_images = net(torch.cat([latent_vectors, labels_one_hot], dim=1))\n",
        "        else:\n",
        "            generated_images = net(latent_vectors, labels)\n",
        "\n",
        "    # Criar uma figura com 10 linhas e 5 colunas de subplots\n",
        "    fig, axes = plt.subplots(classes, examples_per_class, figsize=(5, 9))\n",
        "\n",
        "    # Adiciona título no topo da figura\n",
        "    if isinstance(client_id, int):\n",
        "        fig.text(0.5, 0.98, f\"Round: {round_number} | Client: {client_id}\", ha=\"center\", fontsize=12)\n",
        "    else:\n",
        "        fig.text(0.5, 0.98, f\"Round: {round_number}\", ha=\"center\", fontsize=12)\n",
        "\n",
        "    # Exibir as imagens nos subplots\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if dataset == \"mnist\":\n",
        "            ax.imshow(generated_images[i, 0, :, :], cmap='gray')\n",
        "        else:\n",
        "            images = (generated_images[i] + 1)/2\n",
        "            ax.imshow(images.permute(1, 2, 0).clamp(0,1))\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "    # Ajustar o layout antes de calcular as posições\n",
        "    plt.tight_layout(rect=[0.05, 0, 1, 0.96])\n",
        "\n",
        "    # Reduzir espaço entre colunas\n",
        "    # plt.subplots_adjust(wspace=0.05)\n",
        "\n",
        "    # Adicionar os rótulos das classes corretamente alinhados\n",
        "    fig.canvas.draw()  # Atualiza a renderização para obter posições corretas\n",
        "    for row in range(classes):\n",
        "        # Obter posição do subplot em coordenadas da figura\n",
        "        bbox = axes[row, 0].get_window_extent(fig.canvas.get_renderer())\n",
        "        pos = fig.transFigure.inverted().transform([(bbox.x0, bbox.y0), (bbox.x1, bbox.y1)])\n",
        "        center_y = (pos[0, 1] + pos[1, 1]) / 2  # Centro exato da linha\n",
        "\n",
        "        # Adicionar o rótulo\n",
        "        fig.text(0.04, center_y, str(row), va='center', fontsize=12, color='black')\n",
        "\n",
        "    IN_COLAB = False\n",
        "    try:\n",
        "        # Tenta importar um módulo específico do Colab\n",
        "        import google.colab\n",
        "        IN_COLAB = True\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    if IN_COLAB:\n",
        "        if isinstance(client_id, int):\n",
        "            fig.savefig(os.path.join(save_dir, f\"{dataset}_{net_type}_r{round_number}_c{client_id}.png\"))\n",
        "            print(\"Imagem do cliente salva no drive\")\n",
        "        else:\n",
        "            fig.savefig(os.path.join(save_dir, f\"{dataset}{net_type}_r{round_number}.png\"))\n",
        "            print(\"Imagem do servidor salva no drive\")\n",
        "    else:\n",
        "        if isinstance(client_id, int):\n",
        "            fig.savefig(f\"{dataset}{net_type}_r{round_number}_c{client_id}.png\")\n",
        "            print(\"Imagem do cliente salva\")\n",
        "        else:\n",
        "            fig.savefig(f\"{dataset}{net_type}_r{round_number}.png\")\n",
        "            print(\"Imagem do servidor salva\")\n",
        "    plt.close(fig)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a88e7c6",
      "metadata": {
        "id": "3a88e7c6"
      },
      "outputs": [],
      "source": [
        "def plot_unconditional_generated(\n",
        "        generator,\n",
        "        device,\n",
        "        total_samples,\n",
        "        samples_per_row=5,\n",
        "        latent_dim=100,\n",
        "        save_path=None,\n",
        "        round_number=None):\n",
        "    \"\"\"\n",
        "    Generates and plots images from an unconditional generator in a grid.\n",
        "\n",
        "    Args:\n",
        "        generator: The unconditional torch generator model (z -> image).\n",
        "        device: Device to run generation on ('cpu' or 'cuda').\n",
        "        total_samples (int): Number of images to generate.\n",
        "        samples_per_row (int): Number of images per row in the grid.\n",
        "        latent_dim (int): Dimension of latent vector.\n",
        "        save_path (str, optional): Filepath to save the figure. If None, just shows plot.\n",
        "    \"\"\"\n",
        "\n",
        "    generator.eval()\n",
        "    generator.to(device)\n",
        "\n",
        "    # Sample latent vectors\n",
        "    z = torch.randn(total_samples, latent_dim, device=device)\n",
        "    with torch.no_grad():\n",
        "        imgs = generator(z)\n",
        "\n",
        "    # Determine grid size\n",
        "    cols = samples_per_row\n",
        "    rows = math.ceil(total_samples / cols)\n",
        "\n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(cols-2*cols/(rows+cols), rows-1*rows/(rows+cols)))\n",
        "    axes = axes.flatten() if total_samples > 1 else [axes]\n",
        "\n",
        "    fig.text(0.5, 0.99, f\"Round: {round_number}\", ha=\"center\", fontsize=11)\n",
        "\n",
        "    for idx in range(rows * cols):\n",
        "        ax = axes[idx]\n",
        "        ax.axis('off')\n",
        "        if idx < total_samples:\n",
        "            img = imgs[idx]\n",
        "            # Assume (C, H, W) and single-channel\n",
        "            ax.imshow(img[0], cmap='gray')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "        fig.savefig(save_path)\n",
        "        print(f\"Figure saved to {save_path}\")\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "    plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bd1a6ff",
      "metadata": {
        "id": "5bd1a6ff"
      },
      "source": [
        "## Importa Pacotes Federado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e7c02c2",
      "metadata": {
        "id": "3e7c02c2"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    !pip install flwr_datasets\n",
        "    !pip install flwr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9793cd9a",
      "metadata": {
        "id": "9793cd9a"
      },
      "outputs": [],
      "source": [
        "from flwr_datasets.partitioner import DirichletPartitioner, IidPartitioner\n",
        "from flwr_datasets.visualization import plot_label_distributions\n",
        "from flwr_datasets import FederatedDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5ac2e55",
      "metadata": {
        "id": "a5ac2e55"
      },
      "source": [
        "## Particionador por classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3acd60f5",
      "metadata": {
        "id": "3acd60f5"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Flower Labs GmbH. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Class-based partitioner for Hugging Face Datasets.\"\"\"\n",
        "\n",
        "\n",
        "from collections import defaultdict\n",
        "import random\n",
        "from typing import Optional, List\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from flwr_datasets.partitioner.partitioner import Partitioner  # Assuming this is in the package structure\n",
        "\n",
        "\n",
        "class ClassPartitioner(Partitioner):\n",
        "    \"\"\"Partitions a dataset by class, ensuring each class appears in exactly one partition.\n",
        "\n",
        "    Attributes:\n",
        "        num_partitions (int): Total number of partitions to create\n",
        "        seed (int, optional): Random seed for reproducibility\n",
        "        label_column (str): Name of the column containing class labels\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_partitions: int,\n",
        "        seed: Optional[int] = None,\n",
        "        label_column: str = \"label\"\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self._num_partitions = num_partitions\n",
        "        self._seed = seed\n",
        "        self._label_column = label_column\n",
        "        self._partition_indices: Optional[List[List[int]]] = None\n",
        "\n",
        "    def _create_partitions(self) -> None:\n",
        "        \"\"\"Create class-based partitions and store indices.\"\"\"\n",
        "        # Extract labels from dataset\n",
        "        labels = self.dataset[self._label_column]\n",
        "\n",
        "        # Group indices by class\n",
        "        class_indices = defaultdict(list)\n",
        "        for idx, label in enumerate(labels):\n",
        "            class_indices[label].append(idx)\n",
        "\n",
        "        classes = list(class_indices.keys())\n",
        "        num_classes = len(classes)\n",
        "\n",
        "        # Validate number of partitions\n",
        "        if self._num_partitions > num_classes:\n",
        "            raise ValueError(\n",
        "                f\"Cannot create {self._num_partitions} partitions with only {num_classes} classes. \"\n",
        "                f\"Reduce partitions to ≤ {num_classes}.\"\n",
        "            )\n",
        "\n",
        "        # Shuffle classes for random distribution\n",
        "        rng = random.Random(self._seed)\n",
        "        rng.shuffle(classes)\n",
        "\n",
        "        # Split classes into partitions\n",
        "        partition_classes = np.array_split(classes, self._num_partitions)\n",
        "\n",
        "        # Create index lists for each partition\n",
        "        self._partition_indices = []\n",
        "        for class_group in partition_classes:\n",
        "            indices = []\n",
        "            for cls in class_group:\n",
        "                indices.extend(class_indices[cls])\n",
        "            self._partition_indices.append(indices)\n",
        "\n",
        "    @property\n",
        "    def dataset(self) -> Dataset:\n",
        "        return super().dataset\n",
        "\n",
        "    @dataset.setter\n",
        "    def dataset(self, value: Dataset) -> None:\n",
        "        # Use parent setter for basic validation\n",
        "        super(ClassPartitioner, ClassPartitioner).dataset.fset(self, value)\n",
        "\n",
        "        # Create partitions once dataset is set\n",
        "        self._create_partitions()\n",
        "\n",
        "    def load_partition(self, partition_id: int) -> Dataset:\n",
        "        \"\"\"Load a partition containing exclusive classes.\n",
        "\n",
        "        Args:\n",
        "            partition_id: The ID of the partition to load (0-based index)\n",
        "\n",
        "        Returns:\n",
        "            Dataset: Subset of the dataset containing only the specified partition's data\n",
        "        \"\"\"\n",
        "        if not self.is_dataset_assigned():\n",
        "            raise RuntimeError(\"Dataset must be assigned before loading partitions\")\n",
        "        if partition_id < 0 or partition_id >= self.num_partitions:\n",
        "            raise ValueError(f\"Invalid partition ID: {partition_id}\")\n",
        "\n",
        "        return self.dataset.select(self._partition_indices[partition_id])\n",
        "\n",
        "    @property\n",
        "    def num_partitions(self) -> int:\n",
        "        return self._num_partitions\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f\"ClassPartitioner(num_partitions={self._num_partitions}, \"\n",
        "                f\"seed={self._seed}, label_column='{self._label_column}')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1ee55f5",
      "metadata": {
        "id": "a1ee55f5"
      },
      "source": [
        "## Carrega e divide dados entre clientes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6fdba10d",
      "metadata": {
        "id": "6fdba10d"
      },
      "outputs": [],
      "source": [
        "num_partitions = 4\n",
        "alpha_dir = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cd9c472",
      "metadata": {
        "id": "6cd9c472"
      },
      "source": [
        "Rodar somente o particionador desejado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42644935",
      "metadata": {
        "id": "42644935"
      },
      "outputs": [],
      "source": [
        "partitioner = ClassPartitioner(num_partitions=num_partitions, seed=42, label_column=\"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "312626b5",
      "metadata": {
        "id": "312626b5"
      },
      "outputs": [],
      "source": [
        "partitioner = DirichletPartitioner(\n",
        "    num_partitions=num_partitions,\n",
        "    partition_by=\"label\",\n",
        "    alpha=alpha_dir,\n",
        "    min_partition_size=0,\n",
        "    self_balancing=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8582a179",
      "metadata": {
        "id": "8582a179"
      },
      "outputs": [],
      "source": [
        "partitioner = IidPartitioner(\n",
        "    num_partitions=num_partitions\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3f9a435",
      "metadata": {
        "id": "a3f9a435"
      },
      "outputs": [],
      "source": [
        "fds = FederatedDataset(\n",
        "    dataset=\"mnist\",\n",
        "    partitioners={\"train\": partitioner}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d21553c",
      "metadata": {
        "id": "7d21553c"
      },
      "outputs": [],
      "source": [
        "fds = FederatedDataset(\n",
        "    dataset=\"cifar10\",\n",
        "    partitioners={\"train\": partitioner}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "026da6c7",
      "metadata": {
        "id": "026da6c7"
      },
      "outputs": [],
      "source": [
        "partitioner = fds.partitioners[\"train\"]\n",
        "figure, axis, dataframe = plot_label_distributions(\n",
        "    partitioner=partitioner,\n",
        "    label_name=\"label\",\n",
        "    title=\"Per Partition Label Distribution\",\n",
        "    legend=True,\n",
        "    verbose_labels=True,\n",
        "    size_unit=\"absolute\",\n",
        "    partition_id_axis=\"x\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93ff7171",
      "metadata": {
        "id": "93ff7171"
      },
      "outputs": [],
      "source": [
        "train_partitions = [fds.load_partition(i, split=\"train\") for i in range(num_partitions)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j-L_He1Qvz0e",
      "metadata": {
        "id": "j-L_He1Qvz0e"
      },
      "source": [
        "Rodar proxima celula somente se quiser testar com dataset reduzido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w2n6dMxcvx2k",
      "metadata": {
        "id": "w2n6dMxcvx2k"
      },
      "outputs": [],
      "source": [
        "# num_samples = [int(len(train_partition)/10) for train_partition in train_partitions]\n",
        "# train_partitions = [train_partition.select(range(n)) for train_partition, n in zip(train_partitions, num_samples)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1b7cf8f",
      "metadata": {
        "id": "d1b7cf8f"
      },
      "source": [
        "Cria dicionario de label para cliente para controle do dmax_mismatch. Tive que colocar aqui antes do apply_transform para não dar erro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e07fdcb9",
      "metadata": {
        "id": "e07fdcb9"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b106654b",
      "metadata": {
        "id": "b106654b"
      },
      "outputs": [],
      "source": [
        "min_lbl_count = 0.05\n",
        "class_labels = train_partitions[0].info.features[\"label\"]\n",
        "labels_str = class_labels.names\n",
        "label_to_client = {lbl: [] for lbl in labels_str}\n",
        "for idx, ds in enumerate(train_partitions):\n",
        "    counts = Counter(ds['label'])\n",
        "    for label, cnt in counts.items():\n",
        "        if cnt / len(ds) >= min_lbl_count:\n",
        "            label_to_client[class_labels.int2str(label)].append(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56dcbb9b",
      "metadata": {
        "id": "56dcbb9b"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Compose, ToTensor, Normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df48b029",
      "metadata": {
        "id": "df48b029"
      },
      "outputs": [],
      "source": [
        "pytorch_transforms = Compose([\n",
        "    ToTensor(),\n",
        "    Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "def apply_transforms(batch):\n",
        "    batch[\"image\"] = [pytorch_transforms(img) for img in batch[\"image\"]]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbbc667a",
      "metadata": {
        "id": "cbbc667a"
      },
      "outputs": [],
      "source": [
        "# Para CIFAR-10: 3 canais, normalização média=0.5 e std=0.5\n",
        "pytorch_transforms = Compose([\n",
        "    ToTensor(),\n",
        "    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "def apply_transforms(batch):\n",
        "    # batch[\"image\"] é uma lista de PIL.Image ou tensores em H×W×C\n",
        "    # aplicamos o mesmo transform a cada imagem e depois empilhamos\n",
        "    batch[\"img\"] = torch.stack([pytorch_transforms(img) for img in batch[\"img\"]])\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34de09aa",
      "metadata": {
        "id": "34de09aa"
      },
      "outputs": [],
      "source": [
        "train_partitions = [train_partition.with_transform(apply_transforms) for train_partition in train_partitions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MwJAQ213fi-w",
      "metadata": {
        "id": "MwJAQ213fi-w"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CuBEfRZ6fX8i",
      "metadata": {
        "id": "CuBEfRZ6fX8i"
      },
      "outputs": [],
      "source": [
        "test_frac = 0.2\n",
        "client_datasets = []\n",
        "\n",
        "for train_part in train_partitions:\n",
        "    total     = len(train_part)\n",
        "    test_size = int(total * test_frac)\n",
        "    train_size = total - test_size\n",
        "\n",
        "    client_train, client_test = random_split(\n",
        "        train_part,\n",
        "        [train_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42),\n",
        "    )\n",
        "\n",
        "    client_datasets.append({\n",
        "        \"train\": client_train,\n",
        "        \"test\":  client_test,\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0ae0635",
      "metadata": {
        "id": "b0ae0635"
      },
      "source": [
        "## Inicializa modelos e otimizadores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1b818e92",
      "metadata": {
        "id": "1b818e92"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5be9636",
      "metadata": {
        "id": "b5be9636"
      },
      "source": [
        "Rodar somente o modelo desejado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e76e482",
      "metadata": {
        "id": "8e76e482"
      },
      "outputs": [],
      "source": [
        "models = [CGAN() for i in range(num_partitions)]\n",
        "gen = CGAN().to(device)\n",
        "optim_G = torch.optim.Adam(gen.generator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "70debb0f",
      "metadata": {
        "id": "70debb0f"
      },
      "outputs": [],
      "source": [
        "models = [F2U_GAN(condition=True, seed=42) for i in range(num_partitions)]\n",
        "gen = F2U_GAN(condition=True, seed=42).to(device)\n",
        "optim_G = torch.optim.Adam(gen.generator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a813dfe",
      "metadata": {
        "id": "9a813dfe"
      },
      "outputs": [],
      "source": [
        "models = [F2U_GAN_CIFAR(condition=True, seed=42) for i in range(num_partitions)]\n",
        "gen = F2U_GAN_CIFAR(condition=True, seed=42).to(device)\n",
        "optim_G = torch.optim.Adam(gen.generator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70f37272",
      "metadata": {
        "id": "70f37272"
      },
      "outputs": [],
      "source": [
        "optim_Ds = [\n",
        "    torch.optim.Adam(model.discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    for model in models\n",
        "]\n",
        "\n",
        "# scheduler_D = torch.optim.lr_scheduler.StepLR(optim_D, step_size=5, gamma=0.9)\n",
        "# scheduler_G = torch.optim.lr_scheduler.StepLR(optim_G, step_size=5, gamma=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e08c26a0",
      "metadata": {
        "id": "e08c26a0"
      },
      "source": [
        "Inicializa lambda para F2A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "893b45d4",
      "metadata": {
        "id": "893b45d4"
      },
      "outputs": [],
      "source": [
        "# initial λ* (unconstrained), wrap with ReLU to keep λ ≥ 0\n",
        "lambda_star = nn.Parameter(torch.tensor(0.1, device=device))\n",
        "relu = nn.ReLU()\n",
        "\n",
        "beta = 0.1  # same β as in the paper\n",
        "\n",
        "# now make your generator optimizer also update lambda_star\n",
        "# (so its gradient from the βλ² term can flow)\n",
        "optim_G = torch.optim.Adam(\n",
        "    list(gen.parameters()) + [lambda_star],\n",
        "    lr=2e-4, betas=(0.5, 0.999)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a3a7e9e",
      "metadata": {
        "id": "7a3a7e9e"
      },
      "source": [
        "# Treinamento dos modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b38a6962",
      "metadata": {
        "id": "b38a6962"
      },
      "source": [
        "## Cria chunks para o treinamento alternado entre discriminadora e geradora ser mais constante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b5d8adc",
      "metadata": {
        "id": "9b5d8adc"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2505ab00",
      "metadata": {
        "id": "2505ab00"
      },
      "source": [
        "Quanto menos chunks, mais dados em cada chunk e mais dados são treinados na discriminadora antes de treinar a geradora. No paper do F2U, não está claro como os treinamentos são alternados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FTvOVoSLVpta",
      "metadata": {
        "id": "FTvOVoSLVpta"
      },
      "outputs": [],
      "source": [
        "# prompt: set each train partition as the only first minimum lenght of the partitions samples, the partitions have same lenght\n",
        "\n",
        "min_len = min(len(p) for p in train_partitions)\n",
        "train_partitions = [p.select(range(min_len)) for p in train_partitions]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CVz-ThoCVfoh",
      "metadata": {
        "id": "CVz-ThoCVfoh"
      },
      "outputs": [],
      "source": [
        "for train_partition in train_partitions:\n",
        "  print(len(train_partition))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff747284",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_chunks = 100\n",
        "seed = 42  # escolha qualquer inteiro para reprodutibilidade\n",
        "client_chunks = []\n",
        "\n",
        "for train_partition in client_datasets:\n",
        "    dataset = train_partition[\"train\"]\n",
        "    n = len(dataset)\n",
        "\n",
        "    # 1) embaralha os índices com seed fixa\n",
        "    indices = list(range(n))\n",
        "    random.seed(seed)\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    # 2) calcula tamanho aproximado de cada chunk\n",
        "    chunk_size = math.ceil(n / num_chunks)\n",
        "\n",
        "    # 3) divide em chunks usando fatias dos índices embaralhados\n",
        "    chunks = []\n",
        "    for i in range(num_chunks):\n",
        "        start = i * chunk_size\n",
        "        end = min((i + 1) * chunk_size, n)\n",
        "        chunk_indices = indices[start:end]\n",
        "        chunks.append(Subset(dataset, chunk_indices))\n",
        "\n",
        "    client_chunks.append(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o6WJTKp6B5vD",
      "metadata": {
        "id": "o6WJTKp6B5vD"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "client_test_loaders = [DataLoader(dataset=ds[\"test\"], batch_size=batch_size, shuffle=True) for ds in client_datasets]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ab8d65e",
      "metadata": {
        "id": "4ab8d65e"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "e70bd3c8",
      "metadata": {
        "id": "e70bd3c8"
      },
      "outputs": [],
      "source": [
        "nets = [Net().to(device) for _ in range(num_partitions)]\n",
        "optims = [torch.optim.Adam(net.parameters(), lr=0.01) for net in nets]\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbc668cf",
      "metadata": {
        "id": "bbc668cf"
      },
      "outputs": [],
      "source": [
        "testpartition = fds.load_split(\"test\")\n",
        "testpartition = testpartition.with_transform(apply_transforms)\n",
        "testloader = DataLoader(testpartition, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e86ba4bc",
      "metadata": {
        "id": "e86ba4bc"
      },
      "source": [
        "Carregar modelo pré-treinado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d3c145b",
      "metadata": {
        "id": "3d3c145b"
      },
      "outputs": [],
      "source": [
        "global_net = Net_Cifar(42).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b66f9a29",
      "metadata": {
        "id": "b66f9a29"
      },
      "outputs": [],
      "source": [
        "checkpoint_loaded = torch.load(\"checkpoint_epoch48.pth\")\n",
        "\n",
        "global_net.load_state_dict(checkpoint_loaded['alvo_state_dict'])\n",
        "global_net.to(device)\n",
        "for optim, state in zip(optims, checkpoint_loaded['optimizer_alvo_state_dict']):\n",
        "    optim.load_state_dict(state)\n",
        "\n",
        "gen.load_state_dict(checkpoint_loaded[\"gen_state_dict\"])\n",
        "gen.to(device)\n",
        "optim_G.load_state_dict(checkpoint_loaded[\"optim_G_state_dict\"])\n",
        "\n",
        "for model, optim_d, state_model, state_optim in zip(models, optim_Ds, checkpoint_loaded[\"discs_state_dict\"], checkpoint_loaded[\"optim_Ds_state_dict:\"]):\n",
        "    model.load_state_dict(state_model)\n",
        "    model.to(device)\n",
        "    optim_d.load_state_dict(state_optim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa1265b7",
      "metadata": {
        "id": "aa1265b7"
      },
      "source": [
        "Não esquecer de reinicializar os modelos e otimizadores se for reinicializar o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d116bedf",
      "metadata": {
        "id": "d116bedf"
      },
      "outputs": [],
      "source": [
        "from flwr.server.strategy.aggregate import aggregate_inplace\n",
        "from flwr.common import FitRes, Status, Code, ndarrays_to_parameters\n",
        "from collections import OrderedDict, defaultdict\n",
        "from torch.utils.data import ConcatDataset\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1447e9f",
      "metadata": {
        "collapsed": true,
        "id": "c1447e9f"
      },
      "outputs": [],
      "source": [
        "wgan = False\n",
        "f2a = False\n",
        "epochs = 100\n",
        "losses_dict = {\"g_losses_chunk\": [],\n",
        "               \"d_losses_chunk\": [],\n",
        "               \"g_losses_round\": [],\n",
        "               \"d_losses_round\": [],\n",
        "               \"net_loss_chunk\": [],\n",
        "               \"net_acc_chunk\": [],\n",
        "               \"net_loss_round\": [],\n",
        "               \"net_acc_round\": [],\n",
        "               \"time_chunk\": [],\n",
        "               \"time_round\": []}\n",
        "\n",
        "epoch_bar = tqdm(range(0, epochs), desc=\"Treinamento\", leave=True, position=0)\n",
        "\n",
        "batch_size_gen = 1\n",
        "batch_tam = 32\n",
        "extra_g_e = 20\n",
        "latent_dim = 128\n",
        "num_classes = 10\n",
        "if type(nets[0]).__name__ == \"Net\":\n",
        "  image = \"image\"\n",
        "else:\n",
        "  image = \"img\"\n",
        "\n",
        "if IN_COLAB:\n",
        "  acc_filename = os.path.join(save_dir,\"accuracy_report.txt\")\n",
        "  loss_filename = os.path.join(save_dir, \"losses.json\")\n",
        "  dmax_mismatch_log = os.path.join(save_dir, \"dmax_mismatch.txt\")\n",
        "  lambda_log = os.path.join(save_dir, \"lambda_log.txt\")\n",
        "\n",
        "else:\n",
        "  acc_filename = \"accuracy_report.txt\"\n",
        "  loss_filename = \"losses.json\"\n",
        "  dmax_mismatch_log = \"dmax_mismatch.txt\"\n",
        "  lambda_log = \"lambda_log.txt\"\n",
        "\n",
        "for epoch in epoch_bar:\n",
        "  epoch_start_time = time.time()\n",
        "  mismatch_count = 0\n",
        "  total_checked = 0\n",
        "  g_loss_c = 0.0\n",
        "  d_loss_c = 0.0\n",
        "  total_d_samples = 0  # Amostras totais processadas pelos discriminadores\n",
        "  total_g_samples = 0  # Amostras totais processadas pelo gerador\n",
        "  params = []\n",
        "  results = []\n",
        "\n",
        "  chunk_bar = tqdm(range(num_chunks), desc=\"Chunks\", leave=True, position=1)\n",
        "\n",
        "  for chunk_idx in chunk_bar:\n",
        "    chunk_start_time = time.time()\n",
        "    # ====================================================================\n",
        "    # Treino dos Discriminadores (clientes) no bloco atual\n",
        "    # ====================================================================\n",
        "    d_loss_b = 0\n",
        "    total_chunk_samples = 0\n",
        "\n",
        "\n",
        "    client_bar = tqdm(enumerate(zip(nets, models, client_chunks)), desc=\"Clients\", leave=True, position=2)\n",
        "\n",
        "    for cliente, (net, disc, chunks) in client_bar:\n",
        "      # Carregar o bloco atual do cliente\n",
        "      chunk_dataset = chunks[chunk_idx]\n",
        "      if len(chunk_dataset) == 0:\n",
        "        print(f\"Chunk {chunk_idx} for client {cliente} is empty, skipping.\")\n",
        "        continue\n",
        "      chunk_loader = DataLoader(chunk_dataset, batch_size=batch_tam, shuffle=True)\n",
        "      if chunk_idx == 0:\n",
        "        client_eval_time = time.time()\n",
        "        # Evaluation in client test\n",
        "        # Initialize counters\n",
        "        class_correct = defaultdict(int)\n",
        "        class_total = defaultdict(int)\n",
        "        predictions_counter = defaultdict(int)\n",
        "\n",
        "        global_net.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in client_test_loaders[cliente]:\n",
        "                images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "                outputs = global_net(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Update counts for each sample in batch\n",
        "                for true_label, pred_label in zip(labels, predicted):\n",
        "                    true_idx = true_label.item()\n",
        "                    pred_idx = pred_label.item()\n",
        "\n",
        "                    class_total[true_idx] += 1\n",
        "                    predictions_counter[pred_idx] += 1\n",
        "\n",
        "                    if true_idx == pred_idx:\n",
        "                        class_correct[true_idx] += 1\n",
        "\n",
        "            # Create results dictionary\n",
        "            results_metrics = {\n",
        "                \"class_metrics\": {},\n",
        "                \"overall_accuracy\": None,\n",
        "                \"prediction_distribution\": dict(predictions_counter)\n",
        "            }\n",
        "\n",
        "            # Calculate class-wise metrics\n",
        "            for i in range(num_classes):\n",
        "                metrics = {\n",
        "                    \"samples\": class_total[i],\n",
        "                    \"predictions\": predictions_counter[i],\n",
        "                    \"accuracy\": class_correct[i] / class_total[i] if class_total[i] > 0 else \"N/A\"\n",
        "                }\n",
        "                results_metrics[\"class_metrics\"][f\"class_{i}\"] = metrics\n",
        "\n",
        "            # Calculate overall accuracy\n",
        "            total_samples = sum(class_total.values())\n",
        "            results_metrics[\"overall_accuracy\"] = sum(class_correct.values()) / total_samples\n",
        "\n",
        "            # Save to txt file\n",
        "            with open(acc_filename, \"a\") as f:\n",
        "                f.write(f\"Epoch {epoch + 1} - Client {cliente}\\n\")\n",
        "                # Header with fixed widths\n",
        "                f.write(\"{:<10} {:<10} {:<10} {:<10}\\n\".format(\n",
        "                    \"Class\", \"Accuracy\", \"Samples\", \"Predictions\"))\n",
        "                f.write(\"-\"*45 + \"\\n\")\n",
        "\n",
        "                # Class rows with consistent formatting\n",
        "                for cls in range(num_classes):\n",
        "                    metrics = results_metrics[\"class_metrics\"][f\"class_{cls}\"]\n",
        "\n",
        "                    # Format accuracy (handle \"N/A\" case)\n",
        "                    accuracy = (f\"{metrics['accuracy']:.4f}\"\n",
        "                              if isinstance(metrics['accuracy'], float)\n",
        "                              else \"  N/A  \")\n",
        "\n",
        "                    f.write(\"{:<10} {:<10} {:<10} {:<10}\\n\".format(\n",
        "                        f\"Class {cls}\",\n",
        "                        accuracy,\n",
        "                        metrics['samples'],\n",
        "                        metrics['predictions']\n",
        "                    ))\n",
        "\n",
        "                # Footer with alignment\n",
        "                f.write(\"\\n{:<20} {:.4f}\".format(\"Overall Accuracy:\", results_metrics[\"overall_accuracy\"]))\n",
        "                f.write(\"\\n{:<20} {}\".format(\"Total Samples:\", total_samples))\n",
        "                f.write(\"\\n{:<20} {}\".format(\"Total Predictions:\", sum(predictions_counter.values())))\n",
        "                f.write(\"\\n{:<20} {:.4f}\".format(\"Client Evaluation Time:\", time.time() - client_eval_time))\n",
        "                f.write(\"\\n\")\n",
        "                f.write(\"\\n\")\n",
        "\n",
        "        print(\"Results saved to accuracy_report.txt\")\n",
        "\n",
        "      # Treinar o discriminador no bloco\n",
        "      net.load_state_dict(global_net.state_dict(), strict=True)\n",
        "      net.to(device)\n",
        "      net.train()\n",
        "      disc.to(device)\n",
        "      optim = optims[cliente]\n",
        "      optim_D = optim_Ds[cliente]\n",
        "\n",
        "      num_samples = int(13 * (math.exp(0.01*epoch) - 1) / (math.exp(0.01*50) - 1)) * 10\n",
        "      generated_dataset = GeneratedDataset(generator=gen.to(\"cpu\"), num_samples=num_samples, latent_dim=latent_dim, num_classes=10, device=\"cpu\", image_col_name=image)\n",
        "      gen.to(device)\n",
        "      cmb_ds = ConcatDataset([chunk_dataset, generated_dataset])\n",
        "      \n",
        "\n",
        "      batch_bar_net = tqdm(combined_dataloader, desc=\"Batches\", leave=True, position=3)\n",
        "\n",
        "      for batch in batch_bar_net:\n",
        "        images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "        batch_size = images.size(0)\n",
        "        if batch_size == 1:\n",
        "          print(\"Batch size is 1, skipping batch\")\n",
        "          continue\n",
        "        optim.zero_grad()\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "      batch_bar = tqdm(chunk_loader, desc=\"Batches\", leave=True, position=4)\n",
        "\n",
        "      for batch in batch_bar:\n",
        "          images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "          batch_size = images.size(0)\n",
        "          if batch_size == 1:\n",
        "            print(\"Batch size is 1, skipping batch\")\n",
        "            continue\n",
        "\n",
        "          real_ident = torch.full((batch_size, 1), 1., device=device)\n",
        "          fake_ident = torch.full((batch_size, 1), 0., device=device)\n",
        "\n",
        "          z_noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "          x_fake_labels = torch.randint(0, 10, (batch_size,), device=device)\n",
        "\n",
        "          # Train D\n",
        "          optim_D.zero_grad()\n",
        "\n",
        "          if wgan:\n",
        "            labels = torch.nn.functional.one_hot(labels, 10).float().to(device)\n",
        "            x_fake_l = torch.nn.functional.one_hot(x_fake_labels, 10).float()\n",
        "\n",
        "            # Adicionar labels ao images para treinamento do Discriminador\n",
        "            image_labels = labels.view(labels.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "            image_fake_labels = x_fake_l.view(x_fake_l.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "\n",
        "            images = torch.cat([images, image_labels], dim=1)\n",
        "\n",
        "            # Treinar Discriminador\n",
        "            z = torch.cat([z_noise, x_fake_l], dim=1)\n",
        "            fake_images = gen(z).detach()\n",
        "            fake_images = torch.cat([fake_images, image_fake_labels], dim=1)\n",
        "\n",
        "            d_loss = discriminator_loss(disc(images), disc(fake_images)) + 10 * gradient_penalty(disc, images, fake_images)\n",
        "\n",
        "          else:\n",
        "            # Dados Reais\n",
        "            y_real = disc(images, labels)\n",
        "            d_real_loss = disc.loss(y_real, real_ident)\n",
        "\n",
        "            # Dados Falsos\n",
        "            x_fake = gen(z_noise, x_fake_labels).detach()\n",
        "            y_fake_d = disc(x_fake, x_fake_labels)\n",
        "            d_fake_loss = disc.loss(y_fake_d, fake_ident)\n",
        "\n",
        "            # Loss total e backprop\n",
        "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "          d_loss.backward()\n",
        "          #torch.nn.utils.clip_grad_norm_(disc.discriminator.parameters(), max_norm=1.0)\n",
        "          optim_D.step()\n",
        "          d_loss_b += d_loss.item()\n",
        "          total_chunk_samples += 1\n",
        "\n",
        "      params.append(ndarrays_to_parameters([val.cpu().numpy() for _, val in net.state_dict().items()]))\n",
        "      results.append((cliente, FitRes(status=Status(code=Code.OK, message=\"Success\"), parameters=params[cliente], num_examples=len(chunk_loader.dataset), metrics={})))\n",
        "\n",
        "    aggregated_ndarrays = aggregate_inplace(results)\n",
        "\n",
        "    params_dict = zip(global_net.state_dict().keys(), aggregated_ndarrays)\n",
        "    state_dict = OrderedDict({k: torch.tensor(v).to(device) for k, v in params_dict})\n",
        "    global_net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # Evaluation\n",
        "    if chunk_idx % 10 == 0:\n",
        "        global_net.eval()\n",
        "        correct, loss = 0, 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in testloader:\n",
        "                images = batch[image].to(device)\n",
        "                labels = batch[\"label\"].to(device)\n",
        "                outputs = global_net(images)\n",
        "                loss += criterion(outputs, labels).item()\n",
        "                correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        accuracy = correct / len(testloader.dataset)\n",
        "        losses_dict[\"net_loss_chunk\"].append(loss / len(testloader))\n",
        "        losses_dict[\"net_acc_chunk\"].append(accuracy)\n",
        "\n",
        "\n",
        "    # Média da perda dos discriminadores neste chunk\n",
        "    avg_d_loss_chunk = d_loss_b / total_chunk_samples if total_chunk_samples > 0 else 0.0\n",
        "    losses_dict[\"d_losses_chunk\"].append(avg_d_loss_chunk)\n",
        "    d_loss_c += avg_d_loss_chunk * total_chunk_samples\n",
        "    total_d_samples += total_chunk_samples\n",
        "\n",
        "    chunk_g_loss = 0.0\n",
        "\n",
        "    epoch_gen_bar = tqdm(range(extra_g_e), desc=\"Gerador\", leave=True, position=2)\n",
        "\n",
        "    for g_epoch in epoch_gen_bar:\n",
        "      # Train G\n",
        "      optim_G.zero_grad()\n",
        "\n",
        "      # Gera dados falsos\n",
        "      z_noise = torch.randn(batch_size_gen, latent_dim, device=device)\n",
        "      x_fake_labels = torch.randint(0, 10, (batch_size_gen,), device=device)\n",
        "      label = int(x_fake_labels.item())\n",
        "\n",
        "      if wgan:\n",
        "        x_fake_labels = torch.nn.functional.one_hot(x_fake_labels, 10).float()\n",
        "        z_noise = torch.cat([z_noise, x_fake_labels], dim=1)\n",
        "        fake_images = gen(z_noise)\n",
        "\n",
        "        # Seleciona o melhor discriminador (Dmax)\n",
        "        image_fake_labels = x_fake_labels.view(x_fake_labels.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "        fake_images = torch.cat([fake_images, image_fake_labels], dim=1)\n",
        "\n",
        "        y_fake_gs = [model(fake_images.detach()) for model in models]\n",
        "\n",
        "      else:\n",
        "        x_fake = gen(z_noise, x_fake_labels)\n",
        "\n",
        "        if f2a:\n",
        "          y_fakes = []\n",
        "          for D in models:\n",
        "              D = D.to(device)\n",
        "              y_fakes.append(D(x_fake, x_fake_labels))  # each is [B,1]\n",
        "          # stack into [N_discriminators, B, 1]\n",
        "          y_stack = torch.stack(y_fakes, dim=0)\n",
        "\n",
        "          # 4) Compute λ = ReLU(lambda_star) to enforce λ ≥ 0\n",
        "          lam = relu(lambda_star)\n",
        "\n",
        "          # 5) Soft‐max weights across the 0th dim (discriminators)\n",
        "          #    we want S_i = exp(λ D_i) / sum_j exp(λ D_j)\n",
        "          #    shape remains [N, B, 1]\n",
        "          S = torch.softmax(lam * y_stack, dim=0)\n",
        "\n",
        "          # 6) Weighted sum: D_agg shape [B,1]\n",
        "          D_agg = (S * y_stack).sum(dim=0)\n",
        "\n",
        "          # 7) Compute your generator loss + β λ² regularizer\n",
        "          real_ident = torch.full((batch_size_gen, 1), 1., device=device)\n",
        "          adv_loss   = gen.loss(D_agg, real_ident)       # BCEWithLogitsLoss or whatever\n",
        "          reg_loss   = beta * lam.pow(2)                 # β λ²\n",
        "          g_loss     = adv_loss + reg_loss\n",
        "\n",
        "        else:\n",
        "          # Seleciona o melhor discriminador (Dmax)\n",
        "          y_fake_gs = [model(x_fake.detach(), x_fake_labels) for model in models]\n",
        "          y_fake_g_means = [torch.mean(y).item() for y in y_fake_gs]\n",
        "          dmax_index = y_fake_g_means.index(max(y_fake_g_means))\n",
        "          Dmax = models[dmax_index]\n",
        "\n",
        "          #Track mismatches\n",
        "          expected_indexes = label_to_client[class_labels.int2str(x_fake_labels.item())] ##PEGA SOMENTE A PRIMEIRA LABEL, SE BATCH_SIZE_GEN FOR DIFERENTE DE 1 VAI DAR ERRO\n",
        "          if dmax_index not in expected_indexes:\n",
        "              mismatch_count += 1\n",
        "              total_checked +=1\n",
        "              percent_mismatch =  mismatch_count / total_checked\n",
        "              with open(dmax_mismatch_log, \"a\") as mismatch_file:\n",
        "                  mismatch_file.write(f\"{epoch+1} {x_fake_labels.item()} {expected_indexes} {dmax_index} {percent_mismatch:.2f}\\n\")\n",
        "          else:\n",
        "              total_checked += 1\n",
        "              if g_epoch == extra_g_e - 1 and chunk_idx == num_chunks - 1:\n",
        "                percent_mismatch =  mismatch_count / total_checked\n",
        "                with open(dmax_mismatch_log, \"a\") as mismatch_file:\n",
        "                  mismatch_file.write(f\"{epoch+1} {x_fake_labels.item()} {expected_indexes} {dmax_index} {percent_mismatch:.2f}\\n\")\n",
        "\n",
        "          # Calcula a perda do gerador\n",
        "          real_ident = torch.full((batch_size_gen, 1), 1., device=device)\n",
        "          if wgan:\n",
        "            y_fake_g = Dmax(fake_images)\n",
        "            g_loss = generator_loss(y_fake_g)\n",
        "\n",
        "          else:\n",
        "            y_fake_g = Dmax(x_fake, x_fake_labels)  # Detach explícito\n",
        "            g_loss = gen.loss(y_fake_g, real_ident)\n",
        "\n",
        "      g_loss.backward()\n",
        "      #torch.nn.utils.clip_grad_norm_(gen.generator.parameters(), max_norm=1.0)\n",
        "      optim_G.step()\n",
        "      gen.to(device)\n",
        "      chunk_g_loss += g_loss.item()\n",
        "\n",
        "    losses_dict[\"g_losses_chunk\"].append(chunk_g_loss / extra_g_e)\n",
        "    g_loss_c += chunk_g_loss /extra_g_e\n",
        "\n",
        "    losses_dict[\"time_chunk\"].append(time.time() - chunk_start_time)\n",
        "\n",
        "\n",
        "  g_loss_e = g_loss_c/num_chunks\n",
        "  d_loss_e = d_loss_c / total_d_samples if total_d_samples > 0 else 0.0\n",
        "\n",
        "  losses_dict[\"g_losses_round\"].append(g_loss_e)\n",
        "  losses_dict[\"d_losses_round\"].append(d_loss_e)\n",
        "\n",
        "  if (epoch+1)%2==0:\n",
        "      checkpoint = {\n",
        "            'epoch': epoch+1,  # número da última época concluída\n",
        "            'alvo_state_dict': global_net.state_dict(),\n",
        "            'optimizer_alvo_state_dict': [optim.state_dict() for optim in optims],\n",
        "            'gen_state_dict': gen.state_dict(),\n",
        "            'optim_G_state_dict': optim_G.state_dict(),\n",
        "            'discs_state_dict': [model.state_dict() for model in models],\n",
        "            'optim_Ds_state_dict:': [optim_d.state_dict() for optim_d in optim_Ds]\n",
        "          }\n",
        "      checkpoint_file = f\"checkpoint_epoch{epoch+1}.pth\"\n",
        "      if IN_COLAB:\n",
        "          checkpoint_file = os.path.join(save_dir, checkpoint_file)\n",
        "      torch.save(checkpoint, checkpoint_file)\n",
        "      print(f\"Global net saved to {checkpoint_file}\")\n",
        "\n",
        "      if f2a:\n",
        "        current_lambda_star = lambda_star.item()\n",
        "        current_lam         = F.relu(lambda_star).item()\n",
        "\n",
        "        with open(lambda_log, \"a\") as f:\n",
        "          f.write(f\"{current_lambda_star},{current_lam}\\n\")\n",
        "\n",
        "  correct, loss = 0, 0.0\n",
        "  global_net.eval()\n",
        "  with torch.no_grad():\n",
        "      for batch in testloader:\n",
        "          images = batch[image].to(device)\n",
        "          labels = batch[\"label\"].to(device)\n",
        "          outputs = global_net(images)\n",
        "          loss += criterion(outputs, labels).item()\n",
        "          correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "  accuracy = correct / len(testloader.dataset)\n",
        "  losses_dict[\"net_loss_round\"].append(loss / len(testloader))\n",
        "  losses_dict[\"net_acc_round\"].append(accuracy)\n",
        "\n",
        "  print(f\"Época {epoch+1} completa\")\n",
        "  generate_plot(gen, \"cpu\", epoch+1, latent_dim=128)\n",
        "  gen.to(device)\n",
        "\n",
        "  losses_dict[\"time_round\"].append(time.time() - epoch_start_time)\n",
        "\n",
        "  try:\n",
        "      with open(loss_filename, 'w', encoding='utf-8') as f:\n",
        "          json.dump(losses_dict, f, ensure_ascii=False, indent=4) # indent makes it readable\n",
        "      print(f\"Losses dict successfully saved to {loss_filename}\")\n",
        "  except Exception as e:\n",
        "      print(f\"Error saving losses dict to JSON: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_OdHAvK0LQp3",
      "metadata": {
        "collapsed": true,
        "id": "_OdHAvK0LQp3"
      },
      "outputs": [],
      "source": [
        "epochs = 2\n",
        "losses_dict = {\"net_loss_chunk\": [],\n",
        "               \"net_acc_chunk\": [],\n",
        "               \"net_loss_round\": [],\n",
        "               \"net_acc_round\": [],\n",
        "               \"time_chunk\": [],\n",
        "               \"time_round\": []}\n",
        "\n",
        "epoch_bar = tqdm(range(0, epochs), desc=\"Treinamento\", leave=True, position=0)\n",
        "\n",
        "batch_tam = 32\n",
        "latent_dim = 128\n",
        "num_classes = 10\n",
        "if type(nets[0]).__name__ == \"Net\":\n",
        "  image = \"image\"\n",
        "else:\n",
        "  image = \"img\"\n",
        "\n",
        "if IN_COLAB:\n",
        "  acc_filename = os.path.join(save_dir,\"accuracy_report.txt\")\n",
        "  loss_filename = os.path.join(save_dir, \"losses.json\")\n",
        "else:\n",
        "  acc_filename = \"accuracy_report.txt\"\n",
        "  loss_filename = \"losses.json\"\n",
        "\n",
        "for epoch in epoch_bar:\n",
        "  epoch_start_time = time.time()\n",
        "\n",
        "  chunk_bar = tqdm(range(num_chunks), desc=\"Chunks\", leave=True, position=1)\n",
        "\n",
        "  for chunk_idx in chunk_bar:\n",
        "    params = []\n",
        "    results = []\n",
        "    chunk_start_time = time.time()\n",
        "    total_chunk_samples = 0\n",
        "\n",
        "    client_bar = tqdm(enumerate(zip(nets, client_chunks)), desc=\"Clients\", leave=True, position=2)\n",
        "\n",
        "    for cliente, (net, chunks) in client_bar:\n",
        "\n",
        "      if chunk_idx == 0:\n",
        "        client_eval_time = time.time()\n",
        "        # Evaluation in client test\n",
        "        # Initialize counters\n",
        "        class_correct = defaultdict(int)\n",
        "        class_total = defaultdict(int)\n",
        "        predictions_counter = defaultdict(int)\n",
        "\n",
        "        global_net.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in client_test_loaders[cliente]:\n",
        "                images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "                outputs = global_net(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Update counts for each sample in batch\n",
        "                for true_label, pred_label in zip(labels, predicted):\n",
        "                    true_idx = true_label.item()\n",
        "                    pred_idx = pred_label.item()\n",
        "\n",
        "                    class_total[true_idx] += 1\n",
        "                    predictions_counter[pred_idx] += 1\n",
        "\n",
        "                    if true_idx == pred_idx:\n",
        "                        class_correct[true_idx] += 1\n",
        "\n",
        "            # Create results dictionary\n",
        "            results_metrics = {\n",
        "                \"class_metrics\": {},\n",
        "                \"overall_accuracy\": None,\n",
        "                \"prediction_distribution\": dict(predictions_counter)\n",
        "            }\n",
        "\n",
        "            # Calculate class-wise metrics\n",
        "            for i in range(num_classes):\n",
        "                metrics = {\n",
        "                    \"samples\": class_total[i],\n",
        "                    \"predictions\": predictions_counter[i],\n",
        "                    \"accuracy\": class_correct[i] / class_total[i] if class_total[i] > 0 else \"N/A\"\n",
        "                }\n",
        "                results_metrics[\"class_metrics\"][f\"class_{i}\"] = metrics\n",
        "\n",
        "            # Calculate overall accuracy\n",
        "            total_samples = sum(class_total.values())\n",
        "            results_metrics[\"overall_accuracy\"] = sum(class_correct.values()) / total_samples\n",
        "\n",
        "            # Save to txt file\n",
        "            with open(acc_filename, \"a\") as f:\n",
        "                f.write(f\"Epoch {epoch + 1} - Client {cliente}\\n\")\n",
        "                # Header with fixed widths\n",
        "                f.write(\"{:<10} {:<10} {:<10} {:<10}\\n\".format(\n",
        "                    \"Class\", \"Accuracy\", \"Samples\", \"Predictions\"))\n",
        "                f.write(\"-\"*45 + \"\\n\")\n",
        "\n",
        "                # Class rows with consistent formatting\n",
        "                for cls in range(num_classes):\n",
        "                    metrics = results_metrics[\"class_metrics\"][f\"class_{cls}\"]\n",
        "\n",
        "                    # Format accuracy (handle \"N/A\" case)\n",
        "                    accuracy = (f\"{metrics['accuracy']:.4f}\"\n",
        "                              if isinstance(metrics['accuracy'], float)\n",
        "                              else \"  N/A  \")\n",
        "\n",
        "                    f.write(\"{:<10} {:<10} {:<10} {:<10}\\n\".format(\n",
        "                        f\"Class {cls}\",\n",
        "                        accuracy,\n",
        "                        metrics['samples'],\n",
        "                        metrics['predictions']\n",
        "                    ))\n",
        "\n",
        "                # Footer with alignment\n",
        "                f.write(\"\\n{:<20} {:.4f}\".format(\"Overall Accuracy:\", results_metrics[\"overall_accuracy\"]))\n",
        "                f.write(\"\\n{:<20} {}\".format(\"Total Samples:\", total_samples))\n",
        "                f.write(\"\\n{:<20} {}\".format(\"Total Predictions:\", sum(predictions_counter.values())))\n",
        "                f.write(\"\\n{:<20} {:.4f}\".format(\"Client Evaluation Time:\", time.time() - client_eval_time))\n",
        "                f.write(\"\\n\")\n",
        "                f.write(\"\\n\")\n",
        "\n",
        "        print(\"Results saved to accuracy_report.txt\")\n",
        "\n",
        "      # Carregar o bloco atual do cliente\n",
        "      chunk_dataset = chunks[chunk_idx]\n",
        "      if len(chunk_dataset) == 0:\n",
        "        print(f\"Chunk {chunk_idx} for client {cliente} is empty, skipping.\")\n",
        "        continue\n",
        "      chunk_loader = DataLoader(chunk_dataset, batch_size=batch_tam, shuffle=False)\n",
        "\n",
        "      net.load_state_dict(global_net.state_dict(), strict=True)\n",
        "      net.to(device)\n",
        "      net.train()\n",
        "      optim = optims[cliente]\n",
        "\n",
        "      batch_bar = tqdm(chunk_loader, desc=\"Batches\", leave=True, position=3)\n",
        "\n",
        "      for batch in batch_bar:\n",
        "        images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "        batch_size = images.size(0)\n",
        "        if batch_size == 1:\n",
        "          print(\"Batch size is 1, skipping batch\")\n",
        "          continue\n",
        "        optim.zero_grad()\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "\n",
        "      params.append(ndarrays_to_parameters([val.cpu().numpy() for _, val in net.state_dict().items()]))\n",
        "      results.append((cliente, FitRes(status=Status(code=Code.OK, message=\"Success\"), parameters=params[cliente], num_examples=len(chunk_loader.dataset), metrics={})))\n",
        "\n",
        "    aggregated_ndarrays = aggregate_inplace(results)\n",
        "\n",
        "    params_dict = zip(global_net.state_dict().keys(), aggregated_ndarrays)\n",
        "    state_dict = OrderedDict({k: torch.tensor(v).to(device) for k, v in params_dict})\n",
        "    global_net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # Evaluation\n",
        "    if chunk_idx % 10 == 0:\n",
        "        global_net.eval()\n",
        "        correct, loss = 0, 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in testloader:\n",
        "                images = batch[image].to(device)\n",
        "                labels = batch[\"label\"].to(device)\n",
        "                outputs = global_net(images)\n",
        "                loss += criterion(outputs, labels).item()\n",
        "                correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        accuracy = correct / len(testloader.dataset)\n",
        "        losses_dict[\"net_loss_chunk\"].append(loss / len(testloader))\n",
        "        losses_dict[\"net_acc_chunk\"].append(accuracy)\n",
        "\n",
        "        losses_dict[\"time_chunk\"].append(time.time() - chunk_start_time)\n",
        "\n",
        "  correct, loss = 0, 0.0\n",
        "  global_net.eval()\n",
        "  with torch.no_grad():\n",
        "      for batch in testloader:\n",
        "          images = batch[image].to(device)\n",
        "          labels = batch[\"label\"].to(device)\n",
        "          outputs = global_net(images)\n",
        "          loss += criterion(outputs, labels).item()\n",
        "          correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "  accuracy = correct / len(testloader.dataset)\n",
        "  losses_dict[\"net_loss_round\"].append(loss / len(testloader))\n",
        "  losses_dict[\"net_acc_round\"].append(accuracy)\n",
        "\n",
        "\n",
        "  print(f\"Época {epoch+1} completa\")\n",
        "\n",
        "  losses_dict[\"time_round\"].append(time.time() - epoch_start_time)\n",
        "\n",
        "  try:\n",
        "      with open(loss_filename, 'w', encoding='utf-8') as f:\n",
        "          json.dump(losses_dict, f, ensure_ascii=False, indent=4) # indent makes it readable\n",
        "      print(f\"Losses dict successfully saved to {loss_filename}\")\n",
        "  except Exception as e:\n",
        "      print(f\"Error saving losses dict to JSON: {e}\")\n",
        "\n",
        "  if (epoch+1)%1==0:\n",
        "    checkpoint = {\n",
        "          'epoch': epoch+1,  # número da última época concluída\n",
        "          'alvo_state_dict': global_net.state_dict(),\n",
        "          'optimizer_alvo_state_dict': [optim.state_dict() for optim in optims],\n",
        "        }\n",
        "    checkpoint_file = f\"checkpoint_epoch{epoch+1}.pth\"\n",
        "    if IN_COLAB:\n",
        "        checkpoint_file = os.path.join(save_dir, checkpoint_file)\n",
        "    torch.save(checkpoint, checkpoint_file)\n",
        "    print(f\"Global net saved to {checkpoint_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c3ce47d",
      "metadata": {
        "id": "2c3ce47d"
      },
      "source": [
        "# Gráficos de perda e acurácia"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01f7dbfb",
      "metadata": {
        "id": "01f7dbfb"
      },
      "source": [
        "## Le o arquivo de perda salvo no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FaRDCz_cSJDf",
      "metadata": {
        "id": "FaRDCz_cSJDf"
      },
      "outputs": [],
      "source": [
        "loss_filename = \"losses.json\"\n",
        "# if IN_COLAB:\n",
        "#   loss_filename = os.path.join(save_dir, loss_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-by_-71kSOeu",
      "metadata": {
        "id": "-by_-71kSOeu"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49537f37",
      "metadata": {
        "id": "49537f37"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    with open(loss_filename, 'r', encoding='utf-8') as f:\n",
        "        # The load function also works the same\n",
        "        loaded_dict = json.load(f)\n",
        "    print(f\"Dictionary successfully loaded from {loss_filename}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File '{loss_filename}' not found.\")\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Error: Could not decode JSON from '{loss_filename}'. File might be corrupted or not JSON.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dictionary from JSON: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "237af03a",
      "metadata": {
        "id": "237af03a"
      },
      "source": [
        "## Coleta acurácias locais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d24b634",
      "metadata": {
        "id": "8d24b634"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f0588a2",
      "metadata": {
        "id": "8f0588a2"
      },
      "outputs": [],
      "source": [
        "def parse_client_accuracies(log_path):\n",
        "   # Regex to match \"Round X - Cliente Y\" and \"Overall Accuracy:    Z.ZZZZ\"\n",
        "   header_re   = re.compile(r\"Epoch\\s+\\d+\\s*-\\s*Client\\s*(\\d+)\", re.IGNORECASE)\n",
        "   accuracy_re = re.compile(r\"Overall Accuracy:\\s*([\\d.]+)\")\n",
        "\n",
        "\n",
        "   # Now client → list of accuracies\n",
        "   client_accuracies = defaultdict(list)\n",
        "\n",
        "\n",
        "   with open(log_path, 'r', encoding='utf-8') as f:\n",
        "       current_client = None\n",
        "\n",
        "\n",
        "       for line in f:\n",
        "           # Detect the client header\n",
        "           hdr = header_re.search(line)\n",
        "           if hdr:\n",
        "               current_client = int(hdr.group(1))\n",
        "               continue\n",
        "\n",
        "\n",
        "           # Once we see the accuracy line, append and reset\n",
        "           if current_client is not None:\n",
        "               acc = accuracy_re.search(line)\n",
        "               if acc:\n",
        "                   client_accuracies[current_client].append(float(acc.group(1)))\n",
        "                   current_client = None\n",
        "\n",
        "\n",
        "   return dict(client_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f397ca9c",
      "metadata": {
        "id": "f397ca9c"
      },
      "outputs": [],
      "source": [
        "log_file = \"accuracy_report.txt\"\n",
        "local_acc_alvo = parse_client_accuracies(log_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b890d518",
      "metadata": {
        "id": "b890d518"
      },
      "source": [
        "## Funcao de plotagem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39493e97",
      "metadata": {
        "id": "39493e97"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from typing import Iterable, Mapping, Literal, Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cc3c2af",
      "metadata": {
        "id": "3cc3c2af"
      },
      "outputs": [],
      "source": [
        "def plot_series(\n",
        "    series: Mapping[str, Iterable[float]],\n",
        "    *,\n",
        "    # Series-specific styles: color, linestyle, etc.\n",
        "    series_styles: Mapping[str, Mapping[str, Any]] = None,\n",
        "    # Axis limits\n",
        "    xlim: tuple[float, float] = None,\n",
        "    ylim: tuple[float, float] = None,\n",
        "    # Tick control\n",
        "    first_step: int = None,\n",
        "    xtick_step: int = 1,\n",
        "    xtick_offset: int = 0,\n",
        "    # Labels\n",
        "    xlabel: str = \"Epochs\",\n",
        "    ylabel: str = \"Value\",\n",
        "    title: str = None,\n",
        "    # Highlight control: per-series \"max\", \"min\", \"both\"\n",
        "    highlight: Mapping[str, Literal[\"max\", \"min\", \"both\"]] = None,\n",
        "    highlight_marker: str = \"o\",\n",
        "    highlight_markersize: float = 4,\n",
        "    highlight_color: str = None,\n",
        "    # Legend control\n",
        "    legend_loc: str = 'best',           # e.g. 'lower right'\n",
        "    legend_fontsize: float = 10,\n",
        "    # Figure size\n",
        "    figsize: tuple[float, float] = (10, 5),\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Plots one or more series with per-series options for line style/color,\n",
        "    tick control, axis limits, per-series max/min highlighting,\n",
        "    and legend styling.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    series : Mapping[str, Iterable[float]]\n",
        "        Dict from legend label to its sequence of values.\n",
        "    series_styles : Mapping[str, Mapping[str, Any]], optional\n",
        "        Per-series plotting kwargs (e.g. 'color', 'linestyle', etc.).\n",
        "    xlim : (float, float), optional\n",
        "        X-axis limits.\n",
        "    ylim : (float, float), optional\n",
        "        Y-axis limits.\n",
        "    first_step : int, optional\n",
        "        If given, ticks at 1, 1+first_step, then +xtick_step thereafter.\n",
        "    xtick_step : int, optional\n",
        "        Uniform tick step if first_step is None.\n",
        "    xtick_offset : int, optional\n",
        "        Added to every tick label.\n",
        "    xlabel, ylabel, title : str, optional\n",
        "        Axis and title labels.\n",
        "    highlight : Mapping[str, {\"max\",\"min\",\"both\"}], optional\n",
        "        For each series name, what to highlight. Omit or None to skip.\n",
        "    highlight_marker : str\n",
        "        Marker style for highlights.\n",
        "    highlight_color : str, optional\n",
        "        Color for highlight markers (overrides series color if set).\n",
        "    highlight_markersize : float\n",
        "        Size of highlight markers.\n",
        "    legend_loc : str\n",
        "        Location code for plt.legend (e.g. 'lower right').\n",
        "    legend_fontsize : float\n",
        "        Font size for legend text.\n",
        "    figsize : (w, h)\n",
        "        Figure size in inches.\n",
        "    \"\"\"\n",
        "    # Validate lengths\n",
        "    lengths = {len(v) for v in series.values()}\n",
        "    if not lengths:\n",
        "        raise ValueError(\"No data series provided.\")\n",
        "    if len(lengths) > 1:\n",
        "        raise ValueError(f\"Series length mismatch: {lengths}\")\n",
        "    n = lengths.pop()\n",
        "\n",
        "    xs = list(range(n))\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    for name, ys in series.items():\n",
        "        # Get style for this series\n",
        "        style = {} if series_styles is None or name not in series_styles else series_styles[name]\n",
        "        # Plot and capture line for default color\n",
        "        line, = plt.plot(xs, ys, label=name, **style)\n",
        "        mode = highlight[name] if (highlight and name in highlight) else None\n",
        "\n",
        "        # Determine marker color\n",
        "        base_color = style.get('color', line.get_color())\n",
        "        mcolor = highlight_color or base_color\n",
        "\n",
        "        # Highlight max\n",
        "        if mode in (\"max\", \"both\"):\n",
        "            i_max = max(range(n), key=lambda i: ys[i])\n",
        "            plt.plot(i_max, ys[i_max], marker=highlight_marker,\n",
        "                     markersize=highlight_markersize, color=mcolor, linestyle=\"\")\n",
        "            plt.text(i_max, ys[i_max] + 0.01, f\"{ys[i_max]:.2f}\",\n",
        "                     va=\"bottom\", ha=\"center\", fontsize=8)\n",
        "        # Highlight min\n",
        "        if mode in (\"min\", \"both\"):\n",
        "            i_min = min(range(n), key=lambda i: ys[i])\n",
        "            plt.plot(i_min, ys[i_min], marker=highlight_marker,\n",
        "                     markersize=highlight_markersize, color=mcolor, linestyle=\"\")\n",
        "            plt.text(i_min, ys[i_min], f\"{ys[i_min]:.2f}\",\n",
        "                     va=\"top\", ha=\"center\", fontsize=8)\n",
        "\n",
        "    # X-ticks logic\n",
        "    if first_step is not None:\n",
        "        labels = [1]\n",
        "        next_label = 1 + first_step\n",
        "        while next_label <= n:\n",
        "            labels.append(next_label)\n",
        "            next_label += xtick_step\n",
        "        positions = [lbl - 1 for lbl in labels]\n",
        "        labels = [lbl + xtick_offset for lbl in labels]\n",
        "        plt.xticks(positions, labels)\n",
        "    elif xtick_step > 0:\n",
        "        positions = list(range(0, n, xtick_step))\n",
        "        labels = [pos + 1 + xtick_offset for pos in positions]\n",
        "        plt.xticks(positions, labels)\n",
        "\n",
        "    # Axis limits\n",
        "    if xlim is not None:\n",
        "        plt.xlim(*xlim)\n",
        "    else:\n",
        "        plt.xlim(0, n - 1)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    # Legend with custom location and font size\n",
        "    plt.legend(loc=legend_loc, fontsize=legend_fontsize)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "febb881b",
      "metadata": {},
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7df4d40",
      "metadata": {},
      "source": [
        "### Loss e Acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a663f1c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "  series = {\n",
        "      \"Loss\": loaded_dict[\"net_loss_round\"],\n",
        "      \"Accuracy\": loaded_dict[\"net_acc_round\"]\n",
        "  },\n",
        "  highlight = {\n",
        "      \"Accuracy\": \"max\"\n",
        "  },\n",
        "  highlight_markersize=4,\n",
        "  xtick_step=5,\n",
        "  first_step=4,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28b0d95c",
      "metadata": {},
      "source": [
        "### Local Acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "209bd071",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series = {\n",
        "        #\"Global - Alvo\": loaded_dict_alvo[\"net_acc_round\"],\n",
        "        #\"Global - GeraFed\": loaded_dict[\"net_acc_round\"][:100],\n",
        "        \"Client 0 - Alvo\": local_acc_alvo[0],\n",
        "       # \"Client 0 - GeraFed\": local_acc[0],\n",
        "        \"Client 1 - Alvo\": local_acc_alvo[1],\n",
        "      #  \"Client 1 - GeraFed\": local_acc[1],\n",
        "        \"Client 2 - Alvo\": local_acc_alvo[2],\n",
        "       # \"Client 2 - GeraFed\": local_acc[2],\n",
        "        \"Client 3 - Alvo\": local_acc_alvo[3],\n",
        "        #\"Client 3 - GeraFed\": local_acc[3],\n",
        "    },\n",
        "    series_styles = {\n",
        "        #\"Global - Alvo\": {\"color\": \"lightblue\", \"linestyle\": \"-\"},\n",
        "        #\"Global - GeraFed\": {\"color\": \"lightblue\", \"linestyle\": \"--\"},\n",
        "        \"Client 0 - Alvo\": {\"color\": \"orange\", \"linestyle\": \"-\"},\n",
        "        #\"Client 0 - GeraFed\": {\"color\": \"orange\", \"linestyle\": \"--\"},\n",
        "        \"Client 1 - Alvo\": {\"color\": \"green\", \"linestyle\": \"-\"},\n",
        "        #\"Client 1 - GeraFed\": {\"color\": \"green\", \"linestyle\": \"--\"},\n",
        "        \"Client 2 - Alvo\": {\"color\": \"brown\", \"linestyle\": \"-\"},\n",
        "        #\"Client 2 - GeraFed\": {\"color\": \"brown\", \"linestyle\": \"--\"},\n",
        "        \"Client 3 - Alvo\": {\"color\": \"purple\", \"linestyle\": \"-\"},\n",
        "        #\"Client 3 - GeraFed\": {\"color\": \"purple\", \"linestyle\": \"--\"},\n",
        "    },\n",
        "    highlight={\n",
        "       # \"Global - Alvo\": \"max\",\n",
        "        #\"Global - GeraFed\": \"max\",\n",
        "        \"Client 0 - Alvo\": \"max\",\n",
        "       # \"Client 0 - GeraFed\": \"max\",\n",
        "        \"Client 1 - Alvo\": \"max\",\n",
        "       # \"Client 1 - GeraFed\": \"max\",\n",
        "        \"Client 2 - Alvo\": \"max\",\n",
        "       # \"Client 2 - GeraFed\": \"max\",\n",
        "        \"Client 3 - Alvo\": \"max\",\n",
        "        #\"Client 3 - GeraFed\": \"max\",\n",
        "    },\n",
        "    highlight_markersize=4,\n",
        "    xtick_step=5,\n",
        "    first_step=4,\n",
        "    ylabel=\"Accuracy\",\n",
        "    ylim=(0,1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8952ba7e",
      "metadata": {},
      "source": [
        "### Different distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf794d8a",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series={\n",
        "        \"IID\": loaded_dict_iid[\"net_acc_round\"],\n",
        "        \"Dir05\": loaded_dict[\"net_acc_round\"],\n",
        "        \"Dir01\": loaded_dict_dir[\"net_acc_round\"][:100],\n",
        "        \"NIID Class\": loaded_dict_class[\"net_acc_round\"],\n",
        "    },\n",
        "    highlight={\n",
        "        \"IID\": \"max\",\n",
        "        \"Dir05\": \"max\",\n",
        "        \"Dir01\": \"max\",\n",
        "        \"NIID Class\": \"max\",\n",
        "    },\n",
        "    highlight_markersize=4,\n",
        "    xtick_step=5,\n",
        "    first_step=4,\n",
        "    ylabel=\"Accuracy\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc847093",
      "metadata": {},
      "source": [
        "### GAN loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17fca7c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series={\n",
        "        \"Generator\": loaded_dict['g_losses_round'],\n",
        "        \"Discriminator\": loaded_dict['d_losses_round']\n",
        "    },\n",
        "    xtick_step=5,\n",
        "    first_step=4,\n",
        "    ylabel=\"Loss\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b608dfdb",
      "metadata": {},
      "source": [
        "### GeraFed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0637fcc",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series = {\n",
        "        \"Alvo\": loaded_dict_alvo[\"net_acc_round\"],\n",
        "        \"GeraFed\": loaded_dict[\"net_acc_round\"][:100]\n",
        "    },\n",
        "    highlight={\n",
        "        \"Alvo\": \"max\",\n",
        "        \"GeraFed\": \"max\",\n",
        "    },\n",
        "    highlight_markersize=4,\n",
        "    xtick_step=5,\n",
        "    first_step=4,\n",
        "    ylabel=\"Accuracy\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5d66909",
      "metadata": {},
      "source": [
        "## Plot generator images per epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfa906d3",
      "metadata": {
        "id": "bfa906d3"
      },
      "outputs": [],
      "source": [
        "for i in range(1,5,1):\n",
        "    gen = F2U_GAN(condition=True).to(\"cpu\")\n",
        "    if IN_COLAB:\n",
        "      gen.load_state_dict(torch.load(os.path.join(save_dir,f\"gen_round{i}.pt\")))\n",
        "    else:\n",
        "      gen.load_state_dict(torch.load(f\"gen_round{i}.pt\"))\n",
        "    generate_plot(gen, \"cpu\", i, latent_dim=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeeddbca",
      "metadata": {
        "id": "aeeddbca"
      },
      "source": [
        "# Compara treino de classificador em dados reais, sintéticos e misturados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c400df8",
      "metadata": {
        "id": "6c400df8"
      },
      "outputs": [],
      "source": [
        "nets = [Net().to(device) for _ in range(num_partitions)]\n",
        "optims = [torch.optim.Adam(net.parameters(), lr=0.01) for net in nets]\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2117f9e5",
      "metadata": {
        "id": "2117f9e5"
      },
      "outputs": [],
      "source": [
        "for i, (net, optim) in enumerate(zip(nets, optims)):\n",
        "    net.train()\n",
        "    for epoch in range(50):\n",
        "        for data in trainloaders[i]:\n",
        "            inputs, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "            optim.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optim.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7ad2d72",
      "metadata": {
        "id": "c7ad2d72"
      },
      "outputs": [],
      "source": [
        "testpartition = fds.load_split(\"test\")\n",
        "testpartition = testpartition.with_transform(apply_transforms)\n",
        "testloader = DataLoader(testpartition, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abfbb983",
      "metadata": {
        "id": "abfbb983"
      },
      "outputs": [],
      "source": [
        "accuracies = []\n",
        "for net in nets:\n",
        "    correct, loss = 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "    accuracy = correct / len(testloader.dataset)\n",
        "    accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eedc9b7",
      "metadata": {
        "id": "0eedc9b7"
      },
      "outputs": [],
      "source": [
        "accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea7a7b0",
      "metadata": {
        "id": "5ea7a7b0"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "num_samples = 1000\n",
        "latent_dim = 128\n",
        "\n",
        "# gen = F2U_GAN()\n",
        "# gen.load_state_dict(torch.load(\"gen_round50.pt\", map_location=torch.device('cpu')))\n",
        "\n",
        "# Create the dataset and dataloader\n",
        "generated_dataset = GeneratedDataset(generator=gen.to(\"cpu\"), num_samples=num_samples, latent_dim=latent_dim, num_classes=10, device=\"cpu\")\n",
        "generated_dataloader = DataLoader(generated_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bc9f7fe",
      "metadata": {
        "id": "3bc9f7fe"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import ConcatDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99e1cbfd",
      "metadata": {
        "id": "99e1cbfd"
      },
      "outputs": [],
      "source": [
        "combined_dataloaders = []\n",
        "for train_partition in train_partitions:\n",
        "    # Ensure the partition is transformed\n",
        "    cmb_ds = ConcatDataset([train_partition, generated_dataset])\n",
        "    combined_dataloaders.append(DataLoader(cmb_ds, batch_size=batch_size, shuffle=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85df355d",
      "metadata": {
        "id": "85df355d"
      },
      "outputs": [],
      "source": [
        "nets = [Net().to(device) for _ in range(num_partitions)]\n",
        "optims = [torch.optim.Adam(net.parameters(), lr=0.01) for net in nets]\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ea13f13",
      "metadata": {
        "id": "9ea13f13"
      },
      "outputs": [],
      "source": [
        "for i, (net, optim) in enumerate(zip(nets, optims)):\n",
        "    net.train()\n",
        "    for epoch in range(50):\n",
        "        for data in combined_dataloaders[i]:\n",
        "            inputs, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "            optim.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optim.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9818e23a",
      "metadata": {
        "id": "9818e23a"
      },
      "outputs": [],
      "source": [
        "accuracies = []\n",
        "for net in nets:\n",
        "    correct, loss = 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "    accuracy = correct / len(testloader.dataset)\n",
        "    accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2b2cb6d",
      "metadata": {
        "id": "c2b2cb6d"
      },
      "outputs": [],
      "source": [
        "accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff260823",
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Definindo x e N\n",
        "x = list(range(1, 101))\n",
        "den = math.exp(0.01 * 50) - 1\n",
        "N = [int(13 * (math.exp(0.01 * (xi - 1)) - 1) / den) * 1000 for xi in x]\n",
        "y = [390*xi for xi in x]\n",
        "\n",
        "# Plot\n",
        "plt.figure()\n",
        "plt.plot(x, N)\n",
        "plt.plot(x, y)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"N\")\n",
        "plt.title(\"Plot de N = int(13 * (exp(0.01*(x-1)) - 1)/(exp(0.5) - 1)) * 1000\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d05e564",
      "metadata": {},
      "source": [
        "# Calcula tamanho dos modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "e3570976",
      "metadata": {},
      "outputs": [],
      "source": [
        "net_ndarrays = [val.cpu().numpy() for _, val in nets[0].state_dict().items()]\n",
        "disc_ndarrays = [val.cpu().numpy() for key, val in models[0].state_dict().items() if 'discriminator' in key or 'label' in key]\n",
        "gen_ndarrays = [val.cpu().numpy() for key, val in models[0].state_dict().items() if 'generator' in key or 'label' in key]\n",
        "\n",
        "classifier_net_MB = sum(arr.nbytes for arr in net_ndarrays)/(1000**2)\n",
        "disc_MB = sum(arr.nbytes for arr in disc_ndarrays)/(1000**2)\n",
        "gen_MB = sum(arr.nbytes for arr in gen_ndarrays)/(1000**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db1071d9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Per-epoch upload  = 0.175 GB\n",
            "Per-epoch download= 0.978 GB\n",
            "Total upload over 100 epochs:   17.534 GB\n",
            "Total download over 100 epochs: 97.802 GB\n",
            "Total combined (upload + download):  115.336 GB\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "# Per-epoch traffic (GB)\n",
        "upload_per_epoch = (classifier_net_MB + disc_MB) / 10 #*100(100 rounds for 1 epoch) /1000 (from GB to GB)\n",
        "download_per_epoch = (classifier_net_MB + gen_MB) / 10\n",
        "\n",
        "# Cumulative arrays with an initial 0 so the plot has horizontal lines before first epoch\n",
        "x = np.arange(0, epochs + 1)  # 0..epochs inclusive\n",
        "cum_upload = np.insert(np.cumsum(np.full(epochs, upload_per_epoch)), 0, 0)\n",
        "cum_download = np.insert(np.cumsum(np.full(epochs, download_per_epoch)), 0, 0)\n",
        "\n",
        "total_upload_GB = cum_upload[-1]\n",
        "total_download_GB = cum_download[-1]\n",
        "\n",
        "print(f\"Per-epoch upload  = {upload_per_epoch:.3f} GB\")\n",
        "print(f\"Per-epoch download= {download_per_epoch:.3f} GB\")\n",
        "print(f\"Total upload over {epochs} epochs:   {total_upload_GB:.3f} GB\")\n",
        "print(f\"Total download over {epochs} epochs: {total_download_GB:.3f} GB\")\n",
        "print(f\"Total combined (upload + download):  {(total_upload_GB + total_download_GB):.3f} GB\")\n",
        "\n",
        "# Single step plot (cumulative). Using where='post' so the vertical jumps happen at integer epochs.\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.step(x, cum_upload, where='post', label=\"Cumulative upload (GB)\")\n",
        "plt.step(x, cum_download, where='post', label=\"Cumulative download (GB)\")\n",
        "plt.xlim(0, epochs)\n",
        "plt.xticks(np.arange(0, epochs+1, max(1, epochs//10)))\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Cumulative GB\")\n",
        "plt.title(\"Cumulative upload/download traffic (step plot)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "# Annotate final totals on the right side\n",
        "plt.annotate(f\"{total_upload_GB:.0f} GB\", xy=(epochs, total_upload_GB),\n",
        "             xytext=(epochs-5, total_upload_GB + max(1, total_upload_GB*0.02)),\n",
        "             arrowprops=dict(arrowstyle=\"->\"), fontsize=9, va=\"bottom\")\n",
        "plt.annotate(f\"{total_download_GB:.0f} GB\", xy=(epochs, total_download_GB),\n",
        "             xytext=(epochs-5, total_download_GB + max(1, total_download_GB*0.02)),\n",
        "             arrowprops=dict(arrowstyle=\"->\"), fontsize=9, va=\"bottom\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "11f6eb0a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Per-round upload  = 1.753 MB\n",
            "Per-round download= 9.780 MB\n",
            "Total upload over 10000 rounds:   17.534 GB\n",
            "Total download over 10000 rounds: 97.802 GB\n",
            "Total combined (upload + download):  115.336 GB\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rounds = 10000\n",
        "\n",
        "# Per-round traffic (MB)\n",
        "upload_per_round = (classifier_net_MB + disc_MB)\n",
        "download_per_round = (classifier_net_MB + gen_MB)\n",
        "\n",
        "# Cumulative arrays with an initial 0 so the plot has horizontal lines before first round\n",
        "x = np.arange(0, rounds + 1)  # 0..rounds inclusive\n",
        "cum_upload = np.insert(np.cumsum(np.full(rounds, upload_per_round)), 0, 0)\n",
        "cum_download = np.insert(np.cumsum(np.full(rounds, download_per_round)), 0, 0)\n",
        "\n",
        "total_upload_GB = cum_upload[-1]/1000\n",
        "total_download_GB = cum_download[-1]/1000\n",
        "\n",
        "print(f\"Per-round upload  = {upload_per_round:.3f} MB\")\n",
        "print(f\"Per-round download= {download_per_round:.3f} MB\")\n",
        "print(f\"Total upload over {rounds} rounds:   {total_upload_GB:.3f} GB\")\n",
        "print(f\"Total download over {rounds} rounds: {total_download_GB:.3f} GB\")\n",
        "print(f\"Total combined (upload + download):  {(total_upload_GB + total_download_GB):.3f} GB\")\n",
        "\n",
        "# Single step plot (cumulative). Using where='post' so the vertical jumps happen at integer rounds.\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.step(x, cum_upload, where='post', label=\"Cumulative upload (MB)\")\n",
        "plt.step(x, cum_download, where='post', label=\"Cumulative download (MB)\")\n",
        "plt.xlim(0, rounds)\n",
        "plt.xticks(np.arange(0, rounds+1, max(1, rounds//10)))\n",
        "plt.xlabel(\"Round\")\n",
        "plt.ylabel(\"Cumulative MB\")\n",
        "plt.title(\"Cumulative upload/download traffic (step plot)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "\n",
        "# Annotate final totals on the right side\n",
        "plt.annotate(f\"{total_upload_GB:.0f} GB\", xy=(rounds, total_upload_GB*1000),\n",
        "             xytext=(rounds-5, total_upload_GB*1000 + max(1, total_upload_GB*400)),\n",
        "             arrowprops=dict(arrowstyle=\"->\"), fontsize=9, va=\"bottom\")\n",
        "plt.annotate(f\"{total_download_GB:.0f} GB\", xy=(rounds, total_download_GB*1000),\n",
        "             xytext=(rounds-5, total_download_GB*900 + max(1, total_download_GB*0.1)),\n",
        "             arrowprops=dict(arrowstyle=\"->\"), fontsize=9, va=\"bottom\")\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "6d8c276e",
        "314c3604"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gerafed",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
