{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "07f8307e",
      "metadata": {
        "id": "07f8307e"
      },
      "source": [
        "# Inicialização"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f47d1996",
      "metadata": {
        "id": "f47d1996"
      },
      "source": [
        "## Prepara o ambiente local ou colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "88a7ea1c",
      "metadata": {
        "id": "88a7ea1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Ambiente local detectado. Downloads automáticos desativados.\n"
          ]
        }
      ],
      "source": [
        "# --- Detectar Ambiente (Colab ou Local) ---\n",
        "IN_COLAB = False\n",
        "try:\n",
        "    # Tenta importar um módulo específico do Colab\n",
        "    from google.colab import drive\n",
        "    import shutil # Usaremos para copiar, se necessário, mas salvar direto é melhor\n",
        "    import os\n",
        "\n",
        "    try:\n",
        "        drive.mount('/content/drive')\n",
        "        # Crie um diretório específico para salvar os resultados desta execução\n",
        "        save_base_dir = \"/content/drive/MyDrive/GAN_Training_Results\" # Ajuste o caminho como desejar\n",
        "        os.makedirs(save_base_dir, exist_ok=True)\n",
        "        # Opcional: Crie um subdiretório único para esta execução específica (ex: baseado em timestamp)\n",
        "        # import datetime\n",
        "        # timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        # save_dir = os.path.join(save_base_dir, f\"run_{timestamp}\")\n",
        "        # os.makedirs(save_dir, exist_ok=True)\n",
        "        # Por simplicidade, vamos usar o diretório base diretamente por enquanto\n",
        "        save_dir = save_base_dir\n",
        "        print(f\"✅ Google Drive montado. Arquivos serão salvos em: {save_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Erro ao montar o Google Drive: {e}\")\n",
        "        print(\"   Downloads diretos serão tentados, mas podem atrasar.\")\n",
        "        save_dir = \".\" # Salvar localmente se o Drive falhar\n",
        "    IN_COLAB = True\n",
        "    print(\"✅ Ambiente Google Colab detectado. Downloads automáticos (a cada 2 épocas) ativados.\")\n",
        "except ImportError:\n",
        "    print(\"✅ Ambiente local detectado. Downloads automáticos desativados.\")\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08e68593",
      "metadata": {
        "id": "08e68593"
      },
      "source": [
        "## Importa Pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1e43ad3e",
      "metadata": {
        "id": "1e43ad3e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5df872b",
      "metadata": {
        "id": "b5df872b"
      },
      "source": [
        "## Modelo Classificador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4395f020",
      "metadata": {
        "id": "4395f020"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, seed=None):\n",
        "        if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(16*4*4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16*4*4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "a98df505",
      "metadata": {
        "id": "a98df505"
      },
      "outputs": [],
      "source": [
        "class Net_Cifar(nn.Module):\n",
        "    def __init__(self,seed=None):\n",
        "        if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d8c276e",
      "metadata": {
        "id": "6d8c276e"
      },
      "source": [
        "## Carrega Dados MNIST centralizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a82cbfd1",
      "metadata": {
        "id": "a82cbfd1"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13ad4aaf",
      "metadata": {
        "id": "13ad4aaf"
      },
      "outputs": [],
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Load the training and test datasets\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "trainset_reduzido = torch.utils.data.random_split(trainset, [1000, len(trainset) - 1000])[0]\n",
        "# Create data loaders\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "trainloader_reduzido = DataLoader(trainset_reduzido, batch_size=BATCH_SIZE, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c27cfeac",
      "metadata": {
        "id": "c27cfeac"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# parameters\n",
        "num_classes = 10\n",
        "samples_per_class = 5\n",
        "\n",
        "# containers\n",
        "class_counts = {i: 0 for i in range(num_classes)}\n",
        "class_images = {i: [] for i in range(num_classes)}\n",
        "\n",
        "# gather up to 5 images per class\n",
        "for img, label in trainset:\n",
        "    if class_counts[label] < samples_per_class:\n",
        "        class_images[label].append(img)\n",
        "        class_counts[label] += 1\n",
        "    # stop early once we have enough of every class\n",
        "    if all(count >= samples_per_class for count in class_counts.values()):\n",
        "        break\n",
        "\n",
        "# plot\n",
        "fig, axes = plt.subplots(num_classes, samples_per_class, figsize=(5, 10))\n",
        "for digit in range(num_classes):\n",
        "    for i in range(samples_per_class):\n",
        "        ax = axes[digit, i]\n",
        "        ax.imshow(class_images[digit][i].squeeze(), cmap='gray')\n",
        "        ax.axis('off')\n",
        "    # label the rows on the leftmost subplot\n",
        "    axes[digit, 0].set_ylabel(str(digit), rotation=0, labelpad=12, va='center', fontsize=12)\n",
        "\n",
        "plt.suptitle(\"5 MNIST examples per digit (0–9)\", fontsize=16)\n",
        "plt.tight_layout(rect=[0,0,1,0.97])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54f6fbda",
      "metadata": {
        "id": "54f6fbda"
      },
      "source": [
        "## Modelo Generativo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ea03ea69",
      "metadata": {
        "id": "ea03ea69"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "314c3604",
      "metadata": {
        "id": "314c3604"
      },
      "source": [
        "### CGAN (simples, mlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23cfec37",
      "metadata": {
        "id": "23cfec37"
      },
      "outputs": [],
      "source": [
        "class CGAN(nn.Module):\n",
        "    def __init__(self, dataset=\"mnist\", img_size=28, latent_dim=100):\n",
        "        super(CGAN, self).__init__()\n",
        "        if dataset == \"mnist\":\n",
        "            self.classes = 10\n",
        "            self.channels = 1\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes)\n",
        "        self.adv_loss = torch.nn.BCELoss()\n",
        "\n",
        "\n",
        "        self.generator = nn.Sequential(\n",
        "            *self._create_layer_gen(self.latent_dim + self.classes, 128, False),\n",
        "            *self._create_layer_gen(128, 256),\n",
        "            *self._create_layer_gen(256, 512),\n",
        "            *self._create_layer_gen(512, 1024),\n",
        "            nn.Linear(1024, int(np.prod(self.img_shape))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.discriminator = nn.Sequential(\n",
        "            *self._create_layer_disc(self.classes + int(np.prod(self.img_shape)), 1024, False, True),\n",
        "            *self._create_layer_disc(1024, 512, True, True),\n",
        "            *self._create_layer_disc(512, 256, True, True),\n",
        "            *self._create_layer_disc(256, 128, False, False),\n",
        "            *self._create_layer_disc(128, 1, False, False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def _create_layer_gen(self, size_in, size_out, normalize=True):\n",
        "        layers = [nn.Linear(size_in, size_out)]\n",
        "        if normalize:\n",
        "            layers.append(nn.BatchNorm1d(size_out))\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return layers\n",
        "\n",
        "    def _create_layer_disc(self, size_in, size_out, drop_out=True, act_func=True):\n",
        "        layers = [nn.Linear(size_in, size_out)]\n",
        "        if drop_out:\n",
        "            layers.append(nn.Dropout(0.4))\n",
        "        if act_func:\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return layers\n",
        "\n",
        "    def forward(self, input, labels):\n",
        "        if input.dim() == 2:\n",
        "            z = torch.cat((self.label_embedding(labels), input), -1)\n",
        "            x = self.generator(z)\n",
        "            x = x.view(x.size(0), *self.img_shape) #Em\n",
        "            return x\n",
        "        elif input.dim() == 4:\n",
        "            x = torch.cat((input.view(input.size(0), -1), self.label_embedding(labels)), -1)\n",
        "            return self.discriminator(x)\n",
        "\n",
        "    def loss(self, output, label):\n",
        "        return self.adv_loss(output, label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f1a5b73",
      "metadata": {
        "id": "4f1a5b73"
      },
      "source": [
        "### Arquitetura do paper F2U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cbb8292a",
      "metadata": {
        "id": "cbb8292a"
      },
      "outputs": [],
      "source": [
        "class F2U_GAN(nn.Module):\n",
        "    def __init__(self, dataset=\"mnist\", img_size=28, latent_dim=128, condition=True, seed=None):\n",
        "        if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "        super(F2U_GAN, self).__init__()\n",
        "        if dataset == \"mnist\":\n",
        "            self.classes = 10\n",
        "            self.channels = 1\n",
        "        else:\n",
        "            raise NotImplementedError(\"Only MNIST is supported\")\n",
        "\n",
        "        self.condition = condition\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes) if condition else None\n",
        "        #self.label_embedding_disc = nn.Embedding(self.classes, self.img_size*self.img_size) if condition else None\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
        "        self.input_shape_gen = self.latent_dim + self.label_embedding.embedding_dim if condition else self.latent_dim\n",
        "        self.input_shape_disc = self.channels + self.classes if condition else self.channels\n",
        "\n",
        "        self.adv_loss = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "        # Generator (unchanged) To calculate output shape of convtranspose layers, we can use the formula:\n",
        "        # output_shape = (input_shape - 1) * stride - 2 * padding + kernel_size + output_padding (or dilation * (kernel_size - 1) + 1 inplace of kernel_size if using dilation)\n",
        "        self.generator = nn.Sequential(\n",
        "            nn.Linear(self.input_shape_gen, 256 * 7 * 7),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Unflatten(1, (256, 7, 7)),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1), # (256,7,7) -> (128,14,14)\n",
        "            nn.BatchNorm2d(128, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1), # (128,14,14) -> (64,28,28)\n",
        "            nn.BatchNorm2d(64, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64, self.channels, kernel_size=3, stride=1, padding=1), # (64,28,28) -> (1,28,28)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # Discriminator (corrected) To calculate output shape of conv layers, we can use the formula:\n",
        "        # output_shape = ⌊(input_shape - kernel_size + 2 * padding) / stride + 1⌋ (or (dilation * (kernel_size - 1) - 1) inplace of kernel_size if using dilation)\n",
        "        self.discriminator = nn.Sequential(\n",
        "        # Camada 1: (1,28,28) -> (32,13,13)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(self.input_shape_disc, 32, kernel_size=3, stride=2, padding=0)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Camada 2: (32,14,14) -> (64,7,7)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Camada 3: (64,7,7) -> (128,3,3)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=0)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Camada 4: (128,3,3) -> (256,1,1)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=0)),  # Padding 0 aqui!\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Achata e concatena com as labels\n",
        "        nn.Flatten(), # (256,1,1) -> (256*1*1,)\n",
        "        nn.utils.spectral_norm(nn.Linear(256 * 1 * 1, 1))  # 256 (features)\n",
        "        )\n",
        "\n",
        "    def forward(self, input, labels=None):\n",
        "        if input.dim() == 2:\n",
        "            # Generator forward pass (unchanged)\n",
        "            if self.condition:\n",
        "                embedded_labels = self.label_embedding(labels)\n",
        "                gen_input = torch.cat((input, embedded_labels), dim=1)\n",
        "                x = self.generator(gen_input)\n",
        "            else:\n",
        "                x = self.generator(input)\n",
        "            return x.view(-1, *self.img_shape)\n",
        "\n",
        "        elif input.dim() == 4:\n",
        "            # Discriminator forward pass\n",
        "            if self.condition:\n",
        "                embedded_labels = self.label_embedding(labels)\n",
        "                image_labels = embedded_labels.view(embedded_labels.size(0), self.label_embedding.embedding_dim, 1, 1).expand(-1, -1, self.img_size, self.img_size)\n",
        "                x = torch.cat((input, image_labels), dim=1)\n",
        "            else:\n",
        "                x = input\n",
        "            return self.discriminator(x)\n",
        "\n",
        "    def loss(self, output, label):\n",
        "        return self.adv_loss(output, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "c52363e9",
      "metadata": {
        "id": "c52363e9"
      },
      "outputs": [],
      "source": [
        "class F2U_GAN_CIFAR(nn.Module):\n",
        "    def __init__(self, img_size=32, latent_dim=128, condition=True, seed=None):\n",
        "        if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "        super(F2U_GAN_CIFAR, self).__init__()\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.classes = 10\n",
        "        self.channels = 3\n",
        "        self.condition = condition\n",
        "\n",
        "        # Embedding para condicionamento\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes) if self.condition else None\n",
        "\n",
        "        # Shapes de entrada\n",
        "        self.input_shape_gen = self.latent_dim + (self.classes if self.condition else 0)\n",
        "        self.input_shape_disc = self.channels + (self.classes if self.condition else 0)\n",
        "\n",
        "        # -----------------\n",
        "        #  Generator\n",
        "        # -----------------\n",
        "        self.generator = nn.Sequential(\n",
        "            nn.Linear(self.input_shape_gen, 512 * 4 * 4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Unflatten(1, (512, 4, 4)),                  # → (512,4,4)\n",
        "\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),  # → (256,8,8)\n",
        "            nn.BatchNorm2d(256, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # → (128,16,16)\n",
        "            nn.BatchNorm2d(128, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(128,  64, kernel_size=4, stride=2, padding=1),  # → ( 64,32,32)\n",
        "            nn.BatchNorm2d(64,  momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d( 64,   self.channels, kernel_size=3, stride=1, padding=1),  # → (3,32,32)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # -----------------\n",
        "        #  Discriminator\n",
        "        # -----------------\n",
        "        layers = []\n",
        "        in_ch = self.input_shape_disc\n",
        "        cfg = [\n",
        "            ( 64, 3, 1),  # → spatial stays 32\n",
        "            ( 64, 4, 2),  # → 16\n",
        "            (128, 3, 1),  # → 16\n",
        "            (128, 4, 2),  # → 8\n",
        "            (256, 4, 2),  # → 4\n",
        "        ]\n",
        "        for out_ch, k, s in cfg:\n",
        "            layers += [\n",
        "                nn.utils.spectral_norm(\n",
        "                    nn.Conv2d(in_ch, out_ch, kernel_size=k, stride=s, padding=1)\n",
        "                ),\n",
        "                nn.LeakyReLU(0.1, inplace=True)\n",
        "            ]\n",
        "            in_ch = out_ch\n",
        "\n",
        "        layers += [\n",
        "            nn.Flatten(),\n",
        "            nn.utils.spectral_norm(\n",
        "                nn.Linear(256 * 4 * 4, 1)\n",
        "            )\n",
        "        ]\n",
        "        self.discriminator = nn.Sequential(*layers)\n",
        "\n",
        "        # adversarial loss\n",
        "        self.adv_loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, input, labels=None):\n",
        "        # Generator pass\n",
        "        if input.dim() == 2 and input.size(1) == self.latent_dim:\n",
        "            if self.condition:\n",
        "                if labels is None:\n",
        "                    raise ValueError(\"Labels must be provided for conditional generation\")\n",
        "                embedded = self.label_embedding(labels)\n",
        "                gen_input = torch.cat((input, embedded), dim=1)\n",
        "            else:\n",
        "                gen_input = input\n",
        "            img = self.generator(gen_input)\n",
        "            return img\n",
        "\n",
        "        # Discriminator pass\n",
        "        elif input.dim() == 4 and input.size(1) == self.channels:\n",
        "            x = input\n",
        "            if self.condition:\n",
        "                if labels is None:\n",
        "                    raise ValueError(\"Labels must be provided for conditional discrimination\")\n",
        "                embedded = self.label_embedding(labels)\n",
        "                # criar mapa de labels e concatenar\n",
        "                lbl_map = embedded.view(-1, self.classes, 1, 1).expand(-1, self.classes, self.img_size, self.img_size)\n",
        "                x = torch.cat((x, lbl_map), dim=1)\n",
        "            return self.discriminator(x)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Input shape not recognized\")\n",
        "\n",
        "    def loss(self, logits, targets):\n",
        "        return self.adv_loss(logits.view(-1), targets.float().view(-1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "144a24f4",
      "metadata": {
        "id": "144a24f4"
      },
      "source": [
        "## Funções para geração de dataset e imagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b3487d31",
      "metadata": {
        "id": "b3487d31"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn.functional as F\n",
        "import random # Needed for handling remainders if samples aren't perfectly divisible\n",
        "\n",
        "class GeneratedDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 generator,\n",
        "                 num_samples,\n",
        "                 latent_dim=100,\n",
        "                 num_classes=10, # Total classes the generator model knows\n",
        "                 desired_classes=None, # Optional: List of specific class indices to generate\n",
        "                 device=\"cpu\",\n",
        "                 image_col_name=\"image\",\n",
        "                 label_col_name=\"label\"):\n",
        "        \"\"\"\n",
        "        Generates a dataset using a conditional generative model, potentially\n",
        "        focusing on a subset of classes.\n",
        "\n",
        "        Args:\n",
        "            generator: The pre-trained generative model.\n",
        "            num_samples (int): Total number of images to generate across the desired classes.\n",
        "            latent_dim (int): Dimension of the latent space vector (z).\n",
        "            num_classes (int): The total number of classes the generator was trained on.\n",
        "                               This is crucial for correct label conditioning (e.g., one-hot dim).\n",
        "            desired_classes (list[int], optional): A list of integer class indices to generate.\n",
        "                                                  If None or empty, images for all classes\n",
        "                                                  (from 0 to num_classes-1) will be generated,\n",
        "                                                  distributed as evenly as possible.\n",
        "                                                  Defaults to None.\n",
        "            device (str): Device to run generation on ('cpu' or 'cuda').\n",
        "            image_col_name (str): Name for the image column in the output dictionary.\n",
        "            label_col_name (str): Name for the label column in the output dictionary.\n",
        "        \"\"\"\n",
        "        self.generator = generator\n",
        "        self.num_samples = num_samples\n",
        "        self.latent_dim = latent_dim\n",
        "        # Store the total number of classes the generator understands\n",
        "        self.total_num_classes = num_classes\n",
        "        self.device = device\n",
        "        self.model_type = type(self.generator).__name__ # Get generator class name\n",
        "        self.image_col_name = image_col_name\n",
        "        self.label_col_name = label_col_name\n",
        "\n",
        "        # Determine the actual classes to generate based on desired_classes\n",
        "        if desired_classes is not None and len(desired_classes) > 0:\n",
        "            # Validate that desired classes are within the generator's known range\n",
        "            if not all(0 <= c < self.total_num_classes for c in desired_classes):\n",
        "                raise ValueError(f\"All desired classes must be integers between 0 and {self.total_num_classes - 1}\")\n",
        "            # Use only the unique desired classes, sorted for consistency\n",
        "            self._actual_classes_to_generate = sorted(list(set(desired_classes)))\n",
        "        else:\n",
        "            # If no specific classes desired, generate all classes\n",
        "            self._actual_classes_to_generate = list(range(self.total_num_classes))\n",
        "\n",
        "        # The 'classes' attribute of the dataset reflects only those generated\n",
        "        self.classes = self._actual_classes_to_generate\n",
        "        self.num_generated_classes = len(self.classes) # Number of classes being generated\n",
        "\n",
        "        if self.num_generated_classes == 0 and self.num_samples > 0:\n",
        "             raise ValueError(\"Cannot generate samples with an empty list of desired classes.\")\n",
        "        elif self.num_samples == 0:\n",
        "             print(\"Warning: num_samples is 0. Dataset will be empty.\")\n",
        "             self.images = torch.empty(0) # Adjust shape if known\n",
        "             self.labels = torch.empty(0, dtype=torch.long)\n",
        "        else:\n",
        "             # Generate the data only if needed\n",
        "             self.images, self.labels = self.generate_data()\n",
        "\n",
        "\n",
        "    def generate_data(self):\n",
        "        \"\"\"Generates images and corresponding labels for the specified classes.\"\"\"\n",
        "        self.generator.eval()\n",
        "        self.generator.to(self.device)\n",
        "\n",
        "        # --- Create Labels ---\n",
        "        generated_labels_list = []\n",
        "        if self.num_generated_classes > 0:\n",
        "            # Distribute samples as evenly as possible among the desired classes\n",
        "            samples_per_class = self.num_samples // self.num_generated_classes\n",
        "            for cls in self._actual_classes_to_generate:\n",
        "                generated_labels_list.extend([cls] * samples_per_class)\n",
        "\n",
        "            # Handle remaining samples if num_samples is not perfectly divisible\n",
        "            num_remaining = self.num_samples - len(generated_labels_list)\n",
        "            if num_remaining > 0:\n",
        "                # Add remaining samples by randomly choosing from the desired classes\n",
        "                remainder_labels = random.choices(self._actual_classes_to_generate, k=num_remaining)\n",
        "                generated_labels_list.extend(remainder_labels)\n",
        "\n",
        "            # Shuffle labels for better distribution in batches later\n",
        "            random.shuffle(generated_labels_list)\n",
        "\n",
        "        # Convert labels list to tensor\n",
        "        labels = torch.tensor(generated_labels_list, dtype=torch.long, device=self.device)\n",
        "\n",
        "        # Double check label count (should match num_samples due to logic above)\n",
        "        if len(labels) != self.num_samples:\n",
        "             # This indicates an unexpected issue, potentially if num_generated_classes was 0 initially\n",
        "             # but num_samples > 0. Raise error or adjust. Let's adjust defensively.\n",
        "             print(f\"Warning: Label count mismatch. Expected {self.num_samples}, got {len(labels)}. Adjusting size.\")\n",
        "             if len(labels) > self.num_samples:\n",
        "                 labels = labels[:self.num_samples]\n",
        "             else:\n",
        "                 # Pad if too few (less likely with current logic unless num_generated_classes=0)\n",
        "                 num_needed = self.num_samples - len(labels)\n",
        "                 if self.num_generated_classes > 0:\n",
        "                      padding = torch.tensor(random.choices(self._actual_classes_to_generate, k=num_needed), dtype=torch.long, device=self.device)\n",
        "                      labels = torch.cat((labels, padding))\n",
        "                 # If no classes to generate from, labels tensor might remain smaller\n",
        "\n",
        "        # --- Create Latent Noise ---\n",
        "        z = torch.randn(self.num_samples, self.latent_dim, device=self.device)\n",
        "\n",
        "        # --- Generate Images in Batches ---\n",
        "        generated_images_list = []\n",
        "        # Consider making batch_size configurable\n",
        "        batch_size = min(1024, self.num_samples) if self.num_samples > 0 else 1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, self.num_samples, batch_size):\n",
        "                z_batch = z[i : min(i + batch_size, self.num_samples)]\n",
        "                labels_batch = labels[i : min(i + batch_size, self.num_samples)]\n",
        "\n",
        "                # Skip if batch is empty (can happen if num_samples = 0)\n",
        "                if z_batch.shape[0] == 0:\n",
        "                    continue\n",
        "\n",
        "                # --- Condition the generator based on its type ---\n",
        "                if self.model_type == 'Generator': # Assumes input: concat(z, one_hot_label)\n",
        "                    # One-hot encode labels using the TOTAL number of classes the generator knows\n",
        "                    labels_one_hot_batch = F.one_hot(labels_batch, num_classes=self.total_num_classes).float()\n",
        "                    generator_input = torch.cat([z_batch, labels_one_hot_batch], dim=1)\n",
        "                    gen_imgs = self.generator(generator_input)\n",
        "                elif self.model_type in ('CGAN', 'F2U_GAN', 'F2U_GAN_CIFAR'): # Assumes input: z, label_index\n",
        "                    gen_imgs = self.generator(z_batch, labels_batch)\n",
        "                else:\n",
        "                    # Handle other potential generator architectures or raise an error\n",
        "                    raise NotImplementedError(f\"Generation logic not defined for model type: {self.model_type}\")\n",
        "\n",
        "                generated_images_list.append(gen_imgs.cpu()) # Move generated images to CPU\n",
        "\n",
        "        self.generator.cpu() # Move generator back to CPU after generation\n",
        "\n",
        "        # Concatenate all generated image batches\n",
        "        if generated_images_list:\n",
        "            all_gen_imgs = torch.cat(generated_images_list, dim=0)\n",
        "        else:\n",
        "            # If no images were generated (e.g., num_samples = 0)\n",
        "            # Create an empty tensor. Shape needs care - determine from generator or use placeholder.\n",
        "            # Let's attempt a placeholder [0, C, H, W] - requires knowing C, H, W.\n",
        "            # For now, a simple empty tensor. User might need to handle this downstream.\n",
        "            print(\"Warning: No images generated. Returning empty tensor for images.\")\n",
        "            all_gen_imgs = torch.empty(0)\n",
        "\n",
        "        return all_gen_imgs, labels.cpu() # Return images and labels (on CPU)\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the actual number of samples generated\n",
        "        return self.images.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= len(self):\n",
        "            raise IndexError(\"Dataset index out of range\")\n",
        "        return {\n",
        "            self.image_col_name: self.images[idx],\n",
        "            self.label_col_name: int(self.labels[idx]) # Return label as standard Python int\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b1c3d341",
      "metadata": {
        "id": "b1c3d341"
      },
      "outputs": [],
      "source": [
        "class UnconditionalGeneratedDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 generator,\n",
        "                 num_samples,\n",
        "                 latent_dim=128,\n",
        "                 device=\"cpu\",\n",
        "                 image_col_name=\"image\"):\n",
        "        \"\"\"\n",
        "        Generates a dataset using an unconditional generative model.\n",
        "\n",
        "        Args:\n",
        "            generator: The pre-trained unconditional generative model.\n",
        "            num_samples (int): Total number of images to generate.\n",
        "            latent_dim (int): Dimension of the latent space vector (z).\n",
        "            device (str): Device to run generation on ('cpu' or 'cuda').\n",
        "            image_col_name (str): Name for the image column in the output dictionary.\n",
        "        \"\"\"\n",
        "        self.generator = generator\n",
        "        self.num_samples = num_samples\n",
        "        self.latent_dim = latent_dim\n",
        "        self.device = device\n",
        "        self.image_col_name = image_col_name\n",
        "\n",
        "        if self.num_samples < 0:\n",
        "            raise ValueError(\"num_samples must be non-negative\")\n",
        "        elif self.num_samples == 0:\n",
        "            print(\"Warning: num_samples is 0. Dataset will be empty.\")\n",
        "            self.images = torch.empty(0)\n",
        "        else:\n",
        "            self.images = self._generate_images()\n",
        "\n",
        "    def _generate_images(self):\n",
        "        self.generator.eval()\n",
        "        self.generator.to(self.device)\n",
        "\n",
        "        # Create latent noise\n",
        "        z = torch.randn(self.num_samples, self.latent_dim, device=self.device)\n",
        "\n",
        "        # Generate images in batches\n",
        "        generated_images = []\n",
        "        batch_size = min(1024, self.num_samples)\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, self.num_samples, batch_size):\n",
        "                z_batch = z[i : min(i + batch_size, self.num_samples)]\n",
        "                gen_imgs = self.generator(z_batch)\n",
        "                generated_images.append(gen_imgs.cpu())\n",
        "\n",
        "        self.generator.cpu()\n",
        "        return torch.cat(generated_images, dim=0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= len(self):\n",
        "            raise IndexError(\"Dataset index out of range\")\n",
        "        return { self.image_col_name: self.images[idx] }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9452cf54",
      "metadata": {
        "id": "9452cf54"
      },
      "outputs": [],
      "source": [
        "def generate_plot(net, device, round_number, client_id = None, examples_per_class: int=5, classes: int=10, latent_dim: int=100):\n",
        "    \"\"\"Gera plot de imagens de cada classe\"\"\"\n",
        "\n",
        "    net_type = type(net).__name__\n",
        "    net.to(device)\n",
        "    net.eval()\n",
        "    batch_size = examples_per_class * classes\n",
        "    dataset = \"mnist\" if  not net_type == \"F2U_GAN_CIFAR\" else \"cifar10\"\n",
        "\n",
        "    latent_vectors = torch.randn(batch_size, latent_dim, device=device)\n",
        "    labels = torch.tensor([i for i in range(classes) for _ in range(examples_per_class)], device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if net_type == \"Generator\":\n",
        "            labels_one_hot = torch.nn.functional.one_hot(labels, 10).float().to(device)\n",
        "            generated_images = net(torch.cat([latent_vectors, labels_one_hot], dim=1))\n",
        "        else:\n",
        "            generated_images = net(latent_vectors, labels)\n",
        "\n",
        "    # Criar uma figura com 10 linhas e 5 colunas de subplots\n",
        "    fig, axes = plt.subplots(classes, examples_per_class, figsize=(5, 9))\n",
        "\n",
        "    # Adiciona título no topo da figura\n",
        "    if isinstance(client_id, int):\n",
        "        fig.text(0.5, 0.98, f\"Round: {round_number} | Client: {client_id}\", ha=\"center\", fontsize=12)\n",
        "    else:\n",
        "        fig.text(0.5, 0.98, f\"Round: {round_number}\", ha=\"center\", fontsize=12)\n",
        "\n",
        "    # Exibir as imagens nos subplots\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if dataset == \"mnist\":\n",
        "            ax.imshow(generated_images[i, 0, :, :], cmap='gray')\n",
        "        else:\n",
        "            images = (generated_images[i] + 1)/2\n",
        "            ax.imshow(images.permute(1, 2, 0).clamp(0,1))\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "    # Ajustar o layout antes de calcular as posições\n",
        "    plt.tight_layout(rect=[0.05, 0, 1, 0.96])\n",
        "\n",
        "    # Reduzir espaço entre colunas\n",
        "    # plt.subplots_adjust(wspace=0.05)\n",
        "\n",
        "    # Adicionar os rótulos das classes corretamente alinhados\n",
        "    fig.canvas.draw()  # Atualiza a renderização para obter posições corretas\n",
        "    for row in range(classes):\n",
        "        # Obter posição do subplot em coordenadas da figura\n",
        "        bbox = axes[row, 0].get_window_extent(fig.canvas.get_renderer())\n",
        "        pos = fig.transFigure.inverted().transform([(bbox.x0, bbox.y0), (bbox.x1, bbox.y1)])\n",
        "        center_y = (pos[0, 1] + pos[1, 1]) / 2  # Centro exato da linha\n",
        "\n",
        "        # Adicionar o rótulo\n",
        "        fig.text(0.04, center_y, str(row), va='center', fontsize=12, color='black')\n",
        "\n",
        "    IN_COLAB = False\n",
        "    try:\n",
        "        # Tenta importar um módulo específico do Colab\n",
        "        import google.colab\n",
        "        IN_COLAB = True\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    if IN_COLAB:\n",
        "        if isinstance(client_id, int):\n",
        "            fig.savefig(os.path.join(save_dir, f\"{dataset}_{net_type}_r{round_number}_c{client_id}.png\"))\n",
        "            print(\"Imagem do cliente salva no drive\")\n",
        "        else:\n",
        "            fig.savefig(os.path.join(save_dir, f\"{dataset}{net_type}_r{round_number}.png\"))\n",
        "            print(\"Imagem do servidor salva no drive\")\n",
        "    else:\n",
        "        if isinstance(client_id, int):\n",
        "            fig.savefig(f\"{dataset}{net_type}_r{round_number}_c{client_id}.png\")\n",
        "            print(\"Imagem do cliente salva\")\n",
        "        else:\n",
        "            fig.savefig(f\"{dataset}{net_type}_r{round_number}.png\")\n",
        "            print(\"Imagem do servidor salva\")\n",
        "    plt.close(fig)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3a88e7c6",
      "metadata": {
        "id": "3a88e7c6"
      },
      "outputs": [],
      "source": [
        "def plot_unconditional_generated(\n",
        "        generator,\n",
        "        device,\n",
        "        total_samples,\n",
        "        samples_per_row=5,\n",
        "        latent_dim=100,\n",
        "        save_path=None,\n",
        "        round_number=None):\n",
        "    \"\"\"\n",
        "    Generates and plots images from an unconditional generator in a grid.\n",
        "\n",
        "    Args:\n",
        "        generator: The unconditional torch generator model (z -> image).\n",
        "        device: Device to run generation on ('cpu' or 'cuda').\n",
        "        total_samples (int): Number of images to generate.\n",
        "        samples_per_row (int): Number of images per row in the grid.\n",
        "        latent_dim (int): Dimension of latent vector.\n",
        "        save_path (str, optional): Filepath to save the figure. If None, just shows plot.\n",
        "    \"\"\"\n",
        "\n",
        "    generator.eval()\n",
        "    generator.to(device)\n",
        "\n",
        "    # Sample latent vectors\n",
        "    z = torch.randn(total_samples, latent_dim, device=device)\n",
        "    with torch.no_grad():\n",
        "        imgs = generator(z)\n",
        "\n",
        "    # Determine grid size\n",
        "    cols = samples_per_row\n",
        "    rows = math.ceil(total_samples / cols)\n",
        "\n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(cols-2*cols/(rows+cols), rows-1*rows/(rows+cols)))\n",
        "    axes = axes.flatten() if total_samples > 1 else [axes]\n",
        "\n",
        "    fig.text(0.5, 0.99, f\"Round: {round_number}\", ha=\"center\", fontsize=11)\n",
        "\n",
        "    for idx in range(rows * cols):\n",
        "        ax = axes[idx]\n",
        "        ax.axis('off')\n",
        "        if idx < total_samples:\n",
        "            img = imgs[idx]\n",
        "            # Assume (C, H, W) and single-channel\n",
        "            ax.imshow(img[0], cmap='gray')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "        fig.savefig(save_path)\n",
        "        print(f\"Figure saved to {save_path}\")\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "    plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bd1a6ff",
      "metadata": {
        "id": "5bd1a6ff"
      },
      "source": [
        "## Importa Pacotes Federado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3e7c02c2",
      "metadata": {
        "id": "3e7c02c2"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    !pip install flwr_datasets\n",
        "    !pip install flwr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9793cd9a",
      "metadata": {
        "id": "9793cd9a"
      },
      "outputs": [],
      "source": [
        "from flwr_datasets.partitioner import DirichletPartitioner, IidPartitioner\n",
        "from flwr_datasets.visualization import plot_label_distributions\n",
        "from flwr_datasets import FederatedDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5ac2e55",
      "metadata": {
        "id": "a5ac2e55"
      },
      "source": [
        "## Particionador por classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3acd60f5",
      "metadata": {
        "id": "3acd60f5"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Flower Labs GmbH. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Class-based partitioner for Hugging Face Datasets.\"\"\"\n",
        "\n",
        "\n",
        "from collections import defaultdict\n",
        "import random\n",
        "from typing import Optional, List\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from flwr_datasets.partitioner.partitioner import Partitioner  # Assuming this is in the package structure\n",
        "\n",
        "\n",
        "class ClassPartitioner(Partitioner):\n",
        "    \"\"\"Partitions a dataset by class, ensuring each class appears in exactly one partition.\n",
        "\n",
        "    Attributes:\n",
        "        num_partitions (int): Total number of partitions to create\n",
        "        seed (int, optional): Random seed for reproducibility\n",
        "        label_column (str): Name of the column containing class labels\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_partitions: int,\n",
        "        seed: Optional[int] = None,\n",
        "        label_column: str = \"label\"\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self._num_partitions = num_partitions\n",
        "        self._seed = seed\n",
        "        self._label_column = label_column\n",
        "        self._partition_indices: Optional[List[List[int]]] = None\n",
        "\n",
        "    def _create_partitions(self) -> None:\n",
        "        \"\"\"Create class-based partitions and store indices.\"\"\"\n",
        "        # Extract labels from dataset\n",
        "        labels = self.dataset[self._label_column]\n",
        "\n",
        "        # Group indices by class\n",
        "        class_indices = defaultdict(list)\n",
        "        for idx, label in enumerate(labels):\n",
        "            class_indices[label].append(idx)\n",
        "\n",
        "        classes = list(class_indices.keys())\n",
        "        num_classes = len(classes)\n",
        "\n",
        "        # Validate number of partitions\n",
        "        if self._num_partitions > num_classes:\n",
        "            raise ValueError(\n",
        "                f\"Cannot create {self._num_partitions} partitions with only {num_classes} classes. \"\n",
        "                f\"Reduce partitions to ≤ {num_classes}.\"\n",
        "            )\n",
        "\n",
        "        # Shuffle classes for random distribution\n",
        "        rng = random.Random(self._seed)\n",
        "        rng.shuffle(classes)\n",
        "\n",
        "        # Split classes into partitions\n",
        "        partition_classes = np.array_split(classes, self._num_partitions)\n",
        "\n",
        "        # Create index lists for each partition\n",
        "        self._partition_indices = []\n",
        "        for class_group in partition_classes:\n",
        "            indices = []\n",
        "            for cls in class_group:\n",
        "                indices.extend(class_indices[cls])\n",
        "            self._partition_indices.append(indices)\n",
        "\n",
        "    @property\n",
        "    def dataset(self) -> Dataset:\n",
        "        return super().dataset\n",
        "\n",
        "    @dataset.setter\n",
        "    def dataset(self, value: Dataset) -> None:\n",
        "        # Use parent setter for basic validation\n",
        "        super(ClassPartitioner, ClassPartitioner).dataset.fset(self, value)\n",
        "\n",
        "        # Create partitions once dataset is set\n",
        "        self._create_partitions()\n",
        "\n",
        "    def load_partition(self, partition_id: int) -> Dataset:\n",
        "        \"\"\"Load a partition containing exclusive classes.\n",
        "\n",
        "        Args:\n",
        "            partition_id: The ID of the partition to load (0-based index)\n",
        "\n",
        "        Returns:\n",
        "            Dataset: Subset of the dataset containing only the specified partition's data\n",
        "        \"\"\"\n",
        "        if not self.is_dataset_assigned():\n",
        "            raise RuntimeError(\"Dataset must be assigned before loading partitions\")\n",
        "        if partition_id < 0 or partition_id >= self.num_partitions:\n",
        "            raise ValueError(f\"Invalid partition ID: {partition_id}\")\n",
        "\n",
        "        return self.dataset.select(self._partition_indices[partition_id])\n",
        "\n",
        "    @property\n",
        "    def num_partitions(self) -> int:\n",
        "        return self._num_partitions\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f\"ClassPartitioner(num_partitions={self._num_partitions}, \"\n",
        "                f\"seed={self._seed}, label_column='{self._label_column}')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1ee55f5",
      "metadata": {
        "id": "a1ee55f5"
      },
      "source": [
        "## Carrega e divide dados entre clientes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6fdba10d",
      "metadata": {
        "id": "6fdba10d"
      },
      "outputs": [],
      "source": [
        "num_partitions = 4\n",
        "alpha_dir = 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cd9c472",
      "metadata": {
        "id": "6cd9c472"
      },
      "source": [
        "Rodar somente o particionador desejado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "42644935",
      "metadata": {
        "id": "42644935"
      },
      "outputs": [],
      "source": [
        "partitioner = ClassPartitioner(num_partitions=num_partitions, seed=42, label_column=\"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "312626b5",
      "metadata": {
        "id": "312626b5"
      },
      "outputs": [],
      "source": [
        "partitioner = DirichletPartitioner(\n",
        "    num_partitions=num_partitions,\n",
        "    partition_by=\"label\",\n",
        "    alpha=alpha_dir,\n",
        "    min_partition_size=0,\n",
        "    self_balancing=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8582a179",
      "metadata": {
        "id": "8582a179"
      },
      "outputs": [],
      "source": [
        "partitioner = IidPartitioner(\n",
        "    num_partitions=num_partitions\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a3f9a435",
      "metadata": {
        "id": "a3f9a435"
      },
      "outputs": [],
      "source": [
        "fds = FederatedDataset(\n",
        "    dataset=\"mnist\",\n",
        "    partitioners={\"train\": partitioner}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "7d21553c",
      "metadata": {
        "id": "7d21553c"
      },
      "outputs": [],
      "source": [
        "fds = FederatedDataset(\n",
        "    dataset=\"cifar10\",\n",
        "    partitioners={\"train\": partitioner}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "026da6c7",
      "metadata": {
        "id": "026da6c7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqwAAAHHCAYAAAB6GQo0AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUZZJREFUeJzt3XlclWX+//H3AQRcWERlKwTcwF1DI6xcJhINm2wdbRGXNAvM1MycMXPJITNNy4WayaXScZnUHHNUxNRMLMVwKxktyBaQMhVXQLh/f/Tl/DyBG+fguc3X8/E4j4f3dV/nuj83h+rd5XWu22IYhiEAAADApFycXQAAAABwKQRWAAAAmBqBFQAAAKZGYAUAAICpEVgBAABgagRWAAAAmBqBFQAAAKZGYAUAAICpEVgBAABgagRWAFetb9++CgsLu6K+48aNk8ViqdqCroHOnTurRYsWDh0zLCxMffv2deiYkpSTkyOLxaL58+c7fOzfmz9/viwWi3JycqxtYWFh6tGjR5VfW5I2bdoki8WiTZs2XZPrAXAOAitwlcr+A1328vT0VJMmTZSUlKQjR45U+fXLAmDZq0aNGmrWrJnGjBmjgoICh13np59+0rhx45SZmXnZvmfOnNG4ceNMFxosFouSkpKcXYbdLvy83dzc5Ofnp6ioKA0dOlRfffWVw64ze/bsaxJyK8PMtQGoem7OLgC4Xk2YMEHh4eE6d+6ctm7dqjlz5mjNmjXat2+fatSoUeXXnzNnjmrVqqVTp05p/fr1mjRpkjZu3KjPPvvMITOaP/30k8aPH6+wsDC1adPG5tw//vEPlZaWWo/PnDmj8ePHS/ptJvJCY8aM0Ysvvmh3PTe6u+++W3369JFhGDpx4oR2796tBQsWaPbs2Zo8ebKGDx9u7RsaGqqzZ8+qWrVqV3WN2bNnq27dulc16/vEE0+oV69e8vDwuKprXa2L1daxY0edPXtW7u7uVXp9AM5FYAUqqXv37mrXrp0k6cknn1SdOnU0bdo0ffTRR+rdu7ddY585c+ayofehhx5S3bp1JUmDBw/Wgw8+qOXLl2v79u2KiYmp9LXPnz9vE0YrcjVByM3NTW5u/KvGXk2aNNHjjz9u0/bqq6/q3nvv1YgRIxQZGal77rlHkqwz/1Xp9OnTqlmzplxdXeXq6lql17oUFxeXKr9XAM7HkgDAQf70pz9JkrKzs61tH3zwgaKiolS9enX5+fmpV69e+v77723eV7Y2MiMjQx07dlSNGjX017/+1a7rFxUVaezYsYqKipKPj49q1qypO++8U5988onNe8rWOr7++uuaPn26GjZsKA8PD82ePVvt27eXJPXr18/619FlfyV74RrWnJwc1atXT5I0fvx4a99x48ZJqngN6/nz5zVx4kTr9cLCwvTXv/5VhYWFNv3K1kJu3bpVt956qzw9PdWgQQO99957V/3zuZiPPvpI8fHxCg4OloeHhxo2bKiJEyeqpKSkwv4ZGRnq0KGDqlevrvDwcKWkpJTrU1hYqJdfflmNGjWSh4eHQkJC9MILL5S7P3vVqVNHixcvlpubmyZNmmRtr2gNa15envr166ebb75ZHh4eCgoK0n333WddexoWFqb9+/dr8+bN1s+wbLa8bBnM5s2b9cwzz8jf318333yzzbkL17CWWb9+vdq0aSNPT081a9ZMy5cvtzl/sfXNvx/zUrVdbA3rsmXLrP/s1a1bV48//rh+/PFHmz59+/ZVrVq19OOPP6pnz56qVauW6tWrp+eff/6inz8A52DaA3CQb775RtJvIUKSJk2apJdeekmPPPKInnzySf38889666231LFjR3355Zfy9fW1vvfo0aPq3r27evXqpccff1wBAQF2Xb+goED//Oc/1bt3bw0cOFAnT57Uu+++q7i4OH3xxRfl/op/3rx5OnfunAYNGiQPDw/df//9OnnypMaOHatBgwbpzjvvlCR16NCh3HXr1aunOXPm6Omnn9b999+vBx54QJLUqlWri9b65JNPasGCBXrooYc0YsQIff7550pOTtbXX3+tFStW2PQ9dOiQHnroIQ0YMEAJCQmaO3eu+vbtq6ioKDVv3vyqf06/N3/+fNWqVUvDhw9XrVq1tHHjRo0dO1YFBQWaMmWKTd9jx47pnnvu0SOPPKLevXtr6dKlevrpp+Xu7q7+/ftLkkpLS/XnP/9ZW7du1aBBg9S0aVPt3btXb7zxhv73v/9p5cqVdtd8ofr166tTp0765JNPVFBQIG9v7wr7Pfjgg9q/f7+GDBmisLAw5efnKzU1VYcPH1ZYWJimT5+uIUOGqFatWvrb3/4mSeV+D5955hnVq1dPY8eO1enTpy9Z18GDB/WXv/xFgwcPVkJCgubNm6eHH35Ya9eu1d13331V93gltV1o/vz56tevn9q3b6/k5GQdOXJEM2bM0GeffVbun72SkhLFxcUpOjpar7/+ujZs2KCpU6eqYcOGevrpp6+qTgBVyABwVebNm2dIMjZs2GD8/PPPxvfff28sXrzYqFOnjlG9enXjhx9+MHJycgxXV1dj0qRJNu/du3ev4ebmZtPeqVMnQ5KRkpJyRdd/+eWXDUlGVlaW8fPPPxvZ2dnG22+/bXh4eBgBAQHG6dOnjfPnzxuFhYU27zt27JgREBBg9O/f39qWnZ1tSDK8vb2N/Px8m/47duwwJBnz5s0rV0NCQoIRGhpqPf75558NScbLL7980XrLZGZmGpKMJ5980qbf888/b0gyNm7caG0LDQ01JBlbtmyxtuXn5xseHh7GiBEjLvlzMgzDkGQkJiZess+ZM2fKtT311FNGjRo1jHPnzlnbyj6nqVOnWtsKCwuNNm3aGP7+/kZRUZFhGIbx/vvvGy4uLsann35qM2ZKSoohyfjss89s7i8hIcHu+xg6dKghydi9e7dhGP//cy377I4dO2ZIMqZMmXLJ6zRv3tzo1KlTufay3/k77rjDOH/+fIXnsrOzbe5LkvHhhx9a206cOGEEBQUZbdu2tbb9/nfjUmNerLZPPvnEkGR88sknhmEYRlFRkeHv72+0aNHCOHv2rLXf6tWrDUnG2LFjrW0JCQmGJGPChAk2Y7Zt29aIiooqdy0AzsOSAKCSYmNjVa9ePYWEhKhXr16qVauWVqxYoZtuuknLly9XaWmpHnnkEf3yyy/WV2BgoBo3blzur+Y9PDzUr1+/q7p+RESE6tWrp/DwcD311FNq1KiRPv74Y9WoUUOurq7WL6GUlpbq119/1fnz59WuXTvt2rWr3FgPPvig9a/1q9qaNWskyeZLQpI0YsQISdLHH39s096sWTPrDK/024xuRESEvv32W4fUU716deufT548qV9++UV33nmnzpw5owMHDtj0dXNz01NPPWU9dnd311NPPaX8/HxlZGRI+u2vops2barIyEibz75sycbvP3tHqFWrlrX+ilSvXl3u7u7atGmTjh07VunrDBw48IrXqwYHB+v++++3Hnt7e6tPnz768ssvlZeXV+kaLmfnzp3Kz8/XM888Y7O2NT4+XpGRkeV+v6Tf1oBf6M4773TY7xcAx2BJAFBJs2bNUpMmTeTm5qaAgABFRETIxeW3/wc8ePCgDMNQ48aNK3zv77+0dNNNN131t5w//PBDeXt7q1q1arr55pvVsGFDm/MLFizQ1KlTdeDAARUXF1vbw8PDy41VUVtV+e677+Ti4qJGjRrZtAcGBsrX11ffffedTXv9+vXLjVG7dm27gteF9u/frzFjxmjjxo3ltgU7ceKEzXFwcLBq1qxp09akSRNJv60bve2223Tw4EF9/fXXF/0fgPz8fIfUfaFTp05Jkry8vCo87+HhocmTJ2vEiBEKCAjQbbfdph49eqhPnz4KDAy84utcze9Jo0aNyq1PvfBndTXXvRplvz8RERHlzkVGRmrr1q02bZ6enuU+K0f+fgFwDAIrUEm33nqrdZeA3ystLZXFYtF///vfCmekymbEylw4y3elOnbsaN0l4Pc++OAD9e3bVz179tTIkSPl7+8vV1dXJScnW9e62nt9e13p1lsXm9EzDMPuGo4fP65OnTrJ29tbEyZMUMOGDeXp6aldu3Zp1KhRl90toSKlpaVq2bKlpk2bVuH5kJAQe8suZ9++fXJ1db1koHzuued07733auXKlVq3bp1eeuklJScna+PGjWrbtu0VXcfRvycX+x24ll94cuYOBwCuHIEVqAINGzaUYRgKDw+3zipdS//+97/VoEEDLV++3CYUvPzyy1c8xtXs5Xo1fUNDQ1VaWqqDBw+qadOm1vYjR47o+PHjCg0NveKx7LVp0yYdPXpUy5cvV8eOHa3tF+70cKGffvrJup1Tmf/973+SZN01oWHDhtq9e7fuuuuua/KEr8OHD2vz5s2KiYm56AxrmYYNG2rEiBEaMWKEDh48qDZt2mjq1Kn64IMPJF3d53g5hw4dkmEYNmP+/mdVu3ZtSb/9j8OFX4T6/Sz71dRW9vuTlZVlXYZRJisr65r+fgFwHNawAlXggQcekKurq8aPH19uJtAwDB09erRKr182a3ThtT///HOlp6df8Rhloez48eOX7Vu2Z+yV9C3bK3T69Ok27WUzkvHx8Vdco70q+jkVFRVp9uzZFfY/f/683n77bZu+b7/9turVq6eoqChJ0iOPPKIff/xR//jHP8q9/+zZs5f9dv3V+PXXX9W7d2+VlJRYvz1fkTNnzujcuXM2bQ0bNpSXl5fNVls1a9a8os/wSvz00082Oz4UFBTovffeU5s2bazLAcqWsWzZssXa7/Tp01qwYEG58a60tnbt2snf318pKSk29/bf//5XX3/99TX9/QLgOMywAlWgYcOGeuWVVzR69Gjl5OSoZ8+e8vLyUnZ2tlasWKFBgwbp+eefr7Lr9+jRQ8uXL9f999+v+Ph4ZWdnKyUlRc2aNbOud7ySe/D19VVKSoq8vLxUs2ZNRUdHV/jXztWrV1ezZs20ZMkSNWnSRH5+fmrRooVatGhRrm/r1q2VkJCgd955x/pX8l988YUWLFignj17qkuXLnbf/4V27typV155pVx7586d1aFDB9WuXVsJCQl69tlnZbFY9P777190uUFwcLAmT56snJwcNWnSREuWLFFmZqbeeecd67rkJ554QkuXLtXgwYP1ySef6Pbbb1dJSYkOHDigpUuXat26dRddSnIp//vf//TBBx/IMAwVFBRo9+7dWrZsmU6dOqVp06apW7dul3zvXXfdpUceeUTNmjWTm5ubVqxYoSNHjqhXr17WflFRUZozZ45eeeUVNWrUSP7+/uVmKa9UkyZNNGDAAO3YsUMBAQGaO3eujhw5onnz5ln7dO3aVfXr19eAAQM0cuRIubq6au7cuapXr54OHz5sM96V1latWjVNnjxZ/fr1U6dOndS7d2/rtlZhYWEaNmxYpe4HgJM5a3sC4HpVtuXOjh07Ltv3ww8/NO644w6jZs2aRs2aNY3IyEgjMTHRyMrKsvbp1KmT0bx58yu+ftlWQD///PNF+5SWlhp///vfjdDQUMPDw8No27atsXr16nLbUZVtf3Sx7Y4++ugjo1mzZoabm5vNNkm/H8cwDGPbtm1GVFSU4e7ubrPFVUVbFxUXFxvjx483wsPDjWrVqhkhISHG6NGjbbaRMozftkeKj48vV1enTp0q3OLo9yRd9DVx4kTDMAzjs88+M2677TajevXqRnBwsPHCCy8Y69ats9kqqeyazZs3N3bu3GnExMQYnp6eRmhoqDFz5sxy1y0qKjImT55sNG/e3PDw8DBq165tREVFGePHjzdOnDhhc39Xuq1V2cvFxcXw9fU12rZtawwdOtTYv39/uf6/39bql19+MRITE43IyEijZs2aho+PjxEdHW0sXbrU5n15eXlGfHy84eXlZUiy/owv9Tt/sW2t4uPjjXXr1hmtWrUyPDw8jMjISGPZsmXl3p+RkWFER0cb7u7uRv369Y1p06ZVOObFavv9tlZllixZYrRt29bw8PAw/Pz8jMcee8z44YcfbPokJCQYNWvWLFfTxbbbAuA8FsNwwDcXAAAAgCrCGlYAAACYGoEVAAAApkZgBQAAgKkRWAEAAGBqBFYAAACYGoEVAAAApsaDAxyktLRUP/30k7y8vK7J4xgBAID9DMPQyZMnFRwcLBcX5vHMisDqID/99JNCQkKcXQYAAKiE77//XjfffLOzy8BFEFgdxMvLS9Jvv/De3t5OrgYAAFyJgoIChYSEWP87DnMisDpI2TIAb29vAisAANcZlvOZG4s1AAAAYGoEVgAAAJgagRUAAACmRmAFAACAqRFYAQAAYGoEVgAAAJgagRUAAACmRmAFAACAqRFYAQAAYGoEVgAAAJgagRUAAACmRmAFAACAqRFYAQAAYGoEVgAAAJgagRUAAACm5ubsAuAYa797wdklOEW30NecXQIAAKhizLACAADA1AisAAAAMDUCKwAAAEyNwAoAAABTI7ACAADA1AisAAAAMDUCKwAAAEyNwAoAAABTI7ACAADA1AisAAAAMDUCKwAAAEyNwAoAAABTc3N2AQCunuXp25xdglMYc7Y7uwQAgBMwwwoAAABTI7ACAADA1AisAAAAMDWnBtYtW7bo3nvvVXBwsCwWi1auXGlz3mKxVPiaMmWKtU9YWFi586+++qrNOHv27NGdd94pT09PhYSE6LXXXitXy7JlyxQZGSlPT0+1bNlSa9asqZJ7BgAAwNVxamA9ffq0WrdurVmzZlV4Pjc31+Y1d+5cWSwWPfjggzb9JkyYYNNvyJAh1nMFBQXq2rWrQkNDlZGRoSlTpmjcuHF65513rH22bdum3r17a8CAAfryyy/Vs2dP9ezZU/v27auaGwcAAMAVc+ouAd27d1f37t0vej4wMNDm+KOPPlKXLl3UoEEDm3YvL69yfcssXLhQRUVFmjt3rtzd3dW8eXNlZmZq2rRpGjRokCRpxowZ6tatm0aOHClJmjhxolJTUzVz5kylpKTYc4sAAACw03WzhvXIkSP6+OOPNWDAgHLnXn31VdWpU0dt27bVlClTdP78eeu59PR0dezYUe7u7ta2uLg4ZWVl6dixY9Y+sbGxNmPGxcUpPT39ovUUFhaqoKDA5gUAAADHu272YV2wYIG8vLz0wAMP2LQ/++yzuuWWW+Tn56dt27Zp9OjRys3N1bRp0yRJeXl5Cg8Pt3lPQECA9Vzt2rWVl5dnbbuwT15e3kXrSU5O1vjx4x1xawAAALiE6yawzp07V4899pg8PT1t2ocPH279c6tWreTu7q6nnnpKycnJ8vDwqLJ6Ro8ebXPtgoIChYSEVNn1AAAAblTXRWD99NNPlZWVpSVLlly2b3R0tM6fP6+cnBxFREQoMDBQR44cselTdly27vVifS62LlaSPDw8qjQQAwAA4DfXxRrWd999V1FRUWrduvVl+2ZmZsrFxUX+/v6SpJiYGG3ZskXFxcXWPqmpqYqIiFDt2rWtfdLS0mzGSU1NVUxMjAPvAgAAAJXh1MB66tQpZWZmKjMzU5KUnZ2tzMxMHT582NqnoKBAy5Yt05NPPlnu/enp6Zo+fbp2796tb7/9VgsXLtSwYcP0+OOPW8Poo48+Knd3dw0YMED79+/XkiVLNGPGDJu/zh86dKjWrl2rqVOn6sCBAxo3bpx27typpKSkqv0BAAAA4LKcuiRg586d6tKli/W4LEQmJCRo/vz5kqTFixfLMAz17t273Ps9PDy0ePFijRs3ToWFhQoPD9ewYcNswqiPj4/Wr1+vxMRERUVFqW7duho7dqx1SytJ6tChgxYtWqQxY8bor3/9qxo3bqyVK1eqRYsWVXTnAAAAuFIWwzAMZxfxR1BQUCAfHx+dOHFC3t7e1/z6a7974Zpf0wy6hZZ/atmNwPL0bc4uwSmMOdudXQKAPxhn//cbV+a6WMMKAACAGxeBFQAAAKZGYAUAAICpEVgBAABgagRWAAAAmBqBFQAAAKZGYAUAAICpEVgBAABgagRWAAAAmBqBFQAAAKZGYAUAAICpEVgBAABgagRWAAAAmBqBFQAAAKZGYAUAAICpEVgBAABgagRWAAAAmBqBFQAAAKbm5uwCAAAAULGSkhIVFxc7u4wqUa1aNbm6ul5RXwIrAACAyRiGoby8PB0/ftzZpVQpX19fBQYGymKxXLIfgRUAAMBkysKqv7+/atSocdlAd70xDENnzpxRfn6+JCkoKOiS/QmsAAAAJlJSUmINq3Xq1HF2OVWmevXqkqT8/Hz5+/tfcnkAX7oCAAAwkbI1qzVq1HByJVWv7B4vt06XwAoAAGBCf7RlABW50nsksAIAAMDUCKwAAAA3kPnz58vX19fucSwWi1auXGn3OFeCwAoAAHCd6du3r3r27OnsMq4ZAisAAABMjcAKAADwBzJt2jS1bNlSNWvWVEhIiJ555hmdOnWqXL+VK1eqcePG8vT0VFxcnL7//nub8x999JFuueUWeXp6qkGDBho/frzOnz9f4TWLioqUlJSkoKAgeXp6KjQ0VMnJyQ67JwIrAADAH4iLi4vefPNN7d+/XwsWLNDGjRv1wgsv2PQ5c+aMJk2apPfee0+fffaZjh8/rl69elnPf/rpp+rTp4+GDh2qr776Sm+//bbmz5+vSZMmVXjNN998U6tWrdLSpUuVlZWlhQsXKiwszGH3xIMDAAAA/kCee+4565/DwsL0yiuvaPDgwZo9e7a1vbi4WDNnzlR0dLQkacGCBWratKm++OIL3XrrrRo/frxefPFFJSQkSJIaNGigiRMn6oUXXtDLL79c7pqHDx9W48aNdccdd8hisSg0NNSh98QMKwAAwB/Ihg0bdNddd+mmm26Sl5eXnnjiCR09elRnzpyx9nFzc1P79u2tx5GRkfL19dXXX38tSdq9e7cmTJigWrVqWV8DBw5Ubm6uzThl+vbtq8zMTEVEROjZZ5/V+vXrHXpPBFYAAIA/iJycHPXo0UOtWrXShx9+qIyMDM2aNUvSb+tMr9SpU6c0fvx4ZWZmWl979+7VwYMH5enpWa7/LbfcouzsbE2cOFFnz57VI488ooceeshh98WSAAAAgD+IjIwMlZaWaurUqXJx+W1ecunSpeX6nT9/Xjt37tStt94qScrKytLx48fVtGlTSb8F0KysLDVq1OiKr+3t7a2//OUv+stf/qKHHnpI3bp106+//io/Pz+774vACgAAcB06ceKEMjMzbdrq1q2r4uJivfXWW7r33nv12WefKSUlpdx7q1WrpiFDhujNN9+Um5ubkpKSdNttt1kD7NixY9WjRw/Vr19fDz30kFxcXLR7927t27dPr7zySrnxpk2bpqCgILVt21YuLi5atmyZAgMDHfKAAoklAQAAANelTZs2qW3btjav999/X9OmTdPkyZPVokULLVy4sMLtpWrUqKFRo0bp0Ucf1e23365atWppyZIl1vNxcXFavXq11q9fr/bt2+u2227TG2+8cdEvU3l5eem1115Tu3bt1L59e+Xk5GjNmjXWWV57WQzDMBwyUiVs2bJFU6ZMUUZGhnJzc7VixQqbpzb07dtXCxYssHlPXFyc1q5daz3+9ddfNWTIEP3nP/+Ri4uLHnzwQc2YMUO1atWy9tmzZ48SExO1Y8cO1atXT0OGDCm3vcOyZcv00ksvKScnR40bN9bkyZN1zz33XPG9FBQUyMfHRydOnJC3t/dV/iTst/a7Fy7f6Q+oW+hrzi7BKSxP3+bsEpzCmLPd2SUA+INx9n+/K3Lu3DllZ2crPDy8wvWifyRXeq9OnWE9ffq0WrdubV0MXJFu3bopNzfX+vrXv/5lc/6xxx7T/v37lZqaqtWrV2vLli0aNGiQ9XxBQYG6du2q0NBQZWRkaMqUKRo3bpzeeecda59t27apd+/eGjBggL788kv17NlTPXv21L59+xx/0wAAALgqTl3D2r17d3Xv3v2SfTw8PBQYGFjhua+//lpr167Vjh071K5dO0nSW2+9pXvuuUevv/66goODtXDhQhUVFWnu3Llyd3dX8+bNlZmZqWnTplmD7YwZM9StWzeNHDlSkjRx4kSlpqZq5syZFa77AAAAwLVj+jWsmzZtkr+/vyIiIvT000/r6NGj1nPp6eny9fW1hlVJio2NlYuLiz7//HNrn44dO8rd3d3aJy4uTllZWTp27Ji1T2xsrM114+LilJ6eftG6CgsLVVBQYPMCAACA45k6sHbr1k3vvfee0tLSNHnyZG3evFndu3dXSUmJJCkvL0/+/v4273Fzc5Ofn5/y8vKsfQICAmz6lB1frk/Z+YokJyfLx8fH+goJCbHvZgEAAFAhU29rdeEzbVu2bKlWrVqpYcOG2rRpk+666y4nViaNHj1aw4cPtx4XFBQQWgEAAKqAqWdYf69BgwaqW7euDh06JEkKDAxUfn6+TZ/z58/r119/ta57DQwM1JEjR2z6lB1frs/F1s5Kv62t9fb2tnkBAADA8a6rwPrDDz/o6NGjCgoKkiTFxMTo+PHjysjIsPbZuHGjSktLFR0dbe2zZcsWFRcXW/ukpqYqIiJCtWvXtvZJS0uzuVZqaqpiYmKq+pYAAABwGU4NrKdOnbI+n1aSsrOzlZmZqcOHD+vUqVMaOXKktm/frpycHKWlpem+++5To0aNFBcXJ0lq2rSpunXrpoEDB+qLL77QZ599pqSkJPXq1UvBwcGSpEcffVTu7u4aMGCA9u/fryVLlmjGjBk2f50/dOhQrV27VlOnTtWBAwc0btw47dy5U0lJSdf8ZwIAAABbTg2sO3futD6ZQZKGDx+utm3bauzYsXJ1ddWePXv05z//WU2aNNGAAQMUFRWlTz/9VB4eHtYxFi5cqMjISN1111265557dMcdd9jsserj46P169crOztbUVFRGjFihMaOHWuzV2uHDh20aNEivfPOO2rdurX+/e9/a+XKlWrRosW1+2EAAACgQk790lXnzp11qQdtrVu37rJj+Pn5adGiRZfs06pVK3366aeX7PPwww/r4Ycfvuz1AAAAcG2ZepcAAAAA/OZaP5a7Mo/DPnnypF566SWtWLFC+fn5atu2rWbMmKH27dvbVct19aUrAAAAmNeTTz6p1NRUvf/++9q7d6+6du2q2NhY/fjjj3aNS2AFAACA3c6ePasPP/xQr732mjp27KhGjRpp3LhxatSokebMmWPX2ARWAAAA2O38+fMqKSmRp6enTXv16tW1detWu8YmsAIAAMBuXl5eiomJ0cSJE/XTTz+ppKREH3zwgdLT05Wbm2vX2ARWAAAAOMT7778vwzB00003ycPDQ2+++aZ69+4tFxf7IieBFQAAAA7RsGFDbd68WadOndL333+vL774QsXFxWrQoIFd4xJYAQAA4FA1a9ZUUFCQjh07pnXr1um+++6zazz2YQUAAIBDrFu3ToZhKCIiQocOHdLIkSMVGRmpfv362TUuM6wAAABwiBMnTigxMVGRkZHq06eP7rjjDq1bt07VqlWza1xmWAEAAK4DlXny1LX2yCOP6JFHHnH4uMywAgAAwNQIrAAAADA1AisAAABMjcAKAAAAUyOwAgAAwNQIrAAAADA1AisAAABMjcAKAAAAUyOwAgAAwNQIrAAAADA1Hs0KAABwHWjw7oPX9HrfDvjwqvqXlJRo3Lhx+uCDD5SXl6fg4GD17dtXY8aMkcVisasWAisAAADsNnnyZM2ZM0cLFixQ8+bNtXPnTvXr108+Pj569tln7RqbwAoAAAC7bdu2Tffdd5/i4+MlSWFhYfrXv/6lL774wu6xWcMKAAAAu3Xo0EFpaWn63//+J0navXu3tm7dqu7du9s9NjOsAAAAsNuLL76ogoICRUZGytXVVSUlJZo0aZIee+wxu8cmsAIAAMBuS5cu1cKFC7Vo0SI1b95cmZmZeu655xQcHKyEhAS7xiawAgAAwG4jR47Uiy++qF69ekmSWrZsqe+++07Jycl2B1bWsAIAAMBuZ86ckYuLbbR0dXVVaWmp3WMzwwoAAAC73XvvvZo0aZLq16+v5s2b68svv9S0adPUv39/u8cmsAIAAMBub731ll566SU988wzys/PV3BwsJ566imNHTvW7rEJrAAAANeBq33y1LXm5eWl6dOna/r06Q4fmzWsAAAAMDUCKwAAAEyNwAoAAABTI7ACAADA1JwaWLds2aJ7771XwcHBslgsWrlypfVccXGxRo0apZYtW6pmzZoKDg5Wnz599NNPP9mMERYWJovFYvN69dVXbfrs2bNHd955pzw9PRUSEqLXXnutXC3Lli1TZGSkPD091bJlS61Zs6ZK7hkAAABXx6m7BJw+fVqtW7dW//799cADD9icO3PmjHbt2qWXXnpJrVu31rFjxzR06FD9+c9/1s6dO236TpgwQQMHDrQee3l5Wf9cUFCgrl27KjY2VikpKdq7d6/69+8vX19fDRo0SJK0bds29e7dW8nJyerRo4cWLVqknj17ateuXWrRokUV/gQcp9M7+5xdgnNMcnYBAACgqjk1sHbv3l3du3ev8JyPj49SU1Nt2mbOnKlbb71Vhw8fVv369a3tXl5eCgwMrHCchQsXqqioSHPnzpW7u7v12bbTpk2zBtYZM2aoW7duGjlypCRp4sSJSk1N1cyZM5WSkuKIWwUAAEAlXVdrWE+cOCGLxSJfX1+b9ldffVV16tRR27ZtNWXKFJ0/f956Lj09XR07dpS7u7u1LS4uTllZWTp27Ji1T2xsrM2YcXFxSk9Pv2gthYWFKigosHkBAADA8a6bBwecO3dOo0aNUu/eveXt7W1tf/bZZ3XLLbfIz89P27Zt0+jRo5Wbm6tp06ZJkvLy8hQeHm4zVkBAgPVc7dq1lZeXZ227sE9eXt5F60lOTtb48eMddXsAAAC4iOsisBYXF+uRRx6RYRiaM2eOzbnhw4db/9yqVSu5u7vrqaeeUnJysjw8PKqsptGjR9tcu6CgQCEhIVV2PQAAgBuV6QNrWVj97rvvtHHjRpvZ1YpER0fr/PnzysnJUUREhAIDA3XkyBGbPmXHZeteL9bnYutiJcnDw6NKAzEAAMCFnv904OU7OdDrd/7jqvqHhYXpu+++K9f+zDPPaNasWXbVYuo1rGVh9eDBg9qwYYPq1Klz2fdkZmbKxcVF/v7+kqSYmBht2bJFxcXF1j6pqamKiIhQ7dq1rX3S0tJsxklNTVVMTIwD7wYAAOCPa8eOHcrNzbW+yr48//DDD9s9tlNnWE+dOqVDhw5Zj7Ozs5WZmSk/Pz8FBQXpoYce0q5du7R69WqVlJRY15T6+fnJ3d1d6enp+vzzz9WlSxd5eXkpPT1dw4YN0+OPP24No48++qjGjx+vAQMGaNSoUdq3b59mzJihN954w3rdoUOHqlOnTpo6dari4+O1ePFi7dy5U++88861/YEAAABcp+rVq2dz/Oqrr6phw4bq1KmT3WM7NbDu3LlTXbp0sR6XrQlNSEjQuHHjtGrVKklSmzZtbN73ySefqHPnzvLw8NDixYs1btw4FRYWKjw8XMOGDbNZW+rj46P169crMTFRUVFRqlu3rsaOHWvd0kqSOnTooEWLFmnMmDH661//qsaNG2vlypXXzR6sAAAAZlJUVKQPPvhAw4cPl8VisXs8pwbWzp07yzCMi56/1DlJuuWWW7R9+/bLXqdVq1b69NNPL9nn4YcfdsiUNQAAwI1u5cqVOn78uPr27euQ8Uy9hhUAAADXn3fffVfdu3dXcHCwQ8Yz/S4BAADcSBq8+6CzS3CKbwd86OwS4CDfffedNmzYoOXLlztsTGZYAQAA4DDz5s2Tv7+/4uPjHTYmM6zAdah00jPOLgEAgHJKS0s1b948JSQkyM3NcTGTGVYAAAA4xIYNG3T48GH179/foeMywwoAAHAduNonTzlD165dL7vLU2UwwwoAAABTI7ACAADA1AisAAAAMDUCKwAAAEyNwAoAAABTI7ACAADA1AisAAAAMDUCKwAAAEyNwAoAAABT40lXAGBy+Wffc3YJTuFfvY+zSwBgEgRWAACA68Da7164ptfrFvraVb/nxx9/1KhRo/Tf//5XZ86cUaNGjTRv3jy1a9fOrloIrAAAALDbsWPHdPvtt6tLly7673//q3r16ungwYOqXbu23WMTWAEAAGC3yZMnKyQkRPPmzbO2hYeHO2RsvnQFAAAAu61atUrt2rXTww8/LH9/f7Vt21b/+Mc/HDI2gRUAAAB2+/bbbzVnzhw1btxY69at09NPP61nn31WCxYssHtslgQAAADAbqWlpWrXrp3+/ve/S5Latm2rffv2KSUlRQkJCXaNzQwrAAAA7BYUFKRmzZrZtDVt2lSHDx+2e2wCKwAAAOx2++23Kysry6btf//7n0JDQ+0em8AKAAAAuw0bNkzbt2/X3//+dx06dEiLFi3SO++8o8TERLvHJrACAADAbu3bt9eKFSv0r3/9Sy1atNDEiRM1ffp0PfbYY3aPzZeuAAAArgOVefLUtdajRw/16NHD4eNWaoa1QYMGOnr0aLn248ePq0GDBnYXBQAAAJSpVGDNyclRSUlJufbCwkL9+OOPdhcFAAAAlLmqJQGrVq2y/nndunXy8fGxHpeUlCgtLU1hYWEOKw4AAAC4qsDas2dPSZLFYim3AWy1atUUFhamqVOnOqw4AAAA4KoCa2lpqSQpPDxcO3bsUN26daukKAAAAKBMpXYJyM7OdnQdAAAAQIUqva1VWlqa0tLSlJ+fb515LTN37ly7CwMAAACkSgbW8ePHa8KECWrXrp2CgoJksVgcXRcAAAAgqZKBNSUlRfPnz9cTTzzh6HoAAAAAG5Xah7WoqEgdOnSw++JbtmzRvffeq+DgYFksFq1cudLmvGEYGjt2rIKCglS9enXFxsbq4MGDNn1+/fVXPfbYY/L29pavr68GDBigU6dO2fTZs2eP7rzzTnl6eiokJESvvVb+SRHLli1TZGSkPD091bJlS61Zs8bu+wMAAID9KjXD+uSTT2rRokV66aWX7Lr46dOn1bp1a/Xv318PPPBAufOvvfaa3nzzTS1YsEDh4eF66aWXFBcXp6+++kqenp6SpMcee0y5ublKTU1VcXGx+vXrp0GDBmnRokWSpIKCAnXt2lWxsbFKSUnR3r171b9/f/n6+mrQoEGSpG3btql3795KTk5Wjx49tGjRIvXs2VO7du1SixYt7LpHAAAAR8g/+941vZ5/9T5X1X/cuHEaP368TVtERIQOHDhgdy2VCqznzp3TO++8ow0bNqhVq1aqVq2azflp06Zd0Tjdu3dX9+7dKzxnGIamT5+uMWPG6L777pMkvffeewoICNDKlSvVq1cvff3111q7dq127Nihdu3aSZLeeust3XPPPXr99dcVHByshQsXqqioSHPnzpW7u7uaN2+uzMxMTZs2zRpYZ8yYoW7dumnkyJGSpIkTJyo1NVUzZ85USkpKZX5EAAAAN5zmzZtrw4YN1mM3t0p/v99GpZYE7NmzR23atJGLi4v27dunL7/80vrKzMx0SGHZ2dnKy8tTbGystc3Hx0fR0dFKT0+XJKWnp8vX19caViUpNjZWLi4u+vzzz619OnbsKHd3d2ufuLg4ZWVl6dixY9Y+F16nrE/ZdQAAAHB5bm5uCgwMtL4ctWd/pWLvJ5984pCLX0peXp4kKSAgwKY9ICDAei4vL0/+/v42593c3OTn52fTJzw8vNwYZedq166tvLy8S16nIoWFhSosLLQeFxQUXM3tAQAA/OEcPHhQwcHB8vT0VExMjJKTk1W/fn27x63UDCuk5ORk+fj4WF8hISHOLgkAAMBpoqOjNX/+fK1du1Zz5sxRdna27rzzTp08edLusSs1w9qlS5dL7r26cePGShdUJjAwUJJ05MgRBQUFWduPHDmiNm3aWPvk5+fbvO/8+fP69ddfre8PDAzUkSNHbPqUHV+uT9n5iowePVrDhw+3HhcUFBBaAQDADevC7yW1atVK0dHRCg0N1dKlSzVgwAC7xq7UDGubNm3UunVr66tZs2YqKirSrl271LJlS7sKKhMeHq7AwEClpaVZ2woKCvT5558rJiZGkhQTE6Pjx48rIyPD2mfjxo0qLS1VdHS0tc+WLVtUXFxs7ZOamqqIiAjVrl3b2ufC65T1KbtORTw8POTt7W3zAgAAwG98fX3VpEkTHTp0yO6xKjXD+sYbb1TYPm7cuHJ7oF7KqVOnbG4iOztbmZmZ8vPzU/369fXcc8/plVdeUePGja3bWgUHB6tnz56SpKZNm6pbt24aOHCgUlJSVFxcrKSkJPXq1UvBwcGSpEcffVTjx4/XgAEDNGrUKO3bt08zZsywuYehQ4eqU6dOmjp1quLj47V48WLt3LlT77zzTiV+OgAAADh16pS++eYbhzxoyqFrWB9//HHNnTv3ivvv3LlTbdu2Vdu2bSVJw4cPV9u2bTV27FhJ0gsvvKAhQ4Zo0KBBat++vU6dOqW1a9da92CVpIULFyoyMlJ33XWX7rnnHt1xxx02QdPHx0fr169Xdna2oqKiNGLECI0dO9a6pZUkdejQQYsWLdI777yj1q1b69///rdWrlzJHqwAAABX6Pnnn9fmzZuVk5Ojbdu26f7775erq6t69+5t99iO2Rzr/6Snp9uEycvp3LmzDMO46HmLxaIJEyZowoQJF+3j5+dnfUjAxbRq1UqffvrpJfs8/PDDevjhhy9dMAAAACr0ww8/qHfv3jp69Kjq1aunO+64Q9u3b1e9evXsHrtSgfX3T6UyDEO5ubnauXOn3U+/AgAAQHlX++Spa23x4sVVNnalAquPj4/NsYuLiyIiIjRhwgR17drVIYUBAAAAUiUD67x58xxdBwAAAFAhu9awZmRk6Ouvv5b027Njy748BQAAADhKpQJrfn6+evXqpU2bNsnX11eSdPz4cXXp0kWLFy92yOJaAAAAQKrktlZDhgzRyZMntX//fv3666/69ddftW/fPhUUFOjZZ591dI0AAAC4gVVqhnXt2rXasGGDmjZtam1r1qyZZs2axZeuAAAA4FCVmmEtLS1VtWrVyrVXq1ZNpaWldhcFAAAAlKlUYP3Tn/6koUOH6qeffrK2/fjjjxo2bJjuuusuhxUHAAAAVCqwzpw5UwUFBQoLC1PDhg3VsGFDhYeHq6CgQG+99ZajawQAAMANrFJrWENCQrRr1y5t2LBBBw4ckCQ1bdpUsbGxDi0OAAAAuKrAunHjRiUlJWn79u3y9vbW3XffrbvvvluSdOLECTVv3lwpKSm68847q6RYAACAG5Xx63vX9HoWP/seBfvqq69q9OjRGjp0qKZPn27XWFe1JGD69OkaOHCgvL29y53z8fHRU089pWnTptlVEAAAAK5vO3bs0Ntvv61WrVo5ZLyrCqy7d+9Wt27dLnq+a9euysjIsLsoAAAAXJ9OnTqlxx57TP/4xz9Uu3Zth4x5VYH1yJEjFW5nVcbNzU0///yz3UUBAADg+pSYmKj4+HiHfrfpqtaw3nTTTdq3b58aNWpU4fk9e/YoKCjIIYUBAADg+rJ48WLt2rVLO3bscOi4VzXDes899+ill17SuXPnyp07e/asXn75ZfXo0cNhxQEAAOD68P3332vo0KFauHChPD09HTr2Vc2wjhkzRsuXL1eTJk2UlJSkiIgISdKBAwc0a9YslZSU6G9/+5tDCwQAAID5ZWRkKD8/X7fccou1raSkRFu2bNHMmTNVWFgoV1fXSo19VYE1ICBA27Zt09NPP63Ro0fLMAxJksViUVxcnGbNmqWAgIBKFQIAAIDr11133aW9e/fatPXr10+RkZEaNWpUpcOqVIkHB4SGhmrNmjU6duyYDh06JMMw1LhxY4d9CwwAAADXHy8vL7Vo0cKmrWbNmqpTp0659qtVqSddSVLt2rXVvn17uy4OAACAK2PvRv7Xs0oHVgAAAOBSNm3a5JBxrmqXAAAAAOBaI7ACAADA1AisAAAAMDUCKwAAAEyNwAoAAABTI7ACAADA1AisAAAAMDUCKwAAAEyNwAoAAABTI7ACAADA1Hg0KwAAwHWgdNNz1/R6Lp2nX1X/OXPmaM6cOcrJyZEkNW/eXGPHjlX37t3tr8XuEQAAAHDDu/nmm/Xqq68qIyNDO3fu1J/+9Cfdd9992r9/v91jM8MKAAAAu9177702x5MmTdKcOXO0fft2NW/e3K6xCawAAABwqJKSEi1btkynT59WTEyM3eMRWAEAAOAQe/fuVUxMjM6dO6datWppxYoVatasmd3jmn4Na1hYmCwWS7lXYmKiJKlz587lzg0ePNhmjMOHDys+Pl41atSQv7+/Ro4cqfPnz9v02bRpk2655RZ5eHioUaNGmj9//rW6RQAAgD+EiIgIZWZm6vPPP9fTTz+thIQEffXVV3aPa/oZ1h07dqikpMR6vG/fPt199916+OGHrW0DBw7UhAkTrMc1atSw/rmkpETx8fEKDAzUtm3blJubqz59+qhatWr6+9//LknKzs5WfHy8Bg8erIULFyotLU1PPvmkgoKCFBcXdw3uEgAA4Prn7u6uRo0aSZKioqK0Y8cOzZgxQ2+//bZd45o+sNarV8/m+NVXX1XDhg3VqVMna1uNGjUUGBhY4fvXr1+vr776Shs2bFBAQIDatGmjiRMnatSoURo3bpzc3d2VkpKi8PBwTZ06VZLUtGlTbd26VW+88QaBFQAAoJJKS0tVWFho9zimXxJwoaKiIn3wwQfq37+/LBaLtX3hwoWqW7euWrRoodGjR+vMmTPWc+np6WrZsqUCAgKsbXFxcSooKLBus5Cenq7Y2Fiba8XFxSk9Pf2itRQWFqqgoMDmBQAAcKMaPXq0tmzZopycHO3du1ejR4/Wpk2b9Nhjj9k9tulnWC+0cuVKHT9+XH379rW2PfroowoNDVVwcLD27NmjUaNGKSsrS8uXL5ck5eXl2YRVSdbjvLy8S/YpKCjQ2bNnVb169XK1JCcna/z48Y68PQAAgIu62o38r7X8/Hz16dNHubm58vHxUatWrbRu3Trdfffddo99XQXWd999V927d1dwcLC1bdCgQdY/t2zZUkFBQbrrrrv0zTffqGHDhlVWy+jRozV8+HDrcUFBgUJCQqrsegAAAGb27rvvVtnY101g/e6777RhwwbrzOnFREdHS5IOHTqkhg0bKjAwUF988YVNnyNHjkiSdd1rYGCgte3CPt7e3hXOrkqSh4eHPDw8KnUvAAAAuHLXzRrWefPmyd/fX/Hx8Zfsl5mZKUkKCgqSJMXExGjv3r3Kz8+39klNTZW3t7d1X7CYmBilpaXZjJOamuqQjW4BAABgn+sisJaWlmrevHlKSEiQm9v/nxT+5ptvNHHiRGVkZCgnJ0erVq1Snz591LFjR7Vq1UqS1LVrVzVr1kxPPPGEdu/erXXr1mnMmDFKTEy0zpAOHjxY3377rV544QUdOHBAs2fP1tKlSzVs2DCn3C8AAAD+v+sisG7YsEGHDx9W//79bdrd3d21YcMGde3aVZGRkRoxYoQefPBB/ec//7H2cXV11erVq+Xq6qqYmBg9/vjj6tOnj82+reHh4fr444+Vmpqq1q1ba+rUqfrnP//JllYAAAAmcF2sYe3atasMwyjXHhISos2bN1/2/aGhoVqzZs0l+3Tu3FlffvllpWsEAABA1bguZlgBAABw4yKwAgAAwNQIrAAAADA1AisAAABMjcAKAAAAU7sudgkAAAC40Z392z3X9HrVJ116h6XfS05O1vLly3XgwAFVr15dHTp00OTJkxUREWF3LcywAgAAwG6bN29WYmKitm/frtTUVBUXF6tr1646ffq03WMzw/oH8cOG75xdglM0nuTsCgAAgCStXbvW5nj+/Pny9/dXRkaGOnbsaNfYzLACAADA4U6cOCFJ8vPzs3ssAisAAAAcqrS0VM8995xuv/12tWjRwu7xWBIAAAAAh0pMTNS+ffu0detWh4xHYAUAAIDDJCUlafXq1dqyZYtuvvlmh4xJYAUAAIDdDMPQkCFDtGLFCm3atEnh4eEOG5vACgAAALslJiZq0aJF+uijj+Tl5aW8vDxJko+Pj6pXr27X2ARWAACA68DVbuR/rc2ZM0eS1LlzZ5v2efPmqW/fvnaNTWAFAACA3QzDqLKxCawAAJjIA03s37MS+KNhH1YAAACYGoEVAAAApsaSAOA6ZOzZ5ewSnMLSuY+zSwAAOAEzrAAAADA1AisAAABMjcAKAAAAU2MNKwCY3IYak5xdglM8arBmGcBvmGEFAACAqRFYAQAAYGosCQAAALgOHIxufk2v1/jz/Vf9ni1btmjKlCnKyMhQbm6uVqxYoZ49e9pdCzOsAAAAcIjTp0+rdevWmjVrlkPHZYYVAAAADtG9e3d1797d4eMywwoAAABTI7ACAADA1AisAAAAMDUCKwAAAEyNwAoAAABTY5cAAAAAOMSpU6d06NAh63F2drYyMzPl5+en+vXrV3pcAisAAMB1oDIb+V9rO3fuVJcuXazHw4cPlyQlJCRo/vz5lR7X1EsCxo0bJ4vFYvOKjIy0nj937pwSExNVp04d1apVSw8++KCOHDliM8bhw4cVHx+vGjVqyN/fXyNHjtT58+dt+mzatEm33HKLPDw81KhRI7t+oAAAADeqzp07yzCMci97s5WpA6skNW/eXLm5udbX1q1breeGDRum//znP1q2bJk2b96sn376SQ888ID1fElJieLj41VUVKRt27ZpwYIFmj9/vsaOHWvtk52drfj4eHXp0kWZmZl67rnn9OSTT2rdunXX9D4BAABQMdMvCXBzc1NgYGC59hMnTujdd9/VokWL9Kc//UmSNG/ePDVt2lTbt2/XbbfdpvXr1+urr77Shg0bFBAQoDZt2mjixIkaNWqUxo0bJ3d3d6WkpCg8PFxTp06VJDVt2lRbt27VG2+8obi4uGt6rwAAACjP9DOsBw8eVHBwsBo0aKDHHntMhw8fliRlZGSouLhYsbGx1r6RkZGqX7++0tPTJUnp6elq2bKlAgICrH3i4uJUUFCg/fv3W/tcOEZZn7IxLqawsFAFBQU2LwAAADieqQNrdHS05s+fr7Vr12rOnDnKzs7WnXfeqZMnTyovL0/u7u7y9fW1eU9AQIDy8vIkSXl5eTZhtex82blL9SkoKNDZs2cvWltycrJ8fHysr5CQEHtvFwAAABUw9ZKA7t27W//cqlUrRUdHKzQ0VEuXLlX16tWdWJk0evRo6zffJKmgoIDQCgAAUAVMPcP6e76+vmrSpIkOHTqkwMBAFRUV6fjx4zZ9jhw5Yl3zGhgYWG7XgLLjy/Xx9va+ZCj28PCQt7e3zQsAAACOd10F1lOnTumbb75RUFCQoqKiVK1aNaWlpVnPZ2Vl6fDhw4qJiZEkxcTEaO/evcrPz7f2SU1Nlbe3t5o1a2btc+EYZX3KxgAAAIBzmTqwPv/889q8ebNycnK0bds23X///XJ1dVXv3r3l4+OjAQMGaPjw4frkk0+UkZGhfv36KSYmRrfddpskqWvXrmrWrJmeeOIJ7d69W+vWrdOYMWOUmJgoDw8PSdLgwYP17bff6oUXXtCBAwc0e/ZsLV26VMOGDXPmrQMAAOD/mHoN6w8//KDevXvr6NGjqlevnu644w5t375d9erVkyS98cYbcnFx0YMPPqjCwkLFxcVp9uzZ1ve7urpq9erVevrppxUTE6OaNWsqISFBEyZMsPYJDw/Xxx9/rGHDhmnGjBm6+eab9c9//pMtrQAAAEzC1IF18eLFlzzv6empWbNmadasWRftExoaqjVr1lxynM6dO+vLL7+sVI0AAAD4/2bNmqUpU6YoLy9PrVu31ltvvaVbb73VrjFNHVgBAADwm0WWiGt6vUeNrKt+z5IlSzR8+HClpKQoOjpa06dPV1xcnLKysuTv71/pWky9hhUAAADXj2nTpmngwIHq16+fmjVrppSUFNWoUUNz5861a1wCKwAAAOxWVFSkjIwMmyeIuri4KDY29rJPEL0cAisAAADs9ssvv6ikpKTCJ4iWPWG0sgisAAAAMDUCKwAAAOxWt25dubq6VvgE0bInjFYWgRUAAAB2c3d3V1RUlM0TREtLS5WWlmb3E0TZ1goAAAAOMXz4cCUkJKhdu3a69dZbNX36dJ0+fVr9+vWza1wCKwAAABziL3/5i37++WeNHTtWeXl5atOmjdauXVvui1hXi8AKAABwHajMRv7OkJSUpKSkJIeOyRpWAAAAmBqBFQAAAKZGYAUAAICpEVgBAABgagRWAAAAmBqBFQAAwIQMw3B2CVXuSu+RwAoAAGAi1apVkySdOXPGyZVUvbJ7LLvni2EfVgAAABNxdXWVr6+v8vPzJUk1atSQxWJxclWOZRiGzpw5o/z8fPn6+srV1fWS/QmsAAAAJhMYGChJ1tD6R+Xr62u910shsAIAAJiMxWJRUFCQ/P39VVxc7OxyqkS1atUuO7NahsAKAABgUq6urlcc6v7I+NIVAAAATI3ACgAAAFMjsAIAAMDUCKwAAAAwNQIrAAAATI3ACgAAAFMjsAIAAMDUCKwAAAAwNQIrAAAATI3ACgAAAFMjsAIAAMDUCKwAAAAwNQIrAAAATI3ACgAAAFMjsAIAAMDUTB1Yk5OT1b59e3l5ecnf3189e/ZUVlaWTZ/OnTvLYrHYvAYPHmzT5/Dhw4qPj1eNGjXk7++vkSNH6vz58zZ9Nm3apFtuuUUeHh5q1KiR5s+fX9W3BwAAgCtg6sC6efNmJSYmavv27UpNTVVxcbG6du2q06dP2/QbOHCgcnNzra/XXnvNeq6kpETx8fEqKirStm3btGDBAs2fP19jx4619snOzlZ8fLy6dOmizMxMPffcc3ryySe1bt26a3avAAAAqJibswu4lLVr19ocz58/X/7+/srIyFDHjh2t7TVq1FBgYGCFY6xfv15fffWVNmzYoICAALVp00YTJ07UqFGjNG7cOLm7uyslJUXh4eGaOnWqJKlp06baunWr3njjDcXFxVXdDQIAAOCyTD3D+nsnTpyQJPn5+dm0L1y4UHXr1lWLFi00evRonTlzxnouPT1dLVu2VEBAgLUtLi5OBQUF2r9/v7VPbGyszZhxcXFKT0+/aC2FhYUqKCiweQEAAMDxTD3DeqHS0lI999xzuv3229WiRQtr+6OPPqrQ0FAFBwdrz549GjVqlLKysrR8+XJJUl5enk1YlWQ9zsvLu2SfgoICnT17VtWrVy9XT3JyssaPH+/QewQAAEB5101gTUxM1L59+7R161ab9kGDBln/3LJlSwUFBemuu+7SN998o4YNG1ZZPaNHj9bw4cOtxwUFBQoJCamy6wEAANyoroslAUlJSVq9erU++eQT3XzzzZfsGx0dLUk6dOiQJCkwMFBHjhyx6VN2XLbu9WJ9vL29K5xdlSQPDw95e3vbvAAAAOB4pg6shmEoKSlJK1as0MaNGxUeHn7Z92RmZkqSgoKCJEkxMTHau3ev8vPzrX1SU1Pl7e2tZs2aWfukpaXZjJOamqqYmBgH3QkAAAAqy9SBNTExUR988IEWLVokLy8v5eXlKS8vT2fPnpUkffPNN5o4caIyMjKUk5OjVatWqU+fPurYsaNatWolSeratauaNWumJ554Qrt379a6des0ZswYJSYmysPDQ5I0ePBgffvtt3rhhRd04MABzZ49W0uXLtWwYcOcdu8AAAD4jakD65w5c3TixAl17txZQUFB1teSJUskSe7u7tqwYYO6du2qyMhIjRgxQg8++KD+85//WMdwdXXV6tWr5erqqpiYGD3++OPq06ePJkyYYO0THh6ujz/+WKmpqWrdurWmTp2qf/7zn2xpBQAAYAKm/tKVYRiXPB8SEqLNmzdfdpzQ0FCtWbPmkn06d+6sL7/88qrqAwAAQNUz9QwrAAAAQGAFAACAqRFYAQAAYGoEVgAAAJgagRUAAACmRmAFAACAqRFYAQAAYGoEVgAAAJgagRUAAACmRmAFAACAqRFYAQAAYGoEVgAAAJgagRUAAACmRmAFAACAqRFYAQAAYGoEVgAAAJgagRUAAACmRmAFAACAqRFYAQAAYGoEVgAAAJgagRUAAACmRmAFAACAqRFYAQAAYGoEVgAAAJgagRUAAACmRmAFAACAqRFYAQAAYGoEVgAAAJgagRUAAACmRmAFAACAqRFYAQAAYGoEVgAAAJgagRUAAACmRmAFAACAqRFYAQAAYGoEVgAAAJgagfV3Zs2apbCwMHl6eio6OlpffPGFs0sCAAC4oRFYL7BkyRINHz5cL7/8snbt2qXWrVsrLi5O+fn5zi4NAADghkVgvcC0adM0cOBA9evXT82aNVNKSopq1KihuXPnOrs0AACAGxaB9f8UFRUpIyNDsbGx1jYXFxfFxsYqPT3diZUBAADc2NycXYBZ/PLLLyopKVFAQIBNe0BAgA4cOFCuf2FhoQoLC63HJ06ckCQVFBRUbaEXcaqkxCnXdTZn/bydrfR04eU7/QG53KCf9xnxz/eNpPB0kbNLcApnfd5l1zUMwynXx5UhsFZScnKyxo8fX649JCTECdXcwHx8nF0BrqkUZxeAa2gg/3zfUGbqPade/+TJk/Lhd860CKz/p27dunJ1ddWRI0ds2o8cOaLAwMBy/UePHq3hw4dbj0tLS/Xrr7+qTp06slgsVV6vWRQUFCgkJETff/+9vL29nV0Oqhif942Fz/vGcqN+3oZh6OTJkwoODnZ2KbgEAuv/cXd3V1RUlNLS0tSzZ09Jv4XQtLQ0JSUllevv4eEhDw8PmzZfX99rUKk5eXt731D/grvR8XnfWPi8byw34ufNzKr5EVgvMHz4cCUkJKhdu3a69dZbNX36dJ0+fVr9+vVzdmkAAAA3LALrBf7yl7/o559/1tixY5WXl6c2bdpo7dq15b6IBQAAgGuHwPo7SUlJFS4BQMU8PDz08ssvl1segT8mPu8bC5/3jYXPG2ZmMdjHAQAAACbGgwMAAABgagRWAAAAmBqBFQAAAKZGYAUAAICpEVhhl1mzZiksLEyenp6Kjo7WF1984eySUAW2bNmie++9V8HBwbJYLFq5cqWzS0IVSk5OVvv27eXl5SV/f3/17NlTWVlZzi4LVWTOnDlq1aqV9YEBMTEx+u9//+vssgAbBFZU2pIlSzR8+HC9/PLL2rVrl1q3bq24uDjl5+c7uzQ42OnTp9W6dWvNmjXL2aXgGti8ebMSExO1fft2paamqri4WF27dtXp06edXRqqwM0336xXX31VGRkZ2rlzp/70pz/pvvvu0/79+51dGmDFtlaotOjoaLVv314zZ86U9NujbENCQjRkyBC9+OKLTq4OVcVisWjFihXWRxjjj+/nn3+Wv7+/Nm/erI4dOzq7HFwDfn5+mjJligYMGODsUgBJzLCikoqKipSRkaHY2Fhrm4uLi2JjY5Wenu7EygA42okTJyT9FmLwx1ZSUqLFixfr9OnTiomJcXY5gBVPukKl/PLLLyopKSn32NqAgAAdOHDASVUBcLTS0lI999xzuv3229WiRQtnl4MqsnfvXsXExOjcuXOqVauWVqxYoWbNmjm7LMCKwAoAuKjExETt27dPW7dudXYpqEIRERHKzMzUiRMn9O9//1sJCQnavHkzoRWmQWBFpdStW1eurq46cuSITfuRI0cUGBjopKoAOFJSUpJWr16tLVu26Oabb3Z2OahC7u7uatSokSQpKipKO3bs0IwZM/T22287uTLgN6xhRaW4u7srKipKaWlp1rbS0lKlpaWx7gm4zhmGoaSkJK1YsUIbN25UeHi4s0vCNVZaWqrCwkJnlwFYMcOKShs+fLgSEhLUrl073XrrrZo+fbpOnz6tfv36Obs0ONipU6d06NAh63F2drYyMzPl5+en+vXrO7EyVIXExEQtWrRIH330kby8vJSXlydJ8vHxUfXq1Z1cHRxt9OjR6t69u+rXr6+TJ09q0aJF2rRpk9atW+fs0gArtrWCXWbOnKkpU6YoLy9Pbdq00Ztvvqno6GhnlwUH27Rpk7p06VKuPSEhQfPnz7/2BaFKWSyWCtvnzZunvn37XttiUOUGDBigtLQ05ebmysfHR61atdKoUaN09913O7s0wIrACgAAAFNjDSsAAABMjcAKAAAAUyOwAgAAwNQIrAAAADA1AisAAABMjcAKAAAAUyOwAgAAwNQIrABuaDk5ObJYLMrMzLxkv86dO+u55567JjUBAGwRWAGYTt++fWWxWGSxWOTu7q5GjRppwoQJOn/+vN3j9uzZ06YtJCREubm5atGihaTfnuplsVh0/Phxm37Lly/XxIkT7br+5fw+PJcdl728vLzUvHlzJSYm6uDBg1VaCwCYCYEVgCl169ZNubm5OnjwoEaMGKFx48ZpypQplRqrpKREpaWlFZ5zdXVVYGCg3NzcLjmGn5+fvLy8KnV9e23YsEG5ubnavXu3/v73v+vrr79W69atlZaW5pR6AOBaI7ACMCUPDw8FBgYqNDRUTz/9tGJjY7Vq1SpJ0rRp09SyZUvVrFlTISEheuaZZ3Tq1Cnre+fPny9fX1+tWrVKzZo1k4eHh/r3768FCxboo48+ss5Ybtq0yWZWMycnR126dJEk1a5dWxaLRX379pVUfknAsWPH1KdPH9WuXVs1atRQ9+7dbWY9y2pYt26dmjZtqlq1allD+NWqU6eOAgMD1aBBA913333asGGDoqOjNWDAAJWUlFTipwsA1xcCK4DrQvXq1VVUVCRJcnFx0Ztvvqn9+/drwYIF2rhxo1544QWb/mfOnNHkyZP1z3/+U/v379ebb76pRx55xBoac3Nz1aFDB5v3hISE6MMPP5QkZWVlKTc3VzNmzKiwnr59+2rnzp1atWqV0tPTZRiG7rnnHhUXF9vU8Prrr+v999/Xli1bdPjwYT3//PN2/yxcXFw0dOhQfffdd8rIyLB7PAAwu0v/HRgAOJlhGEpLS9O6des0ZMgQSbKZ6QwLC9Mrr7yiwYMHa/bs2db24uJizZ49W61bt7a2Va9eXYWFhQoMDKzwWq6urvLz85Mk+fv7y9fXt8J+Bw8e1KpVq/TZZ59ZQ+/ChQsVEhKilStX6uGHH7bWkJKSooYNG0qSkpKSNGHChMr9IH4nMjJS0m/rXG+99VaHjAkAZkVgBWBKq1evVq1atVRcXKzS0lI9+uijGjdunKTf1nQmJyfrwIEDKigo0Pnz53Xu3DmdOXNGNWrUkCS5u7urVatWVVLb119/LTc3N0VHR1vb6tSpo4iICH399dfWtho1aljDqiQFBQUpPz/fITUYhiFJslgsDhkPAMyMJQEATKlLly7KzMzUwYMHdfbsWS1YsEA1a9ZUTk6OevTooVatWunDDz9URkaGZs2aJUnWJQPSb7Opzg5z1apVszm2WCzWoGmvsmAcHh7ukPEAwMyYYQVgSjVr1lSjRo3KtWdkZKi0tFRTp06Vi8tv/8+9dOnSKxrT3d39sl9Scnd3l6RL9mvatKnOnz+vzz//3Lok4OjRo8rKylKzZs2uqBZ7lJaW6s0331R4eLjatm1b5dcDAGdjhhXAdaVRo0YqLi7WW2+9pW+//Vbvv/++UlJSrui9YWFh2rNnj7KysvTLL7/YfEGqTGhoqCwWi1avXq2ff/7ZZveBMo0bN9Z9992ngQMHauvWrdq9e7cef/xx3XTTTbrvvvvsvsffO3r0qPLy8vTtt99q1apVio2N1RdffKF3331Xrq6uDr8eAJgNgRXAdaV169aaNm2aJk+erBYtWmjhwoVKTk6+ovcOHDhQERERateunerVq6fPPvusXJ+bbrpJ48eP14svvqiAgAAlJSVVONa8efMUFRWlHj16KCYmRoZhaM2aNeWWAThCbGysgoKC1LJlS7344otq2rSp9uzZY92CCwD+6CyGoxZUAQAAAFWAGVYAAACYGoEVAAAApkZgBQAAgKkRWAEAAGBqBFYAAACYGoEVAAAApkZgBQAAgKkRWAEAAGBqBFYAAACYGoEVAAAApkZgBQAAgKkRWAEAAGBq/w+elBdb5l3bogAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "partitioner = fds.partitioners[\"train\"]\n",
        "figure, axis, dataframe = plot_label_distributions(\n",
        "    partitioner=partitioner,\n",
        "    label_name=\"label\",\n",
        "    title=\"Per Partition Label Distribution\",\n",
        "    legend=True,\n",
        "    verbose_labels=True,\n",
        "    size_unit=\"absolute\",\n",
        "    partition_id_axis=\"x\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "93ff7171",
      "metadata": {
        "id": "93ff7171"
      },
      "outputs": [],
      "source": [
        "train_partitions = [fds.load_partition(i, split=\"train\") for i in range(num_partitions)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j-L_He1Qvz0e",
      "metadata": {
        "id": "j-L_He1Qvz0e"
      },
      "source": [
        "Rodar proxima celula somente se quiser testar com dataset reduzido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w2n6dMxcvx2k",
      "metadata": {
        "id": "w2n6dMxcvx2k"
      },
      "outputs": [],
      "source": [
        "# num_samples = [int(len(train_partition)/10) for train_partition in train_partitions]\n",
        "# train_partitions = [train_partition.select(range(n)) for train_partition, n in zip(train_partitions, num_samples)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1b7cf8f",
      "metadata": {
        "id": "d1b7cf8f"
      },
      "source": [
        "Cria dicionario de label para cliente para controle do dmax_mismatch. Tive que colocar aqui antes do apply_transform para não dar erro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e07fdcb9",
      "metadata": {
        "id": "e07fdcb9"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b106654b",
      "metadata": {
        "id": "b106654b"
      },
      "outputs": [],
      "source": [
        "min_lbl_count = 0.05\n",
        "class_labels = train_partitions[0].info.features[\"label\"]\n",
        "labels_str = class_labels.names\n",
        "label_to_client = {lbl: [] for lbl in labels_str}\n",
        "for idx, ds in enumerate(train_partitions):\n",
        "    counts = Counter(ds['label'])\n",
        "    for label, cnt in counts.items():\n",
        "        if cnt / len(ds) >= min_lbl_count:\n",
        "            label_to_client[class_labels.int2str(label)].append(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "56dcbb9b",
      "metadata": {
        "id": "56dcbb9b"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Compose, ToTensor, Normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "df48b029",
      "metadata": {
        "id": "df48b029"
      },
      "outputs": [],
      "source": [
        "pytorch_transforms = Compose([\n",
        "    ToTensor(),\n",
        "    Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "def apply_transforms(batch):\n",
        "    batch[\"image\"] = [pytorch_transforms(img) for img in batch[\"image\"]]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "cbbc667a",
      "metadata": {
        "id": "cbbc667a"
      },
      "outputs": [],
      "source": [
        "# Para CIFAR-10: 3 canais, normalização média=0.5 e std=0.5\n",
        "pytorch_transforms = Compose([\n",
        "    ToTensor(),\n",
        "    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "def apply_transforms(batch):\n",
        "    # batch[\"image\"] é uma lista de PIL.Image ou tensores em H×W×C\n",
        "    # aplicamos o mesmo transform a cada imagem e depois empilhamos\n",
        "    batch[\"img\"] = torch.stack([pytorch_transforms(img) for img in batch[\"img\"]])\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "34de09aa",
      "metadata": {
        "id": "34de09aa"
      },
      "outputs": [],
      "source": [
        "train_partitions = [train_partition.with_transform(apply_transforms) for train_partition in train_partitions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "MwJAQ213fi-w",
      "metadata": {
        "id": "MwJAQ213fi-w"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "CuBEfRZ6fX8i",
      "metadata": {
        "id": "CuBEfRZ6fX8i"
      },
      "outputs": [],
      "source": [
        "test_frac = 0.2\n",
        "client_datasets = []\n",
        "\n",
        "for train_part in train_partitions:\n",
        "    total     = len(train_part)\n",
        "    test_size = int(total * test_frac)\n",
        "    train_size = total - test_size\n",
        "\n",
        "    client_train, client_test = random_split(\n",
        "        train_part,\n",
        "        [train_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42),\n",
        "    )\n",
        "\n",
        "    client_datasets.append({\n",
        "        \"train\": client_train,\n",
        "        \"test\":  client_test,\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0ae0635",
      "metadata": {
        "id": "b0ae0635"
      },
      "source": [
        "## Inicializa modelos e otimizadores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "1b818e92",
      "metadata": {
        "id": "1b818e92"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5be9636",
      "metadata": {
        "id": "b5be9636"
      },
      "source": [
        "Rodar somente o modelo desejado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e76e482",
      "metadata": {
        "id": "8e76e482"
      },
      "outputs": [],
      "source": [
        "models = [CGAN() for i in range(num_partitions)]\n",
        "gen = CGAN().to(device)\n",
        "optim_G = torch.optim.Adam(gen.generator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "70debb0f",
      "metadata": {
        "id": "70debb0f"
      },
      "outputs": [],
      "source": [
        "models = [F2U_GAN(condition=True, seed=42) for i in range(num_partitions)]\n",
        "gen = F2U_GAN(condition=True, seed=42).to(device)\n",
        "optim_G = torch.optim.Adam(gen.generator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "9a813dfe",
      "metadata": {
        "id": "9a813dfe"
      },
      "outputs": [],
      "source": [
        "models = [F2U_GAN_CIFAR(condition=True, seed=42) for i in range(num_partitions)]\n",
        "gen = F2U_GAN_CIFAR(condition=True, seed=42).to(device)\n",
        "optim_G = torch.optim.Adam(gen.generator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "70f37272",
      "metadata": {
        "id": "70f37272"
      },
      "outputs": [],
      "source": [
        "optim_Ds = [\n",
        "    torch.optim.Adam(model.discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    for model in models\n",
        "]\n",
        "\n",
        "# scheduler_D = torch.optim.lr_scheduler.StepLR(optim_D, step_size=5, gamma=0.9)\n",
        "# scheduler_G = torch.optim.lr_scheduler.StepLR(optim_G, step_size=5, gamma=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e08c26a0",
      "metadata": {
        "id": "e08c26a0"
      },
      "source": [
        "Inicializa lambda para F2A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "893b45d4",
      "metadata": {
        "id": "893b45d4"
      },
      "outputs": [],
      "source": [
        "# initial λ* (unconstrained), wrap with ReLU to keep λ ≥ 0\n",
        "lambda_star = nn.Parameter(torch.tensor(0.1, device=device))\n",
        "relu = nn.ReLU()\n",
        "\n",
        "beta = 0.1  # same β as in the paper\n",
        "\n",
        "# now make your generator optimizer also update lambda_star\n",
        "# (so its gradient from the βλ² term can flow)\n",
        "optim_G = torch.optim.Adam(\n",
        "    list(gen.parameters()) + [lambda_star],\n",
        "    lr=2e-4, betas=(0.5, 0.999)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a3a7e9e",
      "metadata": {
        "id": "7a3a7e9e"
      },
      "source": [
        "# Treinamento dos modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b38a6962",
      "metadata": {
        "id": "b38a6962"
      },
      "source": [
        "## Cria chunks para o treinamento alternado entre discriminadora e geradora ser mais constante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "9b5d8adc",
      "metadata": {
        "id": "9b5d8adc"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2505ab00",
      "metadata": {
        "id": "2505ab00"
      },
      "source": [
        "Quanto menos chunks, mais dados em cada chunk e mais dados são treinados na discriminadora antes de treinar a geradora. No paper do F2U, não está claro como os treinamentos são alternados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FTvOVoSLVpta",
      "metadata": {
        "id": "FTvOVoSLVpta"
      },
      "outputs": [],
      "source": [
        "# prompt: set each train partition as the only first minimum lenght of the partitions samples, the partitions have same lenght\n",
        "\n",
        "min_len = min(len(p) for p in train_partitions)\n",
        "train_partitions = [p.select(range(min_len)) for p in train_partitions]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CVz-ThoCVfoh",
      "metadata": {
        "id": "CVz-ThoCVfoh"
      },
      "outputs": [],
      "source": [
        "for train_partition in train_partitions:\n",
        "  print(len(train_partition))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "8c5b5104",
      "metadata": {
        "id": "8c5b5104"
      },
      "outputs": [],
      "source": [
        "num_chunks = 100\n",
        "client_chunks = []\n",
        "for train_partition in client_datasets:\n",
        "  chunk_size = math.ceil(len(train_partition[\"train\"])/num_chunks)\n",
        "\n",
        "  chunks = []\n",
        "  for i in range(num_chunks):\n",
        "      start = i * chunk_size\n",
        "      end = min((i + 1) * chunk_size, len(train_partition[\"train\"]))\n",
        "      chunks.append(Subset(train_partition[\"train\"], range(start, end)))\n",
        "\n",
        "  client_chunks.append(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b0ad204d",
      "metadata": {
        "id": "b0ad204d"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "o6WJTKp6B5vD",
      "metadata": {
        "id": "o6WJTKp6B5vD"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "client_test_loaders = [DataLoader(dataset=ds[\"test\"], batch_size=batch_size, shuffle=False) for ds in client_datasets]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y1pa9oE9dRRy",
      "metadata": {
        "id": "Y1pa9oE9dRRy"
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "    # (re)seed PyTorch’s RNG for both CPU and all GPUs\n",
        "    torch.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "    # (optionally) enforce deterministic CuDNN behavior\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    # now construct the model\n",
        "    model = MyNetwork(...)\n",
        "    return model\n",
        "\n",
        "# both of these will have identical initial parameters:\n",
        "model1 = make_model()\n",
        "model2 = make_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ab8d65e",
      "metadata": {
        "id": "4ab8d65e"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "e70bd3c8",
      "metadata": {
        "id": "e70bd3c8"
      },
      "outputs": [],
      "source": [
        "nets = [Net(42).to(device) for _ in range(num_partitions)]\n",
        "optims = [torch.optim.Adam(net.parameters(), lr=0.01) for net in nets]\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "bbc668cf",
      "metadata": {
        "id": "bbc668cf"
      },
      "outputs": [],
      "source": [
        "testpartition = fds.load_split(\"test\")\n",
        "testpartition = testpartition.with_transform(apply_transforms)\n",
        "testloader = DataLoader(testpartition, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e86ba4bc",
      "metadata": {
        "id": "e86ba4bc"
      },
      "source": [
        "Carregar modelo pré-treinado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "3d3c145b",
      "metadata": {
        "id": "3d3c145b"
      },
      "outputs": [],
      "source": [
        "global_net = Net(42).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b66f9a29",
      "metadata": {
        "id": "b66f9a29"
      },
      "outputs": [],
      "source": [
        "checkpoint_loaded = torch.load(\"../Experimentos/GeraFed_4c_01Dir/CIFAR/checkpoint_epoch35.pth\")\n",
        "\n",
        "global_net.load_state_dict(checkpoint_loaded['alvo_state_dict'])\n",
        "global_net.to(device)\n",
        "for optim, state in zip(optims, checkpoint_loaded['optimizer_alvo_state_dict']):\n",
        "    optim.load_state_dict(state)\n",
        "\n",
        "gen.load_state_dict(checkpoint_loaded[\"gen_state_dict\"])\n",
        "gen.to(device)\n",
        "optim_G.load_state_dict(checkpoint_loaded[\"optim_G_state_dict\"])\n",
        "\n",
        "for model, optim_d, state_model, state_optim in zip(models, optim_Ds, checkpoint_loaded[\"discs_state_dict\"], checkpoint_loaded[\"optim_Ds_state_dict:\"]):\n",
        "    model.load_state_dict(state_model)\n",
        "    model.to(device)\n",
        "    optim_d.load_state_dict(state_optim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa1265b7",
      "metadata": {
        "id": "aa1265b7"
      },
      "source": [
        "Não esquecer de reinicializar os modelos e otimizadores se for reinicializar o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "d116bedf",
      "metadata": {
        "id": "d116bedf"
      },
      "outputs": [],
      "source": [
        "from flwr.server.strategy.aggregate import aggregate_inplace\n",
        "from flwr.common import FitRes, Status, Code, ndarrays_to_parameters\n",
        "from collections import OrderedDict, defaultdict\n",
        "from torch.utils.data import ConcatDataset\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1447e9f",
      "metadata": {
        "collapsed": true,
        "id": "c1447e9f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ce8ec3907204a9fb216f6d4ea868782",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Treinamento:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54b440dfcef347669731767a213e7744",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Chunks:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59b413f4dc2a438c9dcc4d6e854467a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to accuracy_report.txt\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dec37f02b9294f7697c95ae700d60c78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to accuracy_report.txt\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f7baeb9724f4260b5fc05e7557ecc53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to accuracy_report.txt\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b919771d11f3492c992af4fdc4dc887e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to accuracy_report.txt\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0912a97572c94af5b7a687987b798f05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "679b211b5eb84d33b31ba48e4b3be70d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc6ce1f7551d44bea8115becdcd0864b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b98407ec9fb4711b6ff537e3c27d9df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "131e996249464b299ce54c22e0574205",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0689555d60bf4e4ca8f42a2410b0a4a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1234dc08b34b47e38509d35665633d7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a84da80f7d0f45b6beb6055df1df0daa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2e981177de74816a2a2b7acaad3a734",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "af3234a5f590433ab2c0fb7d1c2a459d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7bf37826eeb4c21bcdc061dd3422f4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77ab498f245e4adfb34240892c14f402",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b08def2a46ac4304a89cfd77f63ffb6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e58c4d5fdacd44888a15c8c80719fde5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55942a60ee3840fa80443fa17c41fb62",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a6e40be19ec4442864d524898ae9ec3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99616512920c443fa259731f0c8e0e92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8615598ea68348dcbb6dbef940ac6442",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22b462c39f24406fa998307ed2e1e2f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f575d045ac34ee7b4cfbb4bf7b9a29d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38248fe4007a4bd887259870615901a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fad3cc5d0ef74c25b6d1528526a0d34c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b728e606d3a45a9a56abcdafb293f8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "000410686da14ef4bd07f85a525d56ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd265a20fb134f25a03222ce4c3402df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "868b8b9c1bee43f692b09b6a59d6fc98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04df39017fc8462bb106b96209c9eb89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88f6b15e19b647af873ba9ecdaaa2496",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cf1297b1f704d428824d3ed018819f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38138bf64076414d96e94cfdef0fdd63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04c914d37aa34c71852ea266c74dd4e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9a554fea19a4cf2a78272833028d7c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76ccf5d52f3c4844b20ac400161c49ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "756758a021084386b7924895da10ac8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03046fec9bbd42219a04d6341154d9a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2e476482ba74cb79422c84e3db19837",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "604e9262f6a44f2a9e7c4d65c40439a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44ad1e4396524ce4a483c006c27558ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "833b93be8f8a4eaa95b2a6cf6d23361f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99e1be74942b4f39ab33ebeaaf728f97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19683a50a8544c60932a2473ff36d8ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7a3dc1ec5d94726b8ab69d4455bff85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "844658c15601434990857f8ab934a1df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d41efd9f58445e1890452f94e9ae380",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e82b0d8b59374860b4317acec95d0141",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a45a9b7adfc249fcbc85539fcffd7442",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25ef5f99aff84a009e2efc63dc841c04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62d6295c314e4ceabd6f9fefae0122ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "988e5b7bc4a0468d88a6f2ab66ee406a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18bcb2a2f67b4de49d4ec16b32e2d172",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ce1b010849741dda34964afc7d8544e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fed60feeef9a483891bb1bcbe615fb14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67d0bd1aac264126affb93fa6d5f3612",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a154438692b54f4dbc4ce7c08ef58429",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59269b789dc6429882745d6025c50941",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6ad649a12f041d99161ab9d86d29a39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d87e1cacddc4070a5264e3390f9cf85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "51a95847ddf8488f9a00e532066bf705",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4e9c86c972845889443a7825bca75f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18486d59a09149bb8f70fd5a7620ec15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "136a67902e30411ebb8c9bbfd0e504a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccdd6602b0124c099a6281e5bca4b291",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e53f6e3bbc24414ac1b239a60ffb76d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a38bef857694b0ba2f07c9d0a78127c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2d2c329706e4a8281013ea244c39730",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c21a0166f846426a9176f57fc0720645",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fcbc63a6281e4a2982150c07f6a397f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "594d5234b147453c879a1449bb16e81b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd7f6541a6a4465e921e29b2c06e46d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8be898a6e8cf454694b13a695ec34ac3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ebf6dc0b417447cb301e1af27be889b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9e7d55cc60a4ef8b3959b5724302806",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b8591ad742045b68a732f76930277ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd847f9aa02541d183d2f60f304cc9e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc259c01d01547e3a1e8f34bf7cf6b8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65b7ede5ebb04682aff553ef0e2d7650",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f9d5429522a482e90d9a2f2b42eb537",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71cec70290a44f57a2932e0335c2c2cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55da5efe621640aeaf5e34a2ad9f9667",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55b6cbcdd2894a728acb18c4036e8d98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76158509df9e43d1b98c9d781cbc75a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1bdfd2c5ebb4ed6908ea895944f1293",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d30075417fe4ecc8e9c70ebce120df1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28ef4f434572408e82f8c2110385c0f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8afcf12de22b4abe92e686d24d56bffd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "586f66c1174645dcbca790cd84fdfb40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7bbfe14d36524f85958b79700dc7ed61",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70762f70fa5a4fbf924ab1f0c29f1098",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6dcf926a15764a58ab08567e36746f7b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49e73a66857c42aa8e80b2dab78ca31b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68a96c4a602d4a2d912fb345a2df70d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85e2ce9212b74e6486351a4122faa5cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9512c8f4ce04eb483ab254c91cadde1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d393faed32814fd08cd9d920ed952928",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96c7c0d540424cc98632a8b639fef457",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6111d2a9aa884f0598793cf556a31e08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68bfac7fa9204039b65aee5d3f582068",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "170c48c3434045ad9fe98f0d4501397c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d082b0d7269c495b98af25f3896db51e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b0b2d4f710a4dfe9874b79991db9277",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7473d23e8c4d48bab277f6312b72a6c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f83b46da45074b32ae9dbe5cbe77924f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90c230d5c809446987ccda700613fd4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e199aa692b64266a619cd5d4343f114",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c124b792881647079a76715040b899d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce56bec09cd84c8dbbb91d62acf2f04d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36fed2fa224248cf9fc4bfd5433bfcbd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afb508d95e464373a38173d5456a4da6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52d2281dee834081aaebb221e9f25de7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d0d20360df44c77a68e92274848b0a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88a09c0cf22a4d73abdbe381479e70f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7429b65cbf94e25a40bce0767a50d7d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6483ca7be9e140acab5e958b5b9b6bc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "211ceb3ccc6b4c7c9702c85a6820a0a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ecd41e337b044c8867f1881f331a65b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "989b0701b36c442fa5ee0909d3a47cfb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6dd08969f9243a1ad31c734875ecb38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "037025f6ccc24f208c98b31a002a7f72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e045d5b769df4289ade8645c23984f73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e33130a857b14cceb015b29ecb78282f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "565cbb83d6c94aa5ac23eb4f0b2ac21d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91eae08bff6745848c506e46615b0746",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e21b857d38ee4f068b2402d44469e860",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae7c6d4e709e433e832b66ea026a448a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e713498c03349968e50642ed86db829",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b46634d6295d4f61959a8c7240be37ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e88639100734ba1834ad7ac2e8e4465",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab5042618cb04e9f84978526f36ded07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62138d410f374d378751f15b0a04f27a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49400f4fcef14efe9561cccd94e1d89c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c07e321218164fcc82044f733e327820",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3cd9fdf4bfde4900a78e36210b354ba9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1855ee602f6a44ecb9d62a9bd942ec31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c27d4161c5b4417b39d9d6dfcae7a2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acbd3b59db0846f8ae4e1b237aa32d15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41854a7a4b644348b3303cff06916bfd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11adbbded93b4afdbc697172c19d693b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee523476bc56406b81fcb878b1e84334",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ec8c71437f04d9daa46c8e3bc23d4dd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c98bc7aa54a4a8b90f588f21dbaedb2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1160c6da163a41fcb9b7198efce3d6d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0da8836afc154501a82941f33028c5ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf713e0c15124bd79ad9525de3133ed9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5552540169924a4492baf51885c41b1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82094e2c144f4d809caf0758a431a58c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9952eabc4bdc4940a6609c6d9e9f10fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61a45b1e5fff414e9fe46a249c6a1af6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ccd9abea0c84814afdb42af309c5193",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e92e73152fc42d4a825b18dd04e1602",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "949ccde937a14c10b9459dbfee11f2fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd561e6bd6084f428c5814271df28053",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb4d14812af0477a92379b2798d1eb09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e347626fe3e84f32aec011dedbdf17e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Clients: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78ee2e6762eb4eed999b44cd98132a92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ca3bcd4a6204ec4931c39a4bae4a568",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a33643e35964d369c1ecee180dade7b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa9079c9a6b44d63adb9ba10929efadf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size is 1, skipping batch\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4de9607e3e94139993452daac1c51cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Gerador:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wgan = False\n",
        "f2a = False\n",
        "epochs = 100\n",
        "losses_dict = {\"g_losses_chunk\": [],\n",
        "               \"d_losses_chunk\": [],\n",
        "               \"g_losses_round\": [],\n",
        "               \"d_losses_round\": [],\n",
        "               \"net_loss_chunk\": [],\n",
        "               \"net_acc_chunk\": [],\n",
        "               \"net_loss_round\": [],\n",
        "               \"net_acc_round\": [],\n",
        "               \"time_chunk\": [],\n",
        "               \"time_round\": []}\n",
        "\n",
        "epoch_bar = tqdm(range(0, epochs), desc=\"Treinamento\", leave=True, position=0)\n",
        "\n",
        "batch_size_gen = 1\n",
        "batch_tam = 32\n",
        "extra_g_e = 20\n",
        "latent_dim = 128\n",
        "num_classes = 10\n",
        "if type(nets[0]).__name__ == \"Net\":\n",
        "  image = \"image\"\n",
        "else:\n",
        "  image = \"img\"\n",
        "\n",
        "if IN_COLAB:\n",
        "  acc_filename = os.path.join(save_dir,\"accuracy_report.txt\")\n",
        "  loss_filename = os.path.join(save_dir, \"losses.json\")\n",
        "  #log_lblcnt_path = os.path.join(save_dir, \"label_counter.txt\")\n",
        "  dmax_mismatch_log = os.path.join(save_dir, \"dmax_mismatch.txt\")\n",
        "  lambda_log = os.path.join(save_dir, \"lambda_log.txt\")\n",
        "\n",
        "else:\n",
        "  acc_filename = \"accuracy_report.txt\"\n",
        "  loss_filename = \"losses.json\"\n",
        "  #log_lblcnt_path = \"label_count.txt\"\n",
        "  dmax_mismatch_log = \"dmax_mismatch.txt\"\n",
        "  lambda_log = \"lambda_log.txt\"\n",
        "\n",
        "for epoch in epoch_bar:\n",
        "  epoch_start_time = time.time()\n",
        "  mismatch_count = 0\n",
        "  total_checked = 0\n",
        "  g_loss_c = 0.0\n",
        "  d_loss_c = 0.0\n",
        "  total_d_samples = 0  # Amostras totais processadas pelos discriminadores\n",
        "  total_g_samples = 0  # Amostras totais processadas pelo gerador\n",
        "  params = []\n",
        "  results = []\n",
        "  # Starta counter\n",
        "  #label_counter = Counter()\n",
        "\n",
        "  chunk_bar = tqdm(range(num_chunks), desc=\"Chunks\", leave=True, position=1)\n",
        "\n",
        "  for chunk_idx in chunk_bar:\n",
        "    chunk_start_time = time.time()\n",
        "    # ====================================================================\n",
        "    # Treino dos Discriminadores (clientes) no bloco atual\n",
        "    # ====================================================================\n",
        "    d_loss_b = 0\n",
        "    total_chunk_samples = 0\n",
        "\n",
        "\n",
        "    client_bar = tqdm(enumerate(zip(nets, models, client_chunks)), desc=\"Clients\", leave=True, position=2)\n",
        "\n",
        "    for cliente, (net, disc, chunks) in client_bar:\n",
        "      # Carregar o bloco atual do cliente\n",
        "      chunk_dataset = chunks[chunk_idx]\n",
        "      if len(chunk_dataset) == 0:\n",
        "        print(f\"Chunk {chunk_idx} for client {cliente} is empty, skipping.\")\n",
        "        continue\n",
        "      chunk_loader = DataLoader(chunk_dataset, batch_size=batch_tam, shuffle=False)\n",
        "      if chunk_idx == 0:\n",
        "        client_eval_time = time.time()\n",
        "        # Evaluation in client test\n",
        "        # Initialize counters\n",
        "        class_correct = defaultdict(int)\n",
        "        class_total = defaultdict(int)\n",
        "        predictions_counter = defaultdict(int)\n",
        "\n",
        "        global_net.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in client_test_loaders[cliente]:\n",
        "                images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "                outputs = global_net(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Update counts for each sample in batch\n",
        "                for true_label, pred_label in zip(labels, predicted):\n",
        "                    true_idx = true_label.item()\n",
        "                    pred_idx = pred_label.item()\n",
        "\n",
        "                    class_total[true_idx] += 1\n",
        "                    predictions_counter[pred_idx] += 1\n",
        "\n",
        "                    if true_idx == pred_idx:\n",
        "                        class_correct[true_idx] += 1\n",
        "\n",
        "            # Create results dictionary\n",
        "            results_metrics = {\n",
        "                \"class_metrics\": {},\n",
        "                \"overall_accuracy\": None,\n",
        "                \"prediction_distribution\": dict(predictions_counter)\n",
        "            }\n",
        "\n",
        "            # Calculate class-wise metrics\n",
        "            for i in range(num_classes):\n",
        "                metrics = {\n",
        "                    \"samples\": class_total[i],\n",
        "                    \"predictions\": predictions_counter[i],\n",
        "                    \"accuracy\": class_correct[i] / class_total[i] if class_total[i] > 0 else \"N/A\"\n",
        "                }\n",
        "                results_metrics[\"class_metrics\"][f\"class_{i}\"] = metrics\n",
        "\n",
        "            # Calculate overall accuracy\n",
        "            total_samples = sum(class_total.values())\n",
        "            results_metrics[\"overall_accuracy\"] = sum(class_correct.values()) / total_samples\n",
        "\n",
        "            # Save to txt file\n",
        "            with open(acc_filename, \"a\") as f:\n",
        "                f.write(f\"Epoch {epoch + 1} - Client {cliente}\\n\")\n",
        "                # Header with fixed widths\n",
        "                f.write(\"{:<10} {:<10} {:<10} {:<10}\\n\".format(\n",
        "                    \"Class\", \"Accuracy\", \"Samples\", \"Predictions\"))\n",
        "                f.write(\"-\"*45 + \"\\n\")\n",
        "\n",
        "                # Class rows with consistent formatting\n",
        "                for cls in range(num_classes):\n",
        "                    metrics = results_metrics[\"class_metrics\"][f\"class_{cls}\"]\n",
        "\n",
        "                    # Format accuracy (handle \"N/A\" case)\n",
        "                    accuracy = (f\"{metrics['accuracy']:.4f}\"\n",
        "                              if isinstance(metrics['accuracy'], float)\n",
        "                              else \"  N/A  \")\n",
        "\n",
        "                    f.write(\"{:<10} {:<10} {:<10} {:<10}\\n\".format(\n",
        "                        f\"Class {cls}\",\n",
        "                        accuracy,\n",
        "                        metrics['samples'],\n",
        "                        metrics['predictions']\n",
        "                    ))\n",
        "\n",
        "                # Footer with alignment\n",
        "                f.write(\"\\n{:<20} {:.4f}\".format(\"Overall Accuracy:\", results_metrics[\"overall_accuracy\"]))\n",
        "                f.write(\"\\n{:<20} {}\".format(\"Total Samples:\", total_samples))\n",
        "                f.write(\"\\n{:<20} {}\".format(\"Total Predictions:\", sum(predictions_counter.values())))\n",
        "                f.write(\"\\n{:<20} {:.4f}\".format(\"Client Evaluation Time:\", time.time() - client_eval_time))\n",
        "                f.write(\"\\n\")\n",
        "                f.write(\"\\n\")\n",
        "\n",
        "        print(\"Results saved to accuracy_report.txt\")\n",
        "\n",
        "      # Treinar o discriminador no bloco\n",
        "      net.load_state_dict(global_net.state_dict(), strict=True)\n",
        "      net.to(device)\n",
        "      net.train()\n",
        "      disc.to(device)\n",
        "      optim = optims[cliente]\n",
        "      optim_D = optim_Ds[cliente]\n",
        "\n",
        "      # num_samples = int(13 * (math.exp(0.01*epoch) - 1) / (math.exp(0.01*50) - 1)) * 10\n",
        "      # generated_dataset = GeneratedDataset(generator=gen.to(\"cpu\"), num_samples=num_samples, latent_dim=latent_dim, num_classes=10, device=\"cpu\", image_col_name=image)\n",
        "      # gen.to(device)\n",
        "      # cmb_ds = ConcatDataset([chunk_dataset, generated_dataset])\n",
        "      # combined_dataloader= DataLoader(cmb_ds, batch_size=batch_tam, shuffle=True)\n",
        "\n",
        "      # batch_bar_net = tqdm(combined_dataloader, desc=\"Batches\", leave=True, position=3)\n",
        "\n",
        "      # for batch in batch_bar_net:\n",
        "      #   images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "      #   batch_size = images.size(0)\n",
        "      #   if batch_size == 1:\n",
        "      #     print(\"Batch size is 1, skipping batch\")\n",
        "      #     continue\n",
        "      #   optim.zero_grad()\n",
        "      #   outputs = net(images)\n",
        "      #   loss = criterion(outputs, labels)\n",
        "      #   loss.backward()\n",
        "      #   optim.step()\n",
        "\n",
        "      batch_bar = tqdm(chunk_loader, desc=\"Batches\", leave=True, position=4)\n",
        "\n",
        "      for batch in batch_bar:\n",
        "          images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "          batch_size = images.size(0)\n",
        "          if batch_size == 1:\n",
        "            print(\"Batch size is 1, skipping batch\")\n",
        "            continue\n",
        "\n",
        "          optim.zero_grad()\n",
        "          outputs = net(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optim.step()\n",
        "\n",
        "          real_ident = torch.full((batch_size, 1), 1., device=device)\n",
        "          fake_ident = torch.full((batch_size, 1), 0., device=device)\n",
        "\n",
        "          z_noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "          x_fake_labels = torch.randint(0, 10, (batch_size,), device=device)\n",
        "\n",
        "          # Train D\n",
        "          optim_D.zero_grad()\n",
        "\n",
        "          if wgan:\n",
        "            labels = torch.nn.functional.one_hot(labels, 10).float().to(device)\n",
        "            x_fake_l = torch.nn.functional.one_hot(x_fake_labels, 10).float()\n",
        "\n",
        "            # Adicionar labels ao images para treinamento do Discriminador\n",
        "            image_labels = labels.view(labels.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "            image_fake_labels = x_fake_l.view(x_fake_l.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "\n",
        "            images = torch.cat([images, image_labels], dim=1)\n",
        "\n",
        "            # Treinar Discriminador\n",
        "            z = torch.cat([z_noise, x_fake_l], dim=1)\n",
        "            fake_images = gen(z).detach()\n",
        "            fake_images = torch.cat([fake_images, image_fake_labels], dim=1)\n",
        "\n",
        "            d_loss = discriminator_loss(disc(images), disc(fake_images)) + 10 * gradient_penalty(disc, images, fake_images)\n",
        "\n",
        "          else:\n",
        "            # Dados Reais\n",
        "            y_real = disc(images, labels)\n",
        "            d_real_loss = disc.loss(y_real, real_ident)\n",
        "\n",
        "            # Dados Falsos\n",
        "            x_fake = gen(z_noise, x_fake_labels).detach()\n",
        "            y_fake_d = disc(x_fake, x_fake_labels)\n",
        "            d_fake_loss = disc.loss(y_fake_d, fake_ident)\n",
        "\n",
        "            # Loss total e backprop\n",
        "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "          d_loss.backward()\n",
        "          #torch.nn.utils.clip_grad_norm_(disc.discriminator.parameters(), max_norm=1.0)\n",
        "          optim_D.step()\n",
        "          d_loss_b += d_loss.item()\n",
        "          total_chunk_samples += 1\n",
        "\n",
        "      params.append(ndarrays_to_parameters([val.cpu().numpy() for _, val in net.state_dict().items()]))\n",
        "      results.append((cliente, FitRes(status=Status(code=Code.OK, message=\"Success\"), parameters=params[cliente], num_examples=len(chunk_loader.dataset), metrics={})))\n",
        "\n",
        "    aggregated_ndarrays = aggregate_inplace(results)\n",
        "\n",
        "    params_dict = zip(global_net.state_dict().keys(), aggregated_ndarrays)\n",
        "    state_dict = OrderedDict({k: torch.tensor(v).to(device) for k, v in params_dict})\n",
        "    global_net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # Evaluation\n",
        "    if chunk_idx % 10 == 0:\n",
        "        global_net.eval()\n",
        "        correct, loss = 0, 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in testloader:\n",
        "                images = batch[image].to(device)\n",
        "                labels = batch[\"label\"].to(device)\n",
        "                outputs = global_net(images)\n",
        "                loss += criterion(outputs, labels).item()\n",
        "                correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        accuracy = correct / len(testloader.dataset)\n",
        "        losses_dict[\"net_loss_chunk\"].append(loss / len(testloader))\n",
        "        losses_dict[\"net_acc_chunk\"].append(accuracy)\n",
        "\n",
        "\n",
        "    # Média da perda dos discriminadores neste chunk\n",
        "    avg_d_loss_chunk = d_loss_b / total_chunk_samples if total_chunk_samples > 0 else 0.0\n",
        "    losses_dict[\"d_losses_chunk\"].append(avg_d_loss_chunk)\n",
        "    d_loss_c += avg_d_loss_chunk * total_chunk_samples\n",
        "    total_d_samples += total_chunk_samples\n",
        "\n",
        "    chunk_g_loss = 0.0\n",
        "\n",
        "    epoch_gen_bar = tqdm(range(extra_g_e), desc=\"Gerador\", leave=True, position=2)\n",
        "\n",
        "    for g_epoch in epoch_gen_bar:\n",
        "      # Train G\n",
        "      optim_G.zero_grad()\n",
        "\n",
        "      # Gera dados falsos\n",
        "      z_noise = torch.randn(batch_size_gen, latent_dim, device=device)\n",
        "      x_fake_labels = torch.randint(0, 10, (batch_size_gen,), device=device)\n",
        "      label = int(x_fake_labels.item())\n",
        "\n",
        "      # Count label usage\n",
        "      #label_counter[label] += 1\n",
        "\n",
        "      if wgan:\n",
        "        x_fake_labels = torch.nn.functional.one_hot(x_fake_labels, 10).float()\n",
        "        z_noise = torch.cat([z_noise, x_fake_labels], dim=1)\n",
        "        fake_images = gen(z_noise)\n",
        "\n",
        "        # Seleciona o melhor discriminador (Dmax)\n",
        "        image_fake_labels = x_fake_labels.view(x_fake_labels.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "        fake_images = torch.cat([fake_images, image_fake_labels], dim=1)\n",
        "\n",
        "        y_fake_gs = [model(fake_images.detach()) for model in models]\n",
        "\n",
        "      else:\n",
        "        x_fake = gen(z_noise, x_fake_labels)\n",
        "\n",
        "        if f2a:\n",
        "          y_fakes = []\n",
        "          for D in models:\n",
        "              D = D.to(device)\n",
        "              y_fakes.append(D(x_fake, x_fake_labels))  # each is [B,1]\n",
        "          # stack into [N_discriminators, B, 1]\n",
        "          y_stack = torch.stack(y_fakes, dim=0)\n",
        "\n",
        "          # 4) Compute λ = ReLU(lambda_star) to enforce λ ≥ 0\n",
        "          lam = relu(lambda_star)\n",
        "\n",
        "          # 5) Soft‐max weights across the 0th dim (discriminators)\n",
        "          #    we want S_i = exp(λ D_i) / sum_j exp(λ D_j)\n",
        "          #    shape remains [N, B, 1]\n",
        "          S = torch.softmax(lam * y_stack, dim=0)\n",
        "\n",
        "          # 6) Weighted sum: D_agg shape [B,1]\n",
        "          D_agg = (S * y_stack).sum(dim=0)\n",
        "\n",
        "          # 7) Compute your generator loss + β λ² regularizer\n",
        "          real_ident = torch.full((batch_size_gen, 1), 1., device=device)\n",
        "          adv_loss   = gen.loss(D_agg, real_ident)       # BCEWithLogitsLoss or whatever\n",
        "          reg_loss   = beta * lam.pow(2)                 # β λ²\n",
        "          g_loss     = adv_loss + reg_loss\n",
        "\n",
        "        else:\n",
        "          # Seleciona o melhor discriminador (Dmax)\n",
        "          y_fake_gs = [model(x_fake.detach(), x_fake_labels) for model in models]\n",
        "          y_fake_g_means = [torch.mean(y).item() for y in y_fake_gs]\n",
        "          dmax_index = y_fake_g_means.index(max(y_fake_g_means))\n",
        "          Dmax = models[dmax_index]\n",
        "\n",
        "          #Track mismatches\n",
        "          expected_indexes = label_to_client[class_labels.int2str(x_fake_labels.item())] ##PEGA SOMENTE A PRIMEIRA LABEL, SE BATCH_SIZE_GEN FOR DIFERENTE DE 1 VAI DAR ERRO\n",
        "          if dmax_index not in expected_indexes:\n",
        "              mismatch_count += 1\n",
        "              total_checked +=1\n",
        "              percent_mismatch =  mismatch_count / total_checked\n",
        "              with open(dmax_mismatch_log, \"a\") as mismatch_file:\n",
        "                  mismatch_file.write(f\"{epoch+1} {x_fake_labels.item()} {expected_indexes} {dmax_index} {percent_mismatch:.2f}\\n\")\n",
        "          else:\n",
        "              total_checked += 1\n",
        "              if g_epoch == extra_g_e - 1 and chunk_idx == num_chunks - 1:\n",
        "                percent_mismatch =  mismatch_count / total_checked\n",
        "                with open(dmax_mismatch_log, \"a\") as mismatch_file:\n",
        "                  mismatch_file.write(f\"{epoch+1} {x_fake_labels.item()} {expected_indexes} {dmax_index} {percent_mismatch:.2f}\\n\")\n",
        "\n",
        "          # Calcula a perda do gerador\n",
        "          real_ident = torch.full((batch_size_gen, 1), 1., device=device)\n",
        "          if wgan:\n",
        "            y_fake_g = Dmax(fake_images)\n",
        "            g_loss = generator_loss(y_fake_g)\n",
        "\n",
        "          else:\n",
        "            y_fake_g = Dmax(x_fake, x_fake_labels)  # Detach explícito\n",
        "            g_loss = gen.loss(y_fake_g, real_ident)\n",
        "\n",
        "      g_loss.backward()\n",
        "      #torch.nn.utils.clip_grad_norm_(gen.generator.parameters(), max_norm=1.0)\n",
        "      optim_G.step()\n",
        "      gen.to(device)\n",
        "      chunk_g_loss += g_loss.item()\n",
        "\n",
        "    losses_dict[\"g_losses_chunk\"].append(chunk_g_loss / extra_g_e)\n",
        "    g_loss_c += chunk_g_loss /extra_g_e\n",
        "\n",
        "    losses_dict[\"time_chunk\"].append(time.time() - chunk_start_time)\n",
        "\n",
        "\n",
        "  g_loss_e = g_loss_c/num_chunks\n",
        "  d_loss_e = d_loss_c / total_d_samples if total_d_samples > 0 else 0.0\n",
        "\n",
        "  losses_dict[\"g_losses_round\"].append(g_loss_e)\n",
        "  losses_dict[\"d_losses_round\"].append(d_loss_e)\n",
        "\n",
        "  if (epoch+1)%2==0:\n",
        "      checkpoint = {\n",
        "            'epoch': epoch+1,  # número da última época concluída\n",
        "            'alvo_state_dict': global_net.state_dict(),\n",
        "            'optimizer_alvo_state_dict': [optim.state_dict() for optim in optims],\n",
        "            'gen_state_dict': gen.state_dict(),\n",
        "            'optim_G_state_dict': optim_G.state_dict(),\n",
        "            'discs_state_dict': [model.state_dict() for model in models],\n",
        "            'optim_Ds_state_dict:': [optim_d.state_dict() for optim_d in optim_Ds]\n",
        "          }\n",
        "      checkpoint_file = f\"checkpoint_epoch{epoch+1}.pth\"\n",
        "      if IN_COLAB:\n",
        "          checkpoint_file = os.path.join(save_dir, checkpoint_file)\n",
        "      torch.save(checkpoint, checkpoint_file)\n",
        "      print(f\"Global net saved to {checkpoint_file}\")\n",
        "      # Log label distribution for this epoch\n",
        "      # with open(log_lblcnt_path, \"a\") as log_file:\n",
        "      #     # Prepare counts string for labels 0-9\n",
        "      #     counts = [label_counter[i] for i in range(10)]\n",
        "      #     counts_str = \" \".join(str(c) for c in counts)\n",
        "      #     log_file.write(f\"{epoch} {counts_str}\\n\")\n",
        "      if f2a:\n",
        "        current_lambda_star = lambda_star.item()\n",
        "        current_lam         = F.relu(lambda_star).item()\n",
        "\n",
        "        with open(lambda_log, \"a\") as f:\n",
        "          f.write(f\"{current_lambda_star},{current_lam}\\n\")\n",
        "\n",
        "  correct, loss = 0, 0.0\n",
        "  global_net.eval()\n",
        "  with torch.no_grad():\n",
        "      for batch in testloader:\n",
        "          images = batch[image].to(device)\n",
        "          labels = batch[\"label\"].to(device)\n",
        "          outputs = global_net(images)\n",
        "          loss += criterion(outputs, labels).item()\n",
        "          correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "  accuracy = correct / len(testloader.dataset)\n",
        "  losses_dict[\"net_loss_round\"].append(loss / len(testloader))\n",
        "  losses_dict[\"net_acc_round\"].append(accuracy)\n",
        "\n",
        "    # generate_plot(disc=gen, device=\"cpu\", round_number=epoch+1, latent_dim=latent_dim)\n",
        "    # generated_dataset = GeneratedDataset(generator=gen.to(\"cpu\"), num_samples=12000, latent_dim=latent_dim, num_classes=10, device=\"cpu\")\n",
        "    # generated_dataloader = DataLoader(generated_dataset, batch_size=64, shuffle=True)\n",
        "    # print(\"Treinando modelo classificador\")\n",
        "    # disc = Net().to(device)\n",
        "    # criterion = torch.nn.CrossEntropyLoss()\n",
        "    # optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
        "    # net.train()\n",
        "    # for epoch in range(5):\n",
        "    #     for data in generated_dataloader:\n",
        "    #         inputs, labels = data[image].to(device), data[\"label\"].to(device)\n",
        "    #         optimizer.zero_grad()\n",
        "    #         outputs = net(inputs)\n",
        "    #         loss = criterion(outputs, labels)\n",
        "    #         loss.backward()\n",
        "    #         optimizer.step()\n",
        "    # correct, loss = 0, 0.0\n",
        "\n",
        "    # Initialize counters\n",
        "    # num_classes = 10  # Update with your actual number of classes\n",
        "    # class_correct = defaultdict(int)\n",
        "    # class_total = defaultdict(int)\n",
        "    # predictions_counter = defaultdict(int)\n",
        "\n",
        "    # # Evaluation\n",
        "    # net.eval()\n",
        "    # with torch.no_grad():\n",
        "    #     for batch in testloader:\n",
        "    #         images, labels = batch[0].to(device), batch[1].to(device)\n",
        "    #         outputs = net(images)\n",
        "    #         _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    #         # Update counts for each sample in batch\n",
        "    #         for true_label, pred_label in zip(labels, predicted):\n",
        "    #             true_idx = true_label.item()\n",
        "    #             pred_idx = pred_label.item()\n",
        "\n",
        "    #             class_total[true_idx] += 1\n",
        "    #             predictions_counter[pred_idx] += 1\n",
        "\n",
        "    #             if true_idx == pred_idx:\n",
        "    #                 class_correct[true_idx] += 1\n",
        "\n",
        "    # # Create results dictionary\n",
        "    # results = {\n",
        "    #     \"class_metrics\": {},\n",
        "    #     \"overall_accuracy\": None,\n",
        "    #     \"prediction_distribution\": dict(predictions_counter)\n",
        "    # }\n",
        "\n",
        "    # # Calculate class-wise metrics\n",
        "    # for i in range(num_classes):\n",
        "    #     metrics = {\n",
        "    #         \"samples\": class_total[i],\n",
        "    #         \"predictions\": predictions_counter[i],\n",
        "    #         \"accuracy\": class_correct[i] / class_total[i] if class_total[i] > 0 else \"N/A\"\n",
        "    #     }\n",
        "    #     results[\"class_metrics\"][f\"class_{i}\"] = metrics\n",
        "\n",
        "    # # Calculate overall accuracy\n",
        "    # total_samples = sum(class_total.values())\n",
        "    # results[\"overall_accuracy\"] = sum(class_correct.values()) / total_samples\n",
        "    # accuracies.append(results[\"overall_accuracy\"])\n",
        "\n",
        "    # # Save to txt file\n",
        "    # with open(acc_filename, \"a\") as f:\n",
        "    #     # Header with fixed widths\n",
        "    #     f.write(\"{:<10} {:<10} {:<10} {:<10}\\n\".format(\n",
        "    #         \"Class\", \"Accuracy\", \"Samples\", \"Predictions\"))\n",
        "    #     f.write(\"-\"*45 + \"\\n\")\n",
        "\n",
        "    #     # Class rows with consistent formatting\n",
        "    #     for cls in range(num_classes):\n",
        "    #         metrics = results[\"class_metrics\"][f\"class_{cls}\"]\n",
        "\n",
        "    #         # Format accuracy (handle \"N/A\" case)\n",
        "    #         accuracy = (f\"{metrics['accuracy']:.4f}\"\n",
        "    #                   if isinstance(metrics['accuracy'], float)\n",
        "    #                   else \"  N/A  \")\n",
        "\n",
        "    #         f.write(\"{:<10} {:<10} {:<10} {:<10}\\n\".format(\n",
        "    #             f\"Class {cls}\",\n",
        "    #             accuracy,\n",
        "    #             metrics['samples'],\n",
        "    #             metrics['predictions']\n",
        "    #         ))\n",
        "\n",
        "    #     # Footer with alignment\n",
        "    #     f.write(\"\\n{:<20} {:.4f}\".format(\"Overall Accuracy:\", results[\"overall_accuracy\"]))\n",
        "    #     f.write(\"\\n{:<20} {}\".format(\"Total Samples:\", total_samples))\n",
        "    #     f.write(\"\\n{:<20} {}\".format(\"Total Predictions:\", sum(predictions_counter.values())))\n",
        "\n",
        "    # print(\"Results saved to accuracy_report.txt\")\n",
        "\n",
        "\n",
        "  print(f\"Época {epoch+1} completa\")\n",
        "  generate_plot(gen, \"cpu\", epoch+1, latent_dim=128)\n",
        "  gen.to(device)\n",
        "\n",
        "  losses_dict[\"time_round\"].append(time.time() - epoch_start_time)\n",
        "\n",
        "  try:\n",
        "      with open(loss_filename, 'w', encoding='utf-8') as f:\n",
        "          json.dump(losses_dict, f, ensure_ascii=False, indent=4) # indent makes it readable\n",
        "      print(f\"Losses dict successfully saved to {loss_filename}\")\n",
        "  except Exception as e:\n",
        "      print(f\"Error saving losses dict to JSON: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "011aa6f7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'0': [],\n",
              " '1': [],\n",
              " '2': [0],\n",
              " '3': [],\n",
              " '4': [],\n",
              " '5': [2],\n",
              " '6': [],\n",
              " '7': [],\n",
              " '8': [3],\n",
              " '9': [1]}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_to_client "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_OdHAvK0LQp3",
      "metadata": {
        "collapsed": true,
        "id": "_OdHAvK0LQp3"
      },
      "outputs": [],
      "source": [
        "epochs = 2\n",
        "losses_dict = {\"net_loss_chunk\": [],\n",
        "               \"net_acc_chunk\": [],\n",
        "               \"net_loss_round\": [],\n",
        "               \"net_acc_round\": [],\n",
        "               \"time_chunk\": [],\n",
        "               \"time_round\": []}\n",
        "\n",
        "epoch_bar = tqdm(range(0, epochs), desc=\"Treinamento\", leave=True, position=0)\n",
        "\n",
        "batch_tam = 32\n",
        "latent_dim = 128\n",
        "num_classes = 10\n",
        "if type(nets[0]).__name__ == \"Net\":\n",
        "  image = \"image\"\n",
        "else:\n",
        "  image = \"img\"\n",
        "\n",
        "if IN_COLAB:\n",
        "  acc_filename = os.path.join(save_dir,\"accuracy_report.txt\")\n",
        "  loss_filename = os.path.join(save_dir, \"losses.json\")\n",
        "else:\n",
        "  acc_filename = \"accuracy_report.txt\"\n",
        "  loss_filename = \"losses.json\"\n",
        "\n",
        "for epoch in epoch_bar:\n",
        "  epoch_start_time = time.time()\n",
        "\n",
        "  chunk_bar = tqdm(range(num_chunks), desc=\"Chunks\", leave=True, position=1)\n",
        "\n",
        "  for chunk_idx in chunk_bar:\n",
        "    params = []\n",
        "    results = []\n",
        "    chunk_start_time = time.time()\n",
        "    total_chunk_samples = 0\n",
        "\n",
        "    client_bar = tqdm(enumerate(zip(nets, client_chunks)), desc=\"Clients\", leave=True, position=2)\n",
        "\n",
        "    for cliente, (net, chunks) in client_bar:\n",
        "\n",
        "      if chunk_idx == 0:\n",
        "        client_eval_time = time.time()\n",
        "        # Evaluation in client test\n",
        "        # Initialize counters\n",
        "        class_correct = defaultdict(int)\n",
        "        class_total = defaultdict(int)\n",
        "        predictions_counter = defaultdict(int)\n",
        "\n",
        "        global_net.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in client_test_loaders[cliente]:\n",
        "                images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "                outputs = global_net(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Update counts for each sample in batch\n",
        "                for true_label, pred_label in zip(labels, predicted):\n",
        "                    true_idx = true_label.item()\n",
        "                    pred_idx = pred_label.item()\n",
        "\n",
        "                    class_total[true_idx] += 1\n",
        "                    predictions_counter[pred_idx] += 1\n",
        "\n",
        "                    if true_idx == pred_idx:\n",
        "                        class_correct[true_idx] += 1\n",
        "\n",
        "            # Create results dictionary\n",
        "            results_metrics = {\n",
        "                \"class_metrics\": {},\n",
        "                \"overall_accuracy\": None,\n",
        "                \"prediction_distribution\": dict(predictions_counter)\n",
        "            }\n",
        "\n",
        "            # Calculate class-wise metrics\n",
        "            for i in range(num_classes):\n",
        "                metrics = {\n",
        "                    \"samples\": class_total[i],\n",
        "                    \"predictions\": predictions_counter[i],\n",
        "                    \"accuracy\": class_correct[i] / class_total[i] if class_total[i] > 0 else \"N/A\"\n",
        "                }\n",
        "                results_metrics[\"class_metrics\"][f\"class_{i}\"] = metrics\n",
        "\n",
        "            # Calculate overall accuracy\n",
        "            total_samples = sum(class_total.values())\n",
        "            results_metrics[\"overall_accuracy\"] = sum(class_correct.values()) / total_samples\n",
        "\n",
        "            # Save to txt file\n",
        "            with open(acc_filename, \"a\") as f:\n",
        "                f.write(f\"Epoch {epoch + 1} - Client {cliente}\\n\")\n",
        "                # Header with fixed widths\n",
        "                f.write(\"{:<10} {:<10} {:<10} {:<10}\\n\".format(\n",
        "                    \"Class\", \"Accuracy\", \"Samples\", \"Predictions\"))\n",
        "                f.write(\"-\"*45 + \"\\n\")\n",
        "\n",
        "                # Class rows with consistent formatting\n",
        "                for cls in range(num_classes):\n",
        "                    metrics = results_metrics[\"class_metrics\"][f\"class_{cls}\"]\n",
        "\n",
        "                    # Format accuracy (handle \"N/A\" case)\n",
        "                    accuracy = (f\"{metrics['accuracy']:.4f}\"\n",
        "                              if isinstance(metrics['accuracy'], float)\n",
        "                              else \"  N/A  \")\n",
        "\n",
        "                    f.write(\"{:<10} {:<10} {:<10} {:<10}\\n\".format(\n",
        "                        f\"Class {cls}\",\n",
        "                        accuracy,\n",
        "                        metrics['samples'],\n",
        "                        metrics['predictions']\n",
        "                    ))\n",
        "\n",
        "                # Footer with alignment\n",
        "                f.write(\"\\n{:<20} {:.4f}\".format(\"Overall Accuracy:\", results_metrics[\"overall_accuracy\"]))\n",
        "                f.write(\"\\n{:<20} {}\".format(\"Total Samples:\", total_samples))\n",
        "                f.write(\"\\n{:<20} {}\".format(\"Total Predictions:\", sum(predictions_counter.values())))\n",
        "                f.write(\"\\n{:<20} {:.4f}\".format(\"Client Evaluation Time:\", time.time() - client_eval_time))\n",
        "                f.write(\"\\n\")\n",
        "                f.write(\"\\n\")\n",
        "\n",
        "        print(\"Results saved to accuracy_report.txt\")\n",
        "\n",
        "      # Carregar o bloco atual do cliente\n",
        "      chunk_dataset = chunks[chunk_idx]\n",
        "      if len(chunk_dataset) == 0:\n",
        "        print(f\"Chunk {chunk_idx} for client {cliente} is empty, skipping.\")\n",
        "        continue\n",
        "      chunk_loader = DataLoader(chunk_dataset, batch_size=batch_tam, shuffle=False)\n",
        "\n",
        "      net.load_state_dict(global_net.state_dict(), strict=True)\n",
        "      net.to(device)\n",
        "      net.train()\n",
        "      optim = optims[cliente]\n",
        "\n",
        "      batch_bar = tqdm(chunk_loader, desc=\"Batches\", leave=True, position=3)\n",
        "\n",
        "      for batch in batch_bar:\n",
        "        images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "        batch_size = images.size(0)\n",
        "        if batch_size == 1:\n",
        "          print(\"Batch size is 1, skipping batch\")\n",
        "          continue\n",
        "        optim.zero_grad()\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "\n",
        "      params.append(ndarrays_to_parameters([val.cpu().numpy() for _, val in net.state_dict().items()]))\n",
        "      results.append((cliente, FitRes(status=Status(code=Code.OK, message=\"Success\"), parameters=params[cliente], num_examples=len(chunk_loader.dataset), metrics={})))\n",
        "\n",
        "    aggregated_ndarrays = aggregate_inplace(results)\n",
        "\n",
        "    params_dict = zip(global_net.state_dict().keys(), aggregated_ndarrays)\n",
        "    state_dict = OrderedDict({k: torch.tensor(v).to(device) for k, v in params_dict})\n",
        "    global_net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # Evaluation\n",
        "    if chunk_idx % 10 == 0:\n",
        "        global_net.eval()\n",
        "        correct, loss = 0, 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in testloader:\n",
        "                images = batch[image].to(device)\n",
        "                labels = batch[\"label\"].to(device)\n",
        "                outputs = global_net(images)\n",
        "                loss += criterion(outputs, labels).item()\n",
        "                correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        accuracy = correct / len(testloader.dataset)\n",
        "        losses_dict[\"net_loss_chunk\"].append(loss / len(testloader))\n",
        "        losses_dict[\"net_acc_chunk\"].append(accuracy)\n",
        "\n",
        "        losses_dict[\"time_chunk\"].append(time.time() - chunk_start_time)\n",
        "\n",
        "  correct, loss = 0, 0.0\n",
        "  global_net.eval()\n",
        "  with torch.no_grad():\n",
        "      for batch in testloader:\n",
        "          images = batch[image].to(device)\n",
        "          labels = batch[\"label\"].to(device)\n",
        "          outputs = global_net(images)\n",
        "          loss += criterion(outputs, labels).item()\n",
        "          correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "  accuracy = correct / len(testloader.dataset)\n",
        "  losses_dict[\"net_loss_round\"].append(loss / len(testloader))\n",
        "  losses_dict[\"net_acc_round\"].append(accuracy)\n",
        "\n",
        "\n",
        "  print(f\"Época {epoch+1} completa\")\n",
        "\n",
        "  losses_dict[\"time_round\"].append(time.time() - epoch_start_time)\n",
        "\n",
        "  try:\n",
        "      with open(loss_filename, 'w', encoding='utf-8') as f:\n",
        "          json.dump(losses_dict, f, ensure_ascii=False, indent=4) # indent makes it readable\n",
        "      print(f\"Losses dict successfully saved to {loss_filename}\")\n",
        "  except Exception as e:\n",
        "      print(f\"Error saving losses dict to JSON: {e}\")\n",
        "\n",
        "  if (epoch+1)%1==0:\n",
        "    checkpoint = {\n",
        "          'epoch': epoch+1,  # número da última época concluída\n",
        "          'alvo_state_dict': global_net.state_dict(),\n",
        "          'optimizer_alvo_state_dict': [optim.state_dict() for optim in optims],\n",
        "        }\n",
        "    checkpoint_file = f\"checkpoint_epoch{epoch+1}.pth\"\n",
        "    if IN_COLAB:\n",
        "        checkpoint_file = os.path.join(save_dir, checkpoint_file)\n",
        "    torch.save(checkpoint, checkpoint_file)\n",
        "    print(f\"Global net saved to {checkpoint_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c3ce47d",
      "metadata": {
        "id": "2c3ce47d"
      },
      "source": [
        "# Gráficos de perda e acurácia"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01f7dbfb",
      "metadata": {
        "id": "01f7dbfb"
      },
      "source": [
        "## Le o arquivo de perda salvo no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FaRDCz_cSJDf",
      "metadata": {
        "id": "FaRDCz_cSJDf"
      },
      "outputs": [],
      "source": [
        "loss_filename = \"losses.json\"\n",
        "if IN_COLAB:\n",
        "  loss_filename = os.path.join(save_dir, loss_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-by_-71kSOeu",
      "metadata": {
        "id": "-by_-71kSOeu"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49537f37",
      "metadata": {
        "id": "49537f37"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    with open(loss_filename, 'r', encoding='utf-8') as f:\n",
        "        # The load function also works the same\n",
        "        loaded_dict = json.load(f)\n",
        "    print(f\"Dictionary successfully loaded from {loss_filename}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File '{loss_filename}' not found.\")\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Error: Could not decode JSON from '{loss_filename}'. File might be corrupted or not JSON.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dictionary from JSON: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "237af03a",
      "metadata": {
        "id": "237af03a"
      },
      "source": [
        "Coleta acurácias locais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d24b634",
      "metadata": {
        "id": "8d24b634"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f0588a2",
      "metadata": {
        "id": "8f0588a2"
      },
      "outputs": [],
      "source": [
        "def parse_client_accuracies(log_path):\n",
        "   # Regex to match \"Round X - Cliente Y\" and \"Overall Accuracy:    Z.ZZZZ\"\n",
        "   header_re   = re.compile(r\"Epoch\\s+\\d+\\s*-\\s*Client\\s*(\\d+)\", re.IGNORECASE)\n",
        "   accuracy_re = re.compile(r\"Overall Accuracy:\\s*([\\d.]+)\")\n",
        "\n",
        "\n",
        "   # Now client → list of accuracies\n",
        "   client_accuracies = defaultdict(list)\n",
        "\n",
        "\n",
        "   with open(log_path, 'r', encoding='utf-8') as f:\n",
        "       current_client = None\n",
        "\n",
        "\n",
        "       for line in f:\n",
        "           # Detect the client header\n",
        "           hdr = header_re.search(line)\n",
        "           if hdr:\n",
        "               current_client = int(hdr.group(1))\n",
        "               continue\n",
        "\n",
        "\n",
        "           # Once we see the accuracy line, append and reset\n",
        "           if current_client is not None:\n",
        "               acc = accuracy_re.search(line)\n",
        "               if acc:\n",
        "                   client_accuracies[current_client].append(float(acc.group(1)))\n",
        "                   current_client = None\n",
        "\n",
        "\n",
        "   return dict(client_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f397ca9c",
      "metadata": {
        "id": "f397ca9c"
      },
      "outputs": [],
      "source": [
        "log_file = \"../Experimentos/Alvo_4c_NIIDClass/accuracy_report.txt\"\n",
        "accuracies_class = parse_client_accuracies(log_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b890d518",
      "metadata": {
        "id": "b890d518"
      },
      "source": [
        "## Exibe gráficos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39493e97",
      "metadata": {
        "id": "39493e97"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from typing import Iterable, Mapping, Literal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cc3c2af",
      "metadata": {
        "id": "3cc3c2af"
      },
      "outputs": [],
      "source": [
        "def plot_series(\n",
        "    series: Mapping[str, Iterable[float]],\n",
        "    *,\n",
        "    # Series-specific styles: color, linestyle, etc.\n",
        "    series_styles: Mapping[str, Mapping[str, Any]] = None,\n",
        "    # Axis limits\n",
        "    xlim: tuple[float, float] = None,\n",
        "    ylim: tuple[float, float] = None,\n",
        "    # Tick control\n",
        "    first_step: int = None,\n",
        "    xtick_step: int = 1,\n",
        "    xtick_offset: int = 0,\n",
        "    # Labels\n",
        "    xlabel: str = \"Epochs\",\n",
        "    ylabel: str = \"Value\",\n",
        "    title: str = None,\n",
        "    # Highlight control: per-series \"max\", \"min\", \"both\"\n",
        "    highlight: Mapping[str, Literal[\"max\", \"min\", \"both\"]] = None,\n",
        "    highlight_marker: str = \"o\",\n",
        "    highlight_markersize: float = 4,\n",
        "    highlight_color: str = None,\n",
        "    # Figure size\n",
        "    figsize: tuple[float, float] = (10, 5),\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Plots one or more series with per-series options for line style/color,\n",
        "    tick control, axis limits, and per-series max/min highlighting.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    series : Mapping[str, Iterable[float]]\n",
        "        Dict from legend label to its sequence of values.\n",
        "    series_styles : Mapping[str, Mapping[str, Any]], optional\n",
        "        Per-series plotting kwargs (e.g. 'color', 'linestyle', etc.).\n",
        "    xlim : (float, float), optional\n",
        "        X-axis limits.\n",
        "    ylim : (float, float), optional\n",
        "        Y-axis limits.\n",
        "    first_step : int, optional\n",
        "        If given, ticks at 1, 1+first_step, then +xtick_step thereafter.\n",
        "    xtick_step : int, optional\n",
        "        Uniform tick step if first_step is None.\n",
        "    xtick_offset : int, optional\n",
        "        Added to every tick label.\n",
        "    xlabel, ylabel, title : str, optional\n",
        "        Axis and title labels.\n",
        "    highlight : Mapping[str, {\"max\",\"min\",\"both\"}], optional\n",
        "        For each series name, what to highlight. Omit or None to skip.\n",
        "    highlight_marker : str\n",
        "        Marker style for highlights.\n",
        "    highlight_color : str, optional\n",
        "        Color for highlight markers (overrides series color if set).\n",
        "    highlight_markersize : float\n",
        "        Size of highlight markers.\n",
        "    figsize : (w, h)\n",
        "        Figure size in inches.\n",
        "    \"\"\"\n",
        "    # Validate lengths\n",
        "    lengths = {len(v) for v in series.values()}\n",
        "    if not lengths:\n",
        "        raise ValueError(\"No data series provided.\")\n",
        "    if len(lengths) > 1:\n",
        "        raise ValueError(f\"Series length mismatch: {lengths}\")\n",
        "    n = lengths.pop()\n",
        "\n",
        "    xs = list(range(n))\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    for name, ys in series.items():\n",
        "        # Get style for this series\n",
        "        style = {} if series_styles is None or name not in series_styles else series_styles[name]\n",
        "        # Plot and capture line for default color\n",
        "        line, = plt.plot(xs, ys, label=name, **style)\n",
        "        mode = highlight[name] if (highlight and name in highlight) else None\n",
        "\n",
        "        # Determine marker color\n",
        "        base_color = style.get('color', line.get_color())\n",
        "        mcolor = highlight_color or base_color\n",
        "\n",
        "        # Highlight max\n",
        "        if mode in (\"max\", \"both\"):\n",
        "            i_max = max(range(n), key=lambda i: ys[i])\n",
        "            plt.plot(i_max, ys[i_max], marker=highlight_marker,\n",
        "                     markersize=highlight_markersize, color=mcolor, linestyle=\"\")\n",
        "            plt.text(i_max, ys[i_max] + 0.01, f\"{ys[i_max]:.2f}\",\n",
        "                     va=\"bottom\", ha=\"center\", fontsize=8)\n",
        "        # Highlight min\n",
        "        if mode in (\"min\", \"both\"):\n",
        "            i_min = min(range(n), key=lambda i: ys[i])\n",
        "            plt.plot(i_min, ys[i_min], marker=highlight_marker,\n",
        "                     markersize=highlight_markersize, color=mcolor, linestyle=\"\")\n",
        "            plt.text(i_min, ys[i_min], f\"{ys[i_min]:.2f}\",\n",
        "                     va=\"top\", ha=\"center\", fontsize=8)\n",
        "\n",
        "    # X-ticks logic\n",
        "    if first_step is not None:\n",
        "        labels = [1]\n",
        "        next_label = 1 + first_step\n",
        "        while next_label <= n:\n",
        "            labels.append(next_label)\n",
        "            next_label += xtick_step\n",
        "        positions = [lbl - 1 for lbl in labels]\n",
        "        labels = [lbl + xtick_offset for lbl in labels]\n",
        "        plt.xticks(positions, labels)\n",
        "    elif xtick_step > 0:\n",
        "        positions = list(range(0, n, xtick_step))\n",
        "        labels = [pos + 1 + xtick_offset for pos in positions]\n",
        "        plt.xticks(positions, labels)\n",
        "\n",
        "    # Axis limits\n",
        "    if xlim is not None:\n",
        "        plt.xlim(*xlim)\n",
        "    else:\n",
        "        plt.xlim(0, n - 1)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af610847",
      "metadata": {
        "id": "af610847"
      },
      "outputs": [],
      "source": [
        "# Find the index and value of the maximum accuracy\n",
        "max_index = accuracies.index(max(accuracies))\n",
        "max_accuracy = accuracies[max_index]\n",
        "\n",
        "# Plot the accuracies\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(len(accuracies)), accuracies, label=\"Accuracy\", marker='o')\n",
        "\n",
        "# Highlight the maximum accuracy point\n",
        "plt.scatter(max_index, max_accuracy, color='red', label=f\"Max Accuracy: {max_accuracy:.4f}\")\n",
        "plt.annotate(f\"{max_accuracy:.4f}\", (max_index, max_accuracy), textcoords=\"offset points\", xytext=(0, 10), ha='center')\n",
        "\n",
        "# Add labels, title, and legend\n",
        "plt.title(\"Accuracy Over Rounds\")\n",
        "plt.xlabel(\"Round\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67b50d9b",
      "metadata": {
        "id": "67b50d9b"
      },
      "outputs": [],
      "source": [
        "loaded_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f5e4075",
      "metadata": {
        "id": "0f5e4075"
      },
      "outputs": [],
      "source": [
        "loss_graph(g_losses=loaded_dict[\"time_chunk\"], d_losses=loaded_dict[\"net_acc_chunk\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfa906d3",
      "metadata": {
        "id": "bfa906d3"
      },
      "outputs": [],
      "source": [
        "for i in range(1,5,1):\n",
        "    gen = F2U_GAN(condition=True).to(\"cpu\")\n",
        "    if IN_COLAB:\n",
        "      gen.load_state_dict(torch.load(os.path.join(save_dir,f\"gen_round{i}.pt\")))\n",
        "    else:\n",
        "      gen.load_state_dict(torch.load(f\"gen_round{i}.pt\"))\n",
        "    generate_plot(gen, \"cpu\", i, latent_dim=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dac89ce6",
      "metadata": {
        "id": "dac89ce6"
      },
      "source": [
        "Avalia a distribuicao das labels geradas pela Gen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a8a7619",
      "metadata": {
        "id": "4a8a7619"
      },
      "outputs": [],
      "source": [
        "with open(\"teste.txt\", \"w\") as f:\n",
        "        # Header\n",
        "        f.write(\"Epoch \" + \" \".join(str(i) for i in range(10)) + \"\\n\")\n",
        "        for epoch in range(100):\n",
        "            # Randomly simulate counts summing to extra_g_e (e.g. 100)\n",
        "            counts = [random.randint(0, 20) for _ in range(10)]\n",
        "            f.write(f\"{epoch} \" + \" \".join(str(c) for c in counts) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fec5ebe",
      "metadata": {
        "id": "7fec5ebe"
      },
      "outputs": [],
      "source": [
        "def plot_epoch_label_counts(path, epoch):\n",
        "    \"\"\"Plots a bar chart of counts per label for a specific epoch.\"\"\"\n",
        "    df = read_label_counts(path)\n",
        "    if epoch not in df['Epoch'].values:\n",
        "        raise ValueError(f\"Epoch {epoch} not found in file.\")\n",
        "    row = df[df['Epoch'] == epoch].iloc[0].drop('Epoch')\n",
        "    plt.figure()\n",
        "    row.plot(kind='bar')\n",
        "    plt.xlabel('Label')\n",
        "    plt.ylabel('Count')\n",
        "    plt.title(f'Label Distribution at Epoch {epoch}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeeddbca",
      "metadata": {
        "id": "aeeddbca"
      },
      "source": [
        "## Compara treino de classificador em dados reais, sintéticos e misturados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c400df8",
      "metadata": {
        "id": "6c400df8"
      },
      "outputs": [],
      "source": [
        "nets = [Net().to(device) for _ in range(num_partitions)]\n",
        "optims = [torch.optim.Adam(net.parameters(), lr=0.01) for net in nets]\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2117f9e5",
      "metadata": {
        "id": "2117f9e5"
      },
      "outputs": [],
      "source": [
        "for i, (net, optim) in enumerate(zip(nets, optims)):\n",
        "    net.train()\n",
        "    for epoch in range(50):\n",
        "        for data in trainloaders[i]:\n",
        "            inputs, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "            optim.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optim.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7ad2d72",
      "metadata": {
        "id": "c7ad2d72"
      },
      "outputs": [],
      "source": [
        "testpartition = fds.load_split(\"test\")\n",
        "testpartition = testpartition.with_transform(apply_transforms)\n",
        "testloader = DataLoader(testpartition, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abfbb983",
      "metadata": {
        "id": "abfbb983"
      },
      "outputs": [],
      "source": [
        "accuracies = []\n",
        "for net in nets:\n",
        "    correct, loss = 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "    accuracy = correct / len(testloader.dataset)\n",
        "    accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eedc9b7",
      "metadata": {
        "id": "0eedc9b7"
      },
      "outputs": [],
      "source": [
        "accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea7a7b0",
      "metadata": {
        "id": "5ea7a7b0"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "num_samples = 1000\n",
        "latent_dim = 128\n",
        "\n",
        "# gen = F2U_GAN()\n",
        "# gen.load_state_dict(torch.load(\"gen_round50.pt\", map_location=torch.device('cpu')))\n",
        "\n",
        "# Create the dataset and dataloader\n",
        "generated_dataset = GeneratedDataset(generator=gen.to(\"cpu\"), num_samples=num_samples, latent_dim=latent_dim, num_classes=10, device=\"cpu\")\n",
        "generated_dataloader = DataLoader(generated_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bc9f7fe",
      "metadata": {
        "id": "3bc9f7fe"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import ConcatDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99e1cbfd",
      "metadata": {
        "id": "99e1cbfd"
      },
      "outputs": [],
      "source": [
        "combined_dataloaders = []\n",
        "for train_partition in train_partitions:\n",
        "    # Ensure the partition is transformed\n",
        "    cmb_ds = ConcatDataset([train_partition, generated_dataset])\n",
        "    combined_dataloaders.append(DataLoader(cmb_ds, batch_size=batch_size, shuffle=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85df355d",
      "metadata": {
        "id": "85df355d"
      },
      "outputs": [],
      "source": [
        "nets = [Net().to(device) for _ in range(num_partitions)]\n",
        "optims = [torch.optim.Adam(net.parameters(), lr=0.01) for net in nets]\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ea13f13",
      "metadata": {
        "id": "9ea13f13"
      },
      "outputs": [],
      "source": [
        "for i, (net, optim) in enumerate(zip(nets, optims)):\n",
        "    net.train()\n",
        "    for epoch in range(50):\n",
        "        for data in combined_dataloaders[i]:\n",
        "            inputs, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "            optim.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optim.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9818e23a",
      "metadata": {
        "id": "9818e23a"
      },
      "outputs": [],
      "source": [
        "accuracies = []\n",
        "for net in nets:\n",
        "    correct, loss = 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "    accuracy = correct / len(testloader.dataset)\n",
        "    accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2b2cb6d",
      "metadata": {
        "id": "c2b2cb6d"
      },
      "outputs": [],
      "source": [
        "accuracies"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "6d8c276e",
        "314c3604"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
