{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "07f8307e",
      "metadata": {
        "id": "07f8307e"
      },
      "source": [
        "# Inicialização"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f47d1996",
      "metadata": {
        "id": "f47d1996"
      },
      "source": [
        "## Prepara o ambiente local ou colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88a7ea1c",
      "metadata": {
        "id": "88a7ea1c"
      },
      "outputs": [],
      "source": [
        "# --- Detectar Ambiente (Colab ou Local) ---\n",
        "IN_COLAB = False\n",
        "try:\n",
        "    # Tenta importar um módulo específico do Colab\n",
        "    from google.colab import drive\n",
        "    import shutil # Usaremos para copiar, se necessário, mas salvar direto é melhor\n",
        "    import os\n",
        "\n",
        "    try:\n",
        "        drive.mount('/content/drive')\n",
        "        # Crie um diretório específico para salvar os resultados desta execução\n",
        "        save_base_dir = \"/content/drive/MyDrive/GAN_Training_Results\" # Ajuste o caminho como desejar\n",
        "        os.makedirs(save_base_dir, exist_ok=True)\n",
        "        # Opcional: Crie um subdiretório único para esta execução específica (ex: baseado em timestamp)\n",
        "        # import datetime\n",
        "        # timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        # save_dir = os.path.join(save_base_dir, f\"run_{timestamp}\")\n",
        "        # os.makedirs(save_dir, exist_ok=True)\n",
        "        # Por simplicidade, vamos usar o diretório base diretamente por enquanto\n",
        "        save_dir = save_base_dir\n",
        "        print(f\"✅ Google Drive montado. Arquivos serão salvos em: {save_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Erro ao montar o Google Drive: {e}\")\n",
        "        print(\"   Downloads diretos serão tentados, mas podem atrasar.\")\n",
        "        save_dir = \".\" # Salvar localmente se o Drive falhar\n",
        "    IN_COLAB = True\n",
        "    print(\"✅ Ambiente Google Colab detectado. Downloads automáticos (a cada 2 épocas) ativados.\")\n",
        "except ImportError:\n",
        "    print(\"✅ Ambiente local detectado. Downloads automáticos desativados.\")\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08e68593",
      "metadata": {
        "id": "08e68593"
      },
      "source": [
        "## Importa Pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e43ad3e",
      "metadata": {
        "id": "1e43ad3e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5df872b",
      "metadata": {
        "id": "b5df872b"
      },
      "source": [
        "## Modelo Classificador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4395f020",
      "metadata": {
        "id": "4395f020"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, seed=None):\n",
        "        if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(16*4*4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16*4*4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a98df505",
      "metadata": {
        "id": "a98df505"
      },
      "outputs": [],
      "source": [
        "class Net_Cifar(nn.Module):\n",
        "    def __init__(self,seed=None):\n",
        "        if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d8c276e",
      "metadata": {
        "id": "6d8c276e"
      },
      "source": [
        "## Carrega Dados MNIST centralizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a82cbfd1",
      "metadata": {
        "id": "a82cbfd1"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13ad4aaf",
      "metadata": {
        "id": "13ad4aaf"
      },
      "outputs": [],
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Load the training and test datasets\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "trainset_reduzido = torch.utils.data.random_split(trainset, [1000, len(trainset) - 1000])[0]\n",
        "# Create data loaders\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "trainloader_reduzido = DataLoader(trainset_reduzido, batch_size=BATCH_SIZE, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "\n",
        "dataset = \"mnist\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64be3f56",
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "# Define transform com ToTensor e Normalize para 3 canais\n",
        "transform_cifar = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),  # média por canal R,G,B\n",
        "                         (0.5, 0.5, 0.5))  # desvio padrão por canal\n",
        "])\n",
        "\n",
        "# Carrega os datasets de treino e teste\n",
        "trainset_cifar = datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform_cifar\n",
        ")\n",
        "testset_cifar = datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform_cifar\n",
        ")\n",
        "\n",
        "# Cria um subset reduzido de treino (por exemplo, 1000 amostras)\n",
        "#trainset_cifar_reduzido = random_split(trainset_cifar, [1000, len(trainset_cifar) - 1000])[0]\n",
        "\n",
        "# DataLoaders\n",
        "trainloader_cifar = DataLoader(\n",
        "    trainset_cifar,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "# trainloader_cifar_reduzido = DataLoader(\n",
        "#     trainset_cifar_reduzido,\n",
        "#     batch_size=BATCH_SIZE,\n",
        "#     shuffle=True,\n",
        "#     num_workers=2,\n",
        "#     pin_memory=True\n",
        "# )\n",
        "testloader_cifar = DataLoader(\n",
        "    testset_cifar,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "dataset = \"mnist\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c27cfeac",
      "metadata": {
        "id": "c27cfeac"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# parameters\n",
        "num_classes = 10\n",
        "samples_per_class = 5\n",
        "\n",
        "if dataset == \"cifar\":\n",
        "    class_names = [\n",
        "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "     'dog', 'frog', 'horse', 'ship', 'truck'\n",
        "    ]\n",
        "\n",
        "# containers\n",
        "class_counts = {i: 0 for i in range(num_classes)}\n",
        "class_images = {i: [] for i in range(num_classes)}\n",
        "\n",
        "# gather up to 5 images per class\n",
        "for img, label in trainset:\n",
        "    if class_counts[label] < samples_per_class:\n",
        "        class_images[label].append(img)\n",
        "        class_counts[label] += 1\n",
        "    # stop early once we have enough of every class\n",
        "    if all(count >= samples_per_class for count in class_counts.values()):\n",
        "        break\n",
        "\n",
        "# plot\n",
        "fig, axes = plt.subplots(num_classes, samples_per_class, figsize=(5, 9))\n",
        "for cls in range(num_classes):\n",
        "    for i in range(samples_per_class):\n",
        "        ax = axes[cls, i]\n",
        "        img = class_images[cls][i]\n",
        "        if dataset == \"mnist\":\n",
        "            ax.imshow(img.squeeze(), cmap='gray')\n",
        "        else:\n",
        "            img_denorm = (img * 0.5 + 0.5)  # denormalize for visualization\n",
        "            ax.imshow(img_denorm.permute(1, 2, 0).numpy())\n",
        "        ax.axis('off')\n",
        "    # label the rows on the leftmost subplot\n",
        "   # axes[cls, 0].set_ylabel(str(cls), rotation=0, labelpad=12, va='center', fontsize=12)\n",
        "\n",
        "# Ajustar o layout antes de calcular as posições\n",
        "plt.tight_layout(rect=[0.05, 0, 1, 0.96])\n",
        "\n",
        "# Adicionar os rótulos das classes corretamente alinhados\n",
        "fig.canvas.draw()  # Atualiza a renderização para obter posições corretas\n",
        "for row in range(num_classes):\n",
        "    # Obter posição do subplot em coordenadas da figura\n",
        "    bbox = axes[row, 0].get_window_extent(fig.canvas.get_renderer())\n",
        "    pos = fig.transFigure.inverted().transform([(bbox.x0, bbox.y0), (bbox.x1, bbox.y1)])\n",
        "    center_y = (pos[0, 1] + pos[1, 1]) / 2  # Centro exato da linha\n",
        "\n",
        "    # Adicionar o rótulo\n",
        "    fig.text(0.03, center_y, str(row), va='center', fontsize=22, color='black')\n",
        "\n",
        "plt.suptitle(\"Real\", fontsize=30, y=0.99)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54f6fbda",
      "metadata": {
        "id": "54f6fbda"
      },
      "source": [
        "## Modelo Generativo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea03ea69",
      "metadata": {
        "id": "ea03ea69"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "314c3604",
      "metadata": {
        "id": "314c3604"
      },
      "source": [
        "### CGAN (simples, mlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23cfec37",
      "metadata": {
        "id": "23cfec37"
      },
      "outputs": [],
      "source": [
        "class CGAN(nn.Module):\n",
        "    def __init__(self, dataset=\"mnist\", img_size=28, latent_dim=100):\n",
        "        super(CGAN, self).__init__()\n",
        "        if dataset == \"mnist\":\n",
        "            self.classes = 10\n",
        "            self.channels = 1\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes)\n",
        "        self.adv_loss = torch.nn.BCELoss()\n",
        "\n",
        "\n",
        "        self.generator = nn.Sequential(\n",
        "            *self._create_layer_gen(self.latent_dim + self.classes, 128, False),\n",
        "            *self._create_layer_gen(128, 256),\n",
        "            *self._create_layer_gen(256, 512),\n",
        "            *self._create_layer_gen(512, 1024),\n",
        "            nn.Linear(1024, int(np.prod(self.img_shape))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.discriminator = nn.Sequential(\n",
        "            *self._create_layer_disc(self.classes + int(np.prod(self.img_shape)), 1024, False, True),\n",
        "            *self._create_layer_disc(1024, 512, True, True),\n",
        "            *self._create_layer_disc(512, 256, True, True),\n",
        "            *self._create_layer_disc(256, 128, False, False),\n",
        "            *self._create_layer_disc(128, 1, False, False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def _create_layer_gen(self, size_in, size_out, normalize=True):\n",
        "        layers = [nn.Linear(size_in, size_out)]\n",
        "        if normalize:\n",
        "            layers.append(nn.BatchNorm1d(size_out))\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return layers\n",
        "\n",
        "    def _create_layer_disc(self, size_in, size_out, drop_out=True, act_func=True):\n",
        "        layers = [nn.Linear(size_in, size_out)]\n",
        "        if drop_out:\n",
        "            layers.append(nn.Dropout(0.4))\n",
        "        if act_func:\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return layers\n",
        "\n",
        "    def forward(self, input, labels):\n",
        "        if input.dim() == 2:\n",
        "            z = torch.cat((self.label_embedding(labels), input), -1)\n",
        "            x = self.generator(z)\n",
        "            x = x.view(x.size(0), *self.img_shape) #Em\n",
        "            return x\n",
        "        elif input.dim() == 4:\n",
        "            x = torch.cat((input.view(input.size(0), -1), self.label_embedding(labels)), -1)\n",
        "            return self.discriminator(x)\n",
        "\n",
        "    def loss(self, output, label):\n",
        "        return self.adv_loss(output, label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f1a5b73",
      "metadata": {
        "id": "4f1a5b73"
      },
      "source": [
        "### Arquitetura do paper F2U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbb8292a",
      "metadata": {
        "id": "cbb8292a"
      },
      "outputs": [],
      "source": [
        "class F2U_GAN(nn.Module):\n",
        "    def __init__(self, dataset=\"mnist\", img_size=28, latent_dim=128, condition=True, seed=None):\n",
        "        if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "        super(F2U_GAN, self).__init__()\n",
        "        if dataset == \"mnist\":\n",
        "            self.classes = 10\n",
        "            self.channels = 1\n",
        "        else:\n",
        "            raise NotImplementedError(\"Only MNIST is supported\")\n",
        "\n",
        "        self.condition = condition\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes) if condition else None\n",
        "        #self.label_embedding_disc = nn.Embedding(self.classes, self.img_size*self.img_size) if condition else None\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
        "        self.input_shape_gen = self.latent_dim + self.label_embedding.embedding_dim if condition else self.latent_dim\n",
        "        self.input_shape_disc = self.channels + self.classes if condition else self.channels\n",
        "\n",
        "        self.adv_loss = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "        # Generator (unchanged) To calculate output shape of convtranspose layers, we can use the formula:\n",
        "        # output_shape = (input_shape - 1) * stride - 2 * padding + kernel_size + output_padding (or dilation * (kernel_size - 1) + 1 inplace of kernel_size if using dilation)\n",
        "        self.generator = nn.Sequential(\n",
        "            nn.Linear(self.input_shape_gen, 256 * 7 * 7),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Unflatten(1, (256, 7, 7)),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1), # (256,7,7) -> (128,14,14)\n",
        "            nn.BatchNorm2d(128, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1), # (128,14,14) -> (64,28,28)\n",
        "            nn.BatchNorm2d(64, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64, self.channels, kernel_size=3, stride=1, padding=1), # (64,28,28) -> (1,28,28)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # Discriminator (corrected) To calculate output shape of conv layers, we can use the formula:\n",
        "        # output_shape = ⌊(input_shape - kernel_size + 2 * padding) / stride + 1⌋ (or (dilation * (kernel_size - 1) - 1) inplace of kernel_size if using dilation)\n",
        "        self.discriminator = nn.Sequential(\n",
        "        # Camada 1: (1,28,28) -> (32,13,13)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(self.input_shape_disc, 32, kernel_size=3, stride=2, padding=0)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Camada 2: (32,14,14) -> (64,7,7)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Camada 3: (64,7,7) -> (128,3,3)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=0)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Camada 4: (128,3,3) -> (256,1,1)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=0)),  # Padding 0 aqui!\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Achata e concatena com as labels\n",
        "        nn.Flatten(), # (256,1,1) -> (256*1*1,)\n",
        "        nn.utils.spectral_norm(nn.Linear(256 * 1 * 1, 1))  # 256 (features)\n",
        "        )\n",
        "\n",
        "    def forward(self, input, labels=None):\n",
        "        if input.dim() == 2:\n",
        "            # Generator forward pass (unchanged)\n",
        "            if self.condition:\n",
        "                embedded_labels = self.label_embedding(labels)\n",
        "                gen_input = torch.cat((input, embedded_labels), dim=1)\n",
        "                x = self.generator(gen_input)\n",
        "            else:\n",
        "                x = self.generator(input)\n",
        "            return x.view(-1, *self.img_shape)\n",
        "\n",
        "        elif input.dim() == 4:\n",
        "            # Discriminator forward pass\n",
        "            if self.condition:\n",
        "                embedded_labels = self.label_embedding(labels)\n",
        "                image_labels = embedded_labels.view(embedded_labels.size(0), self.label_embedding.embedding_dim, 1, 1).expand(-1, -1, self.img_size, self.img_size)\n",
        "                x = torch.cat((input, image_labels), dim=1)\n",
        "            else:\n",
        "                x = input\n",
        "            return self.discriminator(x)\n",
        "\n",
        "    def loss(self, output, label):\n",
        "        return self.adv_loss(output, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "decb2888",
      "metadata": {},
      "outputs": [],
      "source": [
        "class F2U_GAN_SlowDisc(nn.Module):\n",
        "    def __init__(self, dataset=\"mnist\", img_size=28, latent_dim=128, condition=True, seed=None):\n",
        "        if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "        super(F2U_GAN_SlowDisc, self).__init__()\n",
        "        if dataset == \"mnist\":\n",
        "            self.classes = 10\n",
        "            self.channels = 1\n",
        "        else:\n",
        "            raise NotImplementedError(\"Only MNIST is supported\")\n",
        "\n",
        "        self.condition = condition\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes) if condition else None\n",
        "        #self.label_embedding_disc = nn.Embedding(self.classes, self.img_size*self.img_size) if condition else None\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
        "        self.input_shape_gen = self.latent_dim + self.label_embedding.embedding_dim if condition else self.latent_dim\n",
        "        self.input_shape_disc = self.channels + self.classes if condition else self.channels\n",
        "\n",
        "        self.adv_loss = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "        # Generator (unchanged) To calculate output shape of convtranspose layers, we can use the formula:\n",
        "        # output_shape = (input_shape - 1) * stride - 2 * padding + kernel_size + output_padding (or dilation * (kernel_size - 1) + 1 inplace of kernel_size if using dilation)\n",
        "        self.generator = nn.Sequential(\n",
        "            nn.Linear(self.input_shape_gen, 256 * 7 * 7),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Unflatten(1, (256, 7, 7)),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1), # (256,7,7) -> (128,14,14)\n",
        "            nn.BatchNorm2d(128, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1), # (128,14,14) -> (64,28,28)\n",
        "            nn.BatchNorm2d(64, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64, self.channels, kernel_size=3, stride=1, padding=1), # (64,28,28) -> (1,28,28)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # Discriminator (corrected) To calculate output shape of conv layers, we can use the formula:\n",
        "        # output_shape = ⌊(input_shape - kernel_size + 2 * padding) / stride + 1⌋ (or (dilation * (kernel_size - 1) - 1) inplace of kernel_size if using dilation)\n",
        "        self.discriminator = nn.Sequential(\n",
        "        # Camada 1: (1,28,28) -> (32,13,13)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(self.input_shape_disc, 32, kernel_size=3, stride=2, padding=0)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Dropout2d(0.3),\n",
        "\n",
        "        # Camada 2: (32,14,14) -> (64,7,7)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Dropout2d(0.3),\n",
        "\n",
        "        # Camada 3: (64,7,7) -> (128,3,3)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=0)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Dropout2d(0.3),\n",
        "\n",
        "        # Camada 4: (128,3,3) -> (256,1,1)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=0)),  # Padding 0 aqui!\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Achata e concatena com as labels\n",
        "        nn.Flatten(), # (256,1,1) -> (256*1*1,)\n",
        "        nn.utils.spectral_norm(nn.Linear(256 * 1 * 1, 1))  # 256 (features)\n",
        "        )\n",
        "\n",
        "    def forward(self, input, labels=None):\n",
        "        if input.dim() == 2:\n",
        "            # Generator forward pass (unchanged)\n",
        "            if self.condition:\n",
        "                embedded_labels = self.label_embedding(labels)\n",
        "                gen_input = torch.cat((input, embedded_labels), dim=1)\n",
        "                x = self.generator(gen_input)\n",
        "            else:\n",
        "                x = self.generator(input)\n",
        "            return x.view(-1, *self.img_shape)\n",
        "\n",
        "        elif input.dim() == 4:\n",
        "            # Discriminator forward pass\n",
        "            if self.condition:\n",
        "                embedded_labels = self.label_embedding(labels)\n",
        "                image_labels = embedded_labels.view(embedded_labels.size(0), self.label_embedding.embedding_dim, 1, 1).expand(-1, -1, self.img_size, self.img_size)\n",
        "                input = input + torch.randn_like(input) * 0.1\n",
        "                x = torch.cat((input, image_labels), dim=1)\n",
        "            else:\n",
        "                x = input\n",
        "            return self.discriminator(x)\n",
        "\n",
        "    def loss(self, output, label):\n",
        "        return self.adv_loss(output, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c52363e9",
      "metadata": {
        "id": "c52363e9"
      },
      "outputs": [],
      "source": [
        "class F2U_GAN_CIFAR(nn.Module):\n",
        "    def __init__(self, img_size=32, latent_dim=128, condition=True, seed=None):\n",
        "        if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "        super(F2U_GAN_CIFAR, self).__init__()\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.classes = 10\n",
        "        self.channels = 3\n",
        "        self.condition = condition\n",
        "\n",
        "        # Embedding para condicionamento\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes) if self.condition else None\n",
        "\n",
        "        # Shapes de entrada\n",
        "        self.input_shape_gen = self.latent_dim + (self.classes if self.condition else 0)\n",
        "        self.input_shape_disc = self.channels + (self.classes if self.condition else 0)\n",
        "\n",
        "        # -----------------\n",
        "        #  Generator\n",
        "        # -----------------\n",
        "        self.generator = nn.Sequential(\n",
        "            nn.Linear(self.input_shape_gen, 512 * 4 * 4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Unflatten(1, (512, 4, 4)),                  # → (512,4,4)\n",
        "\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),  # → (256,8,8)\n",
        "            nn.BatchNorm2d(256, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # → (128,16,16)\n",
        "            nn.BatchNorm2d(128, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(128,  64, kernel_size=4, stride=2, padding=1),  # → ( 64,32,32)\n",
        "            nn.BatchNorm2d(64,  momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d( 64,   self.channels, kernel_size=3, stride=1, padding=1),  # → (3,32,32)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # -----------------\n",
        "        #  Discriminator\n",
        "        # -----------------\n",
        "        layers = []\n",
        "        in_ch = self.input_shape_disc\n",
        "        cfg = [\n",
        "            ( 64, 3, 1),  # → spatial stays 32\n",
        "            ( 64, 4, 2),  # → 16\n",
        "            (128, 3, 1),  # → 16\n",
        "            (128, 4, 2),  # → 8\n",
        "            (256, 4, 2),  # → 4\n",
        "        ]\n",
        "        for out_ch, k, s in cfg:\n",
        "            layers += [\n",
        "                nn.utils.spectral_norm(\n",
        "                    nn.Conv2d(in_ch, out_ch, kernel_size=k, stride=s, padding=1)\n",
        "                ),\n",
        "                nn.LeakyReLU(0.1, inplace=True)\n",
        "            ]\n",
        "            in_ch = out_ch\n",
        "\n",
        "        layers += [\n",
        "            nn.Flatten(),\n",
        "            nn.utils.spectral_norm(\n",
        "                nn.Linear(256 * 4 * 4, 1)\n",
        "            )\n",
        "        ]\n",
        "        self.discriminator = nn.Sequential(*layers)\n",
        "\n",
        "        # adversarial loss\n",
        "        self.adv_loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, input, labels=None):\n",
        "        # Generator pass\n",
        "        if input.dim() == 2 and input.size(1) == self.latent_dim:\n",
        "            if self.condition:\n",
        "                if labels is None:\n",
        "                    raise ValueError(\"Labels must be provided for conditional generation\")\n",
        "                embedded = self.label_embedding(labels)\n",
        "                gen_input = torch.cat((input, embedded), dim=1)\n",
        "            else:\n",
        "                gen_input = input\n",
        "            img = self.generator(gen_input)\n",
        "            return img\n",
        "\n",
        "        # Discriminator pass\n",
        "        elif input.dim() == 4 and input.size(1) == self.channels:\n",
        "            x = input\n",
        "            if self.condition:\n",
        "                if labels is None:\n",
        "                    raise ValueError(\"Labels must be provided for conditional discrimination\")\n",
        "                embedded = self.label_embedding(labels)\n",
        "                # criar mapa de labels e concatenar\n",
        "                lbl_map = embedded.view(-1, self.classes, 1, 1).expand(-1, self.classes, self.img_size, self.img_size)\n",
        "                x = torch.cat((x, lbl_map), dim=1)\n",
        "            return self.discriminator(x)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Input shape not recognized\")\n",
        "\n",
        "    def loss(self, logits, targets):\n",
        "        return self.adv_loss(logits.view(-1), targets.float().view(-1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "144a24f4",
      "metadata": {
        "id": "144a24f4"
      },
      "source": [
        "## Funções para geração de dataset e imagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3487d31",
      "metadata": {
        "id": "b3487d31"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn.functional as F\n",
        "import random # Needed for handling remainders if samples aren't perfectly divisible\n",
        "\n",
        "class GeneratedDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 generator,\n",
        "                 num_samples,\n",
        "                 latent_dim=100,\n",
        "                 num_classes=10, # Total classes the generator model knows\n",
        "                 desired_classes=None, # Optional: List of specific class indices to generate\n",
        "                 device=\"cpu\",\n",
        "                 image_col_name=\"image\",\n",
        "                 label_col_name=\"label\"):\n",
        "        \"\"\"\n",
        "        Generates a dataset using a conditional generative model, potentially\n",
        "        focusing on a subset of classes.\n",
        "\n",
        "        Args:\n",
        "            generator: The pre-trained generative model.\n",
        "            num_samples (int): Total number of images to generate across the desired classes.\n",
        "            latent_dim (int): Dimension of the latent space vector (z).\n",
        "            num_classes (int): The total number of classes the generator was trained on.\n",
        "                               This is crucial for correct label conditioning (e.g., one-hot dim).\n",
        "            desired_classes (list[int], optional): A list of integer class indices to generate.\n",
        "                                                  If None or empty, images for all classes\n",
        "                                                  (from 0 to num_classes-1) will be generated,\n",
        "                                                  distributed as evenly as possible.\n",
        "                                                  Defaults to None.\n",
        "            device (str): Device to run generation on ('cpu' or 'cuda').\n",
        "            image_col_name (str): Name for the image column in the output dictionary.\n",
        "            label_col_name (str): Name for the label column in the output dictionary.\n",
        "        \"\"\"\n",
        "        self.generator = generator\n",
        "        self.num_samples = num_samples\n",
        "        self.latent_dim = latent_dim\n",
        "        # Store the total number of classes the generator understands\n",
        "        self.total_num_classes = num_classes\n",
        "        self.device = device\n",
        "        self.model_type = type(self.generator).__name__ # Get generator class name\n",
        "        self.image_col_name = image_col_name\n",
        "        self.label_col_name = label_col_name\n",
        "\n",
        "        # Determine the actual classes to generate based on desired_classes\n",
        "        if desired_classes is not None and len(desired_classes) > 0:\n",
        "            # Validate that desired classes are within the generator's known range\n",
        "            if not all(0 <= c < self.total_num_classes for c in desired_classes):\n",
        "                raise ValueError(f\"All desired classes must be integers between 0 and {self.total_num_classes - 1}\")\n",
        "            # Use only the unique desired classes, sorted for consistency\n",
        "            self._actual_classes_to_generate = sorted(list(set(desired_classes)))\n",
        "        else:\n",
        "            # If no specific classes desired, generate all classes\n",
        "            self._actual_classes_to_generate = list(range(self.total_num_classes))\n",
        "\n",
        "        # The 'classes' attribute of the dataset reflects only those generated\n",
        "        self.classes = self._actual_classes_to_generate\n",
        "        self.num_generated_classes = len(self.classes) # Number of classes being generated\n",
        "\n",
        "        if self.num_generated_classes == 0 and self.num_samples > 0:\n",
        "             raise ValueError(\"Cannot generate samples with an empty list of desired classes.\")\n",
        "        elif self.num_samples == 0:\n",
        "             print(\"Warning: num_samples is 0. Dataset will be empty.\")\n",
        "             self.images = torch.empty(0) # Adjust shape if known\n",
        "             self.labels = torch.empty(0, dtype=torch.long)\n",
        "        else:\n",
        "             # Generate the data only if needed\n",
        "             self.images, self.labels = self.generate_data()\n",
        "\n",
        "\n",
        "    def generate_data(self):\n",
        "        \"\"\"Generates images and corresponding labels for the specified classes.\"\"\"\n",
        "        self.generator.eval()\n",
        "        self.generator.to(self.device)\n",
        "\n",
        "        # --- Create Labels ---\n",
        "        generated_labels_list = []\n",
        "        if self.num_generated_classes > 0:\n",
        "            # Distribute samples as evenly as possible among the desired classes\n",
        "            samples_per_class = self.num_samples // self.num_generated_classes\n",
        "            for cls in self._actual_classes_to_generate:\n",
        "                generated_labels_list.extend([cls] * samples_per_class)\n",
        "\n",
        "            # Handle remaining samples if num_samples is not perfectly divisible\n",
        "            num_remaining = self.num_samples - len(generated_labels_list)\n",
        "            if num_remaining > 0:\n",
        "                # Add remaining samples by randomly choosing from the desired classes\n",
        "                remainder_labels = random.choices(self._actual_classes_to_generate, k=num_remaining)\n",
        "                generated_labels_list.extend(remainder_labels)\n",
        "\n",
        "            # Shuffle labels for better distribution in batches later\n",
        "            random.shuffle(generated_labels_list)\n",
        "\n",
        "        # Convert labels list to tensor\n",
        "        labels = torch.tensor(generated_labels_list, dtype=torch.long, device=self.device)\n",
        "\n",
        "        # Double check label count (should match num_samples due to logic above)\n",
        "        if len(labels) != self.num_samples:\n",
        "             # This indicates an unexpected issue, potentially if num_generated_classes was 0 initially\n",
        "             # but num_samples > 0. Raise error or adjust. Let's adjust defensively.\n",
        "             print(f\"Warning: Label count mismatch. Expected {self.num_samples}, got {len(labels)}. Adjusting size.\")\n",
        "             if len(labels) > self.num_samples:\n",
        "                 labels = labels[:self.num_samples]\n",
        "             else:\n",
        "                 # Pad if too few (less likely with current logic unless num_generated_classes=0)\n",
        "                 num_needed = self.num_samples - len(labels)\n",
        "                 if self.num_generated_classes > 0:\n",
        "                      padding = torch.tensor(random.choices(self._actual_classes_to_generate, k=num_needed), dtype=torch.long, device=self.device)\n",
        "                      labels = torch.cat((labels, padding))\n",
        "                 # If no classes to generate from, labels tensor might remain smaller\n",
        "\n",
        "        # --- Create Latent Noise ---\n",
        "        z = torch.randn(self.num_samples, self.latent_dim, device=self.device)\n",
        "\n",
        "        # --- Generate Images in Batches ---\n",
        "        generated_images_list = []\n",
        "        # Consider making batch_size configurable\n",
        "        batch_size = min(1024, self.num_samples) if self.num_samples > 0 else 1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, self.num_samples, batch_size):\n",
        "                z_batch = z[i : min(i + batch_size, self.num_samples)]\n",
        "                labels_batch = labels[i : min(i + batch_size, self.num_samples)]\n",
        "\n",
        "                # Skip if batch is empty (can happen if num_samples = 0)\n",
        "                if z_batch.shape[0] == 0:\n",
        "                    continue\n",
        "\n",
        "                # --- Condition the generator based on its type ---\n",
        "                if self.model_type == 'Generator': # Assumes input: concat(z, one_hot_label)\n",
        "                    # One-hot encode labels using the TOTAL number of classes the generator knows\n",
        "                    labels_one_hot_batch = F.one_hot(labels_batch, num_classes=self.total_num_classes).float()\n",
        "                    generator_input = torch.cat([z_batch, labels_one_hot_batch], dim=1)\n",
        "                    gen_imgs = self.generator(generator_input)\n",
        "                elif self.model_type in ('CGAN', 'F2U_GAN', 'F2U_GAN_CIFAR'): # Assumes input: z, label_index\n",
        "                    gen_imgs = self.generator(z_batch, labels_batch)\n",
        "                else:\n",
        "                    # Handle other potential generator architectures or raise an error\n",
        "                    raise NotImplementedError(f\"Generation logic not defined for model type: {self.model_type}\")\n",
        "\n",
        "                generated_images_list.append(gen_imgs.cpu()) # Move generated images to CPU\n",
        "\n",
        "        self.generator.cpu() # Move generator back to CPU after generation\n",
        "\n",
        "        # Concatenate all generated image batches\n",
        "        if generated_images_list:\n",
        "            all_gen_imgs = torch.cat(generated_images_list, dim=0)\n",
        "        else:\n",
        "            # If no images were generated (e.g., num_samples = 0)\n",
        "            # Create an empty tensor. Shape needs care - determine from generator or use placeholder.\n",
        "            # Let's attempt a placeholder [0, C, H, W] - requires knowing C, H, W.\n",
        "            # For now, a simple empty tensor. User might need to handle this downstream.\n",
        "            print(\"Warning: No images generated. Returning empty tensor for images.\")\n",
        "            all_gen_imgs = torch.empty(0)\n",
        "\n",
        "        return all_gen_imgs, labels.cpu() # Return images and labels (on CPU)\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the actual number of samples generated\n",
        "        return self.images.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= len(self):\n",
        "            raise IndexError(\"Dataset index out of range\")\n",
        "        return {\n",
        "            self.image_col_name: self.images[idx],\n",
        "            self.label_col_name: int(self.labels[idx]) # Return label as standard Python int\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1c3d341",
      "metadata": {
        "id": "b1c3d341"
      },
      "outputs": [],
      "source": [
        "class UnconditionalGeneratedDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 generator,\n",
        "                 num_samples,\n",
        "                 latent_dim=128,\n",
        "                 device=\"cpu\",\n",
        "                 image_col_name=\"image\"):\n",
        "        \"\"\"\n",
        "        Generates a dataset using an unconditional generative model.\n",
        "\n",
        "        Args:\n",
        "            generator: The pre-trained unconditional generative model.\n",
        "            num_samples (int): Total number of images to generate.\n",
        "            latent_dim (int): Dimension of the latent space vector (z).\n",
        "            device (str): Device to run generation on ('cpu' or 'cuda').\n",
        "            image_col_name (str): Name for the image column in the output dictionary.\n",
        "        \"\"\"\n",
        "        self.generator = generator\n",
        "        self.num_samples = num_samples\n",
        "        self.latent_dim = latent_dim\n",
        "        self.device = device\n",
        "        self.image_col_name = image_col_name\n",
        "\n",
        "        if self.num_samples < 0:\n",
        "            raise ValueError(\"num_samples must be non-negative\")\n",
        "        elif self.num_samples == 0:\n",
        "            print(\"Warning: num_samples is 0. Dataset will be empty.\")\n",
        "            self.images = torch.empty(0)\n",
        "        else:\n",
        "            self.images = self._generate_images()\n",
        "\n",
        "    def _generate_images(self):\n",
        "        self.generator.eval()\n",
        "        self.generator.to(self.device)\n",
        "\n",
        "        # Create latent noise\n",
        "        z = torch.randn(self.num_samples, self.latent_dim, device=self.device)\n",
        "\n",
        "        # Generate images in batches\n",
        "        generated_images = []\n",
        "        batch_size = min(1024, self.num_samples)\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, self.num_samples, batch_size):\n",
        "                z_batch = z[i : min(i + batch_size, self.num_samples)]\n",
        "                gen_imgs = self.generator(z_batch)\n",
        "                generated_images.append(gen_imgs.cpu())\n",
        "\n",
        "        self.generator.cpu()\n",
        "        return torch.cat(generated_images, dim=0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= len(self):\n",
        "            raise IndexError(\"Dataset index out of range\")\n",
        "        return { self.image_col_name: self.images[idx] }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9452cf54",
      "metadata": {
        "id": "9452cf54"
      },
      "outputs": [],
      "source": [
        "def generate_plot(net, device, round_number, client_id = None, examples_per_class: int=5, classes: int=10, latent_dim: int=100):\n",
        "    \"\"\"Gera plot de imagens de cada classe\"\"\"\n",
        "\n",
        "    net_type = type(net).__name__\n",
        "    net.to(device)\n",
        "    net.eval()\n",
        "    batch_size = examples_per_class * classes\n",
        "    dataset = \"mnist\" if  not net_type == \"F2U_GAN_CIFAR\" else \"cifar10\"\n",
        "\n",
        "    latent_vectors = torch.randn(batch_size, latent_dim, device=device)\n",
        "    labels = torch.tensor([i for i in range(classes) for _ in range(examples_per_class)], device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if net_type == \"Generator\":\n",
        "            labels_one_hot = torch.nn.functional.one_hot(labels, 10).float().to(device)\n",
        "            generated_images = net(torch.cat([latent_vectors, labels_one_hot], dim=1))\n",
        "        else:\n",
        "            generated_images = net(latent_vectors, labels)\n",
        "\n",
        "    # Criar uma figura com 10 linhas e 5 colunas de subplots\n",
        "    fig, axes = plt.subplots(classes, examples_per_class, figsize=(5, 9))\n",
        "\n",
        "    # Adiciona título no topo da figura\n",
        "    if isinstance(client_id, int):\n",
        "        fig.text(0.5, 0.98, f\"Round: {round_number} | Client: {client_id}\", ha=\"center\", fontsize=12)\n",
        "    else:\n",
        "        fig.text(0.5, 0.96, f\"Epoch: {round_number}\", ha=\"center\", fontsize=30)\n",
        "\n",
        "    # Exibir as imagens nos subplots\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if dataset == \"mnist\":\n",
        "            ax.imshow(generated_images[i, 0, :, :], cmap='gray')\n",
        "        else:\n",
        "            images = (generated_images[i] + 1)/2\n",
        "            ax.imshow(images.permute(1, 2, 0).clamp(0,1))\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "    # Ajustar o layout antes de calcular as posições\n",
        "    plt.tight_layout(rect=[0.05, 0, 1, 0.96])\n",
        "\n",
        "    # Reduzir espaço entre colunas\n",
        "    # plt.subplots_adjust(wspace=0.05)\n",
        "\n",
        "    # Adicionar os rótulos das classes corretamente alinhados\n",
        "    fig.canvas.draw()  # Atualiza a renderização para obter posições corretas\n",
        "    for row in range(classes):\n",
        "        # Obter posição do subplot em coordenadas da figura\n",
        "        bbox = axes[row, 0].get_window_extent(fig.canvas.get_renderer())\n",
        "        pos = fig.transFigure.inverted().transform([(bbox.x0, bbox.y0), (bbox.x1, bbox.y1)])\n",
        "        center_y = (pos[0, 1] + pos[1, 1]) / 2  # Centro exato da linha\n",
        "\n",
        "        # Adicionar o rótulo\n",
        "        fig.text(0.03, center_y, str(row), va='center', fontsize=22, color='black')\n",
        "\n",
        "    IN_COLAB = False\n",
        "    try:\n",
        "        # Tenta importar um módulo específico do Colab\n",
        "        import google.colab\n",
        "        IN_COLAB = True\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    if IN_COLAB:\n",
        "        if isinstance(client_id, int):\n",
        "            fig.savefig(os.path.join(save_dir, f\"{dataset}_{net_type}_r{round_number}_c{client_id}.png\"))\n",
        "            print(\"Imagem do cliente salva no drive\")\n",
        "        else:\n",
        "            fig.savefig(os.path.join(save_dir, f\"{dataset}{net_type}_r{round_number}.png\"))\n",
        "            print(\"Imagem do servidor salva no drive\")\n",
        "    else:\n",
        "        if isinstance(client_id, int):\n",
        "            fig.savefig(f\"{dataset}{net_type}_r{round_number}_c{client_id}.png\")\n",
        "            print(\"Imagem do cliente salva\")\n",
        "        else:\n",
        "            fig.savefig(f\"{dataset}{net_type}_r{round_number}.png\")\n",
        "            print(\"Imagem do servidor salva\")\n",
        "    plt.close(fig)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a88e7c6",
      "metadata": {
        "id": "3a88e7c6"
      },
      "outputs": [],
      "source": [
        "def plot_unconditional_generated(\n",
        "        generator,\n",
        "        device,\n",
        "        total_samples,\n",
        "        samples_per_row=5,\n",
        "        latent_dim=100,\n",
        "        save_path=None,\n",
        "        round_number=None):\n",
        "    \"\"\"\n",
        "    Generates and plots images from an unconditional generator in a grid.\n",
        "\n",
        "    Args:\n",
        "        generator: The unconditional torch generator model (z -> image).\n",
        "        device: Device to run generation on ('cpu' or 'cuda').\n",
        "        total_samples (int): Number of images to generate.\n",
        "        samples_per_row (int): Number of images per row in the grid.\n",
        "        latent_dim (int): Dimension of latent vector.\n",
        "        save_path (str, optional): Filepath to save the figure. If None, just shows plot.\n",
        "    \"\"\"\n",
        "\n",
        "    generator.eval()\n",
        "    generator.to(device)\n",
        "\n",
        "    # Sample latent vectors\n",
        "    z = torch.randn(total_samples, latent_dim, device=device)\n",
        "    with torch.no_grad():\n",
        "        imgs = generator(z)\n",
        "\n",
        "    # Determine grid size\n",
        "    cols = samples_per_row\n",
        "    rows = math.ceil(total_samples / cols)\n",
        "\n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(cols-2*cols/(rows+cols), rows-1*rows/(rows+cols)))\n",
        "    axes = axes.flatten() if total_samples > 1 else [axes]\n",
        "\n",
        "    fig.text(0.5, 0.99, f\"Round: {round_number}\", ha=\"center\", fontsize=11)\n",
        "\n",
        "    for idx in range(rows * cols):\n",
        "        ax = axes[idx]\n",
        "        ax.axis('off')\n",
        "        if idx < total_samples:\n",
        "            img = imgs[idx]\n",
        "            # Assume (C, H, W) and single-channel\n",
        "            ax.imshow(img[0], cmap='gray')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "        fig.savefig(save_path)\n",
        "        print(f\"Figure saved to {save_path}\")\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "    plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bd1a6ff",
      "metadata": {
        "id": "5bd1a6ff"
      },
      "source": [
        "## Importa Pacotes Federado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e7c02c2",
      "metadata": {
        "id": "3e7c02c2"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    !pip install flwr_datasets\n",
        "    !pip install flwr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9793cd9a",
      "metadata": {
        "id": "9793cd9a"
      },
      "outputs": [],
      "source": [
        "from flwr_datasets.partitioner import DirichletPartitioner, IidPartitioner\n",
        "from flwr_datasets.visualization import plot_label_distributions\n",
        "from flwr_datasets import FederatedDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5ac2e55",
      "metadata": {
        "id": "a5ac2e55"
      },
      "source": [
        "## Particionador por classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3acd60f5",
      "metadata": {
        "id": "3acd60f5"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Flower Labs GmbH. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Class-based partitioner for Hugging Face Datasets.\"\"\"\n",
        "\n",
        "\n",
        "from collections import defaultdict\n",
        "import random\n",
        "from typing import Optional, List\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from flwr_datasets.partitioner.partitioner import Partitioner  # Assuming this is in the package structure\n",
        "\n",
        "\n",
        "class ClassPartitioner(Partitioner):\n",
        "    \"\"\"Partitions a dataset by class, ensuring each class appears in exactly one partition.\n",
        "\n",
        "    Attributes:\n",
        "        num_partitions (int): Total number of partitions to create\n",
        "        seed (int, optional): Random seed for reproducibility\n",
        "        label_column (str): Name of the column containing class labels\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_partitions: int,\n",
        "        seed: Optional[int] = None,\n",
        "        label_column: str = \"label\"\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self._num_partitions = num_partitions\n",
        "        self._seed = seed\n",
        "        self._label_column = label_column\n",
        "        self._partition_indices: Optional[List[List[int]]] = None\n",
        "\n",
        "    def _create_partitions(self) -> None:\n",
        "        \"\"\"Create class-based partitions and store indices.\"\"\"\n",
        "        # Extract labels from dataset\n",
        "        labels = self.dataset[self._label_column]\n",
        "\n",
        "        # Group indices by class\n",
        "        class_indices = defaultdict(list)\n",
        "        for idx, label in enumerate(labels):\n",
        "            class_indices[label].append(idx)\n",
        "\n",
        "        classes = list(class_indices.keys())\n",
        "        num_classes = len(classes)\n",
        "\n",
        "        # Validate number of partitions\n",
        "        if self._num_partitions > num_classes:\n",
        "            raise ValueError(\n",
        "                f\"Cannot create {self._num_partitions} partitions with only {num_classes} classes. \"\n",
        "                f\"Reduce partitions to ≤ {num_classes}.\"\n",
        "            )\n",
        "\n",
        "        # Shuffle classes for random distribution\n",
        "        rng = random.Random(self._seed)\n",
        "        rng.shuffle(classes)\n",
        "\n",
        "        # Split classes into partitions\n",
        "        partition_classes = np.array_split(classes, self._num_partitions)\n",
        "\n",
        "        # Create index lists for each partition\n",
        "        self._partition_indices = []\n",
        "        for class_group in partition_classes:\n",
        "            indices = []\n",
        "            for cls in class_group:\n",
        "                indices.extend(class_indices[cls])\n",
        "            self._partition_indices.append(indices)\n",
        "\n",
        "    @property\n",
        "    def dataset(self) -> Dataset:\n",
        "        return super().dataset\n",
        "\n",
        "    @dataset.setter\n",
        "    def dataset(self, value: Dataset) -> None:\n",
        "        # Use parent setter for basic validation\n",
        "        super(ClassPartitioner, ClassPartitioner).dataset.fset(self, value)\n",
        "\n",
        "        # Create partitions once dataset is set\n",
        "        self._create_partitions()\n",
        "\n",
        "    def load_partition(self, partition_id: int) -> Dataset:\n",
        "        \"\"\"Load a partition containing exclusive classes.\n",
        "\n",
        "        Args:\n",
        "            partition_id: The ID of the partition to load (0-based index)\n",
        "\n",
        "        Returns:\n",
        "            Dataset: Subset of the dataset containing only the specified partition's data\n",
        "        \"\"\"\n",
        "        if not self.is_dataset_assigned():\n",
        "            raise RuntimeError(\"Dataset must be assigned before loading partitions\")\n",
        "        if partition_id < 0 or partition_id >= self.num_partitions:\n",
        "            raise ValueError(f\"Invalid partition ID: {partition_id}\")\n",
        "\n",
        "        return self.dataset.select(self._partition_indices[partition_id])\n",
        "\n",
        "    @property\n",
        "    def num_partitions(self) -> int:\n",
        "        return self._num_partitions\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f\"ClassPartitioner(num_partitions={self._num_partitions}, \"\n",
        "                f\"seed={self._seed}, label_column='{self._label_column}')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1ee55f5",
      "metadata": {
        "id": "a1ee55f5"
      },
      "source": [
        "## Carrega e divide dados entre clientes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fdba10d",
      "metadata": {
        "id": "6fdba10d"
      },
      "outputs": [],
      "source": [
        "num_partitions = 4\n",
        "alpha_dir = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cd9c472",
      "metadata": {
        "id": "6cd9c472"
      },
      "source": [
        "Rodar somente o particionador desejado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42644935",
      "metadata": {
        "id": "42644935"
      },
      "outputs": [],
      "source": [
        "partitioner = ClassPartitioner(num_partitions=num_partitions, seed=42, label_column=\"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "312626b5",
      "metadata": {
        "id": "312626b5"
      },
      "outputs": [],
      "source": [
        "partitioner = DirichletPartitioner(\n",
        "    num_partitions=num_partitions,\n",
        "    partition_by=\"label\",\n",
        "    alpha=alpha_dir,\n",
        "    min_partition_size=0,\n",
        "    self_balancing=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8582a179",
      "metadata": {
        "id": "8582a179"
      },
      "outputs": [],
      "source": [
        "partitioner = IidPartitioner(\n",
        "    num_partitions=num_partitions\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3f9a435",
      "metadata": {
        "id": "a3f9a435"
      },
      "outputs": [],
      "source": [
        "fds = FederatedDataset(\n",
        "    dataset=\"mnist\",\n",
        "    partitioners={\"train\": partitioner}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d21553c",
      "metadata": {
        "id": "7d21553c"
      },
      "outputs": [],
      "source": [
        "fds = FederatedDataset(\n",
        "    dataset=\"cifar10\",\n",
        "    partitioners={\"train\": partitioner}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8abf0ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib.ticker import FuncFormatter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "026da6c7",
      "metadata": {
        "id": "026da6c7"
      },
      "outputs": [],
      "source": [
        "partitioner = fds.partitioners[\"train\"]\n",
        "figure, axis, dataframe = plot_label_distributions(\n",
        "    partitioner=partitioner,\n",
        "    label_name=\"label\",\n",
        "    title=\"Dir01\",\n",
        "    legend=False,\n",
        "    verbose_labels=True,\n",
        "    size_unit=\"absolute\",\n",
        "    partition_id_axis=\"x\",\n",
        "    legend_kwargs={'fontsize': 10, 'title_fontsize': 10},\n",
        "    figsize=(6, 5)\n",
        ")\n",
        "\n",
        "axis.title.set_fontsize(18)\n",
        "\n",
        "# 2. Modify the returned 'axis' object for labels and ticks\n",
        "# Set font size for the axis titles (e.g., \"Partition ID\", \"Count\")\n",
        "axis.xaxis.label.set_fontsize(18)\n",
        "axis.yaxis.label.set_fontsize(18)\n",
        "\n",
        "axis.yaxis.set_major_formatter(FuncFormatter(lambda y, _: int(y/1000)))\n",
        "#axis.set_ylabel(\"Count (x$10^3$)\", fontsize=16)\n",
        "\n",
        "axis.set_yticks([0, 5000, 10000, 15000, 20000])\n",
        "\n",
        "axis.set_ylabel(\"Count (x$10^3$)\", fontsize=18)\n",
        "\n",
        "# Set font size for the tick numbers on both axes\n",
        "axis.tick_params(axis='both', labelsize=20)\n",
        "\n",
        "# # 3. Adjust layout and show the final plot\n",
        "# figure.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93ff7171",
      "metadata": {
        "id": "93ff7171"
      },
      "outputs": [],
      "source": [
        "train_partitions = [fds.load_partition(i, split=\"train\") for i in range(num_partitions)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j-L_He1Qvz0e",
      "metadata": {
        "id": "j-L_He1Qvz0e"
      },
      "source": [
        "Rodar proxima celula somente se quiser testar com dataset reduzido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w2n6dMxcvx2k",
      "metadata": {
        "id": "w2n6dMxcvx2k"
      },
      "outputs": [],
      "source": [
        "# num_samples = [int(len(train_partition)/10) for train_partition in train_partitions]\n",
        "# train_partitions = [train_partition.select(range(n)) for train_partition, n in zip(train_partitions, num_samples)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1b7cf8f",
      "metadata": {
        "id": "d1b7cf8f"
      },
      "source": [
        "Cria dicionario de label para cliente para controle do dmax_mismatch. Tive que colocar aqui antes do apply_transform para não dar erro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e07fdcb9",
      "metadata": {
        "id": "e07fdcb9"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b106654b",
      "metadata": {
        "id": "b106654b"
      },
      "outputs": [],
      "source": [
        "min_lbl_count = 0.05\n",
        "class_labels = train_partitions[0].info.features[\"label\"]\n",
        "labels_str = class_labels.names\n",
        "label_to_client = {lbl: [] for lbl in labels_str}\n",
        "for idx, ds in enumerate(train_partitions):\n",
        "    counts = Counter(ds['label'])\n",
        "    for label, cnt in counts.items():\n",
        "        if cnt / len(ds) >= min_lbl_count:\n",
        "            label_to_client[class_labels.int2str(label)].append(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56dcbb9b",
      "metadata": {
        "id": "56dcbb9b"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Compose, ToTensor, Normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df48b029",
      "metadata": {
        "id": "df48b029"
      },
      "outputs": [],
      "source": [
        "pytorch_transforms = Compose([\n",
        "    ToTensor(),\n",
        "    Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "def apply_transforms(batch):\n",
        "    batch[\"image\"] = [pytorch_transforms(img) for img in batch[\"image\"]]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbbc667a",
      "metadata": {
        "id": "cbbc667a"
      },
      "outputs": [],
      "source": [
        "# Para CIFAR-10: 3 canais, normalização média=0.5 e std=0.5\n",
        "pytorch_transforms = Compose([\n",
        "    ToTensor(),\n",
        "    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "def apply_transforms(batch):\n",
        "    # batch[\"image\"] é uma lista de PIL.Image ou tensores em H×W×C\n",
        "    # aplicamos o mesmo transform a cada imagem e depois empilhamos\n",
        "    batch[\"img\"] = torch.stack([pytorch_transforms(img) for img in batch[\"img\"]])\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34de09aa",
      "metadata": {
        "id": "34de09aa"
      },
      "outputs": [],
      "source": [
        "train_partitions = [train_partition.with_transform(apply_transforms) for train_partition in train_partitions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MwJAQ213fi-w",
      "metadata": {
        "id": "MwJAQ213fi-w"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CuBEfRZ6fX8i",
      "metadata": {
        "id": "CuBEfRZ6fX8i"
      },
      "outputs": [],
      "source": [
        "test_frac = 0.2\n",
        "client_datasets = []\n",
        "\n",
        "for train_part in train_partitions:\n",
        "    total     = len(train_part)\n",
        "    test_size = int(total * test_frac)\n",
        "    train_size = total - test_size\n",
        "\n",
        "    client_train, client_test = random_split(\n",
        "        train_part,\n",
        "        [train_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42),\n",
        "    )\n",
        "\n",
        "    client_datasets.append({\n",
        "        \"train\": client_train,\n",
        "        \"test\":  client_test,\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0ae0635",
      "metadata": {
        "id": "b0ae0635"
      },
      "source": [
        "## Inicializa modelos e otimizadores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b818e92",
      "metadata": {
        "id": "1b818e92"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5be9636",
      "metadata": {
        "id": "b5be9636"
      },
      "source": [
        "Rodar somente o modelo desejado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e76e482",
      "metadata": {
        "id": "8e76e482"
      },
      "outputs": [],
      "source": [
        "models = [CGAN() for i in range(num_partitions)]\n",
        "gen = CGAN().to(device)\n",
        "optim_G = torch.optim.Adam(list(gen.generator.parameters())+list(gen.label_embedding.parameters()), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70debb0f",
      "metadata": {
        "id": "70debb0f"
      },
      "outputs": [],
      "source": [
        "models = [F2U_GAN(condition=True, seed=42) for i in range(num_partitions)]\n",
        "gen = F2U_GAN(condition=True, seed=42).to(device)\n",
        "optim_G = torch.optim.Adam(list(gen.generator.parameters())+list(gen.label_embedding.parameters()), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c52f5343",
      "metadata": {},
      "outputs": [],
      "source": [
        "models = [F2U_GAN_SlowDisc(condition=True, seed=42) for i in range(num_partitions)]\n",
        "gen = F2U_GAN(condition=True, seed=42).to(device)\n",
        "optim_G = torch.optim.Adam(list(gen.generator.parameters())+list(gen.label_embedding.parameters()), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a813dfe",
      "metadata": {
        "id": "9a813dfe"
      },
      "outputs": [],
      "source": [
        "models = [F2U_GAN_CIFAR(condition=True, seed=42) for i in range(num_partitions)]\n",
        "gen = F2U_GAN_CIFAR(condition=True, seed=42).to(device)\n",
        "optim_G = torch.optim.Adam(list(gen.generator.parameters())+list(gen.label_embedding.parameters()), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70f37272",
      "metadata": {
        "id": "70f37272"
      },
      "outputs": [],
      "source": [
        "optim_Ds = [\n",
        "    torch.optim.Adam(list(model.discriminator.parameters())+list(model.label_embedding.parameters()), lr=0.0002, betas=(0.5, 0.999))\n",
        "    for model in models\n",
        "]\n",
        "\n",
        "# scheduler_D = torch.optim.lr_scheduler.StepLR(optim_D, step_size=5, gamma=0.9)\n",
        "# scheduler_G = torch.optim.lr_scheduler.StepLR(optim_G, step_size=5, gamma=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e08c26a0",
      "metadata": {
        "id": "e08c26a0"
      },
      "source": [
        "Inicializa lambda para F2A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "893b45d4",
      "metadata": {
        "id": "893b45d4"
      },
      "outputs": [],
      "source": [
        "# initial λ* (unconstrained), wrap with ReLU to keep λ ≥ 0\n",
        "lambda_star = nn.Parameter(torch.tensor(0.1, device=device))\n",
        "relu = nn.ReLU()\n",
        "\n",
        "beta = 0.1  # same β as in the paper\n",
        "\n",
        "# now make your generator optimizer also update lambda_star\n",
        "# (so its gradient from the βλ² term can flow)\n",
        "optim_G = torch.optim.Adam(\n",
        "    list(gen.parameters()) + [lambda_star],\n",
        "    lr=2e-4, betas=(0.5, 0.999)\n",
        ") #ACHO QUE TA ERRADO AQUI, OPTIM_G PEGANDO TODOS PARAMETROS, NAO QUE VAI MUDAR ALGO POIS FAÇO INSTANCIACOES DIFERENTES PARA GE E DISC\n",
        "# optim_G = torch.optim.Adam(\n",
        "#     list(gen.generator.parameters())+list(gen.label_embedding.parameters()) + [lambda_star],\n",
        "#     lr=2e-4, betas=(0.5, 0.999)\n",
        "# ) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a3a7e9e",
      "metadata": {
        "id": "7a3a7e9e"
      },
      "source": [
        "# Treinamento dos modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b38a6962",
      "metadata": {
        "id": "b38a6962"
      },
      "source": [
        "## Cria chunks para o treinamento alternado entre discriminadora e geradora ser mais constante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b5d8adc",
      "metadata": {
        "id": "9b5d8adc"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2505ab00",
      "metadata": {
        "id": "2505ab00"
      },
      "source": [
        "Quanto menos chunks, mais dados em cada chunk e mais dados são treinados na discriminadora antes de treinar a geradora. No paper do F2U, não está claro como os treinamentos são alternados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FTvOVoSLVpta",
      "metadata": {
        "id": "FTvOVoSLVpta"
      },
      "outputs": [],
      "source": [
        "# prompt: set each train partition as the only first minimum lenght of the partitions samples, the partitions have same lenght\n",
        "\n",
        "min_len = min(len(p) for p in train_partitions)\n",
        "train_partitions = [p.select(range(min_len)) for p in train_partitions]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CVz-ThoCVfoh",
      "metadata": {
        "id": "CVz-ThoCVfoh"
      },
      "outputs": [],
      "source": [
        "for train_partition in train_partitions:\n",
        "  print(len(train_partition))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff747284",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_chunks = 100\n",
        "seed = 42  # escolha qualquer inteiro para reprodutibilidade\n",
        "client_chunks = []\n",
        "\n",
        "for train_partition in client_datasets:\n",
        "    dataset = train_partition[\"train\"]\n",
        "    n = len(dataset)\n",
        "\n",
        "    # 1) embaralha os índices com seed fixa\n",
        "    indices = list(range(n))\n",
        "    random.seed(seed)\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    # 2) calcula tamanho aproximado de cada chunk\n",
        "    chunk_size = math.ceil(n / num_chunks)\n",
        "\n",
        "    # 3) divide em chunks usando fatias dos índices embaralhados\n",
        "    chunks = []\n",
        "    for i in range(num_chunks):\n",
        "        start = i * chunk_size\n",
        "        end = min((i + 1) * chunk_size, n)\n",
        "        chunk_indices = indices[start:end]\n",
        "        chunks.append(Subset(dataset, chunk_indices))\n",
        "\n",
        "    client_chunks.append(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o6WJTKp6B5vD",
      "metadata": {
        "id": "o6WJTKp6B5vD"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "client_test_loaders = [DataLoader(dataset=ds[\"test\"], batch_size=batch_size, shuffle=True) for ds in client_datasets]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ab8d65e",
      "metadata": {
        "id": "4ab8d65e"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e70bd3c8",
      "metadata": {
        "id": "e70bd3c8"
      },
      "outputs": [],
      "source": [
        "nets = [Net(42).to(device) for _ in range(num_partitions)]\n",
        "optims = [torch.optim.Adam(net.parameters(), lr=0.01) for net in nets]\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbc668cf",
      "metadata": {
        "id": "bbc668cf"
      },
      "outputs": [],
      "source": [
        "testpartition = fds.load_split(\"test\")\n",
        "testpartition = testpartition.with_transform(apply_transforms)\n",
        "testloader = DataLoader(testpartition, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e86ba4bc",
      "metadata": {
        "id": "e86ba4bc"
      },
      "source": [
        "Carregar modelo pré-treinado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d3c145b",
      "metadata": {
        "id": "3d3c145b"
      },
      "outputs": [],
      "source": [
        "global_net = Net(42).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b66f9a29",
      "metadata": {
        "id": "b66f9a29"
      },
      "outputs": [],
      "source": [
        "checkpoint_loaded = torch.load(\"../Experimentos/NB_F2U/GeraFed_4c_NIIDClass/MNIST/checkpoint_epoch100.pth\")\n",
        "\n",
        "global_net.load_state_dict(checkpoint_loaded['alvo_state_dict'])\n",
        "global_net.to(device)\n",
        "for optim, state in zip(optims, checkpoint_loaded['optimizer_alvo_state_dict']):\n",
        "    optim.load_state_dict(state)\n",
        "\n",
        "gen.load_state_dict(checkpoint_loaded[\"gen_state_dict\"])\n",
        "gen.to(device)\n",
        "optim_G.load_state_dict(checkpoint_loaded[\"optim_G_state_dict\"])\n",
        "\n",
        "for model, optim_d, state_model, state_optim in zip(models, optim_Ds, checkpoint_loaded[\"discs_state_dict\"], checkpoint_loaded[\"optim_Ds_state_dict:\"]):\n",
        "    model.load_state_dict(state_model)\n",
        "    model.to(device)\n",
        "    optim_d.load_state_dict(state_optim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa1265b7",
      "metadata": {
        "id": "aa1265b7"
      },
      "source": [
        "Não esquecer de reinicializar os modelos e otimizadores se for reinicializar o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d116bedf",
      "metadata": {
        "id": "d116bedf"
      },
      "outputs": [],
      "source": [
        "from flwr.server.strategy.aggregate import aggregate_inplace\n",
        "from flwr.common import FitRes, Status, Code, ndarrays_to_parameters\n",
        "from collections import OrderedDict, defaultdict\n",
        "from torch.utils.data import ConcatDataset\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac00db4",
      "metadata": {},
      "source": [
        "### GeraFed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1447e9f",
      "metadata": {
        "collapsed": true,
        "id": "c1447e9f"
      },
      "outputs": [],
      "source": [
        "wgan = False\n",
        "f2a = False\n",
        "epochs = 1\n",
        "losses_dict = {\"g_losses_chunk\": [],\n",
        "               \"d_losses_chunk\": [],\n",
        "               \"g_losses_round\": [],\n",
        "               \"d_losses_round\": [],\n",
        "               \"net_loss_chunk\": [],\n",
        "               \"net_acc_chunk\": [],\n",
        "               \"net_loss_round\": [],\n",
        "               \"net_acc_round\": [],\n",
        "               \"time_chunk\": [],\n",
        "               \"time_round\": [],\n",
        "               \"net_time\": [],\n",
        "               \"disc_time\": [],\n",
        "               \"gen_time\": [],\n",
        "               \"img_syn_time\": [],\n",
        "               \"track_mismatch_time\": []\n",
        "               }\n",
        "\n",
        "epoch_bar = tqdm(range(0, epochs), desc=\"Treinamento\", leave=True, position=0)\n",
        "\n",
        "batch_size_gen = 1\n",
        "batch_tam = 32\n",
        "extra_g_e = 20\n",
        "latent_dim = 128\n",
        "num_classes = 10\n",
        "if type(nets[0]).__name__ == \"Net\":\n",
        "  image = \"image\"\n",
        "else:\n",
        "  image = \"img\"\n",
        "\n",
        "if IN_COLAB:\n",
        "  acc_filename = os.path.join(save_dir,\"accuracy_report.txt\")\n",
        "  loss_filename = os.path.join(save_dir, \"losses.json\")\n",
        "  dmax_mismatch_log = os.path.join(save_dir, \"dmax_mismatch.txt\")\n",
        "  lambda_log = os.path.join(save_dir, \"lambda_log.txt\")\n",
        "\n",
        "else:\n",
        "  acc_filename = \"accuracy_report.txt\"\n",
        "  loss_filename = \"losses.json\"\n",
        "  dmax_mismatch_log = \"dmax_mismatch.txt\"\n",
        "  lambda_log = \"lambda_log.txt\"\n",
        "\n",
        "for epoch in epoch_bar:\n",
        "  epoch_start_time = time.time()\n",
        "  mismatch_count = 0\n",
        "  total_checked = 0\n",
        "  g_loss_c = 0.0\n",
        "  d_loss_c = 0.0\n",
        "  total_d_samples = 0  # Amostras totais processadas pelos discriminadores\n",
        "  total_g_samples = 0  # Amostras totais processadas pelo gerador\n",
        "\n",
        "  chunk_bar = tqdm(range(num_chunks), desc=\"Chunks\", leave=True, position=1)\n",
        "\n",
        "  for chunk_idx in chunk_bar:\n",
        "    chunk_start_time = time.time()\n",
        "    params = []\n",
        "    results = []\n",
        "    # ====================================================================\n",
        "    # Treino dos Discriminadores (clientes) no bloco atual\n",
        "    # ====================================================================\n",
        "    d_loss_b = 0\n",
        "    total_chunk_samples = 0\n",
        "\n",
        "\n",
        "    client_bar = tqdm(enumerate(zip(nets, models, client_chunks)), desc=\"Clients\", leave=True, position=2)\n",
        "\n",
        "    for cliente, (net, disc, chunks) in client_bar:\n",
        "      # Carregar o bloco atual do cliente\n",
        "      chunk_dataset = chunks[chunk_idx]\n",
        "      if len(chunk_dataset) == 0:\n",
        "        print(f\"Chunk {chunk_idx} for client {cliente} is empty, skipping.\")\n",
        "        continue\n",
        "      chunk_loader = DataLoader(chunk_dataset, batch_size=batch_tam, shuffle=True)\n",
        "      if chunk_idx == 0:\n",
        "        client_eval_time = time.time()\n",
        "        # Evaluation in client test\n",
        "        # Initialize counters\n",
        "        class_correct = defaultdict(int)\n",
        "        class_total = defaultdict(int)\n",
        "        predictions_counter = defaultdict(int)\n",
        "\n",
        "        global_net.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in client_test_loaders[cliente]:\n",
        "                images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "                outputs = global_net(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Update counts for each sample in batch\n",
        "                for true_label, pred_label in zip(labels, predicted):\n",
        "                    true_idx = true_label.item()\n",
        "                    pred_idx = pred_label.item()\n",
        "\n",
        "                    class_total[true_idx] += 1\n",
        "                    predictions_counter[pred_idx] += 1\n",
        "\n",
        "                    if true_idx == pred_idx:\n",
        "                        class_correct[true_idx] += 1\n",
        "\n",
        "            # Create results dictionary\n",
        "            results_metrics = {\n",
        "                \"class_metrics\": {},\n",
        "                \"overall_accuracy\": None,\n",
        "                \"prediction_distribution\": dict(predictions_counter)\n",
        "            }\n",
        "\n",
        "            # Calculate class-wise metrics\n",
        "            for i in range(num_classes):\n",
        "                metrics = {\n",
        "                    \"samples\": class_total[i],\n",
        "                    \"predictions\": predictions_counter[i],\n",
        "                    \"accuracy\": class_correct[i] / class_total[i] if class_total[i] > 0 else \"N/A\"\n",
        "                }\n",
        "                results_metrics[\"class_metrics\"][f\"class_{i}\"] = metrics\n",
        "\n",
        "            # Calculate overall accuracy\n",
        "            total_samples = sum(class_total.values())\n",
        "            results_metrics[\"overall_accuracy\"] = sum(class_correct.values()) / total_samples\n",
        "\n",
        "            # Save to txt file\n",
        "            with open(acc_filename, \"a\") as f:\n",
        "                f.write(f\"Epoch {epoch + 1} - Client {cliente}\\n\")\n",
        "                # Header with fixed widths\n",
        "                f.write(\"{:<10} {:<10} {:<10} {:<10}\\n\".format(\n",
        "                    \"Class\", \"Accuracy\", \"Samples\", \"Predictions\"))\n",
        "                f.write(\"-\"*45 + \"\\n\")\n",
        "\n",
        "                # Class rows with consistent formatting\n",
        "                for cls in range(num_classes):\n",
        "                    metrics = results_metrics[\"class_metrics\"][f\"class_{cls}\"]\n",
        "\n",
        "                    # Format accuracy (handle \"N/A\" case)\n",
        "                    accuracy = (f\"{metrics['accuracy']:.4f}\"\n",
        "                              if isinstance(metrics['accuracy'], float)\n",
        "                              else \"  N/A  \")\n",
        "\n",
        "                    f.write(\"{:<10} {:<10} {:<10} {:<10}\\n\".format(\n",
        "                        f\"Class {cls}\",\n",
        "                        accuracy,\n",
        "                        metrics['samples'],\n",
        "                        metrics['predictions']\n",
        "                    ))\n",
        "\n",
        "                # Footer with alignment\n",
        "                f.write(\"\\n{:<20} {:.4f}\".format(\"Overall Accuracy:\", results_metrics[\"overall_accuracy\"]))\n",
        "                f.write(\"\\n{:<20} {}\".format(\"Total Samples:\", total_samples))\n",
        "                f.write(\"\\n{:<20} {}\".format(\"Total Predictions:\", sum(predictions_counter.values())))\n",
        "                f.write(\"\\n{:<20} {:.4f}\".format(\"Client Evaluation Time:\", time.time() - client_eval_time))\n",
        "                f.write(\"\\n\")\n",
        "                f.write(\"\\n\")\n",
        "\n",
        "        print(\"Results saved to accuracy_report.txt\")\n",
        "\n",
        "      # Treinar o discriminador no bloco\n",
        "      net.load_state_dict(global_net.state_dict(), strict=True)\n",
        "      net.to(device)\n",
        "      net.train()\n",
        "      disc.to(device)\n",
        "      optim = optims[cliente]\n",
        "      optim_D = optim_Ds[cliente]\n",
        "\n",
        "      start_img_syn_time = time.time()\n",
        "      num_samples = int(13 * (math.exp(0.01*epoch) - 1) / (math.exp(0.01*50) - 1)) * 10\n",
        "      generated_dataset = GeneratedDataset(generator=gen.to(\"cpu\"), num_samples=num_samples, latent_dim=latent_dim, num_classes=10, device=\"cpu\", image_col_name=image)\n",
        "      gen.to(device)\n",
        "      cmb_ds = ConcatDataset([chunk_dataset, generated_dataset])\n",
        "      combined_dataloader= DataLoader(cmb_ds, batch_size=batch_tam, shuffle=True)\n",
        "\n",
        "      img_syn_time = time.time() - start_img_syn_time\n",
        "\n",
        "      batch_bar_net = tqdm(combined_dataloader, desc=\"Batches\", leave=True, position=3)\n",
        "      start_net_time = time.time()\n",
        "      for batch in batch_bar_net:\n",
        "        images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "        batch_size = images.size(0)\n",
        "        if batch_size == 1:\n",
        "          print(\"Batch size is 1, skipping batch\")\n",
        "          continue\n",
        "        optim.zero_grad()\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "      net_time = time.time() - start_net_time\n",
        "\n",
        "      batch_bar = tqdm(chunk_loader, desc=\"Batches\", leave=True, position=4)\n",
        "\n",
        "      start_disc_time = time.time()\n",
        "      for batch in batch_bar:\n",
        "          images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "          batch_size = images.size(0)\n",
        "          if batch_size == 1:\n",
        "            print(\"Batch size is 1, skipping batch\")\n",
        "            continue\n",
        "\n",
        "          real_ident = torch.full((batch_size, 1), 1., device=device)\n",
        "          fake_ident = torch.full((batch_size, 1), 0., device=device)\n",
        "\n",
        "          z_noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "          x_fake_labels = torch.randint(0, 10, (batch_size,), device=device)\n",
        "\n",
        "          # Train D\n",
        "          optim_D.zero_grad()\n",
        "\n",
        "          if wgan:\n",
        "            labels = torch.nn.functional.one_hot(labels, 10).float().to(device)\n",
        "            x_fake_l = torch.nn.functional.one_hot(x_fake_labels, 10).float()\n",
        "\n",
        "            # Adicionar labels ao images para treinamento do Discriminador\n",
        "            image_labels = labels.view(labels.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "            image_fake_labels = x_fake_l.view(x_fake_l.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "\n",
        "            images = torch.cat([images, image_labels], dim=1)\n",
        "\n",
        "            # Treinar Discriminador\n",
        "            z = torch.cat([z_noise, x_fake_l], dim=1)\n",
        "            fake_images = gen(z).detach()\n",
        "            fake_images = torch.cat([fake_images, image_fake_labels], dim=1)\n",
        "\n",
        "            d_loss = discriminator_loss(disc(images), disc(fake_images)) + 10 * gradient_penalty(disc, images, fake_images)\n",
        "\n",
        "          else:\n",
        "            # Dados Reais\n",
        "            y_real = disc(images, labels)\n",
        "            d_real_loss = disc.loss(y_real, real_ident)\n",
        "\n",
        "            # Dados Falsos\n",
        "            x_fake = gen(z_noise, x_fake_labels).detach()\n",
        "            y_fake_d = disc(x_fake, x_fake_labels)\n",
        "            d_fake_loss = disc.loss(y_fake_d, fake_ident)\n",
        "\n",
        "            # Loss total e backprop\n",
        "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "          d_loss.backward()\n",
        "          #torch.nn.utils.clip_grad_norm_(disc.discriminator.parameters(), max_norm=1.0)\n",
        "          optim_D.step()\n",
        "          d_loss_b += d_loss.item()\n",
        "          total_chunk_samples += 1\n",
        "      disc_time = time.time() - start_disc_time  \n",
        "\n",
        "      params.append(ndarrays_to_parameters([val.cpu().numpy() for _, val in net.state_dict().items()]))\n",
        "      results.append((cliente, FitRes(status=Status(code=Code.OK, message=\"Success\"), parameters=params[cliente], num_examples=len(chunk_loader.dataset), metrics={})))\n",
        "\n",
        "    aggregated_ndarrays = aggregate_inplace(results)\n",
        "\n",
        "    params_dict = zip(global_net.state_dict().keys(), aggregated_ndarrays)\n",
        "    state_dict = OrderedDict({k: torch.tensor(v).to(device) for k, v in params_dict})\n",
        "    global_net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # Evaluation\n",
        "    if chunk_idx % 10 == 0:\n",
        "        global_net.eval()\n",
        "        correct, loss = 0, 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in testloader:\n",
        "                images = batch[image].to(device)\n",
        "                labels = batch[\"label\"].to(device)\n",
        "                outputs = global_net(images)\n",
        "                loss += criterion(outputs, labels).item()\n",
        "                correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        accuracy = correct / len(testloader.dataset)\n",
        "        losses_dict[\"net_loss_chunk\"].append(loss / len(testloader))\n",
        "        losses_dict[\"net_acc_chunk\"].append(accuracy)\n",
        "\n",
        "\n",
        "    # Média da perda dos discriminadores neste chunk\n",
        "    avg_d_loss_chunk = d_loss_b / total_chunk_samples if total_chunk_samples > 0 else 0.0\n",
        "    losses_dict[\"d_losses_chunk\"].append(avg_d_loss_chunk)\n",
        "    d_loss_c += avg_d_loss_chunk * total_chunk_samples\n",
        "    total_d_samples += total_chunk_samples\n",
        "\n",
        "    chunk_g_loss = 0.0\n",
        "\n",
        "    epoch_gen_bar = tqdm(range(extra_g_e), desc=\"Gerador\", leave=True, position=2)\n",
        "\n",
        "    start_gen_time = time.time()\n",
        "    for g_epoch in epoch_gen_bar:\n",
        "      # Train G\n",
        "      optim_G.zero_grad()\n",
        "\n",
        "      # Gera dados falsos\n",
        "      z_noise = torch.randn(batch_size_gen, latent_dim, device=device)\n",
        "      x_fake_labels = torch.randint(0, 10, (batch_size_gen,), device=device)\n",
        "      label = int(x_fake_labels.item())\n",
        "\n",
        "      if wgan:\n",
        "        x_fake_labels = torch.nn.functional.one_hot(x_fake_labels, 10).float()\n",
        "        z_noise = torch.cat([z_noise, x_fake_labels], dim=1)\n",
        "        fake_images = gen(z_noise)\n",
        "\n",
        "        # Seleciona o melhor discriminador (Dmax)\n",
        "        image_fake_labels = x_fake_labels.view(x_fake_labels.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "        fake_images = torch.cat([fake_images, image_fake_labels], dim=1)\n",
        "\n",
        "        y_fake_gs = [model(fake_images.detach()) for model in models]\n",
        "\n",
        "      else:\n",
        "        x_fake = gen(z_noise, x_fake_labels)\n",
        "\n",
        "        if f2a:\n",
        "          y_fakes = []\n",
        "          for D in models:\n",
        "              D = D.to(device)\n",
        "              y_fakes.append(D(x_fake, x_fake_labels))  # each is [B,1]\n",
        "          # stack into [N_discriminators, B, 1]\n",
        "          y_stack = torch.stack(y_fakes, dim=0)\n",
        "\n",
        "          # 4) Compute λ = ReLU(lambda_star) to enforce λ ≥ 0\n",
        "          lam = relu(lambda_star)\n",
        "\n",
        "          # 5) Soft‐max weights across the 0th dim (discriminators)\n",
        "          #    we want S_i = exp(λ D_i) / sum_j exp(λ D_j)\n",
        "          #    shape remains [N, B, 1]\n",
        "          S = torch.softmax(lam * y_stack, dim=0)\n",
        "\n",
        "          # 6) Weighted sum: D_agg shape [B,1]\n",
        "          D_agg = (S * y_stack).sum(dim=0)\n",
        "\n",
        "          # 7) Compute your generator loss + β λ² regularizer\n",
        "          real_ident = torch.full((batch_size_gen, 1), 1., device=device)\n",
        "          adv_loss   = gen.loss(D_agg, real_ident)       # BCEWithLogitsLoss or whatever\n",
        "          reg_loss   = beta * lam.pow(2)                 # β λ²\n",
        "          g_loss     = adv_loss + reg_loss\n",
        "\n",
        "        else:\n",
        "          # Seleciona o melhor discriminador (Dmax)\n",
        "          y_fake_gs = [model(x_fake.detach(), x_fake_labels) for model in models]\n",
        "          y_fake_g_means = [torch.mean(y).item() for y in y_fake_gs]\n",
        "          dmax_index = y_fake_g_means.index(max(y_fake_g_means))\n",
        "          Dmax = models[dmax_index]\n",
        "\n",
        "          start_track_mismatch_time = time.time()\n",
        "          #Track mismatches\n",
        "          expected_indexes = label_to_client[class_labels.int2str(x_fake_labels.item())] ##PEGA SOMENTE A PRIMEIRA LABEL, SE BATCH_SIZE_GEN FOR DIFERENTE DE 1 VAI DAR ERRO\n",
        "          if dmax_index not in expected_indexes:\n",
        "              mismatch_count += 1\n",
        "              total_checked +=1\n",
        "              percent_mismatch =  mismatch_count / total_checked\n",
        "              with open(dmax_mismatch_log, \"a\") as mismatch_file:\n",
        "                  mismatch_file.write(f\"{epoch+1} {x_fake_labels.item()} {expected_indexes} {dmax_index} {percent_mismatch:.2f}\\n\")\n",
        "          else:\n",
        "              total_checked += 1\n",
        "              if g_epoch == extra_g_e - 1 and chunk_idx == num_chunks - 1:\n",
        "                percent_mismatch =  mismatch_count / total_checked\n",
        "                with open(dmax_mismatch_log, \"a\") as mismatch_file:\n",
        "                  mismatch_file.write(f\"{epoch+1} {x_fake_labels.item()} {expected_indexes} {dmax_index} {percent_mismatch:.2f}\\n\")\n",
        "          track_mismatch_time = time.time() - start_track_mismatch_time\n",
        "\n",
        "          # Calcula a perda do gerador\n",
        "          real_ident = torch.full((batch_size_gen, 1), 1., device=device)\n",
        "          if wgan:\n",
        "            y_fake_g = Dmax(fake_images)\n",
        "            g_loss = generator_loss(y_fake_g)\n",
        "\n",
        "          else:\n",
        "            y_fake_g = Dmax(x_fake, x_fake_labels)  # Detach explícito\n",
        "            g_loss = gen.loss(y_fake_g, real_ident)\n",
        "\n",
        "      g_loss.backward()\n",
        "      #torch.nn.utils.clip_grad_norm_(gen.generator.parameters(), max_norm=1.0)\n",
        "      optim_G.step()\n",
        "      gen.to(device)\n",
        "      chunk_g_loss += g_loss.item()\n",
        "    gen_time = time.time() - start_gen_time\n",
        "\n",
        "    losses_dict[\"g_losses_chunk\"].append(chunk_g_loss / extra_g_e)\n",
        "    g_loss_c += chunk_g_loss /extra_g_e\n",
        "\n",
        "    losses_dict[\"time_chunk\"].append(time.time() - chunk_start_time)\n",
        "    losses_dict[\"net_time\"].append(net_time)\n",
        "    losses_dict[\"disc_time\"].append(disc_time)\n",
        "    losses_dict[\"gen_time\"].append(gen_time)\n",
        "    losses_dict[\"img_syn_time\"].append(img_syn_time)\n",
        "    losses_dict[\"track_mismatch_time\"].append(track_mismatch_time)\n",
        "\n",
        "\n",
        "  g_loss_e = g_loss_c/num_chunks\n",
        "  d_loss_e = d_loss_c / total_d_samples if total_d_samples > 0 else 0.0\n",
        "\n",
        "  losses_dict[\"g_losses_round\"].append(g_loss_e)\n",
        "  losses_dict[\"d_losses_round\"].append(d_loss_e)\n",
        "\n",
        "  if (epoch+1)%2==0:\n",
        "      checkpoint = {\n",
        "            'epoch': epoch+1,  # número da última época concluída\n",
        "            'alvo_state_dict': global_net.state_dict(),\n",
        "            'optimizer_alvo_state_dict': [optim.state_dict() for optim in optims],\n",
        "            'gen_state_dict': gen.state_dict(),\n",
        "            'optim_G_state_dict': optim_G.state_dict(),\n",
        "            'discs_state_dict': [model.state_dict() for model in models],\n",
        "            'optim_Ds_state_dict:': [optim_d.state_dict() for optim_d in optim_Ds]\n",
        "          }\n",
        "      checkpoint_file = f\"checkpoint_epoch{epoch+1}.pth\"\n",
        "      if IN_COLAB:\n",
        "          checkpoint_file = os.path.join(save_dir, checkpoint_file)\n",
        "      torch.save(checkpoint, checkpoint_file)\n",
        "      print(f\"Global net saved to {checkpoint_file}\")\n",
        "\n",
        "      if f2a:\n",
        "        current_lambda_star = lambda_star.item()\n",
        "        current_lam         = F.relu(lambda_star).item()\n",
        "\n",
        "        with open(lambda_log, \"a\") as f:\n",
        "          f.write(f\"{current_lambda_star},{current_lam}\\n\")\n",
        "\n",
        "  correct, loss = 0, 0.0\n",
        "  global_net.eval()\n",
        "  with torch.no_grad():\n",
        "      for batch in testloader:\n",
        "          images = batch[image].to(device)\n",
        "          labels = batch[\"label\"].to(device)\n",
        "          outputs = global_net(images)\n",
        "          loss += criterion(outputs, labels).item()\n",
        "          correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "  accuracy = correct / len(testloader.dataset)\n",
        "  losses_dict[\"net_loss_round\"].append(loss / len(testloader))\n",
        "  losses_dict[\"net_acc_round\"].append(accuracy)\n",
        "\n",
        "  print(f\"Época {epoch+1} completa\")\n",
        "  generate_plot(gen, \"cpu\", epoch+1, latent_dim=128)\n",
        "  gen.to(device)\n",
        "\n",
        "  losses_dict[\"time_round\"].append(time.time() - epoch_start_time)\n",
        "\n",
        "  try:\n",
        "      with open(loss_filename, 'w', encoding='utf-8') as f:\n",
        "          json.dump(losses_dict, f, ensure_ascii=False, indent=4) # indent makes it readable\n",
        "      print(f\"Losses dict successfully saved to {loss_filename}\")\n",
        "  except Exception as e:\n",
        "      print(f\"Error saving losses dict to JSON: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4677e695",
      "metadata": {},
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26024cd1",
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoch in range(100):\n",
        "print(\"Epoch\", epoch, int(13 * (math.exp(0.01*epoch) - 1) / (math.exp(0.01*50) - 1)) * 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9aa99aa",
      "metadata": {},
      "source": [
        "### Somente Classificador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_OdHAvK0LQp3",
      "metadata": {
        "collapsed": true,
        "id": "_OdHAvK0LQp3"
      },
      "outputs": [],
      "source": [
        "epochs = 2\n",
        "losses_dict = {\"net_loss_chunk\": [],\n",
        "               \"net_acc_chunk\": [],\n",
        "               \"net_loss_round\": [],\n",
        "               \"net_acc_round\": [],\n",
        "               \"time_chunk\": [],\n",
        "               \"time_round\": []}\n",
        "\n",
        "epoch_bar = tqdm(range(0, epochs), desc=\"Treinamento\", leave=True, position=0)\n",
        "\n",
        "batch_tam = 32\n",
        "latent_dim = 128\n",
        "num_classes = 10\n",
        "if type(nets[0]).__name__ == \"Net\":\n",
        "  image = \"image\"\n",
        "else:\n",
        "  image = \"img\"\n",
        "\n",
        "if IN_COLAB:\n",
        "  acc_filename = os.path.join(save_dir,\"accuracy_report.txt\")\n",
        "  loss_filename = os.path.join(save_dir, \"losses.json\")\n",
        "else:\n",
        "  acc_filename = \"accuracy_report.txt\"\n",
        "  loss_filename = \"losses.json\"\n",
        "\n",
        "for epoch in epoch_bar:\n",
        "  epoch_start_time = time.time()\n",
        "\n",
        "  chunk_bar = tqdm(range(num_chunks), desc=\"Chunks\", leave=True, position=1)\n",
        "\n",
        "  for chunk_idx in chunk_bar:\n",
        "    params = []\n",
        "    results = []\n",
        "    chunk_start_time = time.time()\n",
        "    total_chunk_samples = 0\n",
        "\n",
        "    client_bar = tqdm(enumerate(zip(nets, client_chunks)), desc=\"Clients\", leave=True, position=2)\n",
        "\n",
        "    for cliente, (net, chunks) in client_bar:\n",
        "\n",
        "      if chunk_idx == 0:\n",
        "        client_eval_time = time.time()\n",
        "        # Evaluation in client test\n",
        "        # Initialize counters\n",
        "        class_correct = defaultdict(int)\n",
        "        class_total = defaultdict(int)\n",
        "        predictions_counter = defaultdict(int)\n",
        "\n",
        "        global_net.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in client_test_loaders[cliente]:\n",
        "                images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "                outputs = global_net(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Update counts for each sample in batch\n",
        "                for true_label, pred_label in zip(labels, predicted):\n",
        "                    true_idx = true_label.item()\n",
        "                    pred_idx = pred_label.item()\n",
        "\n",
        "                    class_total[true_idx] += 1\n",
        "                    predictions_counter[pred_idx] += 1\n",
        "\n",
        "                    if true_idx == pred_idx:\n",
        "                        class_correct[true_idx] += 1\n",
        "\n",
        "            # Create results dictionary\n",
        "            results_metrics = {\n",
        "                \"class_metrics\": {},\n",
        "                \"overall_accuracy\": None,\n",
        "                \"prediction_distribution\": dict(predictions_counter)\n",
        "            }\n",
        "\n",
        "            # Calculate class-wise metrics\n",
        "            for i in range(num_classes):\n",
        "                metrics = {\n",
        "                    \"samples\": class_total[i],\n",
        "                    \"predictions\": predictions_counter[i],\n",
        "                    \"accuracy\": class_correct[i] / class_total[i] if class_total[i] > 0 else \"N/A\"\n",
        "                }\n",
        "                results_metrics[\"class_metrics\"][f\"class_{i}\"] = metrics\n",
        "\n",
        "            # Calculate overall accuracy\n",
        "            total_samples = sum(class_total.values())\n",
        "            results_metrics[\"overall_accuracy\"] = sum(class_correct.values()) / total_samples\n",
        "\n",
        "            # Save to txt file\n",
        "            with open(acc_filename, \"a\") as f:\n",
        "                f.write(f\"Epoch {epoch + 1} - Client {cliente}\\n\")\n",
        "                # Header with fixed widths\n",
        "                f.write(\"{:<10} {:<10} {:<10} {:<10}\\n\".format(\n",
        "                    \"Class\", \"Accuracy\", \"Samples\", \"Predictions\"))\n",
        "                f.write(\"-\"*45 + \"\\n\")\n",
        "\n",
        "                # Class rows with consistent formatting\n",
        "                for cls in range(num_classes):\n",
        "                    metrics = results_metrics[\"class_metrics\"][f\"class_{cls}\"]\n",
        "\n",
        "                    # Format accuracy (handle \"N/A\" case)\n",
        "                    accuracy = (f\"{metrics['accuracy']:.4f}\"\n",
        "                              if isinstance(metrics['accuracy'], float)\n",
        "                              else \"  N/A  \")\n",
        "\n",
        "                    f.write(\"{:<10} {:<10} {:<10} {:<10}\\n\".format(\n",
        "                        f\"Class {cls}\",\n",
        "                        accuracy,\n",
        "                        metrics['samples'],\n",
        "                        metrics['predictions']\n",
        "                    ))\n",
        "\n",
        "                # Footer with alignment\n",
        "                f.write(\"\\n{:<20} {:.4f}\".format(\"Overall Accuracy:\", results_metrics[\"overall_accuracy\"]))\n",
        "                f.write(\"\\n{:<20} {}\".format(\"Total Samples:\", total_samples))\n",
        "                f.write(\"\\n{:<20} {}\".format(\"Total Predictions:\", sum(predictions_counter.values())))\n",
        "                f.write(\"\\n{:<20} {:.4f}\".format(\"Client Evaluation Time:\", time.time() - client_eval_time))\n",
        "                f.write(\"\\n\")\n",
        "                f.write(\"\\n\")\n",
        "\n",
        "        print(\"Results saved to accuracy_report.txt\")\n",
        "\n",
        "      # Carregar o bloco atual do cliente\n",
        "      chunk_dataset = chunks[chunk_idx]\n",
        "      if len(chunk_dataset) == 0:\n",
        "        print(f\"Chunk {chunk_idx} for client {cliente} is empty, skipping.\")\n",
        "        continue\n",
        "      chunk_loader = DataLoader(chunk_dataset, batch_size=batch_tam, shuffle=False)\n",
        "\n",
        "      net.load_state_dict(global_net.state_dict(), strict=True)\n",
        "      net.to(device)\n",
        "      net.train()\n",
        "      optim = optims[cliente]\n",
        "\n",
        "      batch_bar = tqdm(chunk_loader, desc=\"Batches\", leave=True, position=3)\n",
        "\n",
        "      for batch in batch_bar:\n",
        "        images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "        batch_size = images.size(0)\n",
        "        if batch_size == 1:\n",
        "          print(\"Batch size is 1, skipping batch\")\n",
        "          continue\n",
        "        optim.zero_grad()\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "\n",
        "      params.append(ndarrays_to_parameters([val.cpu().numpy() for _, val in net.state_dict().items()]))\n",
        "      results.append((cliente, FitRes(status=Status(code=Code.OK, message=\"Success\"), parameters=params[cliente], num_examples=len(chunk_loader.dataset), metrics={})))\n",
        "\n",
        "    aggregated_ndarrays = aggregate_inplace(results)\n",
        "\n",
        "    params_dict = zip(global_net.state_dict().keys(), aggregated_ndarrays)\n",
        "    state_dict = OrderedDict({k: torch.tensor(v).to(device) for k, v in params_dict})\n",
        "    global_net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # Evaluation\n",
        "    if chunk_idx % 10 == 0:\n",
        "        global_net.eval()\n",
        "        correct, loss = 0, 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in testloader:\n",
        "                images = batch[image].to(device)\n",
        "                labels = batch[\"label\"].to(device)\n",
        "                outputs = global_net(images)\n",
        "                loss += criterion(outputs, labels).item()\n",
        "                correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        accuracy = correct / len(testloader.dataset)\n",
        "        losses_dict[\"net_loss_chunk\"].append(loss / len(testloader))\n",
        "        losses_dict[\"net_acc_chunk\"].append(accuracy)\n",
        "\n",
        "        losses_dict[\"time_chunk\"].append(time.time() - chunk_start_time)\n",
        "\n",
        "  correct, loss = 0, 0.0\n",
        "  global_net.eval()\n",
        "  with torch.no_grad():\n",
        "      for batch in testloader:\n",
        "          images = batch[image].to(device)\n",
        "          labels = batch[\"label\"].to(device)\n",
        "          outputs = global_net(images)\n",
        "          loss += criterion(outputs, labels).item()\n",
        "          correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "  accuracy = correct / len(testloader.dataset)\n",
        "  losses_dict[\"net_loss_round\"].append(loss / len(testloader))\n",
        "  losses_dict[\"net_acc_round\"].append(accuracy)\n",
        "\n",
        "\n",
        "  print(f\"Época {epoch+1} completa\")\n",
        "\n",
        "  losses_dict[\"time_round\"].append(time.time() - epoch_start_time)\n",
        "\n",
        "  try:\n",
        "      with open(loss_filename, 'w', encoding='utf-8') as f:\n",
        "          json.dump(losses_dict, f, ensure_ascii=False, indent=4) # indent makes it readable\n",
        "      print(f\"Losses dict successfully saved to {loss_filename}\")\n",
        "  except Exception as e:\n",
        "      print(f\"Error saving losses dict to JSON: {e}\")\n",
        "\n",
        "  if (epoch+1)%1==0:\n",
        "    checkpoint = {\n",
        "          'epoch': epoch+1,  # número da última época concluída\n",
        "          'alvo_state_dict': global_net.state_dict(),\n",
        "          'optimizer_alvo_state_dict': [optim.state_dict() for optim in optims],\n",
        "        }\n",
        "    checkpoint_file = f\"checkpoint_epoch{epoch+1}.pth\"\n",
        "    if IN_COLAB:\n",
        "        checkpoint_file = os.path.join(save_dir, checkpoint_file)\n",
        "    torch.save(checkpoint, checkpoint_file)\n",
        "    print(f\"Global net saved to {checkpoint_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44064765",
      "metadata": {},
      "source": [
        "### Somente Gerador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b7312a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "wgan = False\n",
        "f2a = False\n",
        "epochs = 3\n",
        "losses_dict = {\"g_losses_chunk\": [],\n",
        "               \"d_losses_chunk\": [],\n",
        "               \"g_losses_round\": [],\n",
        "               \"d_losses_round\": [],\n",
        "               \"time_chunk\": [],\n",
        "               \"time_round\": [],\n",
        "               \"disc_time\": [],\n",
        "               \"gen_time\": [],\n",
        "               \"img_syn_time\": [],\n",
        "               \"track_mismatch_time\": []\n",
        "               }\n",
        "\n",
        "epoch_bar = tqdm(range(0, epochs), desc=\"Treinamento\", leave=True, position=0)\n",
        "\n",
        "batch_size_gen = 1\n",
        "batch_tam = 32\n",
        "extra_g_e = 20\n",
        "latent_dim = 128\n",
        "num_classes = 10\n",
        "\n",
        "if IN_COLAB:\n",
        "  loss_filename = os.path.join(save_dir, \"losses.json\")\n",
        "  dmax_mismatch_log = os.path.join(save_dir, \"dmax_mismatch.txt\")\n",
        "  lambda_log = os.path.join(save_dir, \"lambda_log.txt\")\n",
        "\n",
        "else:\n",
        "  loss_filename = \"losses.json\"\n",
        "  dmax_mismatch_log = \"dmax_mismatch.txt\"\n",
        "  lambda_log = \"lambda_log.txt\"\n",
        "\n",
        "for epoch in epoch_bar:\n",
        "  epoch_start_time = time.time()\n",
        "  mismatch_count = 0\n",
        "  total_checked = 0\n",
        "  g_loss_c = 0.0\n",
        "  d_loss_c = 0.0\n",
        "  total_d_samples = 0  # Amostras totais processadas pelos discriminadores\n",
        "  total_g_samples = 0  # Amostras totais processadas pelo gerador\n",
        "\n",
        "  chunk_bar = tqdm(range(num_chunks), desc=\"Chunks\", leave=True, position=1)\n",
        "\n",
        "  for chunk_idx in chunk_bar:\n",
        "    chunk_start_time = time.time()\n",
        "    # ====================================================================\n",
        "    # Treino dos Discriminadores (clientes) no bloco atual\n",
        "    # ====================================================================\n",
        "    d_loss_b = 0\n",
        "    total_chunk_samples = 0\n",
        "\n",
        "\n",
        "    client_bar = tqdm(enumerate(zip(models, client_chunks)), desc=\"Clients\", leave=True, position=2)\n",
        "\n",
        "    for cliente, (disc, chunks) in client_bar:\n",
        "      # Carregar o bloco atual do cliente\n",
        "      chunk_dataset = chunks[chunk_idx]\n",
        "      if len(chunk_dataset) == 0:\n",
        "        print(f\"Chunk {chunk_idx} for client {cliente} is empty, skipping.\")\n",
        "        continue\n",
        "      chunk_loader = DataLoader(chunk_dataset, batch_size=batch_tam, shuffle=True)\n",
        "\n",
        "      # Treinar o discriminador no bloco\n",
        "      disc.to(device)\n",
        "      optim_D = optim_Ds[cliente]\n",
        "\n",
        "      batch_bar = tqdm(chunk_loader, desc=\"Batches\", leave=True, position=4)\n",
        "\n",
        "      start_disc_time = time.time()\n",
        "      for batch in batch_bar:\n",
        "          images, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "          batch_size = images.size(0)\n",
        "          if batch_size == 1:\n",
        "            print(\"Batch size is 1, skipping batch\")\n",
        "            continue\n",
        "\n",
        "          real_ident = torch.full((batch_size, 1), 1., device=device)\n",
        "          fake_ident = torch.full((batch_size, 1), 0., device=device)\n",
        "\n",
        "          z_noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "          x_fake_labels = torch.randint(0, 10, (batch_size,), device=device)\n",
        "\n",
        "          # Train D\n",
        "          optim_D.zero_grad()\n",
        "\n",
        "          if wgan:\n",
        "            labels = torch.nn.functional.one_hot(labels, 10).float().to(device)\n",
        "            x_fake_l = torch.nn.functional.one_hot(x_fake_labels, 10).float()\n",
        "\n",
        "            # Adicionar labels ao images para treinamento do Discriminador\n",
        "            image_labels = labels.view(labels.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "            image_fake_labels = x_fake_l.view(x_fake_l.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "\n",
        "            images = torch.cat([images, image_labels], dim=1)\n",
        "\n",
        "            # Treinar Discriminador\n",
        "            z = torch.cat([z_noise, x_fake_l], dim=1)\n",
        "            fake_images = gen(z).detach()\n",
        "            fake_images = torch.cat([fake_images, image_fake_labels], dim=1)\n",
        "\n",
        "            d_loss = discriminator_loss(disc(images), disc(fake_images)) + 10 * gradient_penalty(disc, images, fake_images)\n",
        "\n",
        "          else:\n",
        "            # Dados Reais\n",
        "            y_real = disc(images, labels)\n",
        "            d_real_loss = disc.loss(y_real, real_ident)\n",
        "\n",
        "            # Dados Falsos\n",
        "            x_fake = gen(z_noise, x_fake_labels).detach()\n",
        "            y_fake_d = disc(x_fake, x_fake_labels)\n",
        "            d_fake_loss = disc.loss(y_fake_d, fake_ident)\n",
        "\n",
        "            # Loss total e backprop\n",
        "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "          d_loss.backward()\n",
        "          #torch.nn.utils.clip_grad_norm_(disc.discriminator.parameters(), max_norm=1.0)\n",
        "          optim_D.step()\n",
        "          d_loss_b += d_loss.item()\n",
        "          total_chunk_samples += 1\n",
        "      disc_time = time.time() - start_disc_time  \n",
        "\n",
        "\n",
        "    # Média da perda dos discriminadores neste chunk\n",
        "    avg_d_loss_chunk = d_loss_b / total_chunk_samples if total_chunk_samples > 0 else 0.0\n",
        "    losses_dict[\"d_losses_chunk\"].append(avg_d_loss_chunk)\n",
        "    d_loss_c += avg_d_loss_chunk * total_chunk_samples\n",
        "    total_d_samples += total_chunk_samples\n",
        "\n",
        "    chunk_g_loss = 0.0\n",
        "\n",
        "    epoch_gen_bar = tqdm(range(extra_g_e), desc=\"Gerador\", leave=True, position=2)\n",
        "\n",
        "    start_gen_time = time.time()\n",
        "    for g_epoch in epoch_gen_bar:\n",
        "      # Train G\n",
        "      optim_G.zero_grad()\n",
        "\n",
        "      # Gera dados falsos\n",
        "      z_noise = torch.randn(batch_size_gen, latent_dim, device=device)\n",
        "      x_fake_labels = torch.randint(0, 10, (batch_size_gen,), device=device)\n",
        "      label = int(x_fake_labels.item())\n",
        "\n",
        "      if wgan:\n",
        "        x_fake_labels = torch.nn.functional.one_hot(x_fake_labels, 10).float()\n",
        "        z_noise = torch.cat([z_noise, x_fake_labels], dim=1)\n",
        "        fake_images = gen(z_noise)\n",
        "\n",
        "        # Seleciona o melhor discriminador (Dmax)\n",
        "        image_fake_labels = x_fake_labels.view(x_fake_labels.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "        fake_images = torch.cat([fake_images, image_fake_labels], dim=1)\n",
        "\n",
        "        y_fake_gs = [model(fake_images.detach()) for model in models]\n",
        "\n",
        "      else:\n",
        "        x_fake = gen(z_noise, x_fake_labels)\n",
        "\n",
        "        if f2a:\n",
        "          y_fakes = []\n",
        "          for D in models:\n",
        "              D = D.to(device)\n",
        "              y_fakes.append(D(x_fake, x_fake_labels))  # each is [B,1]\n",
        "          # stack into [N_discriminators, B, 1]\n",
        "          y_stack = torch.stack(y_fakes, dim=0)\n",
        "\n",
        "          # 4) Compute λ = ReLU(lambda_star) to enforce λ ≥ 0\n",
        "          lam = relu(lambda_star)\n",
        "\n",
        "          # 5) Soft‐max weights across the 0th dim (discriminators)\n",
        "          #    we want S_i = exp(λ D_i) / sum_j exp(λ D_j)\n",
        "          #    shape remains [N, B, 1]\n",
        "          S = torch.softmax(lam * y_stack, dim=0)\n",
        "\n",
        "          # 6) Weighted sum: D_agg shape [B,1]\n",
        "          D_agg = (S * y_stack).sum(dim=0)\n",
        "\n",
        "          # 7) Compute your generator loss + β λ² regularizer\n",
        "          real_ident = torch.full((batch_size_gen, 1), 1., device=device)\n",
        "          adv_loss   = gen.loss(D_agg, real_ident)       # BCEWithLogitsLoss or whatever\n",
        "          reg_loss   = beta * lam.pow(2)                 # β λ²\n",
        "          g_loss     = adv_loss + reg_loss\n",
        "\n",
        "        else:\n",
        "          # Seleciona o melhor discriminador (Dmax)\n",
        "          y_fake_gs = [model(x_fake.detach(), x_fake_labels) for model in models]\n",
        "          y_fake_g_means = [torch.mean(y).item() for y in y_fake_gs]\n",
        "          dmax_index = y_fake_g_means.index(max(y_fake_g_means))\n",
        "          Dmax = models[dmax_index]\n",
        "\n",
        "          start_track_mismatch_time = time.time()\n",
        "          #Track mismatches\n",
        "          expected_indexes = label_to_client[class_labels.int2str(x_fake_labels.item())] ##PEGA SOMENTE A PRIMEIRA LABEL, SE BATCH_SIZE_GEN FOR DIFERENTE DE 1 VAI DAR ERRO\n",
        "          if dmax_index not in expected_indexes:\n",
        "              mismatch_count += 1\n",
        "              total_checked +=1\n",
        "              percent_mismatch =  mismatch_count / total_checked\n",
        "              with open(dmax_mismatch_log, \"a\") as mismatch_file:\n",
        "                  mismatch_file.write(f\"{epoch+1} {x_fake_labels.item()} {expected_indexes} {dmax_index} {percent_mismatch:.2f}\\n\")\n",
        "          else:\n",
        "              total_checked += 1\n",
        "              if g_epoch == extra_g_e - 1 and chunk_idx == num_chunks - 1:\n",
        "                percent_mismatch =  mismatch_count / total_checked\n",
        "                with open(dmax_mismatch_log, \"a\") as mismatch_file:\n",
        "                  mismatch_file.write(f\"{epoch+1} {x_fake_labels.item()} {expected_indexes} {dmax_index} {percent_mismatch:.2f}\\n\")\n",
        "          track_mismatch_time = time.time() - start_track_mismatch_time\n",
        "\n",
        "          # Calcula a perda do gerador\n",
        "          real_ident = torch.full((batch_size_gen, 1), 1., device=device)\n",
        "          if wgan:\n",
        "            y_fake_g = Dmax(fake_images)\n",
        "            g_loss = generator_loss(y_fake_g)\n",
        "\n",
        "          else:\n",
        "            y_fake_g = Dmax(x_fake, x_fake_labels)  # Detach explícito\n",
        "            g_loss = gen.loss(y_fake_g, real_ident)\n",
        "\n",
        "      g_loss.backward()\n",
        "      #torch.nn.utils.clip_grad_norm_(gen.generator.parameters(), max_norm=1.0)\n",
        "      optim_G.step()\n",
        "      gen.to(device)\n",
        "      chunk_g_loss += g_loss.item()\n",
        "    gen_time = time.time() - start_gen_time\n",
        "\n",
        "    losses_dict[\"g_losses_chunk\"].append(chunk_g_loss / extra_g_e)\n",
        "    g_loss_c += chunk_g_loss /extra_g_e\n",
        "\n",
        "    losses_dict[\"time_chunk\"].append(time.time() - chunk_start_time)\n",
        "    losses_dict[\"disc_time\"].append(disc_time)\n",
        "    losses_dict[\"gen_time\"].append(gen_time)\n",
        "    losses_dict[\"track_mismatch_time\"].append(track_mismatch_time)\n",
        "\n",
        "\n",
        "  g_loss_e = g_loss_c/num_chunks\n",
        "  d_loss_e = d_loss_c / total_d_samples if total_d_samples > 0 else 0.0\n",
        "\n",
        "  losses_dict[\"g_losses_round\"].append(g_loss_e)\n",
        "  losses_dict[\"d_losses_round\"].append(d_loss_e)\n",
        "\n",
        "  if (epoch+1)%2==0:\n",
        "      checkpoint = {\n",
        "            'epoch': epoch+1,  # número da última época concluída\n",
        "            'gen_state_dict': gen.state_dict(),\n",
        "            'optim_G_state_dict': optim_G.state_dict(),\n",
        "            'discs_state_dict': [model.state_dict() for model in models],\n",
        "            'optim_Ds_state_dict:': [optim_d.state_dict() for optim_d in optim_Ds]\n",
        "          }\n",
        "      checkpoint_file = f\"checkpoint_epoch{epoch+1}.pth\"\n",
        "      if IN_COLAB:\n",
        "          checkpoint_file = os.path.join(save_dir, checkpoint_file)\n",
        "      torch.save(checkpoint, checkpoint_file)\n",
        "      print(f\"Global net saved to {checkpoint_file}\")\n",
        "\n",
        "      if f2a:\n",
        "        current_lambda_star = lambda_star.item()\n",
        "        current_lam         = F.relu(lambda_star).item()\n",
        "\n",
        "        with open(lambda_log, \"a\") as f:\n",
        "          f.write(f\"{current_lambda_star},{current_lam}\\n\")\n",
        "\n",
        "  print(f\"Época {epoch+1} completa\")\n",
        "  generate_plot(gen, \"cpu\", epoch+1, latent_dim=128)\n",
        "  gen.to(device)\n",
        "\n",
        "  losses_dict[\"time_round\"].append(time.time() - epoch_start_time)\n",
        "\n",
        "  try:\n",
        "      with open(loss_filename, 'w', encoding='utf-8') as f:\n",
        "          json.dump(losses_dict, f, ensure_ascii=False, indent=4) # indent makes it readable\n",
        "      print(f\"Losses dict successfully saved to {loss_filename}\")\n",
        "  except Exception as e:\n",
        "      print(f\"Error saving losses dict to JSON: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c3ce47d",
      "metadata": {
        "id": "2c3ce47d"
      },
      "source": [
        "# Gráficos de perda e acurácia"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01f7dbfb",
      "metadata": {
        "id": "01f7dbfb"
      },
      "source": [
        "## Le o arquivo de perda salvo no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-by_-71kSOeu",
      "metadata": {
        "id": "-by_-71kSOeu"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c75c3fb9",
      "metadata": {},
      "outputs": [],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29ff7c31",
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(\"../../FLEG_Experiments/valid/median/plots\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "129faeb1",
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(\"../../../FLEG_Experiments/plots\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d6140f4",
      "metadata": {},
      "source": [
        "### Hardcode List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "648153d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "files = [\n",
        "    \"class_level0/metrics.json\",\n",
        "    \"class_level1/metrics.json\",\n",
        "    \"class_level1/3000_samples/metrics.json\",\n",
        "    \"class_level1/12000_samples/metrics.json\",\n",
        "    \"class_level1/D_samples/metrics.json\",\n",
        "    \"class_level2/metrics.json\",\n",
        "    \"class_level3/metrics.json\",\n",
        "    \"class_level4/metrics.json\",\n",
        "    \"gan_level1/metrics.json\",\n",
        "    \"gan_level2/metrics.json\",\n",
        "    \"gan_level3/metrics.json\",\n",
        "    \"gan_level4/metrics.json\",\n",
        "    \"class_patience100/metrics.json\",\n",
        "    \"class_patience1000/metrics.json\",\n",
        "    \"../iniciais/mnist_ClassPartitioner_fedavg_numchunks_100_fleg_trial1/metrics.json\",\n",
        "    \"../iniciais/mnist_ClassPartitioner_fedavg_numchunks_10_fleg_trial1/metrics.json\",\n",
        "    \"../iniciais/mnist_ClassPartitioner_fedavg_numchunks_50_fleg_trial1/metrics.json\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fed31822",
      "metadata": {},
      "outputs": [],
      "source": [
        "files = [\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks1_ganepoch40_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks10_ganepoch35_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks50_ganepoch30_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks200_ganepoch20_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg/class_level0/metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg/class_level1/metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg/class_level1/D_samples/metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg/class_level2/metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg/class_level3/metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg/class_level4/metrics.json\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "394e0b15",
      "metadata": {},
      "outputs": [],
      "source": [
        "files = [\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_100_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_100_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_100_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_100_ganepoch20_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_100_ganepoch20_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_100_ganepoch20_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_100_ganepoch30_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_100_ganepoch30_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_100_ganepoch30_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_50_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_50_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_50_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial3/metrics.json\"\n",
        "\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch20_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch20_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch20_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch30_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch30_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch30_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial3/metrics.json\"\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial3/metrics.json\"\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial3/metrics.json\"\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f017ac26",
      "metadata": {},
      "outputs": [],
      "source": [
        "files = [\n",
        "    \"../../Tests_FedGenIA/Padrao_FedGenIA_DML-ICC/mnist_ClassPartitioner_fedavg_fedgenia_trial1/metrics.json\",\n",
        "    \"../../Tests_FedGenIA/Padrao_FedGenIA_DML-ICC/mnist_ClassPartitioner_fedavg_fedgenia_trial2/metrics.json\",\n",
        "    \"../../Tests_FedGenIA/Padrao_FedGenIA_DML-ICC/mnist_ClassPartitioner_fedavg_fedgenia_trial3/metrics.json\",\n",
        "\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/nb_100chunks/metrics.json\",\n",
        "\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/mnist_ClassPartitioner_fedavg_fedgenia_trial1/metrics.json\",\n",
        "\n",
        "    \"../../Experimentos/Flwr_run/FedGenIA_F2U/mnist/Class/fedavg/4_clients/metrics.json\",\n",
        "\n",
        "    \"../../Experimentos/Testing_gen_weights/Flwr_run/FedGenIA_F2U/mnist/Class/fedavg/4_clients/metrics.json\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce3233e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "files =[\n",
        "    #FedAvg\n",
        "    \"MNIST/Class/Trial1/metrics_fedavg.json\",\n",
        "    \"CIFAR10/Class/Trial1/metrics_fedavg.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/metrics_fedavg.json\",\n",
        "    \"CIFAR10/Dir05/Trial1/metrics_fedavg.json\",\n",
        "\n",
        "    # Chunked FedAvg\n",
        "    \"MNIST/Class/Trial1/losses_chunked_fedavg.json\",\n",
        "    \"CIFAR10/Class/Trial1/losses_chunked_fedavg.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/losses_chunked_fedavg.json\",\n",
        "    \"CIFAR10/Dir05/Trial1/losses_chunked_fedavg.json\",\n",
        "\n",
        "    \"CIFAR10/Class/Trial1/fedavg_50chunks_metrics.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/fedavg_50chunks_metrics.json\",\n",
        "    #\"CIFAR10/Dir05/Trial1/\n",
        "\n",
        "\n",
        "    # Chunked FedProx\n",
        "    \"MNIST/Class/Trial1/metrics_chunked_fedprox.json\",\n",
        "    \"CIFAR10/Class/Trial1/metrics_chunked_fedprox.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/metrics_chunked_fedprox.json\",\n",
        "    \"CIFAR10/Dir05/Trial1/metrics_chunked_fedprox.json\",\n",
        "\n",
        "    \"CIFAR10/Class/Trial1/fedprox_50chunks_metrics.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/fedprox_50chunks_metrics.json\",\n",
        "    #\"CIFAR10/Dir05/Trial1/metrics_chunked_fedprox.json\",\n",
        "\n",
        "\n",
        "    # Chunked Scaffold\n",
        "    \"MNIST/Class/Trial1/metrics_chunked_scaffold.json\",\n",
        "    \"CIFAR10/Class/Trial1/metrics_chunked_scaffold.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/metrics_chunked_scaffold.json\",\n",
        "    \"CIFAR10/Dir05/Trial1/metrics_chunked_scaffold.json\",\n",
        "\n",
        "    # FedGenIA\n",
        "    \"MNIST/Class/Trial1/metrics.json\",\n",
        "    \"CIFAR10/Class/Trial1/metrics.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/metrics.json\",\n",
        "    #\"CIFAR10/Dir05/Trial1/metrics.json\",\n",
        "    \"CIFAR10/Dir05/Trial2/metrics.json\",\n",
        "\n",
        "    \"CIFAR10/Class/Trial1/fedavg_fedgenia_50chunks_metrics.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/fedgenia_fedavg_50chunks_metrics.json\",\n",
        "\n",
        "\n",
        "    # FedGenIA + FedProx\n",
        "    \"MNIST/Class/Trial1/metrics_fedprox_fedgenia.json\",\n",
        "    \"CIFAR10/Class/Trial1/metrics_fedprox_fedgenia.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/metrics_fedprox_fedgenia.json\",\n",
        "    \"CIFAR10/Dir05/Trial1/metrics_fedprox_fedgenia.json\",\n",
        "\n",
        "    \"CIFAR10/Class/Trial1/fedgenia_fedprox_50chunks_metrics.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/fedgenia_fedprox_50chunks_metrics.json\",\n",
        "\n",
        "\n",
        "    # FedGenIA + Scaffold\n",
        "    \"MNIST/Class/Trial1/metrics_scaffold_fedgenia.json\",\n",
        "    \"CIFAR10/Class/Trial1/metrics_scaffold_fedgenia.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/metrics_scaffold_fedgenia.json\",\n",
        "    \"CIFAR10/Dir05/Trial1/metrics_scaffold_fedgenia.json\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4434eb27",
      "metadata": {},
      "outputs": [],
      "source": [
        "files = [\n",
        "    \"MNIST/Class/Trial1/losses_chunked_fedavg.json\",\n",
        "    \"MNIST/Dir01/Trial1/losses_chunked_fedavg.json\",\n",
        "    \"MNIST/Dir05/Trial1/losses_chunked_fedavg.json\",\n",
        "    \"losses_iid_mnist_chunked_fedavg.json\",\n",
        "    \"CIFAR10/Class/Trial1/losses_chunked_fedavg.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/losses_chunked_fedavg.json\",\n",
        "    \"CIFAR10/Dir05/Trial1/losses_chunked_fedavg.json\",\n",
        "    \"losses_iid_cifar_chunked_fedavg.json\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FaRDCz_cSJDf",
      "metadata": {
        "id": "FaRDCz_cSJDf"
      },
      "outputs": [],
      "source": [
        "files = [\n",
        "    \"MNIST/Class/Trial1/losses.json\",\n",
        "    \"MNIST/Class/Trial2/losses.json\",\n",
        "    \"MNIST/Class/Trial3/losses.json\",\n",
        "    # \"MNIST/Dir01/Trial1/losses.json\",\n",
        "    # \"MNIST/Dir01/Trial2/losses.json\",\n",
        "    # \"MNIST/Dir01/Trial3/losses.json\",\n",
        "    # \"MNIST/Dir05/Trial1/losses.json\",\n",
        "    # \"MNIST/Dir05/Trial2/losses.json\",\n",
        "    # \"MNIST/Dir05/Trial3/losses.json\",\n",
        "    \"CIFAR10/Class/Trial1/losses.json\",\n",
        "    \"CIFAR10/Class/Trial2/losses.json\",\n",
        "    \"CIFAR10/Class/Trial3/losses.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/losses.json\",\n",
        "    \"CIFAR10/Dir01/Trial2/losses.json\",\n",
        "    \"CIFAR10/Dir01/Trial3/losses.json\",\n",
        "    \"CIFAR10/Dir05/Trial1/losses.json\",\n",
        "    \"CIFAR10/Dir05/Trial2/losses.json\",\n",
        "    \"CIFAR10/Dir05/Trial3/losses.json\"\n",
        "]\n",
        "\n",
        "# if IN_COLAB:\n",
        "#   loss_filename = os.path.join(save_dir, loss_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73f49236",
      "metadata": {},
      "source": [
        "### Automatic Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53b8c419",
      "metadata": {},
      "outputs": [],
      "source": [
        "root = Path(\".\")  # or your experiment root\n",
        "files = list(root.glob(\"**/metrics.json\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49537f37",
      "metadata": {
        "id": "49537f37"
      },
      "outputs": [],
      "source": [
        "loaded_dicts = {}\n",
        "\n",
        "for file in files:\n",
        "    try:\n",
        "        with open(file, 'r', encoding='utf-8') as f:\n",
        "            loaded_dicts[str(file).replace(\"/\", \"_\")] = json.load(f)\n",
        "\n",
        "        print(f\"Dictionary successfully loaded from {file}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{file}' not found.\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Could not decode JSON from '{file}'. File might be corrupted or not JSON.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dictionary from JSON: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d24b634",
      "metadata": {
        "id": "8d24b634"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f0588a2",
      "metadata": {
        "id": "8f0588a2"
      },
      "outputs": [],
      "source": [
        "def parse_client_accuracies(log_path):\n",
        "   # Regex to match \"Round X - Cliente Y\" and \"Overall Accuracy:    Z.ZZZZ\"\n",
        "   header_re   = re.compile(r\"Epoch\\s+\\d+\\s*-\\s*Client\\s*(\\d+)\", re.IGNORECASE)\n",
        "   accuracy_re = re.compile(r\"Overall Accuracy:\\s*([\\d.]+)\")\n",
        "\n",
        "\n",
        "   # Now client → list of accuracies\n",
        "   client_accuracies = defaultdict(list)\n",
        "\n",
        "\n",
        "   with open(log_path, 'r', encoding='utf-8') as f:\n",
        "       current_client = None\n",
        "\n",
        "\n",
        "       for line in f:\n",
        "           # Detect the client header\n",
        "           hdr = header_re.search(line)\n",
        "           if hdr:\n",
        "               current_client = int(hdr.group(1))\n",
        "               continue\n",
        "\n",
        "\n",
        "           # Once we see the accuracy line, append and reset\n",
        "           if current_client is not None:\n",
        "               acc = accuracy_re.search(line)\n",
        "               if acc:\n",
        "                   client_accuracies[current_client].append(float(acc.group(1)))\n",
        "                   current_client = None\n",
        "\n",
        "\n",
        "   return dict(client_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f397ca9c",
      "metadata": {
        "id": "f397ca9c"
      },
      "outputs": [],
      "source": [
        "log_files = [\n",
        "    \"CIFAR10/Dir01/Trial1/local_accuracy_report.txt\",\n",
        "    \"CIFAR10/Dir01/Trial1/local_accuracy_report_chunked_fedavg.txt\",\n",
        "    \"CIFAR10/Dir01/Trial1/local_accuracy_report_chunked_fedprox.txt\",\n",
        "    \"CIFAR10/Dir01/Trial1/local_accuracy_report_fedprox_fedgenia.txt\",\n",
        "    \"CIFAR10/Dir01/Trial1/fedavg_50chunks_metrics.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/fedgenia_fedavg_50chunks_metrics.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/fedprox_50chunks_local_accuracy_report.txt\",\n",
        "    \"CIFAR10/Dir01/Trial1/fedgenia_fedprox_50chunks_metrics.json\"\n",
        "]\n",
        "\n",
        "local_acc_dict = {}\n",
        "\n",
        "for file in log_files:\n",
        "    local_acc_dict[file.replace(\"/\", \"_\")] = parse_client_accuracies(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de16e414",
      "metadata": {},
      "source": [
        "## Obter estatisticas dos trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ac6a130",
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee9f0166",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Group dicts by experiment (e.g. MNIST_Class, CIFAR_Dir01, etc.)\n",
        "grouped = defaultdict(list)\n",
        "\n",
        "for key, metrics in loaded_dicts.items():\n",
        "    # Extract experiment part (remove trial name)\n",
        "    # Example: MNIST_Class_Trial1_losses.json → MNIST_Class\n",
        "    parts = key.split(\"_\")\n",
        "    experiment_name = \"_\".join(parts[:-2])  # remove 'TrialX' and 'losses.json'\n",
        "    grouped[experiment_name].append(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91c2c8ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment_stats = {}\n",
        "\n",
        "for exp_name, trials in grouped.items():\n",
        "    stats = {}\n",
        "    metric_keys = trials[0].keys()  # assume all trials share same keys\n",
        "    \n",
        "    for key in metric_keys:\n",
        "        # Stack all trials' metric lists into a numpy array\n",
        "        values = [t[key] for t in trials if len(t[key]) > 0]\n",
        "\n",
        "        if not values:\n",
        "            continue\n",
        "\n",
        "        # Pad shorter lists if needed to align lengths (optional)\n",
        "        min_len = min(len(v) for v in values)\n",
        "        values = [v[:min_len] for v in values]  # truncate to shortest length\n",
        "\n",
        "        arr = np.array(values)  # shape = (num_trials, num_values)\n",
        "        \n",
        "        stats[key] = {\n",
        "            \"mean\": np.mean(arr, axis=0).tolist(),\n",
        "            \"median\": np.median(arr, axis=0).tolist(),\n",
        "            \"std\": np.std(arr, axis=0).tolist()\n",
        "        }\n",
        "\n",
        "    experiment_stats[exp_name] = stats\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b890d518",
      "metadata": {
        "id": "b890d518"
      },
      "source": [
        "## Funcao de plotagem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39493e97",
      "metadata": {
        "id": "39493e97"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import StrMethodFormatter\n",
        "from typing import Mapping, Iterable, Any, Literal, Union, List, Tuple\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c05bff13",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_series(\n",
        "    series: Mapping[str, Iterable[float]],\n",
        "    *,\n",
        "    series_styles: Mapping[str, Mapping[str, Any]] = None,\n",
        "    subplot_groups: List[List[str]] = None,\n",
        "    subplot_layout: Tuple[int, int] = None,\n",
        "    subplot_margins: dict = None,\n",
        "    legend_subplot_index: Union[int, List[int], str] = 'all',\n",
        "    legend_loc: str = 'best',\n",
        "    legend_fontsize: float = 10,\n",
        "    legend_kwargs: Union[Mapping[str, Any], List[Mapping[str, Any]]] = None,\n",
        "    title: Union[str, List[str]] = None,\n",
        "    title_fontsize: float = None,\n",
        "    figure_title: str = None,\n",
        "    figure_title_fontsize: float = 16,\n",
        "    figure_title_y: float = None,\n",
        "    x_ticks: Union[List[float], List[List[float]]] = None,\n",
        "    y_ticks: Union[List[float], List[List[float]]] = None,\n",
        "    xtick_step: Union[int, List[int]] = 1,\n",
        "    xtick_offset: int = 0,\n",
        "    first_step_xtick: Union[int, List[int]] = None,\n",
        "    tick_fontsize: float = None,\n",
        "    num_xticks: Union[int, List[int]] = None,\n",
        "    num_yticks: Union[int, List[int]] = None,\n",
        "    hide_inner_ticks: bool = False,\n",
        "    xlim: Union[tuple[float, float], List[tuple[float, float]]] = None,\n",
        "    ylim: Union[tuple[float, float], List[tuple[float, float]]] = None,\n",
        "    xlabel: Union[str, List[str]] = \"Epochs\",\n",
        "    ylabel: Union[str, List[str]] = \"Value\",\n",
        "    label_fontsize: float = None,\n",
        "    row_labels: List[str] = None,\n",
        "    row_label_fontsize: float = None,\n",
        "    highlight: Mapping[str, Literal[\"max\", \"min\", \"both\"]] = None,\n",
        "    highlight_marker: str = \"o\",\n",
        "    highlight_markersize: float = 4,\n",
        "    highlight_color: str = None,\n",
        "    highlight_text_size: int = 8,\n",
        "    highlight_text_color: str = None,\n",
        "    highlight_arrow_color: str = None,\n",
        "    highlight_arrow_style: str = \"->\",\n",
        "    highlight_arrow_linewidth: float = 1,\n",
        "    highlight_text_offset_max: tuple[float, float] = (0.1, 0.2),\n",
        "    highlight_text_offset_min: tuple[float, float] = (0.1, -0.2),\n",
        "    highlight_style: Mapping[str, Mapping[str, Any]] = None,\n",
        "    figsize: tuple[float, float] = (10, 5),\n",
        "    hspace: float = None,\n",
        "    vspace: float = None,\n",
        "    save: bool = False,\n",
        "    plot_name: str = \"plot.pdf\",\n",
        "    level_markers: Union[dict, List[dict]] = None,\n",
        ") -> None:\n",
        "    if subplot_groups is None:\n",
        "        subplot_groups = [list(series.keys())]\n",
        "\n",
        "    num_plots = len(subplot_groups)\n",
        "\n",
        "    nrows, ncols = 0, 0\n",
        "    if subplot_layout:\n",
        "        nrows, ncols = subplot_layout\n",
        "        if nrows * ncols < num_plots:\n",
        "            raise ValueError(f\"Layout {subplot_layout} is too small for {num_plots} groups.\")\n",
        "    else:\n",
        "        nrows, ncols = num_plots, 1\n",
        "\n",
        "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize, squeeze=False)\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    # def get_setting(value, index):\n",
        "    #     if isinstance(value, list):\n",
        "    #         return value[index] if index < len(value) else None\n",
        "    #     return value\n",
        "    \n",
        "    def get_setting(value, index):\n",
        "        if isinstance(value, list):\n",
        "            \n",
        "            # Logic for x_ticks and y_ticks specifically:\n",
        "            if value is x_ticks or value is y_ticks:\n",
        "                if len(value) > 0 and isinstance(value[0], list):\n",
        "                    # It is a List[List], return the specific list for this index\n",
        "                    return value[index] if index < len(value) else None\n",
        "                else:\n",
        "                    # It is a List[float], return the whole list for every subplot\n",
        "                    return value\n",
        "            \n",
        "            # Default behavior for other scalar lists (titles, limits, etc.)\n",
        "            return value[index] if index < len(value) else None\n",
        "        return value\n",
        "\n",
        "    for i, (ax, group) in enumerate(zip(axes, subplot_groups)):\n",
        "\n",
        "        row = i // ncols\n",
        "        col = i % ncols\n",
        "        is_bottom_row = (row == nrows - 1)\n",
        "        is_left_col = (col == 0)\n",
        "\n",
        "        n = 0\n",
        "        if group:\n",
        "            n = max(len(series.get(name, [])) for name in group)\n",
        "\n",
        "        for name in group:\n",
        "            if name not in series:\n",
        "                continue\n",
        "            ys = series[name]\n",
        "            # xs = x_values.get(name, range(len(ys))) if x_values else range(len(ys))\n",
        "            xs = range(len(ys)) # Default\n",
        "\n",
        "            raw_style = series_styles.get(name, {}) if series_styles else {}\n",
        "            style = raw_style.copy()\n",
        "            plot_label = style.pop('label', name)\n",
        "\n",
        "            line, = ax.plot(xs, ys, label=plot_label, **style)\n",
        "            \n",
        "            # line, = ax.plot(xs, ys, label=name, **style)\n",
        "            mode = highlight.get(name) if highlight else None\n",
        "            base_color = style.get('color', line.get_color())\n",
        "            mcolor = highlight_color or base_color\n",
        "\n",
        "            current_highlight_style = highlight_style.get(name, {}) if highlight_style else {}\n",
        "\n",
        "            if mode in (\"max\", \"both\"):\n",
        "                i_max = max(range(len(ys)), key=lambda j: ys[j])\n",
        "                x_coord_max = xs[i_max] if hasattr(xs, '__getitem__') else list(xs)[i_max]\n",
        "                ax.plot(i_max, ys[i_max], marker=highlight_marker, markersize=highlight_markersize, color=mcolor)\n",
        "                offset = current_highlight_style.get('highlight_offset_max', highlight_text_offset_max)\n",
        "                text_position = (i_max + offset[0], ys[i_max] + offset[1])\n",
        "                arrow_color = current_highlight_style.get('arrow_color', highlight_arrow_color or 'dimgrey')\n",
        "                arrow_style = current_highlight_style.get('arrow_style', highlight_arrow_style)\n",
        "                arrow_width = current_highlight_style.get('arrow_linewidth', highlight_arrow_linewidth)\n",
        "                text_color = current_highlight_style.get('text_color', highlight_text_color or 'black')\n",
        "                ax.annotate(f\"{ys[i_max]:.2f}\",\n",
        "                            xy=(i_max, ys[i_max]), \n",
        "                            xytext=text_position,\n",
        "                            arrowprops=dict(arrowstyle=arrow_style, color=arrow_color, linewidth=arrow_width),\n",
        "                            fontsize=highlight_text_size, \n",
        "                            color=text_color,\n",
        "                            va=\"bottom\", \n",
        "                            ha=\"center\")\n",
        "\n",
        "            if mode in (\"min\", \"both\"):\n",
        "                i_min = min(range(len(ys)), key=lambda j: ys[j])\n",
        "                ax.plot(i_min, ys[i_min], marker=highlight_marker, markersize=highlight_markersize, color=mcolor)\n",
        "                offset = current_highlight_style.get('highlight_offset_min', highlight_text_offset_min)\n",
        "                text_position = (i_min + offset[0], ys[i_min] + offset[1])\n",
        "                arrow_color = current_highlight_style.get('arrow_color', highlight_arrow_color or 'dimgrey')\n",
        "                arrow_style = current_highlight_style.get('arrow_style', highlight_arrow_style)\n",
        "                arrow_width = current_highlight_style.get('arrow_linewidth', highlight_arrow_linewidth)\n",
        "                text_color = current_highlight_style.get('text_color', highlight_text_color or 'black')\n",
        "                ax.annotate(f\"{ys[i_min]:.2f}\", \n",
        "                            xy=(i_min, ys[i_min]), \n",
        "                            xytext=text_position,\n",
        "                            arrowprops=dict(arrowstyle=arrow_style, color=arrow_color, linewidth=arrow_width),\n",
        "                            fontsize=highlight_text_size,\n",
        "                            color=text_color,\n",
        "                            va=\"top\", \n",
        "                            ha=\"center\")\n",
        "\n",
        "        if n > 0:\n",
        "            current_num_yticks = get_setting(num_yticks, i)\n",
        "            current_y_ticks = get_setting(y_ticks, i)\n",
        "\n",
        "            current_num_xticks = get_setting(num_xticks, i)\n",
        "            current_x_ticks = get_setting(x_ticks, i)\n",
        "\n",
        "            current_first_step_xtick = get_setting(first_step_xtick, i)\n",
        "            current_xtick_step = get_setting(xtick_step, i)\n",
        "\n",
        "            if current_num_yticks or current_y_ticks:\n",
        "                if current_num_yticks:\n",
        "                    # Determine the range for tick calculation\n",
        "                    current_ylim = get_setting(ylim, i)\n",
        "                    if current_ylim:\n",
        "                        # Base ticks on the specified limits\n",
        "                        min_y, max_y = current_ylim\n",
        "                    else:\n",
        "                        # Find the range across all series in this specific group\n",
        "                        min_y = float('inf')\n",
        "                        max_y = float('-inf')\n",
        "                        for name in group:\n",
        "                            if name in series and len(series[name]) > 0:\n",
        "                                min_y = min(min_y, min(series[name]))\n",
        "                                max_y = max(max_y, max(series[name]))\n",
        "\n",
        "                        # Ensure we have a reasonable range\n",
        "                        if min_y == float('inf') or max_y == float('-inf'):\n",
        "                            min_y, max_y = 0, 1.0\n",
        "                        \n",
        "                        # Optional: round the range for cleaner ticks\n",
        "                        min_y = math.floor(min_y * 10) / 10\n",
        "                        max_y = math.ceil(max_y * 10) / 10\n",
        "\n",
        "                    yticks = np.linspace(min_y, max_y, current_num_yticks)\n",
        "\n",
        "                    yticks = np.unique(yticks)\n",
        "                else:\n",
        "                    yticks = current_y_ticks\n",
        "                ax.set_yticks(yticks)\n",
        "                ax.yaxis.set_major_formatter(StrMethodFormatter('{x:.2f}'))\n",
        "\n",
        "            if current_x_ticks is not None:\n",
        "                # If explicit ticks are provided, they take precedence\n",
        "                ax.set_xticks(current_x_ticks)\n",
        "            elif current_num_xticks:\n",
        "                xticks = np.linspace(1, n, current_num_xticks)\n",
        "                ax.set_xticks(xticks.astype(int))\n",
        "            elif current_first_step_xtick is not None:\n",
        "                labels = [1]\n",
        "                # Use the per-subplot step, falling back to the default of 1 if not specified\n",
        "                step = current_xtick_step if current_xtick_step is not None else 1\n",
        "                next_label = 1 + current_first_step_xtick\n",
        "                while next_label <= n:\n",
        "                    labels.append(next_label)\n",
        "                    next_label += step\n",
        "                positions = [lbl - 1 for lbl in labels]\n",
        "                labels = [lbl + xtick_offset for lbl in labels]\n",
        "                ax.set_xticks(positions, labels)\n",
        "            elif current_xtick_step is not None and current_xtick_step > 0:\n",
        "                positions = list(range(0, n, current_xtick_step))\n",
        "                labels = [pos + 1 + xtick_offset for pos in positions]\n",
        "                ax.set_xticks(positions, labels)\n",
        "            \n",
        "        if hide_inner_ticks:\n",
        "            if not is_bottom_row:\n",
        "                ax.set_xticklabels([])\n",
        "            if not is_left_col:\n",
        "                ax.set_yticklabels([])\n",
        "\n",
        "        if num_xticks and xtick_offset != 0 and n > 0 and x_ticks is None:\n",
        "            fig.canvas.draw()\n",
        "            current_ticks = ax.get_xticks()\n",
        "            new_labels = [int(tick) + xtick_offset for tick in current_ticks]\n",
        "            ax.set_xticklabels(new_labels)\n",
        "\n",
        "        if tick_fontsize:\n",
        "            ax.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
        "\n",
        "        # X Label\n",
        "        x_text = get_setting(xlabel, i)\n",
        "        if isinstance(xlabel, list):\n",
        "            ax.set_xlabel(x_text, fontsize=label_fontsize)\n",
        "        elif is_bottom_row:\n",
        "            ax.set_xlabel(x_text, fontsize=label_fontsize)\n",
        "\n",
        "        # Y Label\n",
        "        y_text = get_setting(ylabel, i)\n",
        "        if isinstance(ylabel, list):\n",
        "            ax.set_ylabel(y_text, fontsize=label_fontsize)\n",
        "        elif is_left_col:\n",
        "            ax.set_ylabel(y_text, fontsize=label_fontsize)\n",
        "\n",
        "        # Title\n",
        "        ax.set_title(get_setting(title, i), fontsize=title_fontsize)\n",
        "\n",
        "        show_legend = False\n",
        "        if legend_subplot_index == 'all':\n",
        "            show_legend = True\n",
        "        elif isinstance(legend_subplot_index, list):\n",
        "            if i in legend_subplot_index:\n",
        "                show_legend = True\n",
        "        elif i == legend_subplot_index:\n",
        "            show_legend = True\n",
        "        \n",
        "        if show_legend:\n",
        "            base_kwargs = {'loc': legend_loc, 'fontsize': legend_fontsize}\n",
        "            current_kwargs = get_setting(legend_kwargs, i)\n",
        "            if current_kwargs:\n",
        "                base_kwargs.update(current_kwargs)\n",
        "            ax.legend(**base_kwargs)\n",
        "\n",
        "        current_xlim = get_setting(xlim, i)\n",
        "        if current_xlim:\n",
        "            ax.set_xlim(*current_xlim)\n",
        "        elif n > 0:\n",
        "            # Set a sensible default xlim based on data\n",
        "            if x_ticks and not isinstance(x_ticks, dict):\n",
        "                 ax.set_xlim(min(x_ticks), max(x_ticks))\n",
        "            else:\n",
        "                 ax.set_xlim(0, n)\n",
        "\n",
        "            #ax.set_xlim(0, n)\n",
        "        current_ylim = get_setting(ylim, i)\n",
        "        if current_ylim:\n",
        "            ax.set_ylim(*current_ylim)\n",
        "\n",
        "        if row_labels and (col == ncols - 1):\n",
        "            # Check if we have a label for this specific row\n",
        "            if row < len(row_labels) and row_labels[row]:\n",
        "                ax.text(\n",
        "                    1.05, 0.5, row_labels[row],  # x=1.05 (slightly outside right), y=0.5 (center)\n",
        "                    transform=ax.transAxes,      # Coordinates relative to the subplot\n",
        "                    rotation=270,                # Vertical rotation\n",
        "                    ha='left', \n",
        "                    va='center',\n",
        "                    fontsize=row_label_fontsize,\n",
        "                    fontweight='bold'            # Optional: make it bold to distinguish from data\n",
        "                )\n",
        "\n",
        "        current_markers = get_setting(level_markers, i)\n",
        "\n",
        "        if current_markers:\n",
        "            for label, x_pos in current_markers.items():\n",
        "                ax.axvline(\n",
        "                    x=x_pos, \n",
        "                    color='gray', \n",
        "                    linestyle='--', \n",
        "                    linewidth=2, \n",
        "                    alpha=0.8,\n",
        "                    zorder=0 \n",
        "                )\n",
        "\n",
        "                ax.text(\n",
        "                    x=x_pos, \n",
        "                    y=0.05, \n",
        "                    s=label, \n",
        "                    transform=ax.get_xaxis_transform(), \n",
        "                    rotation=90,      \n",
        "                    ha='right',       \n",
        "                    va='bottom',\n",
        "                    fontsize=18,\n",
        "                    color='dimgrey',\n",
        "                    fontweight='bold'\n",
        "                )\n",
        "\n",
        "    if figure_title:\n",
        "        fig.suptitle(\n",
        "            figure_title, \n",
        "            fontsize=figure_title_fontsize,\n",
        "            y=figure_title_y or 0.98 # Default to slightly near the top\n",
        "        )\n",
        "\n",
        "    for j in range(num_plots, len(axes)):\n",
        "        axes[j].set_visible(False)\n",
        "\n",
        "    if hspace is not None or vspace is not None or subplot_margins:\n",
        "        margins = subplot_margins or {}\n",
        "        plt.subplots_adjust(\n",
        "            hspace=hspace or 0.3,  # Default horizontal spacing\n",
        "            wspace=vspace or 0.2,  # Default vertical spacing\n",
        "            left=margins.get('left', 0.1),\n",
        "            right=margins.get('right', 0.9),\n",
        "            top=margins.get('top', 0.9),\n",
        "            bottom=margins.get('bottom', 0.1)\n",
        "        )\n",
        "    else:\n",
        "        fig.tight_layout()\n",
        "\n",
        "    if save:\n",
        "        print(f\"Saving plot to {plot_name}\")\n",
        "        plt.savefig(plot_name)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "febb881b",
      "metadata": {},
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7df4d40",
      "metadata": {},
      "source": [
        "### Loss e Acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a663f1c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "  series = {\n",
        "      \"Class Loss Trial 1\": loaded_dict_mnist_class[\"net_loss_round\"],\n",
        "      \"Class Accuracy Trial 1\": loaded_dict_mnist_class[\"net_acc_round\"],\n",
        "      \"Dir01 Loss Trial 1\": loaded_dict_mnist_dir01[\"net_loss_round\"],\n",
        "      \"Dir01 Accuracy Trial 1\": loaded_dict_mnist_dir01[\"net_acc_round\"],\n",
        "      \"Dir05 Loss Trial 1\": loaded_dict_mnist_dir05[\"net_loss_round\"],\n",
        "      \"Dir05 Accuracy Trial 1\": loaded_dict_mnist_dir05[\"net_acc_round\"],\n",
        "      \"Class Loss Trial 2\": loaded_dict_mnist_class_trial2[\"net_loss_round\"],\n",
        "      \"Class Accuracy Trial 2\": loaded_dict_mnist_class_trial2[\"net_acc_round\"],\n",
        "      \"Dir01 Loss Trial 2\": loaded_dict_mnist_dir01_trial2[\"net_loss_round\"],\n",
        "      \"Dir01 Accuracy Trial 2\": loaded_dict_mnist_dir01_trial2[\"net_acc_round\"],\n",
        "      \"Dir05 Loss Trial 2\": loaded_dict_mnist_dir05_trial2[\"net_loss_round\"],\n",
        "      \"Dir05 Accuracy Trial 2\": loaded_dict_mnist_dir05_trial2[\"net_acc_round\"],\n",
        "  },\n",
        "  series_styles={\n",
        "      \"Class Loss Trial 1\": {\"color\": \"blue\", \"linestyle\": \"-\"},\n",
        "      \"Class Accuracy Trial 1\": {\"color\": \"blue\", \"linestyle\": \"--\"},\n",
        "      \"Dir01 Loss Trial 1\": {\"color\": \"orange\", \"linestyle\": \"-\"},\n",
        "      \"Dir01 Accuracy Trial 1\": {\"color\": \"orange\", \"linestyle\": \"--\"},\n",
        "      \"Dir05 Loss Trial 1\": {\"color\": \"green\", \"linestyle\": \"-\"},\n",
        "      \"Dir05 Accuracy Trial 1\": {\"color\": \"green\", \"linestyle\": \"--\"},\n",
        "      \"Class Loss Trial 2\": {\"color\": \"lightblue\", \"linestyle\": \"-\"},\n",
        "      \"Class Accuracy Trial 2\": {\"color\": \"lightblue\", \"linestyle\": \"--\"},\n",
        "      \"Dir01 Loss Trial 2\": {\"color\": \"yellow\", \"linestyle\": \"-\"},\n",
        "      \"Dir01 Accuracy Trial 2\": {\"color\": \"yellow\", \"linestyle\": \"--\"},\n",
        "      \"Dir05 Loss Trial 2\": {\"color\": \"lightgreen\", \"linestyle\": \"-\"},\n",
        "      \"Dir05 Accuracy Trial 2\": {\"color\": \"lightgreen\", \"linestyle\": \"--\"},\n",
        "  },\n",
        "  highlight = {\n",
        "      \"Accuracy\": \"max\"\n",
        "  },\n",
        "  highlight_markersize=4,\n",
        "  xtick_step=5,\n",
        "  first_step=4,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28b0d95c",
      "metadata": {},
      "source": [
        "### Local Acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "209bd071",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series = {\n",
        "        # \"Global - Chunked FedAvg\": loaded_dict_cifar_mnist[\"net_acc_round\"][:100],\n",
        "        # \"Global - FedGenIA\": loaded_dict_cifar_mnist_gerafed[\"net_acc_round\"][:100],\n",
        "\n",
        "        \"Client 0 - Chunked FedAvg\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_chunked_fedavg.txt\"][0],\n",
        "        \"Client 0 - Chunked FedProx\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_chunked_fedprox.txt\"][0],\n",
        "        \"Client 0 - FedGenIA\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report.txt\"][0],\n",
        "        \"Client 0 - FedGenIA + FedProx\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_fedprox_fedgenia.txt\"][0],\n",
        "\n",
        "        \"Client 1 - Chunked FedAvg\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_chunked_fedavg.txt\"][1],\n",
        "        \"Client 1 - Chunked FedProx\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_chunked_fedprox.txt\"][1],\n",
        "        \"Client 1 - FedGenIA\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report.txt\"][1],\n",
        "        \"Client 1 - FedGenIA + FedProx\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_fedprox_fedgenia.txt\"][1],\n",
        "\n",
        "        \"Chunked FedAvg\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_chunked_fedavg.txt\"][2],\n",
        "        \"Chunked FedProx\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_chunked_fedprox.txt\"][2],\n",
        "        \"FedGenIA\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report.txt\"][2],\n",
        "        \"FedGenIA + FedProx\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_fedprox_fedgenia.txt\"][2],\n",
        "\n",
        "        \"Client 3 - Chunked FedAvg\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_chunked_fedavg.txt\"][3],\n",
        "        \"Client 3 - Chunked FedProx\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_chunked_fedprox.txt\"][3],\n",
        "        \"Client 3 - FedGenIA\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report.txt\"][3],\n",
        "        \"Client 3 - FedGenIA + FedProx\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_fedprox_fedgenia.txt\"][3],\n",
        "    },\n",
        "    series_styles = {\n",
        "        # \"Global - Chunked FedAvg\": {\"color\": \"lightblue\", \"linestyle\": \"-\"},\n",
        "        # \"Global - FedGenIA\": {\"color\": \"lightblue\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Client 0 - Chunked FedAvg\": {\"color\": \"cornflowerblue\", \"linestyle\": \"-\"},\n",
        "        \"Client 0 - Chunked FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"-\"},\n",
        "        \"Client 0 - FedGenIA\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"Client 0 - FedGenIA + FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Client 1 - Chunked FedAvg\": {\"color\": \"cornflowerblue\", \"linestyle\": \"-\"},\n",
        "        \"Client 1 - Chunked FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"-\"},\n",
        "        \"Client 1 - FedGenIA\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"Client 1 - FedGenIA + FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Chunked FedAvg\": {\"color\": \"cornflowerblue\", \"linestyle\": \"-\"},\n",
        "        \"Chunked FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"-\"},\n",
        "        \"FedGenIA\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"FedGenIA + FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Client 3 - Chunked FedAvg\": {\"color\": \"cornflowerblue\", \"linestyle\": \"-\"},\n",
        "        \"Client 3 - Chunked FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"-\"},\n",
        "        \"Client 3 - FedGenIA\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"Client 3 - FedGenIA + FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "    },\n",
        "    subplot_groups=[\n",
        "        [\"Client 0 - Chunked FedAvg\", \"Client 0 - Chunked FedProx\", \"Client 0 - FedGenIA\", \"Client 0 - FedGenIA + FedProx\"],\n",
        "        [\"Client 1 - Chunked FedAvg\", \"Client 1 - Chunked FedProx\", \"Client 1 - FedGenIA\", \"Client 1 - FedGenIA + FedProx\"],\n",
        "        [\"Chunked FedAvg\", \"Chunked FedProx\", \"FedGenIA\", \"FedGenIA + FedProx\"],\n",
        "        [\"Client 3 - Chunked FedAvg\", \"Client 3 - Chunked FedProx\", \"Client 3 - FedGenIA\", \"Client 3 - FedGenIA + FedProx\"]\n",
        "    ],\n",
        "    highlight={\n",
        "    #    \"Global - Chunked FedAvg\": \"max\",\n",
        "    #     \"Global - FedGenIA\": \"max\",\n",
        "\n",
        "        \"Client 0 - Chunked FedAvg\": \"max\",\n",
        "        \"Client 0 - Chunked FedProx\": \"max\",\n",
        "        \"Client 0 - FedGenIA\": \"max\",\n",
        "        \"Client 0 - FedGenIA + FedProx\": \"max\",\n",
        "\n",
        "        \"Client 1 - Chunked FedAvg\": \"max\",\n",
        "        \"Client 1 - Chunked FedProx\": \"max\",\n",
        "        \"Client 1 - FedGenIA\": \"max\",\n",
        "        \"Client 1 - FedGenIA + FedProx\": \"max\",\n",
        "\n",
        "        \"Chunked FedAvg\": \"max\",\n",
        "        \"Chunked FedProx\": \"max\",\n",
        "        \"FedGenIA\": \"max\",\n",
        "        \"FedGenIA + FedProx\": \"max\",\n",
        "\n",
        "        \"Client 3 - Chunked FedAvg\": \"max\",\n",
        "        \"Client 3 - Chunked FedProx\": \"max\",\n",
        "        \"Client 3 - FedGenIA\": \"max\",\n",
        "        \"Client 3 - FedGenIA + FedProx\": \"max\",\n",
        "    },\n",
        "    subplot_layout=(1,4),\n",
        "    figsize=(20, 2.65),\n",
        "    label_fontsize=16,\n",
        "    tick_fontsize=15,\n",
        "    highlight_markersize=6,\n",
        "    num_xticks=5,\n",
        "    num_yticks=[0,0,0,3,],\n",
        "    y_ticks=[[0,0.4,0.75], [0,0.4,0.75], [0.1,0.4,0.65], None],\n",
        "    ylim=[(0,0.75),(0,0.75),(0.1,0.65),(0,0.6)],\n",
        "    ylabel= [\"Accuracy\",\"\",\"\",\"\"],\n",
        "    highlight_text_size=15,\n",
        "    legend_subplot_index=2,\n",
        "    legend_fontsize=11.6,\n",
        "    legend_kwargs={\n",
        "        \"ncol\": 2,\n",
        "        \"columnspacing\": 0.6,\n",
        "        \"handletextpad\": 0.2,\n",
        "        \"borderpad\": 0.2,\n",
        "        \"bbox_to_anchor\": (0.024, 0.33),\n",
        "        \"handlelength\": 1,\n",
        "        \"labelspacing\": 0.3\n",
        "    },\n",
        "    title_fontsize=18,\n",
        "    title=[\"a) Client 0\", \"b) Client 1\", \"c) Client 2\", \"d) Client 3\"],\n",
        "    save=True,\n",
        "    plot_name=\"../figures/local_acc.pdf\",\n",
        "    highlight_style={\n",
        "        # \"Global - Chunked FedAvg\": {\"color\": \"blue\"},\n",
        "        # \"Global - FedGenIA\": {\"color\": \"blue\"},\n",
        "\n",
        "        \"Client 0 - Chunked FedAvg\": {\"highlight_offset_max\": (-16, 0.01)},\n",
        "        \"Client 0 - Chunked FedProx\": {\"highlight_offset_max\": (0, -0.3)},\n",
        "        \"Client 0 - FedGenIA\": {\"highlight_offset_max\": (-20, -0.5)},\n",
        "        \"Client 0 - FedGenIA + FedProx\": {\"highlight_offset_max\": (-40, -0.05)},\n",
        "\n",
        "        \"Client 1 - Chunked FedAvg\": {\"highlight_offset_max\": (0, 0.06)},\n",
        "        \"Client 1 - Chunked FedProx\": {\"highlight_offset_max\": (-17, 0)},\n",
        "        \"Client 1 - FedGenIA\": {\"highlight_offset_max\": (0, -0.45)},\n",
        "        \"Client 1 - FedGenIA + FedProx\": {\"highlight_offset_max\": (-15, -0.05)},\n",
        "\n",
        "        \"Chunked FedAvg\": {\"highlight_offset_max\": (10, -0.25)},\n",
        "        \"Chunked FedProx\": {\"highlight_offset_max\": (20, -0.3)},\n",
        "        \"FedGenIA\": {\"highlight_offset_max\": (0, -0.24)},\n",
        "        \"FedGenIA + FedProx\": {\"highlight_offset_max\": (17, -0.21)},\n",
        "\n",
        "        \"Client 3 - Chunked FedAvg\": {\"highlight_offset_max\": (-15, -0.14)},\n",
        "        \"Client 3 - Chunked FedProx\": {\"highlight_offset_max\": (-25, 0.14)},\n",
        "        \"Client 3 - FedGenIA\": {\"highlight_offset_max\": (-10, -0.25)},\n",
        "        \"Client 3 - FedGenIA + FedProx\": {\"highlight_offset_max\": (-15, 0.02)},\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8952ba7e",
      "metadata": {},
      "source": [
        "### Different distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf794d8a",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series={\n",
        "        \"IID\": loaded_dicts[\"losses_iid_mnist_chunked_fedavg.json\"][\"net_acc_round\"],\n",
        "        \"Dir05\": loaded_dicts[\"MNIST_Dir05_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"],\n",
        "        \"Dir01\": loaded_dicts[\"MNIST_Dir01_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"][:100],\n",
        "        \"Class\": loaded_dicts[\"MNIST_Class_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"][:100],\n",
        "        \"IID cifar\": loaded_dicts[\"losses_iid_cifar_chunked_fedavg.json\"][\"net_acc_round\"],\n",
        "        \"Dir05 cifar\": loaded_dicts[\"CIFAR10_Dir05_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"],\n",
        "        \"Dir01 cifar\": loaded_dicts[\"CIFAR10_Dir01_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"][:100],\n",
        "        \"Class cifar\": loaded_dicts[\"CIFAR10_Class_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"][:100],\n",
        "    },\n",
        "    subplot_groups=[\n",
        "        [\"IID\", \"Dir05\", \"Dir01\", \"Class\"]\n",
        "        ,[\"IID cifar\", \"Dir05 cifar\", \"Dir01 cifar\", \"Class cifar\"],\n",
        "    ],\n",
        "    legend_subplot_index=0,\n",
        "    title=[\"a) MNIST\", \"b) CIFAR-10\"],\n",
        "    title_fontsize=20,\n",
        "    highlight={\n",
        "        \"IID\": \"max\",\n",
        "        \"Dir05\": \"max\",\n",
        "        \"Dir01\": \"max\",\n",
        "        \"Class\": \"max\",\n",
        "        \"IID cifar\": \"max\",\n",
        "        \"Dir05 cifar\": \"max\",\n",
        "        \"Dir01 cifar\": \"max\",\n",
        "        \"Class cifar\": \"max\",\n",
        "    },\n",
        "    highlight_style={\n",
        "        \"IID\": {\"highlight_offset_max\": (5, -0.07)},\n",
        "        \"Dir05\": {\"highlight_offset_max\": (5, -0.081)},\n",
        "        \"Dir01\": {\"highlight_offset_max\": (-5, -0.069)},\n",
        "        \"Class\": {\"highlight_offset_max\": (5, -0.25)},\n",
        "        \"IID cifar\": {\"highlight_offset_max\": (-5, -0.2)},\n",
        "        \"Dir05 cifar\": {\"highlight_offset_max\": (0, -0.16)},\n",
        "        \"Dir01 cifar\": {\"highlight_offset_max\": (5, 0.07)},\n",
        "        \"Class cifar\": {\"highlight_offset_max\": (10, -0.04)},\n",
        "     }, \n",
        "    highlight_markersize=8,\n",
        "    xtick_step=5,\n",
        "    num_yticks=[3,3],\n",
        "    #y_ticks=[[0,0.5,1], [0.2,0.45,0.65]],\n",
        "    first_step=4,\n",
        "    ylabel=\"Accuracy\",\n",
        "    figsize=(15, 5.9),\n",
        "    highlight_text_size=20,\n",
        "    tick_fontsize=20,\n",
        "    label_fontsize=20,\n",
        "    legend_fontsize=18,\n",
        "    legend_kwargs={\n",
        "        \"ncol\": 2,\n",
        "        \"columnspacing\": 1,\n",
        "        \"handletextpad\": 0.5,\n",
        "        \"borderpad\": 0.2,\n",
        "        \"bbox_to_anchor\": (0.014, 0.5),\n",
        "        \"handlelength\": 2,\n",
        "        \"labelspacing\": 0.5\n",
        "    },\n",
        "    save=True,\n",
        "    plot_name=\"../figures/ACC_alvo.pdf\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7a1f8ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "losses = [\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/nb_losses/d_loss_c0_r0.json\",\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/nb_losses/d_loss_c1_r0.json\",\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/nb_losses/d_loss_c2_r0.json\",\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/nb_losses/d_loss_c3_r0.json\",\n",
        "\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/flwr_losses_depois/d_losses_c0_r1.json\",\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/flwr_losses_depois/d_losses_c1_r1.json\",\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/flwr_losses_depois/d_losses_c2_r1.json\",\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/flwr_losses_depois/d_losses_c3_r1.json\",\n",
        "\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/d_loss_c1_r1.json\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89162806",
      "metadata": {},
      "outputs": [],
      "source": [
        "losses_dict = {}\n",
        "for file in losses:\n",
        "    with open(file, \"r\") as f:\n",
        "        losses_dict[file.replace(\"/\", \"_\")] = json.load(f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc847093",
      "metadata": {},
      "source": [
        "### GAN loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2181e9a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series={\n",
        "        \"c0_flwr\": losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_flwr_losses_depois_d_losses_c0_r1.json\"],\n",
        "        \"c1_flwr\": losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_flwr_losses_depois_d_losses_c1_r1.json\"],\n",
        "        \"c2_flwr\": losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_flwr_losses_depois_d_losses_c2_r1.json\"],\n",
        "        \"c3_flwr\": losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_flwr_losses_depois_d_losses_c3_r1.json\"],\n",
        "        \"c0_nb\": losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_losses_d_loss_c0_r0.json\"],\n",
        "        \"c1_nb\": losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_losses_d_loss_c1_r0.json\"],\n",
        "        \"c2_nb\": losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_losses_d_loss_c2_r0.json\"],\n",
        "        \"c3_nb\": losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_losses_d_loss_c3_r0.json\"],\n",
        "\n",
        "        \"c1_flwr_new\": losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_d_loss_c1_r1.json\"],\n",
        "\n",
        "        \"c0_flwr_mean\": [np.mean(losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_flwr_losses_depois_d_losses_c0_r1.json\"])]*156,\n",
        "        \"c1_flwr_mean\": [np.mean(losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_flwr_losses_depois_d_losses_c1_r1.json\"])]*156,\n",
        "        \"c2_flwr_mean\": [np.mean(losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_flwr_losses_depois_d_losses_c2_r1.json\"])]*156,\n",
        "        \"c3_flwr_mean\": [np.mean(losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_flwr_losses_depois_d_losses_c3_r1.json\"])]*156,\n",
        "        \"c0_nb_mean\": [np.mean(losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_losses_d_loss_c0_r0.json\"])]*156,\n",
        "        \"c1_nb_mean\": [np.mean(losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_losses_d_loss_c1_r0.json\"])]*156,\n",
        "        \"c2_nb_mean\": [np.mean(losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_losses_d_loss_c2_r0.json\"])]*156,\n",
        "        \"c3_nb_mean\": [np.mean(losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_losses_d_loss_c3_r0.json\"])]*156,\n",
        "\n",
        "        \"c1_flwr_new\": [np.mean(losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_d_loss_c1_r1.json\"])]*156,\n",
        "\n",
        "    },\n",
        "    series_styles={\n",
        "        \"c0_flwr\": {\"color\": \"blue\", \"linestyle\": \"-\"},\n",
        "        \"c1_flwr\": {\"color\": \"green\", \"linestyle\": \"-\"},\n",
        "        \"c2_flwr\": {\"color\": \"yellow\", \"linestyle\": \"-\"},\n",
        "        \"c3_flwr\": {\"color\": \"red\", \"linestyle\": \"-\"},\n",
        "        \"c0_nb\": {\"color\": \"blue\", \"linestyle\": \"--\"},\n",
        "        \"c1_nb\": {\"color\": \"green\", \"linestyle\": \"--\"},\n",
        "        \"c2_nb\": {\"color\": \"yellow\", \"linestyle\": \"--\"},\n",
        "        \"c3_nb\": {\"color\": \"red\", \"linestyle\": \"--\"},\n",
        "        \"c1_flwr_new\": {\"color\": \"black\"},\n",
        "\n",
        "        \"c0_flwr_mean\": {\"color\": \"blue\", \"linestyle\": \"-\"},\n",
        "        \"c1_flwr_mean\": {\"color\": \"green\", \"linestyle\": \"-\"},\n",
        "        \"c2_flwr_mean\": {\"color\": \"yellow\", \"linestyle\": \"-\"},\n",
        "        \"c3_flwr_mean\": {\"color\": \"red\", \"linestyle\": \"-\"},\n",
        "        \"c0_nb_mean\": {\"color\": \"blue\", \"linestyle\": \"--\"},\n",
        "        \"c1_nb_mean\": {\"color\": \"green\", \"linestyle\": \"--\"},\n",
        "        \"c2_nb_mean\": {\"color\": \"yellow\", \"linestyle\": \"--\"},\n",
        "        \"c3_nb_mean\": {\"color\": \"red\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"c1_flwr_new_mean\": {\"color\": \"black\"}\n",
        "    },\n",
        "    num_xticks=20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17fca7c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series={\n",
        "        \"G_1_flwr\": loaded_dicts[\".._.._Experimentos_Flwr_run_FedGenIA_F2U_mnist_Class_fedavg_4_clients_metrics.json\"][\"g_loss_chunk\"],\n",
        "        \"D_1_flwr\": loaded_dicts[\".._.._Experimentos_Flwr_run_FedGenIA_F2U_mnist_Class_fedavg_4_clients_metrics.json\"][\"d_loss_chunk\"],\n",
        "\n",
        "        \"G_nb_new\": loaded_dicts[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_100chunks_metrics.json\"][\"g_losses_chunk\"],\n",
        "        \"D_nb_new\": loaded_dicts[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_100chunks_metrics.json\"][\"d_losses_chunk\"],\n",
        "\n",
        "        \"G_flwr_genwgt\": loaded_dicts[\".._.._Experimentos_Testing_gen_weights_Flwr_run_FedGenIA_F2U_mnist_Class_fedavg_4_clients_metrics.json\"][\"g_loss_chunk\"],\n",
        "        \"D_flwr_genwgt\": loaded_dicts[\".._.._Experimentos_Testing_gen_weights_Flwr_run_FedGenIA_F2U_mnist_Class_fedavg_4_clients_metrics.json\"][\"d_loss_chunk\"],\n",
        "\n",
        "        \"G_nb_genwgt\": loaded_dicts[\".._.._Tests_FedGenIA_Teste_pesos_exatos_mnist_ClassPartitioner_fedavg_fedgenia_trial1_metrics.json\"][\"g_losses_chunk\"],\n",
        "        \"D_nb_genwgt\": loaded_dicts[\".._.._Tests_FedGenIA_Teste_pesos_exatos_mnist_ClassPartitioner_fedavg_fedgenia_trial1_metrics.json\"][\"d_losses_chunk\"]\n",
        "\n",
        "        # \"G_1\": loaded_dicts[\".._.._Tests_FedGenIA_Padrao_FedGenIA_DML-ICC_mnist_ClassPartitioner_fedavg_fedgenia_trial1_metrics.json\"][\"g_losses_chunk\"],\n",
        "        # \"D_1\": loaded_dicts[\".._.._Tests_FedGenIA_Padrao_FedGenIA_DML-ICC_mnist_ClassPartitioner_fedavg_fedgenia_trial1_metrics.json\"][\"d_losses_chunk\"],\n",
        "        # \"G_2\": loaded_dicts[\".._.._Tests_FedGenIA_Padrao_FedGenIA_DML-ICC_mnist_ClassPartitioner_fedavg_fedgenia_trial2_metrics.json\"][\"g_losses_chunk\"],\n",
        "        # \"D_2\": loaded_dicts[\".._.._Tests_FedGenIA_Padrao_FedGenIA_DML-ICC_mnist_ClassPartitioner_fedavg_fedgenia_trial2_metrics.json\"][\"d_losses_chunk\"],\n",
        "        # \"G_3\": loaded_dicts[\".._.._Tests_FedGenIA_Padrao_FedGenIA_DML-ICC_mnist_ClassPartitioner_fedavg_fedgenia_trial3_metrics.json\"][\"g_losses_chunk\"],\n",
        "        # \"D_3\": loaded_dicts[\".._.._Tests_FedGenIA_Padrao_FedGenIA_DML-ICC_mnist_ClassPartitioner_fedavg_fedgenia_trial3_metrics.json\"][\"d_losses_chunk\"],\n",
        "\n",
        "\n",
        "    },\n",
        "    series_styles={\n",
        "        \"G_1_flwr\": {\"color\": \"blue\", \"linestyle\": \"-\"},\n",
        "        \"D_1_flwr\": {\"color\": \"blue\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"G_nb_new\": {\"color\": \"black\", \"linestyle\": \"-\"},\n",
        "        \"D_nb_new\": {\"color\": \"black\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"G_flwr_genwgt\": {\"color\": \"red\", \"linestyle\": \"-\"},\n",
        "        \"D_flwr_genwgt\": {\"color\": \"red\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"G_nb_genwgt\": {\"color\": \"green\", \"linestyle\": \"-\"},\n",
        "        \"D_nb_genwgt\": {\"color\": \"green\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"G_1\": {\"color\": \"orange\", \"linestyle\": \"-\"},\n",
        "        \"D_1\": {\"color\": \"orange\", \"linestyle\": \"--\"},\n",
        "        \"G_2\": {\"color\": \"yellow\", \"linestyle\": \"-\"},\n",
        "        \"D_2\": {\"color\": \"yellow\", \"linestyle\": \"--\"},\n",
        "        \"G_3\": {\"color\": \"red\", \"linestyle\": \"-\"},\n",
        "        \"D_3\": {\"color\": \"red\", \"linestyle\": \"--\"},\n",
        "        \"G_500\": {\"color\": \"purple\", \"linestyle\": \"-\"},\n",
        "        \"D_500\": {\"color\": \"purple\", \"linestyle\": \"--\"},\n",
        "        \"G_1000\": {\"color\": \"brown\", \"linestyle\": \"-\"},\n",
        "        \"D_1000\": {\"color\": \"brown\", \"linestyle\": \"--\"},\n",
        "        \"G_5000\": {\"color\": \"pink\", \"linestyle\": \"-\"},\n",
        "        \"D_5000\": {\"color\": \"pink\", \"linestyle\": \"--\"},\n",
        "\n",
        "    },\n",
        "    xtick_step=5,\n",
        "    first_step=4,\n",
        "    ylabel=\"Loss\",\n",
        "    ylim=(0,0.7),\n",
        "    xlim=(90,110),\n",
        "    num_xticks=200\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7768e0ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "for key in loaded_dicts.keys():\n",
        "    print(f\"{key}: {len(loaded_dicts[key]['net_acc_round'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b608dfdb",
      "metadata": {},
      "source": [
        "### GeraFed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6a80e05",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series = {\n",
        "        \"Chunked FedAvg\": loaded_dicts[\"MNIST_Class_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"],\n",
        "        \"Chunked FedProx\": loaded_dicts[\"MNIST_Class_Trial1_metrics_chunked_fedprox.json\"][\"net_acc_round\"],\n",
        "        # \"Chunked SCAFFOLD\": loaded_dicts[\"MNIST_Class_Trial1_metrics_chunked_scaffold.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA\": loaded_dicts[\"MNIST_Class_Trial1_metrics.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA + FedProx\": loaded_dicts[\"MNIST_Class_Trial1_metrics_fedprox_fedgenia.json\"][\"net_acc_round\"],\n",
        "        # \"FedGenIA + SCAFFOLD mnistclass\": loaded_dicts[\"MNIST_Class_Trial1_metrics_scaffold_fedgenia.json\"][\"net_acc_round\"],\n",
        "\n",
        "        \"Chunked FedAvg cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"],\n",
        "        \"Chunked FedProx cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_metrics_chunked_fedprox.json\"][\"net_acc_round\"],\n",
        "        # \"Chunked SCAFFOLD cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_metrics_chunked_scaffold.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial2_metrics.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA + FedProx cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_metrics_fedprox_fedgenia.json\"][\"net_acc_round\"],\n",
        "        # \"FedGenIA + SCAFFOLD cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_metrics_scaffold_fedgenia.json\"][\"net_acc_round\"],\n",
        "\n",
        "        \"Chunked FedAvg cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"][:100],\n",
        "        \"Chunked FedProx cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_metrics_chunked_fedprox.json\"][\"net_acc_round\"],\n",
        "        # \"Chunked SCAFFOLD cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_metrics_chunked_scaffold.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_metrics.json\"][\"net_acc_round\"][:100],\n",
        "        \"FedGenIA + FedProx cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_metrics_fedprox_fedgenia.json\"][\"net_acc_round\"],\n",
        "        # \"FedGenIA + SCAFFOLD cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_metrics_scaffold_fedgenia.json\"][\"net_acc_round\"],\n",
        "\n",
        "        \"Chunked FedAvg cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"],\n",
        "        \"Chunked FedProx cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_metrics_chunked_fedprox.json\"][\"net_acc_round\"],\n",
        "        # \"Chunked SCAFFOLD cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_metrics_chunked_scaffold.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_metrics.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA + FedProx cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_metrics_fedprox_fedgenia.json\"][\"net_acc_round\"],\n",
        "        # \"FedGenIA + SCAFFOLD cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_metrics_scaffold_fedgenia.json\"][\"net_acc_round\"],\n",
        "        \"50chunks FedGenIA\": loaded_dicts[\".._.._cifar10_ClassPartitioner_fedavg_50chunks_fedgenia_metrics.json\"][\"net_acc_round\"]\n",
        "        },\n",
        "\n",
        "    series_styles={\n",
        "        \"Chunked FedAvg\": {\"color\": \"cornflowerblue\"},\n",
        "        \"Chunked FedProx\": {\"color\": \"sandybrown\"},\n",
        "        #\"Chunked SCAFFOLD\": {\"color\": \"yellowgreen\"},\n",
        "        \"FedGenIA\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"FedGenIA + FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "        #\"FedGenIA + SCAFFOLD\": {\"color\": \"yellowgreen\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Chunked FedAvg cifardir05\": {\"color\": \"cornflowerblue\"},\n",
        "        \"Chunked FedProx cifardir05\": {\"color\": \"sandybrown\"},\n",
        "        # \"Chunked SCAFFOLD cifardir05\": {\"color\": \"yellowgreen\"},\n",
        "        \"FedGenIA cifardir05\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"FedGenIA + FedProx cifardir05\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "        #\"FedGenIA + SCAFFOLD cifardir05\": {\"color\": \"yellowgreen\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Chunked FedAvg cifardir01\": {\"color\": \"cornflowerblue\"},\n",
        "        \"Chunked FedProx cifardir01\": {\"color\": \"sandybrown\"},\n",
        "        # \"Chunked SCAFFOLD cifardir01\": {\"color\": \"yellowgreen\"},\n",
        "        \"FedGenIA cifardir01\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"FedGenIA + FedProx cifardir01\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "        # \"FedGenIA + SCAFFOLD cifardir01\": {\"color\": \"yellowgreen\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Chunked FedAvg cifarclass\": {\"color\": \"cornflowerblue\"},\n",
        "        \"Chunked FedProx cifarclass\": {\"color\": \"sandybrown\"},\n",
        "        #\"Chunked SCAFFOLD cifarclass\": {\"color\": \"yellowgreen\"},\n",
        "        \"FedGenIA cifarclass\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"FedGenIA + FedProx cifarclass\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "        #\"FedGenIA + SCAFFOLD cifarclass\": {\"color\": \"yellowgreen\", \"linestyle\": \"--\"},\n",
        "        \"50chunks FedGenIA\": {\"color\": \"red\"}\n",
        "    },\n",
        "\n",
        "    subplot_groups=[\n",
        "                    [\"Chunked FedAvg\", \"Chunked FedProx\", \"Chunked SCAFFOLD\", \"FedGenIA\", \"FedGenIA + FedProx\", \"FedGenIA + SCAFFOLD\"],\n",
        "                    [\"Chunked FedAvg cifardir05\", \"Chunked FedProx cifardir05\", \"Chunked SCAFFOLD cifardir05\", \"FedGenIA cifardir05\", \"FedGenIA + FedProx cifardir05\", \"FedGenIA + SCAFFOLD cifardir05\"],\n",
        "                    [\"Chunked FedAvg cifardir01\", \"Chunked FedProx cifardir01\", \"Chunked SCAFFOLD cifardir01\", \"FedGenIA cifardir01\", \"FedGenIA + FedProx cifardir01\", \"FedGenIA + SCAFFOLD cifardir01\"],\n",
        "                    [\"Chunked FedAvg cifarclass\", \"Chunked FedProx cifarclass\", \"Chunked SCAFFOLD cifarclass\", \"FedGenIA cifarclass\", \"FedGenIA + FedProx cifarclass\", \"FedGenIA + SCAFFOLD cifarclass\", \"50chunks FedGenIA\"],\n",
        "                    ],\n",
        "    subplot_layout=(1,4),\n",
        "    figsize=(20,2.65),\n",
        "    highlight={\n",
        "        \"Chunked FedAvg\": \"max\",\n",
        "        \"Chunked FedProx\": \"max\",\n",
        "        #\"Chunked SCAFFOLD\": \"max\",\n",
        "        \"FedGenIA\": \"max\",\n",
        "        \"FedGenIA + FedProx\": \"max\",\n",
        "        #\"FedGenIA + SCAFFOLD\": \"max\",\n",
        "        \n",
        "        \"Chunked FedAvg cifardir05\": \"max\",\n",
        "        \"Chunked FedProx cifardir05\": \"max\",\n",
        "        # \"Chunked SCAFFOLD cifardir05\": \"max\",\n",
        "        \"FedGenIA cifardir05\": \"max\",\n",
        "        \"FedGenIA + FedProx cifardir05\": \"max\",\n",
        "        # \"FedGenIA + SCAFFOLD cifardir05\": \"max\",\n",
        "\n",
        "        \"Chunked FedAvg cifardir01\": \"max\",\n",
        "        \"Chunked FedProx cifardir01\": \"max\",\n",
        "        # \"Chunked SCAFFOLD cifardir01\": \"max\",\n",
        "        \"FedGenIA cifardir01\": \"max\",\n",
        "        \"FedGenIA + FedProx cifardir01\": \"max\",\n",
        "        # \"FedGenIA + SCAFFOLD cifardir01\": \"max\",\n",
        "\n",
        "        \"Chunked FedAvg cifarclass\": \"max\",\n",
        "        \"Chunked FedProx cifarclass\": \"max\",\n",
        "        # \"Chunked SCAFFOLD cifarclass\": \"max\",\n",
        "        \"FedGenIA cifarclass\": \"max\",\n",
        "        \"FedGenIA + FedProx cifarclass\": \"max\",\n",
        "        # \"FedGenIA + SCAFFOLD cifarclass\": \"max\",\n",
        "    },\n",
        "    highlight_style={\n",
        "        \"Chunked FedAvg\": {\"highlight_offset_max\": (-5, -0.40), 'arrow_color': 'cornflowerblue', 'arrow_style': '->', 'arrow_linewidth': 1},\n",
        "        \"Chunked FedProx\": {\"highlight_offset_max\": (8, -0.4), 'arrow_color': 'sandybrown', 'arrow_style': '->', 'arrow_linewidth': 1},\n",
        "        \"FedGenIA\": {\"highlight_offset_max\": (-7, -0.55), 'arrow_color': 'cornflowerblue', 'arrow_style': '->', 'arrow_linewidth': 1},\n",
        "        \"FedGenIA + FedProx\": {\"highlight_offset_max\": (-25, -0.45), 'arrow_color': 'sandybrown', 'arrow_style': '->', 'arrow_linewidth': 1},\n",
        "\n",
        "        \"Chunked FedAvg cifardir05\": {\"highlight_offset_max\": (5, -0.25),},\n",
        "        \"Chunked FedProx cifardir05\": {\"highlight_offset_max\": (-10, -0.35),},\n",
        "        \"FedGenIA cifardir05\": {\"highlight_offset_max\": (25, -0.20),},\n",
        "        \"FedGenIA + FedProx cifardir05\": {\"highlight_offset_max\": (0, -0.3)},\n",
        "\n",
        "        \"Chunked FedAvg cifardir01\": {\"highlight_offset_max\": (-5, -0.12)},\n",
        "        \"Chunked FedProx cifardir01\": {\"highlight_offset_max\": (-16, 0.02)},\n",
        "        \"FedGenIA cifardir01\": {\"highlight_offset_max\": (0, -0.2)},\n",
        "        \"FedGenIA + FedProx cifardir01\": {\"highlight_offset_max\": (0, -0.25)},\n",
        "\n",
        "        \"Chunked FedAvg cifarclass\": {\"highlight_offset_max\": (7, -0.27)},\n",
        "        \"Chunked FedProx cifarclass\": {\"highlight_offset_max\": (30, 0)},\n",
        "        \"FedGenIA cifarclass\": {\"highlight_offset_max\": (6.5, 0.1)},\n",
        "        \"FedGenIA + FedProx cifarclass\": {\"highlight_offset_max\": (20, 0)},\n",
        "     }, \n",
        "    num_xticks=5,\n",
        "    num_yticks=[None,None,3,3],\n",
        "    y_ticks=[[0,0.5,1], [0.2,0.45,0.65], None, None],\n",
        "    ylim=[(0,1.05), (0.2,0.65), (0.1, 0.6), (0,0.5)],\n",
        "    ylabel=[\"Accuracy\",\"\",\"\",\"\"],\n",
        "    title=[\"a) MNIST Class\", \"b) CIFAR Dir05\", \"c) CIFAR Dir01\", \"d) CIFAR Class\"],\n",
        "    legend_subplot_index=0,\n",
        "    label_fontsize=16,\n",
        "    tick_fontsize=15,\n",
        "    highlight_markersize=6,\n",
        "    highlight_text_size=15,\n",
        "    legend_fontsize=13,\n",
        "    legend_kwargs={\n",
        "        \"ncol\": 2,\n",
        "        \"columnspacing\": 0.4,\n",
        "        \"handletextpad\": 0.2,\n",
        "        \"borderpad\": 0.1,\n",
        "        \"bbox_to_anchor\": (1.0114, 0.4),\n",
        "        \"handlelength\": 1,\n",
        "        \"labelspacing\": 0.3\n",
        "    },\n",
        "    title_fontsize=18,\n",
        "    save=False,\n",
        "    plot_name=\"./FedGenIAxbaselines.pdf\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d0079b",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series = {\n",
        "        \"Chunked FedAvg\": loaded_dicts[\"MNIST_Class_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"],\n",
        "        \"Chunked FedProx\": loaded_dicts[\"MNIST_Class_Trial1_metrics_chunked_fedprox.json\"][\"net_acc_round\"],\n",
        "        # \"Chunked SCAFFOLD\": loaded_dicts[\"MNIST_Class_Trial1_metrics_chunked_scaffold.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA\": loaded_dicts[\"MNIST_Class_Trial1_metrics.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA + FedProx\": loaded_dicts[\"MNIST_Class_Trial1_metrics_fedprox_fedgenia.json\"][\"net_acc_round\"],\n",
        "        # \"FedGenIA + SCAFFOLD mnistclass\": loaded_dicts[\"MNIST_Class_Trial1_metrics_scaffold_fedgenia.json\"][\"net_acc_round\"],\n",
        "\n",
        "        \"Chunked FedAvg cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"],\n",
        "        \"Chunked FedProx cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_metrics_chunked_fedprox.json\"][\"net_acc_round\"],\n",
        "        # \"Chunked SCAFFOLD cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_metrics_chunked_scaffold.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial2_metrics.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA + FedProx cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_metrics_fedprox_fedgenia.json\"][\"net_acc_round\"],\n",
        "        # \"FedGenIA + SCAFFOLD cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_metrics_scaffold_fedgenia.json\"][\"net_acc_round\"],\n",
        "\n",
        "        \"Chunked FedAvg cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_fedavg_50chunks_metrics.json\"][\"net_acc_round\"][:100],\n",
        "        \"Chunked FedProx cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_fedprox_50chunks_metrics.json\"][\"net_acc_round\"],\n",
        "        # \"Chunked SCAFFOLD cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_metrics_chunked_scaffold.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_fedgenia_fedavg_50chunks_metrics.json\"][\"net_acc_round\"][:100],\n",
        "        \"FedGenIA + FedProx cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_fedgenia_fedprox_50chunks_metrics.json\"][\"net_acc_round\"],\n",
        "        # \"FedGenIA + SCAFFOLD cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_metrics_scaffold_fedgenia.json\"][\"net_acc_round\"],\n",
        "\n",
        "        \"Chunked FedAvg cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_fedavg_50chunks_metrics.json\"][\"net_acc_round\"],\n",
        "        \"Chunked FedProx cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_fedprox_50chunks_metrics.json\"][\"net_acc_round\"],\n",
        "        # \"Chunked SCAFFOLD cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_metrics_chunked_scaffold.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_fedavg_fedgenia_50chunks_metrics.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA + FedProx cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_fedgenia_fedprox_50chunks_metrics.json\"][\"net_acc_round\"],\n",
        "        # \"FedGenIA + SCAFFOLD cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_metrics_scaffold_fedgenia.json\"][\"net_acc_round\"],\n",
        "        },\n",
        "\n",
        "    series_styles={\n",
        "        \"Chunked FedAvg\": {\"color\": \"cornflowerblue\"},\n",
        "        \"Chunked FedProx\": {\"color\": \"sandybrown\"},\n",
        "        #\"Chunked SCAFFOLD\": {\"color\": \"yellowgreen\"},\n",
        "        \"FedGenIA\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"FedGenIA + FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "        #\"FedGenIA + SCAFFOLD\": {\"color\": \"yellowgreen\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Chunked FedAvg cifardir05\": {\"color\": \"cornflowerblue\"},\n",
        "        \"Chunked FedProx cifardir05\": {\"color\": \"sandybrown\"},\n",
        "        # \"Chunked SCAFFOLD cifardir05\": {\"color\": \"yellowgreen\"},\n",
        "        \"FedGenIA cifardir05\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"FedGenIA + FedProx cifardir05\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "        #\"FedGenIA + SCAFFOLD cifardir05\": {\"color\": \"yellowgreen\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Chunked FedAvg cifardir01\": {\"color\": \"cornflowerblue\"},\n",
        "        \"Chunked FedProx cifardir01\": {\"color\": \"sandybrown\"},\n",
        "        # \"Chunked SCAFFOLD cifardir01\": {\"color\": \"yellowgreen\"},\n",
        "        \"FedGenIA cifardir01\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"FedGenIA + FedProx cifardir01\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "        # \"FedGenIA + SCAFFOLD cifardir01\": {\"color\": \"yellowgreen\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Chunked FedAvg cifarclass\": {\"color\": \"cornflowerblue\"},\n",
        "        \"Chunked FedProx cifarclass\": {\"color\": \"sandybrown\"},\n",
        "        #\"Chunked SCAFFOLD cifarclass\": {\"color\": \"yellowgreen\"},\n",
        "        \"FedGenIA cifarclass\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"FedGenIA + FedProx cifarclass\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "        #\"FedGenIA + SCAFFOLD cifarclass\": {\"color\": \"yellowgreen\", \"linestyle\": \"--\"},\n",
        "        \"50chunks FedGenIA\": {\"color\": \"red\"}\n",
        "    },\n",
        "\n",
        "    subplot_groups=[\n",
        "                    [\"Chunked FedAvg\", \"Chunked FedProx\", \"Chunked SCAFFOLD\", \"FedGenIA\", \"FedGenIA + FedProx\", \"FedGenIA + SCAFFOLD\"],\n",
        "                    [\"Chunked FedAvg cifardir05\", \"Chunked FedProx cifardir05\", \"Chunked SCAFFOLD cifardir05\", \"FedGenIA cifardir05\", \"FedGenIA + FedProx cifardir05\", \"FedGenIA + SCAFFOLD cifardir05\"],\n",
        "                    [\"Chunked FedAvg cifardir01\", \"Chunked FedProx cifardir01\", \"Chunked SCAFFOLD cifardir01\", \"FedGenIA cifardir01\", \"FedGenIA + FedProx cifardir01\", \"FedGenIA + SCAFFOLD cifardir01\"],\n",
        "                    [\"Chunked FedAvg cifarclass\", \"Chunked FedProx cifarclass\", \"Chunked SCAFFOLD cifarclass\", \"FedGenIA cifarclass\", \"FedGenIA + FedProx cifarclass\", \"FedGenIA + SCAFFOLD cifarclass\", \"50chunks FedGenIA\"],\n",
        "                    ],\n",
        "    subplot_layout=(1,4),\n",
        "    figsize=(20,2.65),\n",
        "    highlight={\n",
        "        \"Chunked FedAvg\": \"max\",\n",
        "        \"Chunked FedProx\": \"max\",\n",
        "        #\"Chunked SCAFFOLD\": \"max\",\n",
        "        \"FedGenIA\": \"max\",\n",
        "        \"FedGenIA + FedProx\": \"max\",\n",
        "        #\"FedGenIA + SCAFFOLD\": \"max\",\n",
        "        \n",
        "        \"Chunked FedAvg cifardir05\": \"max\",\n",
        "        \"Chunked FedProx cifardir05\": \"max\",\n",
        "        # \"Chunked SCAFFOLD cifardir05\": \"max\",\n",
        "        \"FedGenIA cifardir05\": \"max\",\n",
        "        \"FedGenIA + FedProx cifardir05\": \"max\",\n",
        "        # \"FedGenIA + SCAFFOLD cifardir05\": \"max\",\n",
        "\n",
        "        \"Chunked FedAvg cifardir01\": \"max\",\n",
        "        \"Chunked FedProx cifardir01\": \"max\",\n",
        "        # \"Chunked SCAFFOLD cifardir01\": \"max\",\n",
        "        \"FedGenIA cifardir01\": \"max\",\n",
        "        \"FedGenIA + FedProx cifardir01\": \"max\",\n",
        "        # \"FedGenIA + SCAFFOLD cifardir01\": \"max\",\n",
        "\n",
        "        \"Chunked FedAvg cifarclass\": \"max\",\n",
        "        \"Chunked FedProx cifarclass\": \"max\",\n",
        "        # \"Chunked SCAFFOLD cifarclass\": \"max\",\n",
        "        \"FedGenIA cifarclass\": \"max\",\n",
        "        \"FedGenIA + FedProx cifarclass\": \"max\",\n",
        "        # \"FedGenIA + SCAFFOLD cifarclass\": \"max\",\n",
        "    },\n",
        "    highlight_style={\n",
        "        \"Chunked FedAvg\": {\"highlight_offset_max\": (-5, -0.40), 'arrow_color': 'cornflowerblue', 'arrow_style': '->', 'arrow_linewidth': 1},\n",
        "        \"Chunked FedProx\": {\"highlight_offset_max\": (8, -0.4), 'arrow_color': 'sandybrown', 'arrow_style': '->', 'arrow_linewidth': 1},\n",
        "        \"FedGenIA\": {\"highlight_offset_max\": (-7, -0.55), 'arrow_color': 'cornflowerblue', 'arrow_style': '->', 'arrow_linewidth': 1},\n",
        "        \"FedGenIA + FedProx\": {\"highlight_offset_max\": (-25, -0.45), 'arrow_color': 'sandybrown', 'arrow_style': '->', 'arrow_linewidth': 1},\n",
        "\n",
        "        \"Chunked FedAvg cifardir05\": {\"highlight_offset_max\": (5, -0.25),},\n",
        "        \"Chunked FedProx cifardir05\": {\"highlight_offset_max\": (-10, -0.35),},\n",
        "        \"FedGenIA cifardir05\": {\"highlight_offset_max\": (25, -0.20),},\n",
        "        \"FedGenIA + FedProx cifardir05\": {\"highlight_offset_max\": (0, -0.3)},\n",
        "\n",
        "        \"Chunked FedAvg cifardir01\": {\"highlight_offset_max\": (-5, -0.12)},\n",
        "        \"Chunked FedProx cifardir01\": {\"highlight_offset_max\": (-16, 0.02)},\n",
        "        \"FedGenIA cifardir01\": {\"highlight_offset_max\": (0, -0.2)},\n",
        "        \"FedGenIA + FedProx cifardir01\": {\"highlight_offset_max\": (0, -0.25)},\n",
        "\n",
        "        \"Chunked FedAvg cifarclass\": {\"highlight_offset_max\": (7, -0.27)},\n",
        "        \"Chunked FedProx cifarclass\": {\"highlight_offset_max\": (30, 0)},\n",
        "        \"FedGenIA cifarclass\": {\"highlight_offset_max\": (6.5, 0.1)},\n",
        "        \"FedGenIA + FedProx cifarclass\": {\"highlight_offset_max\": (20, 0)},\n",
        "     }, \n",
        "    num_xticks=5,\n",
        "    num_yticks=[None,None,3,3],\n",
        "    y_ticks=[[0,0.5,1], [0.2,0.45,0.65], None, None],\n",
        "    ylim=[(0,1.05), (0.2,0.65), (0.1, 0.6), (0,0.5)],\n",
        "    ylabel=[\"Accuracy\",\"\",\"\",\"\"],\n",
        "    title=[\"a) MNIST Class\", \"b) CIFAR Dir05\", \"c) CIFAR Dir01\", \"d) CIFAR Class\"],\n",
        "    legend_subplot_index=0,\n",
        "    label_fontsize=16,\n",
        "    tick_fontsize=15,\n",
        "    highlight_markersize=6,\n",
        "    highlight_text_size=15,\n",
        "    legend_fontsize=13,\n",
        "    legend_kwargs={\n",
        "        \"ncol\": 2,\n",
        "        \"columnspacing\": 0.4,\n",
        "        \"handletextpad\": 0.2,\n",
        "        \"borderpad\": 0.1,\n",
        "        \"bbox_to_anchor\": (1.0114, 0.4),\n",
        "        \"handlelength\": 1,\n",
        "        \"labelspacing\": 0.3\n",
        "    },\n",
        "    title_fontsize=18,\n",
        "    save=False,\n",
        "    plot_name=\"./FedGenIAxbaselines.pdf\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6e874a0",
      "metadata": {},
      "source": [
        "#### Aggregated Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eece0598",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series = {\n",
        "        \"MNIST Class\": experiment_stats[\"MNIST_Class\"][\"net_acc_round\"][\"std\"],\n",
        "        \"CIFAR Dir05\": experiment_stats[\"CIFAR10_Dir05\"][\"net_acc_round\"][\"std\"],\n",
        "        \"CIFAR Dir01\": experiment_stats[\"CIFAR10_Dir01\"][\"net_acc_round\"][\"std\"],\n",
        "        \"CIFAR Class\": experiment_stats[\"CIFAR10_Class\"][\"net_acc_round\"][\"std\"],\n",
        "        },\n",
        "    # series_styles={\n",
        "    #     \"Chunked FedAvg cifarclass\": {\"color\": \"cornflowerblue\"},\n",
        "    #     \"FedGenIA cifarclass\": {\"color\": \"sandybrown\"},\n",
        "    #     \"Chunked FedAvg cifardir05\": {\"color\": \"cornflowerblue\"},\n",
        "    #     \"FedGenIA cifardir05\": {\"color\": \"sandybrown\"},\n",
        "    #     \"Chunked FedAvg cifardir01\": {\"color\": \"cornflowerblue\"},\n",
        "    #     \"FedGenIA cifardir01\": {\"color\": \"sandybrown\"},\n",
        "    #     \"Chunked FedAvg\": {\"color\": \"cornflowerblue\"},\n",
        "    #     \"FedGenIA\": {\"color\": \"sandybrown\"},\n",
        "    # },\n",
        "    # subplot_groups=[\n",
        "    #                 [\"Chunked FedAvg\", \"FedGenIA\"],\n",
        "    #                 [\"Chunked FedAvg cifardir05\", \"FedGenIA cifardir05\"],\n",
        "    #                 [\"Chunked FedAvg cifardir01\", \"FedGenIA cifardir01\"],\n",
        "    #                 [\"Chunked FedAvg cifarclass\", \"FedGenIA cifarclass\"],],\n",
        "    #subplot_layout=(1,4),\n",
        "    figsize=(16,8),\n",
        "    # highlight={\n",
        "    #     \"Chunked FedAvg cifarclass\": \"max\",\n",
        "    #     \"FedGenIA cifarclass\": \"max\",\n",
        "    #     \"Chunked FedAvg cifardir05\": \"max\",\n",
        "    #     \"FedGenIA cifardir05\": \"max\",\n",
        "    #     \"Chunked FedAvg cifardir01\": \"max\",\n",
        "    #     \"FedGenIA cifardir01\": \"max\",\n",
        "    #     \"Chunked FedAvg\": \"max\",\n",
        "    #     \"FedGenIA\": \"max\",\n",
        "    # },\n",
        "    # highlight_style={\n",
        "    #     \"Chunked FedAvg cifarclass\": {\"highlight_offset_max\": (20, 0.02)},\n",
        "    #     \"FedGenIA cifarclass\": {\"highlight_offset_max\": (-15, 0.005)},\n",
        "    #     \"Chunked FedAvg cifardir05\": {\"highlight_offset_max\": (0, -0.23)},\n",
        "    #     \"FedGenIA cifardir05\": {\"highlight_offset_max\": (-5, -0.22)},\n",
        "    #     \"Chunked FedAvg cifardir01\": {\"highlight_offset_max\": (-5, -0.17)},\n",
        "    #     \"FedGenIA cifardir01\": {\"highlight_offset_max\": (-5, -0.16)},\n",
        "    #     \"Chunked FedAvg\": {\"highlight_offset_max\": (5, -0.35)},\n",
        "    #     \"FedGenIA\": {\"highlight_offset_max\": (-10, -0.4)},\n",
        "    #  }, \n",
        "    # num_xticks=5,\n",
        "    num_yticks=3,\n",
        "    ylabel=[\"Accuracy\"],\n",
        "    # title=[\"a) MNIST Class\", \"b) CIFAR Dir05\", \"c) CIFAR Dir01\", \"d) CIFAR Class\"],\n",
        "    legend_subplot_index=0,\n",
        "    label_fontsize=16,\n",
        "    tick_fontsize=15,\n",
        "    # highlight_markersize=6,\n",
        "    # highlight_text_size=14,\n",
        "    legend_fontsize=12,\n",
        "    title_fontsize=18,\n",
        "    xtick_step=10,\n",
        "    first_step=9\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68f94216",
      "metadata": {},
      "source": [
        "#### Comparing Trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a835bce",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series = {\n",
        "        \"Trial1\": loaded_dicts[\"CIFAR10_Class_Trial1_metrics.json\"][\"net_acc_round\"],\n",
        "        \"Trial2\": loaded_dicts[\"CIFAR10_Class_Trial2_metrics.json\"][\"net_acc_round\"],\n",
        "        \"Trial3\": loaded_dicts[\"CIFAR10_Class_Trial3_metrics.json\"][\"net_acc_round\"]\n",
        "        },\n",
        "    series_styles={\n",
        "        \"FedGenIA com agregação por chunk\": {\"color\": \"cornflowerblue\"},\n",
        "        \"FedGenIA com agregação só com primeiro chunk\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"Chunked FedAvg\": {\"color\": \"sandybrown\"},\n",
        "        \"CIFAR10 Class metrics\": {\"color\": \"cornflowerblue\"},\n",
        "        \"CIFAR10 Class losses\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"CIFAR10 Class alvo\": {\"color\": \"sandybrown\"},\n",
        "        \"CIFAR10 Dir01 metrics\": {\"color\": \"cornflowerblue\"},\n",
        "        \"CIFAR10 Dir01 losses\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"CIFAR10 Dir01 alvo\": {\"color\": \"sandybrown\"},\n",
        "        \"CIFAR10 Dir05 metrics\": {\"color\": \"cornflowerblue\"},\n",
        "        \"CIFAR10 Dir05 losses\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"CIFAR10 Dir05 alvo\": {\"color\": \"sandybrown\"},\n",
        "    },\n",
        "    subplot_layout=(1,1),\n",
        "    figsize=(20,10),\n",
        "    # highlight={\n",
        "    #     \"Chunked FedAvg cifarclass\": \"max\",\n",
        "    #     \"FedGenIA cifarclass\": \"max\",\n",
        "    #     \"Chunked FedAvg cifardir05\": \"max\",\n",
        "    #     \"FedGenIA cifardir05\": \"max\",\n",
        "    #     \"Chunked FedAvg cifardir01\": \"max\",\n",
        "    #     \"FedGenIA cifardir01\": \"max\",\n",
        "    #     \"Chunked FedAvg\": \"max\",\n",
        "    #     \"FedGenIA\": \"max\",\n",
        "    # },\n",
        "    # highlight_style={\n",
        "    #     \"Chunked FedAvg cifarclass\": {\"highlight_offset_max\": (20, 0.02)},\n",
        "    #     \"FedGenIA cifarclass\": {\"highlight_offset_max\": (-15, 0.005)},\n",
        "    #     \"Chunked FedAvg cifardir05\": {\"highlight_offset_max\": (0, -0.23)},\n",
        "    #     \"FedGenIA cifardir05\": {\"highlight_offset_max\": (-5, -0.22)},\n",
        "    #     \"Chunked FedAvg cifardir01\": {\"highlight_offset_max\": (-5, -0.17)},\n",
        "    #     \"FedGenIA cifardir01\": {\"highlight_offset_max\": (-5, -0.16)},\n",
        "    #     \"Chunked FedAvg\": {\"highlight_offset_max\": (5, -0.35)},\n",
        "    #     \"FedGenIA\": {\"highlight_offset_max\": (-10, -0.4)},\n",
        "    #  }, \n",
        "    # num_xticks=5,\n",
        "    num_yticks=4,\n",
        "    ylabel=[\"Accuracy\"],\n",
        "    title=[\"\"],\n",
        "    legend_subplot_index=0,\n",
        "    label_fontsize=16,\n",
        "    tick_fontsize=15,\n",
        "    highlight_markersize=6,\n",
        "    highlight_text_size=14,\n",
        "    legend_fontsize=12,\n",
        "    title_fontsize=18,\n",
        "    first_step=9,\n",
        "    xtick_step=10,\n",
        "    save=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0637fcc",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series = {\n",
        "        \"CIFAR10 Class metrics\": loaded_dicts[\"CIFAR10_Class_Trial1_metrics.json\"][\"net_acc_round\"],\n",
        "        \"CIFAR10 Class losses\": loaded_dicts[\"CIFAR10_Class_Trial1_losses.json\"][\"net_acc_round\"],\n",
        "        \"CIFAR10 Class alvo\": loaded_dicts[\"Alvo_4c_NIIDClass_CIFAR_losses.json\"][\"net_acc_round\"],\n",
        "        \"CIFAR10 Dir01 metrics\": loaded_dicts[\"CIFAR10_Dir01_Trial1_metrics.json\"][\"net_acc_round\"],\n",
        "        \"CIFAR10 Dir01 losses\": loaded_dicts[\"CIFAR10_Dir01_Trial1_losses.json\"][\"net_acc_round\"][:100],\n",
        "        \"CIFAR10 Dir01 alvo\": loaded_dicts[\"Alvo_4c_01Dir_CIFAR_losses.json\"][\"net_acc_round\"][:100],\n",
        "        \"CIFAR10 Dir05 metrics\": loaded_dicts[\"CIFAR10_Dir05_Trial1_metrics.json\"][\"net_acc_round\"],\n",
        "        \"CIFAR10 Dir05 losses\": loaded_dicts[\"CIFAR10_Dir05_Trial1_losses.json\"][\"net_acc_round\"],\n",
        "        \"CIFAR10 Dir05 alvo\": loaded_dicts[\"Alvo_4c_05Dir_CIFAR_losses.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA com agregação por chunk\": loaded_dicts[\"MNIST_Class_Trial1_metrics.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA com agregação só com primeiro chunk\": loaded_dicts[\"MNIST_Class_Trial1_losses.json\"][\"net_acc_round\"],\n",
        "        \"Chunked FedAvg\": loaded_dicts[\"Alvo_4c_NIIDClass_MNIST_losses.json\"][\"net_acc_round\"]\n",
        "        },\n",
        "    series_styles={\n",
        "        \"FedGenIA com agregação por chunk\": {\"color\": \"cornflowerblue\"},\n",
        "        \"FedGenIA com agregação só com primeiro chunk\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"Chunked FedAvg\": {\"color\": \"sandybrown\"},\n",
        "        \"CIFAR10 Class metrics\": {\"color\": \"cornflowerblue\"},\n",
        "        \"CIFAR10 Class losses\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"CIFAR10 Class alvo\": {\"color\": \"sandybrown\"},\n",
        "        \"CIFAR10 Dir01 metrics\": {\"color\": \"cornflowerblue\"},\n",
        "        \"CIFAR10 Dir01 losses\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"CIFAR10 Dir01 alvo\": {\"color\": \"sandybrown\"},\n",
        "        \"CIFAR10 Dir05 metrics\": {\"color\": \"cornflowerblue\"},\n",
        "        \"CIFAR10 Dir05 losses\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"CIFAR10 Dir05 alvo\": {\"color\": \"sandybrown\"},\n",
        "    },\n",
        "    subplot_groups=[\n",
        "                    [\"FedGenIA com agregação por chunk\", \"FedGenIA com agregação só com primeiro chunk\", \"Chunked FedAvg\"],\n",
        "                    [\"CIFAR10 Class metrics\", \"CIFAR10 Class losses\", \"CIFAR10 Class alvo\"],\n",
        "                    [\"CIFAR10 Dir01 metrics\", \"CIFAR10 Dir01 losses\", \"CIFAR10 Dir01 alvo\"],\n",
        "                    [\"CIFAR10 Dir05 metrics\", \"CIFAR10 Dir05 losses\", \"CIFAR10 Dir05 alvo\"],\n",
        "                    ],\n",
        "    subplot_layout=(2,2),\n",
        "    figsize=(20,10),\n",
        "    # highlight={\n",
        "    #     \"Chunked FedAvg cifarclass\": \"max\",\n",
        "    #     \"FedGenIA cifarclass\": \"max\",\n",
        "    #     \"Chunked FedAvg cifardir05\": \"max\",\n",
        "    #     \"FedGenIA cifardir05\": \"max\",\n",
        "    #     \"Chunked FedAvg cifardir01\": \"max\",\n",
        "    #     \"FedGenIA cifardir01\": \"max\",\n",
        "    #     \"Chunked FedAvg\": \"max\",\n",
        "    #     \"FedGenIA\": \"max\",\n",
        "    # },\n",
        "    # highlight_style={\n",
        "    #     \"Chunked FedAvg cifarclass\": {\"highlight_offset_max\": (20, 0.02)},\n",
        "    #     \"FedGenIA cifarclass\": {\"highlight_offset_max\": (-15, 0.005)},\n",
        "    #     \"Chunked FedAvg cifardir05\": {\"highlight_offset_max\": (0, -0.23)},\n",
        "    #     \"FedGenIA cifardir05\": {\"highlight_offset_max\": (-5, -0.22)},\n",
        "    #     \"Chunked FedAvg cifardir01\": {\"highlight_offset_max\": (-5, -0.17)},\n",
        "    #     \"FedGenIA cifardir01\": {\"highlight_offset_max\": (-5, -0.16)},\n",
        "    #     \"Chunked FedAvg\": {\"highlight_offset_max\": (5, -0.35)},\n",
        "    #     \"FedGenIA\": {\"highlight_offset_max\": (-10, -0.4)},\n",
        "    #  }, \n",
        "    # num_xticks=5,\n",
        "    num_yticks=4,\n",
        "    ylabel=[\"Accuracy\", \"Accuracy\", \"Accuracy\", \"Accuracy\"],\n",
        "    title=[\"MNIST Class\", \"CIFAR Class\", \"CIFAR Dir01\", \"CIFAR Dir05\"],\n",
        "    legend_subplot_index=0,\n",
        "    label_fontsize=16,\n",
        "    tick_fontsize=15,\n",
        "    highlight_markersize=6,\n",
        "    highlight_text_size=14,\n",
        "    legend_fontsize=12,\n",
        "    title_fontsize=18,\n",
        "    first_step=9,\n",
        "    xtick_step=10,\n",
        "    save=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af29f8a9",
      "metadata": {},
      "source": [
        "### Optim Compare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "933a5a75",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series = {\n",
        "        \"Adam_loss\": loaded_dict_mnist[\"net_loss_round\"],\n",
        "        \"Adam_GeraFed_loss\": loaded_dict_mnist_gerafed[\"net_loss_round\"],\n",
        "        \"Adam_reiniciando_loss\": loaded_dict_mnist_adam_reiniciando[\"net_loss_round\"],\n",
        "        \"Adam_reiniciando_GeraFed_loss\": loaded_dict_mnist_adam_reiniciando_gerafed[\"net_loss_round\"],\n",
        "        \"SGD_loss\": loaded_dict_mnist_sgd[\"net_loss_round\"],\n",
        "        \"SGD_GeraFed_loss\": loaded_dict_mnist_sgd_gerafed[\"net_loss_round\"],\n",
        "        \"Adam\": loaded_dict_mnist[\"net_acc_round\"],\n",
        "        \"Adam_GeraFed\": loaded_dict_mnist_gerafed[\"net_acc_round\"],\n",
        "        \"Adam_reiniciando\": loaded_dict_mnist_adam_reiniciando[\"net_acc_round\"],\n",
        "        \"Adam_reiniciando_GeraFed\": loaded_dict_mnist_adam_reiniciando_gerafed[\"net_acc_round\"],\n",
        "        \"SGD\": loaded_dict_mnist_sgd[\"net_acc_round\"],\n",
        "        \"SGD_GeraFed\": loaded_dict_mnist_sgd_gerafed[\"net_acc_round\"],\n",
        "    },\n",
        "    subplot_groups=[\n",
        "        [\"Adam_loss\", \"Adam_GeraFed_loss\", \"Adam_reiniciando_loss\", \"Adam_reiniciando_GeraFed_loss\", \"SGD_loss\", \"SGD_GeraFed_loss\"],\n",
        "        [\"Adam\", \"Adam_GeraFed\", \"Adam_reiniciando\", \"Adam_reiniciando_GeraFed\", \"SGD\", \"SGD_GeraFed\"]\n",
        "    ],\n",
        "    subplot_layout=(2, 1),\n",
        "    series_styles={\n",
        "        \"Adam_loss\": {\"color\": \"cornflowerblue\", \"linestyle\": \"-\"},\n",
        "        \"Adam_GeraFed_loss\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"Adam_reiniciando_loss\": {\"color\": \"darkturquoise\", \"linestyle\": \"-\"},\n",
        "        \"Adam_reiniciando_GeraFed_loss\": {\"color\": \"darkturquoise\", \"linestyle\": \"--\"},\n",
        "        \"SGD_loss\": {\"color\": \"yellowgreen\", \"linestyle\": \"-\"},\n",
        "        \"SGD_GeraFed_loss\": {\"color\": \"yellowgreen\", \"linestyle\": \"--\"},\n",
        "        \"Adam\": {\"color\": \"cornflowerblue\",  \"linestyle\": \"-\"},\n",
        "        \"Adam_GeraFed\": {\"color\": \"cornflowerblue\",  \"linestyle\": \"--\"},\n",
        "        \"Adam_reiniciando\": {\"color\": \"darkturquoise\",  \"linestyle\": \"-\"},\n",
        "        \"Adam_reiniciando_GeraFed\": {\"color\": \t\"darkturquoise\", \t\"linestyle\": \"--\"},\n",
        "        \"SGD\": {\"color\": \t\"yellowgreen\", \t\"linestyle\": \"-\"},\n",
        "        \"SGD_GeraFed\": {\"color\": \t\"yellowgreen\", \t\"linestyle\": \"--\"},\n",
        "    },\n",
        "    xlabel=[\"Épocas\", \"\"],\n",
        "    ylabel=[\"Loss\", \"Acurácia\"],\n",
        "    legend_subplot_index=1,\n",
        "    xtick_step=10,\n",
        "    first_step=9,\n",
        "    figsize=(8, 8),\n",
        "    legend_fontsize=8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8d902d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series={\"Class Adam\": loaded_dict_cifar_class[\"net_acc_round\"],\n",
        "            \"Dir01 Adam\": loaded_dict_cifar_dir01[\"net_acc_round\"][:100],\n",
        "            \"Dir05 Adam\": loaded_dict_cifar_dir05[\"net_acc_round\"],\n",
        "            \"Class SGD\": loaded_dict_cifar_class_sgd[\"net_acc_round\"],\n",
        "            \"Dir01 SGD\": loaded_dict_cifar_dir01_sgd[\"net_acc_round\"],\n",
        "            \"Dir05 SGD\": loaded_dict_cifar_dir05_sgd[\"net_acc_round\"],\n",
        "    },\n",
        "    series_styles={\n",
        "        \"Class Adam\": {\"color\": \"cornflowerblue\", \"linestyle\": \"-\"},\n",
        "        \"Dir01 Adam\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"Dir05 Adam\": {\"color\": \"cornflowerblue\", \"linestyle\": \":\"},\n",
        "        \"Class SGD\": {\"color\": \"sandybrown\", \"linestyle\": \"-\"},\n",
        "        \"Dir01 SGD\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "        \"Dir05 SGD\": {\"color\": \"sandybrown\", \"linestyle\": \":\"},\n",
        "    },\n",
        "    highlight={\n",
        "        \"Class Adam\": \"max\",\n",
        "        \"Dir01 Adam\": \"max\",\n",
        "        \"Dir05 Adam\": \"max\",\n",
        "        \"Class SGD\": \"max\",\n",
        "        \"Dir01 SGD\": \"max\",\n",
        "        \"Dir05 SGD\": \"max\",\n",
        "    },\n",
        "    highlight_style={\n",
        "        \"Class Adam\": {\"highlight_offset_max\": (20, 0.02)},\n",
        "        \"Dir01 Adam\": {\"highlight_offset_max\": (-5, -0.17)},\n",
        "        \"Dir05 Adam\": {\"highlight_offset_max\": (0, -0.23)},\n",
        "        \"Class SGD\": {\"highlight_offset_max\": (20, 0.005)},\n",
        "        \"Dir01 SGD\": {\"highlight_offset_max\": (-5, -0.16)},\n",
        "        \"Dir05 SGD\": {\"highlight_offset_max\": (-5, -0.22)},\n",
        "     },\n",
        "    xtick_step=10,\n",
        "    first_step=9\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffc7684f",
      "metadata": {},
      "source": [
        "### FLEG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb505cdd",
      "metadata": {},
      "outputs": [],
      "source": [
        "new_dict = {}\n",
        "\n",
        "for k, v in loaded_dicts.items():\n",
        "    new_k = (\n",
        "        k.replace(\"Dirichlet_0.1\", \"Dir01\")\n",
        "         .replace(\"Dirichlet_0.5\", \"Dir05\")\n",
        "    )\n",
        "    new_dict[new_k] = v\n",
        "\n",
        "loaded_dicts.clear()\n",
        "loaded_dicts.update(new_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e00c7eaf",
      "metadata": {},
      "source": [
        "#### Level Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14b72ef1",
      "metadata": {},
      "source": [
        "##### Old"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbaf5de6",
      "metadata": {},
      "outputs": [],
      "source": [
        "class_levels = [\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg_class_level0_metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg_class_level1_metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg_class_level2_metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg_class_level3_metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg_class_level4_metrics.json\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8532ea4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_dicts.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd512b6b",
      "metadata": {},
      "outputs": [],
      "source": [
        "net_acc_all_levels = [acc for id, d in loaded_dicts.items() for acc in d[\"net_acc\"] if id in class_levels]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6d0405d",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series={\n",
        "        \"FLEG\": net_acc_all_levels,\n",
        "        \"FedAvg\": loaded_dicts[\"class_patience100_metrics.json\"][\"net_acc\"],\n",
        "    },\n",
        "    num_xticks=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d09ba285",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "\n",
        "offset = 0\n",
        "for k in class_levels:\n",
        "    acc = loaded_dicts[k][\"net_acc\"]\n",
        "    epochs = range(offset, offset + len(acc))\n",
        "    plt.axvline(offset, linestyle=\":\", alpha=0.4)\n",
        "    plt.plot(epochs, acc, label=k.replace(\"_metrics.json\", \"\"))\n",
        "    offset += len(acc)\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Classifier training by level\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1743e1c",
      "metadata": {},
      "outputs": [],
      "source": [
        "level1_variants = [\n",
        "    \"class_level1_metrics.json\",\n",
        "    \"class_level1_3000_samples_metrics.json\",\n",
        "    \"class_level1_12000_samples_metrics.json\",\n",
        "    \"class_level1_D_samples_metrics.json\",\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0adce9f",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "offset = 0\n",
        "\n",
        "# ---- Level 0 ----\n",
        "acc0 = loaded_dicts[\"class_level0_metrics.json\"][\"net_acc\"]\n",
        "epochs = range(offset, offset + len(acc0))\n",
        "plt.plot(epochs, acc0, label=\"level0\")\n",
        "offset += len(acc0)\n",
        "\n",
        "# ---- Level 1 (variants) ----\n",
        "styles = [\"-\", \"--\", \"-.\", \":\"]\n",
        "for k, style in zip(level1_variants, styles):\n",
        "    acc = loaded_dicts[k][\"net_acc\"]\n",
        "    epochs = range(offset, offset + len(acc))\n",
        "    plt.plot(epochs, acc, linestyle=style, label=k.replace(\"_metrics.json\", \"\"))\n",
        "\n",
        "# assume same length → move offset once\n",
        "offset += len(acc)\n",
        "\n",
        "# ---- Levels 2–4 ----\n",
        "for k in class_levels[2:]:\n",
        "    acc = loaded_dicts[k][\"net_acc\"]\n",
        "    epochs = range(offset, offset + len(acc))\n",
        "    plt.plot(epochs, acc, label=k.replace(\"_metrics.json\", \"\"))\n",
        "    offset += len(acc)\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Classifier training – Level 1 variants comparison\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1223040a",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series={\n",
        "        \"Gen_Level1\": loaded_dicts[\"gan_level1_metrics_gan.json\"][\"g_losses_epoch\"],\n",
        "        \"Disc_Level1\": loaded_dicts[\"gan_level1_metrics_gan.json\"][\"d_losses_epoch\"],\n",
        "        \"Gen_Level2\": loaded_dicts[\"gan_level2_metrics.json\"][\"g_losses_epoch\"],\n",
        "        \"Disc_Level2\": loaded_dicts[\"gan_level2_metrics.json\"][\"d_losses_epoch\"],\n",
        "        \"Gen_Level3\": loaded_dicts[\"gan_level3_metrics.json\"][\"g_losses_epoch\"],\n",
        "        \"Disc_Level3\": loaded_dicts[\"gan_level3_metrics.json\"][\"d_losses_epoch\"],\n",
        "        \"Gen_Level4\": loaded_dicts[\"gan_level4_metrics.json\"][\"g_losses_epoch\"],\n",
        "        \"Disc_Level4\": loaded_dicts[\"gan_level4_metrics.json\"][\"d_losses_epoch\"],\n",
        "        },\n",
        "        series_styles={\n",
        "            \"Gen_Level1\": {\"color\": \"C0\"}\n",
        "        }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "678a85d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks1_ganepoch40_fleg_trial1_metrics.json\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f4efe4a",
      "metadata": {},
      "source": [
        "##### Current"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "8eeb5495",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving plot to ./FLEG_lvls.pdf\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_series(\n",
        "    series={\n",
        "        \"FLEG\": loaded_dicts[\"cifar10_Dir01_fedavg_numchunks100_ganepoch30_fleg_trial3_metrics.json\"][\"net_acc\"],\n",
        "        \"FedAvg\": loaded_dicts[\"cifar10_Dir01_fedavg_numchunks100_ganepoch25_baseline_trial2_metrics.json\"][\"net_acc\"],\n",
        "    },\n",
        "    series_styles={\n",
        "        \"FLEG\": {\"color\": \"navy\", \"linewidth\": 3},\n",
        "        \"FedAvg\": {\"color\": \"indianred\", \"linewidth\": 3}\n",
        "    },\n",
        "    figsize = (20,4),\n",
        "    level_markers={\n",
        "        \"L1\": 37,\n",
        "        \"L2\": 55,\n",
        "        \"L3\": 67,\n",
        "        \"L4\": 78\n",
        "    },\n",
        "    num_xticks=5,\n",
        "\n",
        "    label_fontsize=22,\n",
        "    tick_fontsize=18,\n",
        "    legend_fontsize=20,\n",
        "\n",
        "    ylabel=\"Accuracy\",\n",
        "\n",
        "    save=True,\n",
        "    plot_name=\"./FLEG_lvls.pdf\"\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0de7dca7",
      "metadata": {},
      "source": [
        "#### General Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fde31d7f",
      "metadata": {},
      "source": [
        "##### Automatic series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba4e04b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5015ae54",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27df01f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "pattern = re.compile(\n",
        "    r\"(cifar10|mnist)_\" \n",
        "    r\"(ClassPartitioner|Dir\\d{2})_\"\n",
        "    r\"fedavg_numchunks(\\d+)\"\n",
        "    r\"_ganepoch(\\d+)_\"\n",
        "    r\"(fixed_|)\"\n",
        "    r\"(fleg|baseline)_\"\n",
        "    r\"trial(\\d+)\"\n",
        ")\n",
        "\n",
        "records = []\n",
        "\n",
        "for key, data in loaded_dicts.items():\n",
        "    m = pattern.search(key) \n",
        "    if not m:\n",
        "        continue\n",
        "    dataset, partitioner, numchunks, ganepochs, num_syn, method, _ = m.groups()\n",
        "    records.append({\n",
        "        \"dataset\": dataset,\n",
        "        \"partitioner\": partitioner,\n",
        "        \"numchunks\": int(numchunks),\n",
        "        \"ganepochs\": int(ganepochs),\n",
        "        \"num_syn\": num_syn,\n",
        "        \"method\": method,\n",
        "        \"values\": np.array(data[\"net_acc\"]),\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72455751",
      "metadata": {},
      "source": [
        "###### With mean trials calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "570e6565",
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bf8cc3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "groups = defaultdict(list)\n",
        "\n",
        "for r in records:\n",
        "    k = (\n",
        "        r[\"dataset\"],\n",
        "        r[\"partitioner\"],\n",
        "        r[\"numchunks\"],\n",
        "        r[\"ganepoch\"],\n",
        "        r[\"num_syn\"]\n",
        "    )\n",
        "    groups[k].append(r)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e72b37d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def select_median_top_trial(trials):\n",
        "    \"\"\"\n",
        "    trials: list of dicts with key 'values'\n",
        "    returns: list with best acc and selected trial dict\n",
        "    \"\"\"\n",
        "    # Compute top accuracy for each trial\n",
        "    scored = [\n",
        "        (np.max(t[\"values\"]), t, t[\"time\"]/60.0) \n",
        "        for t in trials\n",
        "    ]\n",
        "\n",
        "    # Sort by top accuracy\n",
        "    scored.sort(key=lambda x: x[0])\n",
        "\n",
        "    # Pick median\n",
        "    median_idx = len(scored) // 2\n",
        "    return scored[median_idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f217229",
      "metadata": {},
      "outputs": [],
      "source": [
        "series_to_plot = {}\n",
        "\n",
        "for (dataset, part, numchunks, ganepoch), trials in groups.items():\n",
        "    chosen = select_median_top_trial(trials)[1]\n",
        "\n",
        "    label = (\n",
        "        f\"{dataset.upper()} \"\n",
        "        f\"{numchunks if numchunks > 1 else 'No'}Chunks \"\n",
        "        f\"{ganepoch}eGAN\"\n",
        "    )\n",
        "\n",
        "    series_to_plot[label] = chosen[\"values\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "750cb4ec",
      "metadata": {},
      "source": [
        "###### calculating best accuracies for each combination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be40f288",
      "metadata": {},
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "for (dataset, partitioner, numchunks, ganepoch, num_syn), trials in groups.items():\n",
        "\n",
        "    best_acc, trial, time = select_median_top_trial(trials)\n",
        "\n",
        "    results.append({\n",
        "        \"dataset\": dataset,\n",
        "        \"partitioner\": partitioner,\n",
        "        \"numchunks\": numchunks,\n",
        "        \"ganepoch\": ganepoch,\n",
        "        \"num_syn\": \"Fixed\" if num_syn == \"fixed_\" else \"Dynamic\",\n",
        "        \"best_accuracy\": float(best_acc),\n",
        "        \"time (min)\": time\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f69f3b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c5a0266",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75c12c75",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.sort_values(\n",
        "    [\"dataset\", \"partitioner\", \"best_accuracy\"], ascending=[True, True, False]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f77576c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.style.hide(axis=\"index\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2bce6e9",
      "metadata": {},
      "source": [
        "###### Without mean trial calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4260f8ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "series_to_plot = {}\n",
        "\n",
        "for serie in records:\n",
        "    fleg_details = \"\"\n",
        "    if serie['method'] == \"fleg\":\n",
        "        chunk_str = serie['numchunks'] if serie['numchunks'] > 1 else 'No'\n",
        "        fleg_details = (\n",
        "            f\"{chunk_str}Chunks \"\n",
        "            f\"{serie['ganepochs']}eGAN \"\n",
        "            f\"{serie['num_syn']} \"\n",
        "        )\n",
        "    label = f\"{serie['dataset'].upper()} {serie['partitioner']} {fleg_details}{serie['method']}\"\n",
        "    series_to_plot[label] = serie[\"values\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b3ff114",
      "metadata": {},
      "outputs": [],
      "source": [
        "series_to_plot.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7edb8ff",
      "metadata": {},
      "source": [
        "###### Subgroups and styles automation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df4536de",
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets = [\"cifar10\", \"mnist\"]\n",
        "partitioners = [\"ClassPartitioner\", \"Dir01\", \"Dir05\"]\n",
        "\n",
        "subplot_groups_to_plot = []\n",
        "\n",
        "for dataset in datasets:\n",
        "    for part in partitioners:\n",
        "        group = [\n",
        "            name for name in series_to_plot\n",
        "            if name.startswith(dataset.upper())\n",
        "            and part in name\n",
        "        ]\n",
        "        subplot_groups_to_plot.append(sorted(group))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e265c69b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# One color per dataset\n",
        "ganepoch_colors = {\n",
        "    20: \"#61ADE3FF\",  # blue\n",
        "    25: \"#7DC378FF\",\n",
        "    30: \"#c96060\",  # red\n",
        "    35: \"#e090da\",\n",
        "    40: \"#f4e26c\"\n",
        "\n",
        "}\n",
        "\n",
        "legend_labels = {}\n",
        "\n",
        "for serie in records:\n",
        "    if serie['method'] == \"fleg\":\n",
        "        if serie['numchunks'] == 1:\n",
        "            if serie['ganepochs'] == 40:\n",
        "                label[] = \"FLEG Eco2\"\n",
        "            else:\n",
        "                label = \"FLEG Eco\"\n",
        "        elif serie['numchunks'] == 10:\n",
        "            label = \"FLEG Smart\"\n",
        "        else:\n",
        "            label = \"FLEG Full\"\n",
        "    else:\n",
        "        label = \"Baseline\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a3242d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "series_styles_to_plot = {}\n",
        "\n",
        "for name in series_to_plot:\n",
        "    ganepoch = int(re.search(r\"(\\d+)eGAN\", name).group(1))\n",
        "\n",
        "    color = ganepoch_colors[ganepoch]\n",
        "\n",
        "    series_styles_to_plot[name] = {\n",
        "        \"color\": color,\n",
        "        \"linewidth\": 2.5,\n",
        "        \"alpha\": 0.9,\n",
        "        \"label\": f\"{ganepoch} GAN Epochs\"\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d692cd14",
      "metadata": {},
      "outputs": [],
      "source": [
        "column_titles = []\n",
        "numchunks_order = [1, 10, 50, 100, 200]\n",
        "\n",
        "# Cria títulos para a primeira linha (Top Row)\n",
        "for nc in numchunks_order:\n",
        "    title_text = f\"{nc} Chunks\" if nc > 1 else \"No Chunks (1)\"\n",
        "    column_titles.append(title_text)\n",
        "\n",
        "# Preenche o resto com None para a segunda linha (Bottom Row)\n",
        "# (Assumindo que temos 2 datasets = 2 linhas, total 10 plots)\n",
        "while len(column_titles) < 10:\n",
        "    column_titles.append(None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d90ca96",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series=series_to_plot,\n",
        "    subplot_groups = subplot_groups_to_plot,\n",
        "    # series_styles=series_styles_to_plot,\n",
        "\n",
        "    subplot_layout=(2,3),\n",
        "    figsize=(20,4),\n",
        "\n",
        "    # figure_title=\"c) ClassPartition\",\n",
        "    # figure_title_fontsize=14,\n",
        "    # figure_title_y=0.95,\n",
        "\n",
        "    # title=column_titles,\n",
        "    # title_fontsize=13,\n",
        "\n",
        "    row_labels=[\"CIFAR10\", \"MNIST\"],\n",
        "    row_label_fontsize=12,\n",
        "\n",
        "    xlabel=\"Epochs\", \n",
        "    ylabel=\"Accuracy\",\n",
        "    label_fontsize=12,\n",
        "\n",
        "    tick_fontsize=11,\n",
        "\n",
        "    ylim=[(0, 0.35), (0, 0.4), (0.3, 0.5)] + [(0.2, 1.), (0.75,1.), (0.95, 1.)],\n",
        "    num_yticks=3,\n",
        "\n",
        "    xlim=[(1, 100), (1, 100), (1, 150), (1, 100), (1, 115), (1, 100)],\n",
        "    x_ticks=[list(range(0, 101, 20)), list(range(0, 101, 20)), list(range(0, 151, 30)),\n",
        "             list(range(0, 101, 20)), list(range(0, 116, 23)), list(range(0, 101, 20))],\n",
        "\n",
        "    legend_fontsize=6,\n",
        "    legend_subplot_index=[0,1,2,3,4,5],\n",
        "    legend_loc=\"lower right\",\n",
        "\n",
        "    legend_kwargs={\n",
        "        \"frameon\": False,\n",
        "        \"bbox_to_anchor\": (1.01, 0.0001),\n",
        "        \"borderpad\": 0.0001 ,\n",
        "        \"ncol\": 2 \n",
        "    },\n",
        "\n",
        "    # legend_kwargs={\n",
        "    #     \"ncol\": 2,\n",
        "    #     \"columnspacing\": 0.4,\n",
        "    #     \"handletextpad\": 0.2,\n",
        "    #     \"borderpad\": 0.1,\n",
        "    #     \"bbox_to_anchor\": (1.0114, 0.4),\n",
        "    #     \"handlelength\": 1,\n",
        "    #     \"labelspacing\": 0.3\n",
        "    # }\n",
        "    \n",
        "    save=False,\n",
        "    plot_name=\"../figures/GAN_epochs_Class.pdf\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac9fe90",
      "metadata": {},
      "source": [
        "##### Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1b7c692",
      "metadata": {},
      "source": [
        "##### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6adcde5d",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series={\n",
        "        \"Cifar10 Class FLEG Full\": loaded_dicts[\"cifar10_ClassPartitioner_fedavg_numchunks100_ganepoch30_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"Cifar10 Class FLEG Smart\": loaded_dicts[\"cifar10_ClassPartitioner_fedavg_numchunks10_ganepoch35_fleg_trial3_metrics.json\"][\"net_acc\"],\n",
        "        \"Cifar10 Class FLEG Eco\": loaded_dicts[\"cifar10_ClassPartitioner_fedavg_numchunks1_ganepoch25_fleg_trial2_metrics.json\"][\"net_acc\"],\n",
        "        \"Cifar10 Class Baseline\": loaded_dicts[\"cifar10_ClassPartitioner_fedavg_numchunks100_ganepoch25_baseline_trial1_metrics.json\"][\"net_acc\"],\n",
        "\n",
        "        \"Cifar10 Dir01 FLEG Full\": loaded_dicts[\"cifar10_Dir01_fedavg_numchunks100_ganepoch30_fleg_trial3_metrics.json\"][\"net_acc\"],\n",
        "        \"Cifar10 Dir01 FLEG Smart\": loaded_dicts[\"cifar10_Dir01_fedavg_numchunks10_ganepoch35_fleg_trial3_metrics.json\"][\"net_acc\"],\n",
        "        \"Cifar10 Dir01 FLEG Eco\": loaded_dicts[\"cifar10_Dir01_fedavg_numchunks1_ganepoch25_fleg_trial2_metrics.json\"][\"net_acc\"],\n",
        "        \"Cifar10 Dir01 Baseline\": loaded_dicts[\"cifar10_Dir01_fedavg_numchunks100_ganepoch25_baseline_trial2_metrics.json\"][\"net_acc\"],\n",
        "\n",
        "        \"Cifar10 Dir05 FLEG Full\": loaded_dicts[\"cifar10_Dir05_fedavg_numchunks50_ganepoch25_fixed_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"Cifar10 Dir05 FLEG Smart\": loaded_dicts[\"cifar10_Dir05_fedavg_numchunks10_ganepoch25_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"Cifar10 Dir05 FLEG Eco\": loaded_dicts[\"cifar10_Dir05_fedavg_numchunks1_ganepoch25_fleg_trial3_metrics.json\"][\"net_acc\"],\n",
        "        #\"Cifar10 Dir05 FLEG Eco2\": loaded_dicts[\"cifar10_Dir05_fedavg_numchunks1_ganepoch40_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"Cifar10 Dir05 Baseline\": loaded_dicts[\"cifar10_Dir05_fedavg_numchunks100_ganepoch25_baseline_trial1_metrics.json\"][\"net_acc\"],\n",
        "\n",
        "\n",
        "        \"Mnist Class FLEG Full\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks100_ganepoch25_fleg_trial3_metrics.json\"][\"net_acc\"],\n",
        "        \"Mnist Class FLEG Smart\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks10_ganepoch25_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"Mnist Class FLEG Eco\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks1_ganepoch25_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"Mnist Class Baseline\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks100_ganepoch25_baseline_trial3_metrics.json\"][\"net_acc\"],\n",
        "\n",
        "        \"Mnist Dir01 FLEG Full\": loaded_dicts[\"mnist_Dir01_fedavg_numchunks100_ganepoch25_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"Mnist Dir01 FLEG Smart\": loaded_dicts[\"mnist_Dir01_fedavg_numchunks10_ganepoch25_fleg_trial3_metrics.json\"][\"net_acc\"],\n",
        "        \"Mnist Dir01 FLEG Eco\": loaded_dicts[\"mnist_Dir01_fedavg_numchunks1_ganepoch25_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"Mnist Dir01 Baseline\": loaded_dicts[\"mnist_Dir01_fedavg_numchunks100_ganepoch25_baseline_trial3_metrics.json\"][\"net_acc\"],\n",
        "\n",
        "        \"Mnist Dir05 FLEG Full\": loaded_dicts[\"mnist_Dir05_fedavg_numchunks100_ganepoch20_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"Mnist Dir05 FLEG Smart/Eco\": loaded_dicts[\"mnist_Dir05_fedavg_numchunks1_ganepoch25_fleg_trial2_metrics.json\"][\"net_acc\"],\n",
        "        \"Mnist Dir05 Baseline\": loaded_dicts[\"mnist_Dir05_fedavg_numchunks100_ganepoch25_baseline_trial3_metrics.json\"][\"net_acc\"],\n",
        "    },\n",
        "\n",
        "    subplot_groups = [\n",
        "        [\"Cifar10 Class FLEG Full\", \"Cifar10 Class FLEG Smart\", \"Cifar10 Class FLEG Eco\", \"Cifar10 Class Baseline\"],\n",
        "        [\"Cifar10 Dir01 FLEG Full\", \"Cifar10 Dir01 FLEG Smart\", \"Cifar10 Dir01 FLEG Eco\", \"Cifar10 Dir01 Baseline\"],\n",
        "        [\"Cifar10 Dir05 FLEG Full\", \"Cifar10 Dir05 FLEG Smart\",\"Cifar10 Dir05 FLEG Eco\",  \"Cifar10 Dir05 Baseline\"],\n",
        "\n",
        "        [\"Mnist Class FLEG Full\", \"Mnist Class FLEG Smart\", \"Mnist Class FLEG Eco\", \"Mnist Class Baseline\"],\n",
        "        [\"Mnist Dir01 FLEG Full\", \"Mnist Dir01 FLEG Smart\", \"Mnist Dir01 FLEG Eco\", \"Mnist Dir01 Baseline\"],\n",
        "        [\"Mnist Dir05 FLEG Full\", \"Mnist Dir05 FLEG Smart/Eco\", \"Mnist Dir05 Baseline\"],\n",
        "        \n",
        "    ],\n",
        "    series_styles={\n",
        "        \"Cifar10 Class FLEG Full\": {\"color\": \"navy\", \"label\": \"FLEG Full\"},\n",
        "        \"Cifar10 Class FLEG Smart\": {\"color\": \"cornflowerblue\", \"label\": \"FLEG Smart\"},\n",
        "        \"Cifar10 Class FLEG Eco\": {\"color\": \"deepskyblue\", \"label\": \"FLEG Eco\"},\n",
        "        \"Cifar10 Class Baseline\": {\"color\": \"indianred\", \"label\": \"FedAvg\"},\n",
        "\n",
        "        \"Cifar10 Dir01 FLEG Full\": {\"color\": \"navy\", \"label\": \"FLEG Full\"},\n",
        "        \"Cifar10 Dir01 FLEG Smart\": {\"color\": \"cornflowerblue\", \"label\": \"FLEG Smart\"},\n",
        "        \"Cifar10 Dir01 FLEG Eco\": {\"color\": \"deepskyblue\", \"label\": \"FLEG Eco\"},\n",
        "        \"Cifar10 Dir01 Baseline\": {\"color\": \"indianred\", \"label\": \"FedAvg\"},\n",
        "\n",
        "        \"Cifar10 Dir05 FLEG Full\": {\"color\": \"navy\", \"label\": \"FLEG Full\"},\n",
        "        \"Cifar10 Dir05 FLEG Smart\": {\"color\": \"cornflowerblue\", \"label\": \"FLEG Smart\"},\n",
        "        \"Cifar10 Dir05 FLEG Eco\": {\"color\": \"deepskyblue\", \"label\": \"FLEG Eco\"},\n",
        "        #\"Cifar10 Dir05 FLEG Eco2\": {\"color\": \"lightskyblue\", \"label\": \"FLEG Eco2\"},\n",
        "        \"Cifar10 Dir05 Baseline\": {\"color\": \"indianred\", \"label\": \"FedAvg\"},\n",
        "\n",
        "\n",
        "        \"Mnist Class FLEG Full\": {\"color\": \"navy\", \"label\": \"FLEG Full\"},\n",
        "        \"Mnist Class FLEG Smart\":{\"color\": \"cornflowerblue\", \"label\": \"FLEG Smart\"},\n",
        "        \"Mnist Class FLEG Eco\": {\"color\": \"deepskyblue\", \"label\": \"FLEG Eco\"},\n",
        "        \"Mnist Class Baseline\": {\"color\": \"indianred\", \"label\": \"FedAvg\"},\n",
        "\n",
        "        \"Mnist Dir01 FLEG Full\": {\"color\": \"navy\", \"label\": \"FLEG Full\"},\n",
        "        \"Mnist Dir01 FLEG Smart\":{\"color\": \"cornflowerblue\", \"label\": \"FLEG Smart\"},\n",
        "        \"Mnist Dir01 FLEG Eco\": {\"color\": \"deepskyblue\", \"label\": \"FLEG Eco\"},\n",
        "        \"Mnist Dir01 Baseline\": {\"color\": \"indianred\", \"label\": \"FedAvg\"},\n",
        "\n",
        "        \"Mnist Dir05 FLEG Full\": {\"color\": \"navy\", \"label\": \"FLEG Full\"},\n",
        "        \"Mnist Dir05 FLEG Smart/Eco\": {\"color\": \"dodgerblue\", \"label\": \"FLEG Smart/Eco\"},\n",
        "        \"Mnist Dir05 Baseline\": {\"color\": \"indianred\", \"label\": \"FedAvg\"},\n",
        "    },\n",
        "\n",
        "    subplot_layout=(2,3),\n",
        "    figsize=(20,5),\n",
        "\n",
        "    # figure_title=\"a) FLEG & FedAvg\",\n",
        "    # figure_title_fontsize=14,\n",
        "    # figure_title_y=0.95,\n",
        "\n",
        "    title=[\"ClassPartition\", \"Dir01\", \"Dir05\", \"\",\"\",\"\"],\n",
        "    title_fontsize=18,\n",
        "\n",
        "    row_labels=[\"CIFAR10\", \"MNIST\"],\n",
        "    row_label_fontsize=14,\n",
        "\n",
        "    xlabel=\"Epochs\", \n",
        "    ylabel=\"Accuracy\",\n",
        "    label_fontsize=16,\n",
        "\n",
        "    tick_fontsize=14,\n",
        "\n",
        "    ylim=[(0, 0.35), (0, 0.4), (0.3, 0.5)] + [(0.2, 1.), (0.75,1.), (0.95, 1.)],\n",
        "    num_yticks=3,\n",
        "\n",
        "    xlim=[(1, 100), (1, 100), (1, 150), (1, 100), (1, 115), (1, 100)],\n",
        "    x_ticks=[list(range(0, 101, 20)), list(range(0, 101, 20)), list(range(0, 151, 30)),\n",
        "             list(range(0, 101, 20)), list(range(0, 116, 23)), list(range(0, 101, 20))],\n",
        "\n",
        "    legend_fontsize=13,\n",
        "    legend_subplot_index=[0,1,2,3,4,5],\n",
        "    legend_loc=\"lower center\",\n",
        "    legend_kwargs={\"frameon\": False, \"bbox_to_anchor\": (0.515, 0.05),\"ncol\": 4, \"borderaxespad\": 0.0001,\n",
        "                    \"columnspacing\": 1,\"handlelength\": 1,\"labelspacing\": 0.1,\"handletextpad\": 0.2},\n",
        "    \n",
        "    save=True,\n",
        "    plot_name=\"../figures/FLEG_FedAVG.pdf\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb00efe3",
      "metadata": {},
      "source": [
        "##### Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20698704",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ea60ee5",
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_values = {}\n",
        "\n",
        "for key, data in loaded_dicts.items():\n",
        "    if 'baseline' in key:\n",
        "        net_acc_length = len(data.get('net_acc', []))\n",
        "        \n",
        "        if 'cifar10' in key:\n",
        "            value = min(150, net_acc_length) * 0.25\n",
        "        elif 'mnist' in key:\n",
        "            value = min(150, net_acc_length) * 0.18\n",
        "        \n",
        "        baseline_values[key] = value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0e98b4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Define the Regex Pattern\n",
        "pattern = re.compile(\n",
        "    r\"(cifar10|mnist)_\" \n",
        "    r\"(ClassPartitioner|Dir\\d{2})_\"\n",
        "    r\"fedavg_numchunks(\\d+)\"\n",
        "    r\"_ganepoch(\\d+)_\"\n",
        "    r\"(fixed_|)\"\n",
        "    r\"(fleg|baseline)_\"\n",
        "    r\"trial(\\d+)\"\n",
        ")\n",
        "\n",
        "# 2. Setup Figure\n",
        "# (2 rows for datasets, 3 columns for partitions)\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 4), constrained_layout=True)\n",
        "\n",
        "# Define dataset and partition order\n",
        "datasets = [\"cifar10\", \"mnist\"]\n",
        "partitions = [\"ClassPartition\", \"Dir01\", \"Dir05\"]\n",
        "\n",
        "# Generate a color palette for the levels\n",
        "# Assuming max 10 levels, adjust if needed\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, 5)) \n",
        "\n",
        "# 3. Iteration and Plotting\n",
        "for i, dataset in enumerate(datasets):\n",
        "    for j, partition in enumerate(partitions):\n",
        "        ax = axes[i, j]\n",
        "        ax.set_yscale('log')\n",
        "        ax.tick_params(axis='y', labelsize=11)\n",
        "        if i == 0:\n",
        "            ax.set_title(f\"{partition}\", fontsize=13)\n",
        "\n",
        "        if j == 2:\n",
        "            ax.text(\n",
        "                    1.01, 0.5, dataset.upper(),  # x=1.05 (slightly outside right), y=0.5 (center)\n",
        "                    transform=ax.transAxes,      # Coordinates relative to the subplot\n",
        "                    rotation=270,                # Vertical rotation\n",
        "                    ha='left', \n",
        "                    va='center',\n",
        "                    fontsize=11,\n",
        "                    fontweight='bold'            # Optional: make it bold to distinguish from data\n",
        "                )\n",
        "        \n",
        "        # Filter relevant keys for this subplot\n",
        "        subplot_keys = []\n",
        "        for key in loaded_dicts:\n",
        "            match = pattern.match(key)\n",
        "            if match:\n",
        "                key_dataset = match.group(1)\n",
        "                key_partition = match.group(2)\n",
        "                if j in [1,2]:\n",
        "                    if key_dataset == dataset and key_partition == partition:\n",
        "                        subplot_keys.append(key)\n",
        "                else:\n",
        "                    if key_dataset == dataset and key_partition == f\"{partition}er\":\n",
        "                        subplot_keys.append(key)\n",
        "\n",
        "        \n",
        "        # Sort keys to keep order consistent (e.g. by numchunks, then type)\n",
        "        subplot_keys.sort(key=lambda x: (\n",
        "            0 if \"baseline\" in x else 1,                  # Rule 1: Baseline first\n",
        "            int(pattern.match(x).group(3)),             \n",
        "            int(pattern.match(x).group(4))               \n",
        "        ))\n",
        "        \n",
        "        # Plot bars\n",
        "        for idx, key in enumerate(subplot_keys):\n",
        "            match = pattern.match(key)\n",
        "            exp_type = match.group(6) # 'fleg' or 'baseline'\n",
        "            \n",
        "            if exp_type == 'fleg':\n",
        "                # Get the list of transmission costs per level\n",
        "                data = loaded_dicts[key].get('MB_transmission', [])\n",
        "                \n",
        "                # Stacked Bar Plot\n",
        "                bottom = 0\n",
        "                for level_idx, val in enumerate(data):\n",
        "                    # Use modulo for colors in case there are many levels\n",
        "                    color = colors[level_idx % len(colors)]\n",
        "                    ax.bar(idx, val/1000, bottom=bottom, color=color, edgecolor='white', width=0.8)\n",
        "                    bottom += val/1000\n",
        "                    \n",
        "            elif exp_type == 'baseline':\n",
        "                # Solid Bar Plot\n",
        "                # Retrieve the value from your baseline list/dict\n",
        "                # (Assuming baseline_values is a dict mapping key -> value)\n",
        "                val = baseline_values.get(key, 0)\n",
        "                ax.bar(idx, val/1000, color='gray', hatch='//', edgecolor='black', width=0.8)\n",
        "\n",
        "        # X-Axis formatting\n",
        "        ax.set_xticks(range(len(subplot_keys)))\n",
        "        # Create short labels (e.g., C5-T1 for Chunks=5, Trial=1)\n",
        "        labels = []\n",
        "        for key in subplot_keys:\n",
        "            m = pattern.match(key)\n",
        "            if m.group(6) == \"fleg\":\n",
        "                if int(m.group(3)) == 1:\n",
        "                    # if int(m.group(4)) == 40:\n",
        "                    #     short_label = \"FLEG Eco2\"\n",
        "                    # else:\n",
        "                    if j==2 and i==1:\n",
        "                        short_label = \"FLEG Smart/Eco\"\n",
        "                    else:\n",
        "                        short_label = \"FLEG Eco\"\n",
        "                elif int(m.group(3)) == 10:\n",
        "                    short_label = \"FLEG Smart\"\n",
        "                else:\n",
        "                    short_label = \"FLEG Full\"\n",
        "            else:\n",
        "                short_label = \"Baseline\"\n",
        "            labels.append(short_label)\n",
        "        ax.set_xticklabels(labels, rotation=0, fontsize=12)\n",
        "        \n",
        "        if j == 0:\n",
        "            ax.set_ylabel(\"GB Transmitted\", fontsize=12)\n",
        "        \n",
        "\n",
        "# Create a custom legend for the whole figure\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [Patch(facecolor=colors[k], label=f'Level {k}') for k in range(5)] # Adjust range\n",
        "legend_elements.append(Patch(facecolor='gray', hatch='//', label='Baseline'))\n",
        "fig.legend(handles=legend_elements, loc='lower right', bbox_to_anchor=(0.77, 0.096), frameon=False, fontsize=11)\n",
        "plt.savefig(\"../figures/comm_cost.pdf\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e535fd4",
      "metadata": {},
      "source": [
        "##### Time/Computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "662b7f01",
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib.lines import Line2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a813bf7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Define the Regex Pattern\n",
        "pattern = re.compile(\n",
        "    r\"(cifar10|mnist)_\" \n",
        "    r\"(ClassPartitioner|Dir\\d{2})_\"\n",
        "    r\"fedavg_numchunks(\\d+)\"\n",
        "    r\"_ganepoch(\\d+)_\"\n",
        "    r\"(fixed_|)\"\n",
        "    r\"(fleg|baseline)_\"\n",
        "    r\"trial(\\d+)\"\n",
        ")\n",
        "\n",
        "# 2. Setup Figure\n",
        "# (2 rows for datasets, 3 columns for partitions)\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 4), constrained_layout=True)\n",
        "\n",
        "# Define dataset and partition order\n",
        "datasets = [\"cifar10\", \"mnist\"]\n",
        "partitions = [\"ClassPartition\", \"Dir01\", \"Dir05\"]\n",
        "\n",
        "# Generate a color palette for the levels\n",
        "# Assuming max 10 levels, adjust if needed\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, 5)) \n",
        "\n",
        "# 3. Iteration and Plotting\n",
        "for i, dataset in enumerate(datasets):\n",
        "    for j, partition in enumerate(partitions):\n",
        "        ax = axes[i, j]\n",
        "        # ax.set_yscale('log')\n",
        "        ax.tick_params(axis='y', labelsize=11)\n",
        "        if i == 0:\n",
        "            ax.set_title(f\"{partition}\", fontsize=13)\n",
        "\n",
        "        if j == 2:\n",
        "            ax.text(\n",
        "                    1.01, 0.5, dataset.upper(),  # x=1.05 (slightly outside right), y=0.5 (center)\n",
        "                    transform=ax.transAxes,      # Coordinates relative to the subplot\n",
        "                    rotation=270,                # Vertical rotation\n",
        "                    ha='left', \n",
        "                    va='center',\n",
        "                    fontsize=11,\n",
        "                    fontweight='bold'            # Optional: make it bold to distinguish from data\n",
        "                )\n",
        "        \n",
        "        # Filter relevant keys for this subplot\n",
        "        subplot_keys = []\n",
        "        for key in loaded_dicts:\n",
        "            match = pattern.match(key)\n",
        "            if match:\n",
        "                key_dataset = match.group(1)\n",
        "                key_partition = match.group(2)\n",
        "                if j in [1,2]:\n",
        "                    if key_dataset == dataset and key_partition == partition:\n",
        "                        subplot_keys.append(key)\n",
        "                else:\n",
        "                    if key_dataset == dataset and key_partition == f\"{partition}er\":\n",
        "                        subplot_keys.append(key)\n",
        "        \n",
        "        # Sort keys to keep order consistent (e.g. by numchunks, then type)\n",
        "        subplot_keys.sort(key=lambda x: (\n",
        "            0 if \"baseline\" in x else 1,                  # Rule 1: Baseline first\n",
        "            int(pattern.match(x).group(3)),              \n",
        "            int(pattern.match(x).group(4))                \n",
        "        ))\n",
        "        \n",
        "        # Plot bars\n",
        "        for idx, key in enumerate(subplot_keys):\n",
        "            match = pattern.match(key)\n",
        "            exp_type = match.group(6) # 'fleg' or 'baseline'\n",
        "            \n",
        "            # Get the list of transmission costs per level\n",
        "            data = loaded_dicts[key].get('time_level', [])\n",
        "            max_epochs = loaded_dicts[key].get('time_epoch_classifier', [])\n",
        "            \n",
        "            # Stacked Bar Plot\n",
        "            bottom = 0\n",
        "            for level_idx, val in enumerate(data):\n",
        "                # Use modulo for colors in case there are many levels\n",
        "                color = colors[level_idx % len(colors)]\n",
        "                if exp_type == 'fleg':\n",
        "                    ax.bar(idx, val/60, bottom=bottom, color=color, edgecolor='white', width=0.8)\n",
        "                elif exp_type == 'baseline':\n",
        "                    ax.bar(idx, val/60, color='gray', hatch='//', edgecolor='black', width=0.8)\n",
        "                    ax.hlines(sum(max_epochs[:150])/60, xmin=-0.4, xmax=0.4, colors=\"indianred\")\n",
        "                bottom += val/60\n",
        "                    \n",
        "\n",
        "        # X-Axis formatting\n",
        "        ax.set_xticks(range(len(subplot_keys)))\n",
        "        # Create short labels (e.g., C5-T1 for Chunks=5, Trial=1)\n",
        "        labels = []\n",
        "        for key in subplot_keys:\n",
        "            m = pattern.match(key)\n",
        "            if m.group(6) == \"fleg\":\n",
        "                if int(m.group(3)) == 1:\n",
        "                    # if int(m.group(4)) == 40:\n",
        "                    #     short_label = \"FLEG Eco2\"\n",
        "                    # else:\n",
        "                    if j==2 and i==1:\n",
        "                        short_label = \"FLEG Smart/Eco\"\n",
        "                    else:\n",
        "                        short_label = \"FLEG Eco\"\n",
        "                elif int(m.group(3)) == 10:\n",
        "                    short_label = \"FLEG Smart\"\n",
        "                else:\n",
        "                    short_label = \"FLEG Full\"\n",
        "            else:\n",
        "                short_label = \"Baseline\"\n",
        "            labels.append(short_label)\n",
        "        ax.set_xticklabels(labels, rotation=0, fontsize=12)\n",
        "        \n",
        "        if j == 0:\n",
        "            ax.set_ylabel(\"Time (min)\", fontsize=12)\n",
        "        \n",
        "\n",
        "# Create a custom legend for the whole figure\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [Patch(facecolor=colors[k], label=f'Level {k}') for k in range(5)] # Adjust range\n",
        "legend_elements.append(Patch(facecolor='gray', hatch='//', label='Baseline'))\n",
        "legend_elements.append(Line2D([0], [0], color='indianred', lw=2, linestyle='-', label='<= 150 epochs'))\n",
        "fig.legend(handles=legend_elements, loc='lower right', bbox_to_anchor=(0.8999, 0.261), frameon=False, fontsize=11, ncols=3)\n",
        "plt.savefig(\"../figures/time_cost.pdf\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b379c599",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Regex Pattern\n",
        "pattern = re.compile(\n",
        "    r\"(cifar10|mnist)_\" \n",
        "    r\"(ClassPartitioner|Dir\\d{2})_\"\n",
        "    r\"fedavg_numchunks(\\d+)\"\n",
        "    r\"_ganepoch(\\d+)_\"\n",
        "    r\"(fixed_|)\"\n",
        "    r\"(fleg|baseline)_\"\n",
        "    r\"trial(\\d+)\"\n",
        ")\n",
        "\n",
        "# 2. Helper Function to Calculate Cumulative Time\n",
        "def calculate_times_and_accs(exp_data, is_baseline):\n",
        "    \"\"\"\n",
        "    Returns (times, accuracies) lists.\n",
        "    \"\"\"\n",
        "    accs = exp_data.get('net_acc', [])\n",
        "    epoch_times = exp_data.get('time_epoch_classifier', [])\n",
        "    \n",
        "    # --- Case 1: Baseline ---\n",
        "    if is_baseline:\n",
        "        # Just simple cumulative sum of epoch times\n",
        "        times = np.cumsum(epoch_times).tolist()\n",
        "        return times, accs\n",
        "\n",
        "    # --- Case 2: FLEG (with GAN gaps) ---\n",
        "    transitions = exp_data.get('accuracy_transition', [])\n",
        "    time_levels = exp_data.get('time_level', [])\n",
        "    \n",
        "    calculated_times = []\n",
        "    current_cumulative_time = 0\n",
        "    current_epoch_idx = 0\n",
        "    \n",
        "    # Iterate through each level that has a transition (Levels 0 to 3 usually)\n",
        "    for i, target_acc in enumerate(transitions):\n",
        "        # 1. Find the index in net_acc where the level ended\n",
        "        found_idx = -1\n",
        "        # Search starting from where we left off\n",
        "        for k in range(current_epoch_idx, len(accs)):\n",
        "            # Use isclose for float safety, or strict equality if data is exact\n",
        "            if math.isclose(accs[k], target_acc, rel_tol=1e-9):\n",
        "                found_idx = k\n",
        "                break\n",
        "            \n",
        "        # 2. Accumulate Classifier Time for this specific level\n",
        "        level_classifier_time = 0\n",
        "        for k in range(current_epoch_idx, found_idx + 1):\n",
        "            t = epoch_times[k]\n",
        "            level_classifier_time += t\n",
        "            current_cumulative_time += t\n",
        "            calculated_times.append(current_cumulative_time)\n",
        "            \n",
        "        # 3. Add GAN Training Time (The Gap)\n",
        "        # Logic: time_level[i] is the total time for the level.\n",
        "        # GAN Time = Total Level Time - Classifier Time\n",
        "        if i < len(time_levels)-1:\n",
        "            total_level_duration = time_levels[i]\n",
        "            gan_time = total_level_duration - level_classifier_time\n",
        "            \n",
        "            # Ensure we don't subtract if data is noisy (min 0)\n",
        "            gan_time = max(0, gan_time)\n",
        "            \n",
        "            # Add the gap to the cumulative time tracker\n",
        "            current_cumulative_time += gan_time\n",
        "            # Note: We do NOT append to calculated_times here because \n",
        "            # no accuracy is recorded *during* the GAN training.\n",
        "            # The next point will simply start 'gan_time' seconds later.\n",
        "            \n",
        "        current_epoch_idx = found_idx + 1\n",
        "        \n",
        "    # 4. Process the Final Level (No GAN training after this)\n",
        "    # for k in range(current_epoch_idx, len(accs)):\n",
        "    #     t = epoch_times[k]\n",
        "    #     current_cumulative_time += t\n",
        "    #     calculated_times.append(current_cumulative_time)\n",
        "        \n",
        "    # Truncate accs to match times length if there was a mismatch in finding transitions\n",
        "    final_accs = accs[:len(calculated_times)]\n",
        "    \n",
        "    return calculated_times, final_accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe37dede",
      "metadata": {},
      "outputs": [],
      "source": [
        "ylim_settings = {\n",
        "    \"cifar10ClassPartitioner\": (0.0, 0.35), \n",
        "    \"cifar10Dir01\": (0., 0.4),\n",
        "    \"cifar10Dir05\": (0.3, 0.5),\n",
        "    \"mnistClassPartitioner\": (0.2, 1),\n",
        "    \"mnistDir01\": (0.75, 1),\n",
        "    \"mnistDir05\": (0.95, 1)\n",
        "}\n",
        "\n",
        "# 3. Plotting Setup\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 4), constrained_layout=True)\n",
        "datasets = [\"cifar10\", \"mnist\"]\n",
        "partitions = [\"ClassPartition\", \"Dir01\", \"Dir05\"]\n",
        "unique_legend_items = {}\n",
        "\n",
        "# 4. Main Loop\n",
        "for i, dataset in enumerate(datasets):\n",
        "    for j, partition in enumerate(partitions):\n",
        "        ax = axes[i, j]\n",
        "\n",
        "        if j in [1,2]:\n",
        "            ax.set_ylim(ylim_settings[f\"{dataset}{partition}\"])\n",
        "        else:\n",
        "            ax.set_ylim(ylim_settings[f\"{dataset}{partition}er\"])\n",
        "\n",
        "        ax.tick_params(axis='y', labelsize=11)\n",
        "        ax.tick_params(axis='x', labelsize=11)\n",
        "        \n",
        "        # Filter keys\n",
        "        subplot_keys = []\n",
        "        for key in loaded_dicts:\n",
        "            match = pattern.match(key)\n",
        "            if match:\n",
        "                if j in [1,2]:\n",
        "                    if match.group(1) == dataset and match.group(2) == partition:\n",
        "                        subplot_keys.append(key)\n",
        "                else:\n",
        "                    if match.group(1) == dataset and match.group(2) == f\"{partition}er\":\n",
        "                        subplot_keys.append(key)\n",
        "        \n",
        "        # Sort keys (Baseline first)\n",
        "        subplot_keys.sort(key=lambda x: (\n",
        "            0 if \"baseline\" in x else 1,\n",
        "            int(pattern.match(x).group(3)),\n",
        "            int(pattern.match(x).group(7))\n",
        "        ))\n",
        "        \n",
        "        # Plot Lines\n",
        "        for key in subplot_keys:\n",
        "            match = pattern.match(key)\n",
        "            exp_type = match.group(6)\n",
        "            is_baseline = (exp_type == 'baseline')\n",
        "            \n",
        "            # Extract data using the helper\n",
        "            times, accs = calculate_times_and_accs(loaded_dicts[key], is_baseline)\n",
        "            times_min = [t / 60.0 for t in times] \n",
        "            \n",
        "            # Generate Label\n",
        "            if is_baseline:\n",
        "                label = \"Baseline\"\n",
        "                color = \"indianred\"\n",
        "            else:\n",
        "                chunks = int(match.group(3))\n",
        "                gan_epoch = int(match.group(4))\n",
        "                # Custom Naming Logic\n",
        "                if chunks == 1:\n",
        "                    # if gan_epoch == 40:\n",
        "                    #     label = \"FLEG Eco2\" \n",
        "                    #     color = \"lightskyblue\"\n",
        "                    # else:\n",
        "                        label = \"FLEG Eco\"\n",
        "                        color = \"deepskyblue\"\n",
        "                        if dataset == \"mnist\" and partition == \"Dir05\":\n",
        "                            label = \"FLEG Smart/Eco\"\n",
        "                            color = \"dodgerblue\"\n",
        "                elif chunks == 10:\n",
        "                    label = \"FLEG Smart\"\n",
        "                    color = \"cornflowerblue\"\n",
        "                else:\n",
        "                    label = \"FLEG Full\"\n",
        "                    color = \"navy\"\n",
        "            \n",
        "            # Plot\n",
        "            # Using specific styles for Baseline vs FLEG to distinguish them visually\n",
        "            #linestyle = '--' if is_baseline else '-'\n",
        "            # alpha = 0.8 if is_baseline else 1.0\n",
        "            # linewidth = 2 if is_baseline else 1.5\n",
        "            \n",
        "            line, = ax.plot(times_min, accs, label=label, color=color)\n",
        "\n",
        "            unique_legend_items[label] = line\n",
        "\n",
        "        # Formatting\n",
        "        if dataset == \"cifar10\":\n",
        "            ax.set_title(f\"{partition}\", fontsize=13)\n",
        "        ax.grid(True, linestyle=':', alpha=0.6)\n",
        "        \n",
        "        if i == 1: # Bottom row\n",
        "            ax.set_xlabel(\"Time (Minutes)\", fontsize=12)\n",
        "        if j == 0: # Left column\n",
        "            ax.set_ylabel(\"Accuracy\", fontsize=12)\n",
        "\n",
        "        if j == 2:\n",
        "            ax.text(\n",
        "                    1.01, 0.5, dataset.upper(),  # x=1.05 (slightly outside right), y=0.5 (center)\n",
        "                    transform=ax.transAxes,      # Coordinates relative to the subplot\n",
        "                    rotation=270,                # Vertical rotation\n",
        "                    ha='left', \n",
        "                    va='center',\n",
        "                    fontsize=11,\n",
        "                    fontweight='bold'            # Optional: make it bold to distinguish from data\n",
        "                )\n",
        "\n",
        "label_order = [\"Baseline\", \"FLEG Eco\", \"FLEG Eco2\", \"FLEG Smart/Eco\", \"FLEG Smart\", \"FLEG Full\"]\n",
        "sorted_labels = sorted(unique_legend_items.keys(), key=lambda x: label_order.index(x) if x in label_order else 999)\n",
        "sorted_handles = [unique_legend_items[l] for l in sorted_labels]\n",
        "fig.legend(sorted_handles, sorted_labels, loc='lower right', bbox_to_anchor=(0.99, 0.1), fontsize=12, ncols=3, frameon=False)\n",
        "plt.savefig(\"../figures/accxtime.pdf\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5d66909",
      "metadata": {},
      "source": [
        "## Plot generator images per epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfa906d3",
      "metadata": {
        "id": "bfa906d3"
      },
      "outputs": [],
      "source": [
        "gen = F2U_GAN(condition=True).to(\"cpu\")\n",
        "checkpoint_loaded = torch.load(\"../Experimentos/NB_F2U/GeraFed_4c_01Dir/CIFAR/checkpoint_epoch100.pth\", map_location=\"cpu\")\n",
        "gen.load_state_dict(checkpoint_loaded[\"gen_state_dict\"])\n",
        "generate_plot(gen, \"cpu\", 50, latent_dim=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a95346fb",
      "metadata": {},
      "source": [
        "## Evaluate Times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3be75e38",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# A helper function to add labels on top of the bars\n",
        "def add_labels(rects, ax):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate(f'{height:.2f}', # Format the number to 2 decimal places\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center',\n",
        "                    va='bottom',\n",
        "                    fontsize=14) # Fontsize for the labels on bars\n",
        "\n",
        "# --- Main Code ---\n",
        "\n",
        "# Data for the bar plots\n",
        "labels = ['Classifier Training', 'Image Generation']\n",
        "first_epoch_a = [0.1, 0.02]\n",
        "last_epoch_a = [0.23, 0.3]\n",
        "first_epoch_b = [0.09, 0.03]\n",
        "last_epoch_b = [0.2, 0.42]\n",
        "\n",
        "# Setting the positions of the bars\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "# Creating the figure and subplots\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 12))\n",
        "\n",
        "# --- Font sizes ---\n",
        "title_fontsize = 18\n",
        "label_fontsize = 14\n",
        "tick_fontsize = 12\n",
        "legend_fontsize = 12\n",
        "\n",
        "# --- Barplot a) ---\n",
        "# Capture the bar containers in variables (rects1a, rects2a)\n",
        "rects1a = ax1.bar(x - width/2, first_epoch_a, width, label='First Epoch', color=\"cornflowerblue\")\n",
        "rects2a = ax1.bar(x + width/2, last_epoch_a, width, label='Last Epoch', color=\"sandybrown\")\n",
        "\n",
        "# Add titles and labels\n",
        "ax1.set_ylabel('Time (s)', fontsize=label_fontsize)\n",
        "ax1.set_title('a)', fontsize=title_fontsize)\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(labels, fontsize=label_fontsize)\n",
        "ax1.tick_params(axis='y', labelsize=tick_fontsize)\n",
        "ax1.legend(fontsize=legend_fontsize)\n",
        "\n",
        "# Add the labels on top of the bars\n",
        "add_labels(rects1a, ax1)\n",
        "add_labels(rects2a, ax1)\n",
        "\n",
        "# --- Barplot b) ---\n",
        "# Capture the bar containers in variables (rects1b, rects2b)\n",
        "rects1b = ax2.bar(x - width/2, first_epoch_b, width, label='First Epoch', color=\"cornflowerblue\")\n",
        "rects2b = ax2.bar(x + width/2, last_epoch_b, width, label='Last Epoch', color=\"sandybrown\")\n",
        "\n",
        "# Add titles and labels\n",
        "ax2.set_ylabel('Time (s)', fontsize=label_fontsize)\n",
        "ax2.set_title('b)', fontsize=title_fontsize)\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels(labels, fontsize=label_fontsize)\n",
        "ax2.tick_params(axis='y', labelsize=tick_fontsize)\n",
        "ax2.legend(fontsize=legend_fontsize)\n",
        "\n",
        "# Add the labels on top of the bars\n",
        "add_labels(rects1b, ax2)\n",
        "add_labels(rects2b, ax2)\n",
        "\n",
        "# Adjust y-axis limits to make space for the labels\n",
        "ax1.set_ylim(0, ax1.get_ylim()[1] * 1.1)\n",
        "ax2.set_ylim(0, ax2.get_ylim()[1] * 1.1)\n",
        "\n",
        "# Adjust the layout\n",
        "fig.tight_layout(pad=3.0)\n",
        "\n",
        "# Show the figure\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed4a97a6",
      "metadata": {},
      "source": [
        "## Network Traffic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7df05c2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_weights(net):\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "def get_weights_disc(net):\n",
        "    return [val.cpu().numpy() for key, val in net.state_dict().items() if 'discriminator' in key or 'label' in key]\n",
        "\n",
        "def get_weights_gen(net):\n",
        "    return [val.cpu().numpy() for key, val in net.state_dict().items() if 'generator' in key or 'label' in key]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54c58fd5",
      "metadata": {},
      "source": [
        "### FLEG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90647f23",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72371704",
      "metadata": {},
      "outputs": [],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56c92314",
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(\"../../FLEG/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8d9c575",
      "metadata": {},
      "outputs": [],
      "source": [
        "from task import(\n",
        "    ClassifierHead1,\n",
        "    ClassifierHead2,\n",
        "    ClassifierHead3,\n",
        "    ClassifierHead4,\n",
        "    ClassifierHead1_Cifar,\n",
        "    ClassifierHead2_Cifar,\n",
        "    ClassifierHead3_Cifar,\n",
        "    ClassifierHead4_Cifar,\n",
        "    ClassPartitioner,\n",
        "    EmbeddingGAN1,\n",
        "    EmbeddingGAN2,\n",
        "    EmbeddingGAN3,\n",
        "    EmbeddingGAN4,\n",
        "    EmbeddingGAN1_Cifar,\n",
        "    EmbeddingGAN2_Cifar,\n",
        "    EmbeddingGAN3_Cifar,\n",
        "    EmbeddingGAN4_Cifar,\n",
        "    EmbeddingPairDataset,\n",
        "    FeatureExtractor1,\n",
        "    FeatureExtractor2,\n",
        "    FeatureExtractor3,\n",
        "    FeatureExtractor4,\n",
        "    FeatureExtractor1_Cifar,\n",
        "    FeatureExtractor2_Cifar,\n",
        "    FeatureExtractor3_Cifar,\n",
        "    FeatureExtractor4_Cifar,\n",
        "    Net,\n",
        "    Net_Cifar,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec7c8f43",
      "metadata": {},
      "outputs": [],
      "source": [
        "net = Net()\n",
        "gan1 = EmbeddingGAN1()\n",
        "\n",
        "feat_ext1 = FeatureExtractor1()\n",
        "class_head1 = ClassifierHead1()\n",
        "gan2 = EmbeddingGAN2()\n",
        "\n",
        "feat_ext2 = FeatureExtractor2()\n",
        "class_head2 = ClassifierHead2()\n",
        "gan3 = EmbeddingGAN3()\n",
        "\n",
        "feat_ext3 = FeatureExtractor3()\n",
        "class_head3 = ClassifierHead3()\n",
        "gan4 = EmbeddingGAN4()\n",
        "\n",
        "feat_ext4 = FeatureExtractor4()\n",
        "class_head4 = ClassifierHead4()\n",
        "\n",
        "net_cifar = Net_Cifar()\n",
        "gan1_cifar = EmbeddingGAN1_Cifar()\n",
        "\n",
        "feat_ext1_cifar = FeatureExtractor1_Cifar()\n",
        "class_head1_cifar = ClassifierHead1_Cifar()\n",
        "gan2_cifar = EmbeddingGAN2_Cifar()\n",
        "\n",
        "feat_ext2_cifar = FeatureExtractor2_Cifar()\n",
        "class_head2_cifar = ClassifierHead2_Cifar()\n",
        "gan3_cifar = EmbeddingGAN3_Cifar()\n",
        "\n",
        "feat_ext3_cifar = FeatureExtractor3_Cifar()\n",
        "class_head3_cifar = ClassifierHead3_Cifar()\n",
        "gan4_cifar = EmbeddingGAN4_Cifar()\n",
        "\n",
        "feat_ext4_cifar = FeatureExtractor4_Cifar()\n",
        "class_head4_cifar = ClassifierHead4_Cifar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18245589",
      "metadata": {},
      "outputs": [],
      "source": [
        "net_params = get_weights(net)\n",
        "disc1_params = get_weights_disc(gan1)\n",
        "gen1_params = get_weights_gen(gan1)\n",
        "\n",
        "feat_ext1_params = get_weights(feat_ext1)\n",
        "class_head1_params = get_weights(class_head1)\n",
        "disc2_params = get_weights_disc(gan2)\n",
        "gen2_params = get_weights_gen(gan2)\n",
        "\n",
        "feat_ext2_params = get_weights(feat_ext2)\n",
        "class_head2_params = get_weights(class_head2)\n",
        "disc3_params = get_weights_disc(gan3)\n",
        "gen3_params = get_weights_gen(gan3)\n",
        "\n",
        "feat_ext3_params = get_weights(feat_ext3)\n",
        "class_head3_params = get_weights(class_head3)\n",
        "disc4_params = get_weights_disc(gan4)\n",
        "gen4_params = get_weights_gen(gan4)\n",
        "\n",
        "feat_ext4_params = get_weights(feat_ext4)\n",
        "class_head4_params = get_weights(class_head4)\n",
        "\n",
        "net_cifar_params = get_weights(net_cifar)\n",
        "disc1_cifar_params = get_weights_disc(gan1_cifar)\n",
        "gen1_cifar_params = get_weights_gen(gan1_cifar)\n",
        "\n",
        "feat_ext1_cifar_params = get_weights(feat_ext1_cifar)\n",
        "class_head1_cifar_params = get_weights(class_head1_cifar)\n",
        "disc2_cifar_params = get_weights_disc(gan2_cifar)\n",
        "gen2_cifar_params = get_weights_gen(gan2_cifar)\n",
        "\n",
        "feat_ext2_cifar_params = get_weights(feat_ext2_cifar)\n",
        "class_head2_cifar_params = get_weights(class_head2_cifar)\n",
        "disc3_cifar_params = get_weights_disc(gan3_cifar)\n",
        "gen3_cifar_params = get_weights_gen(gan3_cifar)\n",
        "\n",
        "feat_ext3_cifar_params = get_weights(feat_ext3_cifar)\n",
        "class_head3_cifar_params = get_weights(class_head3_cifar)\n",
        "disc4_cifar_params = get_weights_disc(gan4_cifar)\n",
        "gen4_cifar_params = get_weights_gen(gan4_cifar)\n",
        "\n",
        "feat_ext4_cifar_params = get_weights(feat_ext4_cifar)\n",
        "class_head4_cifar_params = get_weights(class_head4_cifar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9394878e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84b97698",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_model_size_mb(params, divisor=10**6):\n",
        "    buffer = io.BytesIO()\n",
        "    np.savez(buffer, *params)\n",
        "    return len(buffer.getvalue()) / divisor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15020846",
      "metadata": {},
      "source": [
        "### FedGenIA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fe472b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier_mnist = Net()\n",
        "classifier_cifar = Net_Cifar()\n",
        "GAN_MNIST = F2U_GAN()\n",
        "GAN_CIFAR = F2U_GAN_CIFAR()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "598a49cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier_mnist_params = get_weights(classifier_mnist)\n",
        "classifier_cifar_params = get_weights(classifier_cifar)\n",
        "GAN_MNIST_disc_params = get_weights_gen(GAN_MNIST)\n",
        "GAN_CIFAR_disc_params = get_weights_gen(GAN_CIFAR)\n",
        "GAN_MNIST_gen_params = [val.cpu().numpy() for key, val in GAN_MNIST.state_dict().items() if 'generator' in key or 'label' in key]\n",
        "GAN_CIFAR_gen_params = [val.cpu().numpy() for key, val in GAN_CIFAR.state_dict().items() if 'generator' in key or 'label' in key]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "016519d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cumulative step plot for upload/download traffic over rounds.\n",
        "import numpy as np\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b0672bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_model_size_mb(params, divisor=10**6):\n",
        "    buffer = io.BytesIO()\n",
        "    np.savez(buffer, *params)\n",
        "    return len(buffer.getvalue()) / divisor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d83f0db2",
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier_mnist_MB = get_model_size_mb(classifier_mnist_params)\n",
        "classifier_cifar_MB = get_model_size_mb(classifier_cifar_params)\n",
        "disc_mnist_MB       = get_model_size_mb(GAN_MNIST_disc_params)\n",
        "disc_cifar_MB       = get_model_size_mb(GAN_CIFAR_disc_params)\n",
        "gen_mnist_MB        = get_model_size_mb(GAN_MNIST_gen_params)\n",
        "gen_cifar_MB        = get_model_size_mb(GAN_CIFAR_gen_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "015b4532",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "# Per-epoch traffic (GB)\n",
        "upload_per_epoch_gerafed_mnist = (classifier_mnist_MB + disc_mnist_MB)/10 #/1000 pra Giga e x100 por epoch por cause do chunk.\n",
        "download_per_epoch_gerafed_mnist = (classifier_mnist_MB + gen_mnist_MB)/10\n",
        "\n",
        "upload_per_epoch_gerafed_cifar = (classifier_cifar_MB + disc_cifar_MB)/10 #/1000 pra Giga e x100 por epoch por cause do chunk.\n",
        "download_per_epoch_gerafed_cifar = (classifier_cifar_MB + gen_cifar_MB)/10\n",
        "\n",
        "\n",
        "upload_per_epoch_chunkedfedavg_mnist = classifier_mnist_MB/10\n",
        "download_per_epoch_chunkedfedavg_mnist = classifier_mnist_MB/10\n",
        "\n",
        "upload_per_epoch_chunkedfedavg_cifar = classifier_cifar_MB/10\n",
        "download_per_epoch_chunkedfedavg_cifar = classifier_cifar_MB/10\n",
        "\n",
        "\n",
        "# Cumulative arrays with an initial 0 so the plot has horizontal lines before first epoch\n",
        "x = np.arange(0, epochs + 1)  # 0..epochs inclusive\n",
        "\n",
        "cum_upload_gerafed_mnist = np.insert(np.cumsum(np.full(epochs, upload_per_epoch_gerafed_mnist)), 0, 0)\n",
        "cum_download_gerafed_mnist = np.insert(np.cumsum(np.full(epochs, download_per_epoch_gerafed_mnist)), 0, 0)\n",
        "\n",
        "cum_upload_gerafed_cifar = np.insert(np.cumsum(np.full(epochs, upload_per_epoch_gerafed_cifar)), 0, 0)\n",
        "cum_download_gerafed_cifar = np.insert(np.cumsum(np.full(epochs, download_per_epoch_gerafed_cifar)), 0, 0)\n",
        "\n",
        "\n",
        "cum_upload_chunkedfedavg_mnist = np.insert(np.cumsum(np.full(epochs, upload_per_epoch_chunkedfedavg_mnist)), 0, 0)\n",
        "cum_download_chunkedfedavg_mnist = np.insert(np.cumsum(np.full(epochs, download_per_epoch_chunkedfedavg_mnist)), 0, 0)\n",
        "\n",
        "cum_upload_chunkedfedavg_cifar = np.insert(np.cumsum(np.full(epochs, upload_per_epoch_chunkedfedavg_cifar)), 0, 0)\n",
        "cum_download_chunkedfedavg_cifar = np.insert(np.cumsum(np.full(epochs, download_per_epoch_chunkedfedavg_cifar)), 0, 0)\n",
        "\n",
        "\n",
        "cum_upload_and_download_chunkedfedavg_mnist = cum_upload_chunkedfedavg_mnist + cum_download_chunkedfedavg_mnist\n",
        "\n",
        "cum_upload_and_download_chunkedfedavg_cifar = cum_upload_chunkedfedavg_cifar + cum_download_chunkedfedavg_cifar\n",
        "\n",
        "\n",
        "total_upload_GB_gerafed_mnist = cum_upload_gerafed_mnist[-1]\n",
        "total_download_GB_gerafed_mnist = cum_download_gerafed_mnist[-1]\n",
        "\n",
        "total_upload_GB_gerafed_cifar = cum_upload_gerafed_cifar[-1]\n",
        "total_download_GB_gerafed_cifar = cum_download_gerafed_cifar[-1]\n",
        "\n",
        "\n",
        "total_upload_GB_chunkedfedavg_mnist = cum_upload_chunkedfedavg_mnist[-1]\n",
        "total_download_GB_chunkedfedavg_mnist = cum_download_chunkedfedavg_mnist[-1]\n",
        "\n",
        "total_upload_GB_chunkedfedavg_cifar = cum_upload_chunkedfedavg_cifar[-1]\n",
        "total_download_GB_chunkedfedavg_cifar = cum_download_chunkedfedavg_cifar[-1]\n",
        "\n",
        "total_upload_and_download_chunkedfedavg_mnist = total_upload_GB_chunkedfedavg_mnist + total_download_GB_chunkedfedavg_mnist\n",
        "\n",
        "total_upload_and_download_chunkedfedavg_cifar = total_upload_GB_chunkedfedavg_cifar + total_download_GB_chunkedfedavg_cifar\n",
        "\n",
        "\n",
        "# Single step plot (cumulative). Using where='post' so the vertical jumps happen at integer epochs.\n",
        "plt.figure(figsize=(20, 3.8))\n",
        "\n",
        "plt.step(x, cum_upload_gerafed_mnist, where='post', label=\"FedGenIA upload\", color=\"palevioletred\", linestyle='--', linewidth=6)\n",
        "plt.step(x, cum_download_gerafed_mnist, where='post', label=\"FedGenIA download\", color=\"yellowgreen\", linestyle='--', linewidth=6)\n",
        "plt.step(x, cum_upload_and_download_chunkedfedavg_mnist, where='post', label=\"Chunked FedAvg upload and download\", color=\"cornflowerblue\", linewidth=6)\n",
        "\n",
        "# plt.step(x, cum_upload_gerafed_cifar, where='post', label=\"GeraFed upload\", color=\"cornflowerblue\")\n",
        "# plt.step(x, cum_download_gerafed_cifar, where='post', label=\"GeraFed download\", color=\"royalblue\")\n",
        "# plt.step(x, cum_upload_and_download_chunkedfedavg_cifar, where='post', label=\"Chunked FedAvg upload and download\", color=\"sandybrown\")\n",
        "\n",
        "# plt.step(x, cum_download_chunkedfedavg, where='post', label=\"Chunked FedAvg download\", color=\"peru\")\n",
        "plt.xlim(0, epochs)\n",
        "plt.xticks(np.arange(0, epochs+1, max(1, epochs//10)), fontsize=26)\n",
        "plt.yticks(fontsize=26)\n",
        "plt.xlabel(\"Epoch\", fontsize=28)\n",
        "plt.ylabel(\"Cumulative GB\", fontsize=28)\n",
        "plt.grid(True)\n",
        "plt.legend(fontsize=23, loc='lower right', ncol=3, handlelength=2.5, handleheight=1.5, handletextpad=0.7)\n",
        "plt.yscale(\"log\")\n",
        "plt.tight_layout()\n",
        "\n",
        "# Annotate final totals on the right side\n",
        "# plt.annotate(f\"{total_upload_GB_gerafed_mnist:.0f} GB\", xy=(epochs, total_upload_GB_gerafed_mnist),\n",
        "#              xytext=(epochs-5, total_upload_GB_gerafed_mnist + max(1, total_upload_GB_gerafed_mnist*0.02)),\n",
        "#              arrowprops=dict(arrowstyle=\"->\"), fontsize=14, va=\"bottom\")\n",
        "# plt.annotate(f\"{total_download_GB_gerafed_mnist:.0f} GB\", xy=(epochs, total_download_GB_gerafed_mnist),\n",
        "#              xytext=(epochs-5, total_download_GB_gerafed_mnist + max(1, total_download_GB_gerafed_mnist*0.02)),\n",
        "#              arrowprops=dict(arrowstyle=\"->\"), fontsize=12, va=\"bottom\")\n",
        "# plt.annotate(f\"{total_upload_and_download_chunkedfedavg_mnist:.0f} GB\", xy=(epochs, total_upload_and_download_chunkedfedavg_mnist),\n",
        "#              xytext=(epochs-5, total_upload_and_download_chunkedfedavg_mnist + max(1, total_upload_and_download_chunkedfedavg_mnist*0.02)),\n",
        "#              arrowprops=dict(arrowstyle=\"->\"), fontsize=9, va=\"bottom\")\n",
        "\n",
        "# plt.annotate(f\"{total_upload_GB_gerafed_cifar:.0f} GB\", xy=(epochs, total_upload_GB_gerafed_cifar),\n",
        "#              xytext=(epochs-5, total_upload_GB_gerafed_cifar + max(1, total_upload_GB_gerafed_cifar*0.02)),\n",
        "#              arrowprops=dict(arrowstyle=\"->\"), fontsize=9, va=\"bottom\")\n",
        "# plt.annotate(f\"{total_download_GB_gerafed_cifar:.0f} GB\", xy=(epochs, total_download_GB_gerafed_cifar),\n",
        "#              xytext=(epochs-5, total_download_GB_gerafed_cifar + max(1, total_download_GB_gerafed_cifar*0.02)),\n",
        "#              arrowprops=dict(arrowstyle=\"->\"), fontsize=9, va=\"bottom\")\n",
        "# plt.annotate(f\"{total_upload_and_download_chunkedfedavg_cifar:.0f} GB\", xy=(epochs, total_upload_and_download_chunkedfedavg_cifar),\n",
        "#              xytext=(epochs-5, total_upload_and_download_chunkedfedavg_cifar + max(1, total_upload_and_download_chunkedfedavg_cifar*0.02)),\n",
        "#              arrowprops=dict(arrowstyle=\"->\"), fontsize=9, va=\"bottom\")\n",
        "\n",
        "plt.savefig(\"../../../DML-ICC/Figures/network_traffic.pdf\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d66fca29",
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(\"../figures/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b605738",
      "metadata": {},
      "source": [
        "## Number of Synthetic Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e65e16b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f302686",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate x (epoch) values from 0 to 100\n",
        "epochs = np.arange(0, 101)\n",
        "\n",
        "# Calculate y values for each epoch\n",
        "y_values = [int(13 * (math.exp(0.01*epoch) - 1) / (math.exp(0.01*50) - 1) * 10) for epoch in epochs]\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(12, 2))\n",
        "plt.plot(epochs, y_values, color='cornflowerblue', linewidth=5)\n",
        "plt.xlabel(\"Epoch\", fontsize=18)\n",
        "plt.ylabel(\"|S|\", fontsize=18)\n",
        "plt.xticks(fontsize=16, ticks=np.linspace(0,100,5))\n",
        "plt.yticks(fontsize=16, ticks=[0, 88, 175, 267, 350])\n",
        "plt.xlim(0, 100)\n",
        "plt.ylim(0, 350)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeeddbca",
      "metadata": {
        "id": "aeeddbca"
      },
      "source": [
        "# Compara treino de classificador em dados reais, sintéticos e misturados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c400df8",
      "metadata": {
        "id": "6c400df8"
      },
      "outputs": [],
      "source": [
        "nets = [Net().to(device) for _ in range(num_partitions)]\n",
        "optims = [torch.optim.SGD(net.parameters(), lr=0.01) for net in nets]\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2117f9e5",
      "metadata": {
        "id": "2117f9e5"
      },
      "outputs": [],
      "source": [
        "for i, (net, optim) in enumerate(zip(nets, optims)):\n",
        "    net.train()\n",
        "    for epoch in range(50):\n",
        "        for data in trainloaders[i]:\n",
        "            inputs, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "            optim.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optim.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7ad2d72",
      "metadata": {
        "id": "c7ad2d72"
      },
      "outputs": [],
      "source": [
        "testpartition = fds.load_split(\"test\")\n",
        "testpartition = testpartition.with_transform(apply_transforms)\n",
        "testloader = DataLoader(testpartition, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abfbb983",
      "metadata": {
        "id": "abfbb983"
      },
      "outputs": [],
      "source": [
        "accuracies = []\n",
        "for net in nets:\n",
        "    correct, loss = 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "    accuracy = correct / len(testloader.dataset)\n",
        "    accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eedc9b7",
      "metadata": {
        "id": "0eedc9b7"
      },
      "outputs": [],
      "source": [
        "accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea7a7b0",
      "metadata": {
        "id": "5ea7a7b0"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "num_samples = 1000\n",
        "latent_dim = 128\n",
        "\n",
        "# gen = F2U_GAN()\n",
        "# gen.load_state_dict(torch.load(\"gen_round50.pt\", map_location=torch.device('cpu')))\n",
        "\n",
        "# Create the dataset and dataloader\n",
        "generated_dataset = GeneratedDataset(generator=gen.to(\"cpu\"), num_samples=num_samples, latent_dim=latent_dim, num_classes=10, device=\"cpu\")\n",
        "generated_dataloader = DataLoader(generated_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bc9f7fe",
      "metadata": {
        "id": "3bc9f7fe"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import ConcatDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99e1cbfd",
      "metadata": {
        "id": "99e1cbfd"
      },
      "outputs": [],
      "source": [
        "combined_dataloaders = []\n",
        "for train_partition in train_partitions:\n",
        "    # Ensure the partition is transformed\n",
        "    cmb_ds = ConcatDataset([train_partition, generated_dataset])\n",
        "    combined_dataloaders.append(DataLoader(cmb_ds, batch_size=batch_size, shuffle=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85df355d",
      "metadata": {
        "id": "85df355d"
      },
      "outputs": [],
      "source": [
        "nets = [Net().to(device) for _ in range(num_partitions)]\n",
        "optims = [torch.optim.Adam(net.parameters(), lr=0.01) for net in nets]\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ea13f13",
      "metadata": {
        "id": "9ea13f13"
      },
      "outputs": [],
      "source": [
        "for i, (net, optim) in enumerate(zip(nets, optims)):\n",
        "    net.train()\n",
        "    for epoch in range(50):\n",
        "        for data in combined_dataloaders[i]:\n",
        "            inputs, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "            optim.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optim.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9818e23a",
      "metadata": {
        "id": "9818e23a"
      },
      "outputs": [],
      "source": [
        "accuracies = []\n",
        "for net in nets:\n",
        "    correct, loss = 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "    accuracy = correct / len(testloader.dataset)\n",
        "    accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2b2cb6d",
      "metadata": {
        "id": "c2b2cb6d"
      },
      "outputs": [],
      "source": [
        "accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff260823",
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Definindo x e N\n",
        "x = list(range(1, 101))\n",
        "den = math.exp(0.01 * 50) - 1\n",
        "N = [int(13 * (math.exp(0.01 * (xi - 1)) - 1) / den) * 1000 for xi in x]\n",
        "y = [390*xi for xi in x]\n",
        "\n",
        "# Plot\n",
        "plt.figure()\n",
        "plt.plot(x, N)\n",
        "plt.plot(x, y)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"N\")\n",
        "plt.title(\"Plot de N = int(13 * (exp(0.01*(x-1)) - 1)/(exp(0.5) - 1)) * 1000\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "6d8c276e",
        "314c3604"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gerafed",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
