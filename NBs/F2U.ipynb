{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "07f8307e",
      "metadata": {
        "id": "07f8307e"
      },
      "source": [
        "# Inicialização"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f47d1996",
      "metadata": {
        "id": "f47d1996"
      },
      "source": [
        "## Prepara o ambiente local ou colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88a7ea1c",
      "metadata": {
        "id": "88a7ea1c"
      },
      "outputs": [],
      "source": [
        "# --- Detectar Ambiente (Colab ou Local) ---\n",
        "IN_COLAB = False\n",
        "try:\n",
        "    # Tenta importar um módulo específico do Colab\n",
        "    from google.colab import drive\n",
        "    import shutil # Usaremos para copiar, se necessário, mas salvar direto é melhor\n",
        "    import os\n",
        "\n",
        "    try:\n",
        "        drive.mount('/content/drive')\n",
        "        # Crie um diretório específico para salvar os resultados desta execução\n",
        "        save_base_dir = \"/content/drive/MyDrive/GAN_Training_Results\" # Ajuste o caminho como desejar\n",
        "        os.makedirs(save_base_dir, exist_ok=True)\n",
        "        # Opcional: Crie um subdiretório único para esta execução específica (ex: baseado em timestamp)\n",
        "        # import datetime\n",
        "        # timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        # save_dir = os.path.join(save_base_dir, f\"run_{timestamp}\")\n",
        "        # os.makedirs(save_dir, exist_ok=True)\n",
        "        # Por simplicidade, vamos usar o diretório base diretamente por enquanto\n",
        "        save_dir = save_base_dir\n",
        "        print(f\"✅ Google Drive montado. Arquivos serão salvos em: {save_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Erro ao montar o Google Drive: {e}\")\n",
        "        print(\"   Downloads diretos serão tentados, mas podem atrasar.\")\n",
        "        save_dir = \".\" # Salvar localmente se o Drive falhar\n",
        "    IN_COLAB = True\n",
        "    print(\"✅ Ambiente Google Colab detectado. Downloads automáticos (a cada 2 épocas) ativados.\")\n",
        "except ImportError:\n",
        "    print(\"✅ Ambiente local detectado. Downloads automáticos desativados.\")\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08e68593",
      "metadata": {
        "id": "08e68593"
      },
      "source": [
        "## Importa Pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e43ad3e",
      "metadata": {
        "id": "1e43ad3e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5df872b",
      "metadata": {
        "id": "b5df872b"
      },
      "source": [
        "## Modelo Classificador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4395f020",
      "metadata": {
        "id": "4395f020"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, seed=None):\n",
        "        if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(16*4*4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16*4*4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a98df505",
      "metadata": {
        "id": "a98df505"
      },
      "outputs": [],
      "source": [
        "class Net_Cifar(nn.Module):\n",
        "    def __init__(self,seed=None):\n",
        "        if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d8c276e",
      "metadata": {
        "id": "6d8c276e"
      },
      "source": [
        "## Carrega Dados MNIST centralizado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a82cbfd1",
      "metadata": {
        "id": "a82cbfd1"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13ad4aaf",
      "metadata": {
        "id": "13ad4aaf"
      },
      "outputs": [],
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Load the training and test datasets\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "trainset_reduzido = torch.utils.data.random_split(trainset, [1000, len(trainset) - 1000])[0]\n",
        "# Create data loaders\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "trainloader_reduzido = DataLoader(trainset_reduzido, batch_size=BATCH_SIZE, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "\n",
        "dataset = \"mnist\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64be3f56",
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "# Define transform com ToTensor e Normalize para 3 canais\n",
        "transform_cifar = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5),  # média por canal R,G,B\n",
        "                         (0.5, 0.5, 0.5))  # desvio padrão por canal\n",
        "])\n",
        "\n",
        "# Carrega os datasets de treino e teste\n",
        "trainset_cifar = datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform_cifar\n",
        ")\n",
        "testset_cifar = datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform_cifar\n",
        ")\n",
        "\n",
        "# Cria um subset reduzido de treino (por exemplo, 1000 amostras)\n",
        "#trainset_cifar_reduzido = random_split(trainset_cifar, [1000, len(trainset_cifar) - 1000])[0]\n",
        "\n",
        "# DataLoaders\n",
        "trainloader_cifar = DataLoader(\n",
        "    trainset_cifar,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "# trainloader_cifar_reduzido = DataLoader(\n",
        "#     trainset_cifar_reduzido,\n",
        "#     batch_size=BATCH_SIZE,\n",
        "#     shuffle=True,\n",
        "#     num_workers=2,\n",
        "#     pin_memory=True\n",
        "# )\n",
        "testloader_cifar = DataLoader(\n",
        "    testset_cifar,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "dataset = \"mnist\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c27cfeac",
      "metadata": {
        "id": "c27cfeac"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# parameters\n",
        "num_classes = 10\n",
        "samples_per_class = 5\n",
        "\n",
        "if dataset == \"cifar\":\n",
        "    class_names = [\n",
        "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "     'dog', 'frog', 'horse', 'ship', 'truck'\n",
        "    ]\n",
        "\n",
        "# containers\n",
        "class_counts = {i: 0 for i in range(num_classes)}\n",
        "class_images = {i: [] for i in range(num_classes)}\n",
        "\n",
        "# gather up to 5 images per class\n",
        "for img, label in trainset:\n",
        "    if class_counts[label] < samples_per_class:\n",
        "        class_images[label].append(img)\n",
        "        class_counts[label] += 1\n",
        "    # stop early once we have enough of every class\n",
        "    if all(count >= samples_per_class for count in class_counts.values()):\n",
        "        break\n",
        "\n",
        "# plot\n",
        "fig, axes = plt.subplots(num_classes, samples_per_class, figsize=(5, 9))\n",
        "for cls in range(num_classes):\n",
        "    for i in range(samples_per_class):\n",
        "        ax = axes[cls, i]\n",
        "        img = class_images[cls][i]\n",
        "        if dataset == \"mnist\":\n",
        "            ax.imshow(img.squeeze(), cmap='gray')\n",
        "        else:\n",
        "            img_denorm = (img * 0.5 + 0.5)  # denormalize for visualization\n",
        "            ax.imshow(img_denorm.permute(1, 2, 0).numpy())\n",
        "        ax.axis('off')\n",
        "    # label the rows on the leftmost subplot\n",
        "   # axes[cls, 0].set_ylabel(str(cls), rotation=0, labelpad=12, va='center', fontsize=12)\n",
        "\n",
        "# Ajustar o layout antes de calcular as posições\n",
        "plt.tight_layout(rect=[0.05, 0, 1, 0.96])\n",
        "\n",
        "# Adicionar os rótulos das classes corretamente alinhados\n",
        "fig.canvas.draw()  # Atualiza a renderização para obter posições corretas\n",
        "for row in range(num_classes):\n",
        "    # Obter posição do subplot em coordenadas da figura\n",
        "    bbox = axes[row, 0].get_window_extent(fig.canvas.get_renderer())\n",
        "    pos = fig.transFigure.inverted().transform([(bbox.x0, bbox.y0), (bbox.x1, bbox.y1)])\n",
        "    center_y = (pos[0, 1] + pos[1, 1]) / 2  # Centro exato da linha\n",
        "\n",
        "    # Adicionar o rótulo\n",
        "    fig.text(0.03, center_y, str(row), va='center', fontsize=22, color='black')\n",
        "\n",
        "plt.suptitle(\"Real\", fontsize=30, y=0.99)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54f6fbda",
      "metadata": {
        "id": "54f6fbda"
      },
      "source": [
        "## Modelo Generativo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea03ea69",
      "metadata": {
        "id": "ea03ea69"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "314c3604",
      "metadata": {
        "id": "314c3604"
      },
      "source": [
        "### CGAN (simples, mlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23cfec37",
      "metadata": {
        "id": "23cfec37"
      },
      "outputs": [],
      "source": [
        "class CGAN(nn.Module):\n",
        "    def __init__(self, dataset=\"mnist\", img_size=28, latent_dim=100):\n",
        "        super(CGAN, self).__init__()\n",
        "        if dataset == \"mnist\":\n",
        "            self.classes = 10\n",
        "            self.channels = 1\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes)\n",
        "        self.adv_loss = torch.nn.BCELoss()\n",
        "\n",
        "\n",
        "        self.generator = nn.Sequential(\n",
        "            *self._create_layer_gen(self.latent_dim + self.classes, 128, False),\n",
        "            *self._create_layer_gen(128, 256),\n",
        "            *self._create_layer_gen(256, 512),\n",
        "            *self._create_layer_gen(512, 1024),\n",
        "            nn.Linear(1024, int(np.prod(self.img_shape))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.discriminator = nn.Sequential(\n",
        "            *self._create_layer_disc(self.classes + int(np.prod(self.img_shape)), 1024, False, True),\n",
        "            *self._create_layer_disc(1024, 512, True, True),\n",
        "            *self._create_layer_disc(512, 256, True, True),\n",
        "            *self._create_layer_disc(256, 128, False, False),\n",
        "            *self._create_layer_disc(128, 1, False, False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def _create_layer_gen(self, size_in, size_out, normalize=True):\n",
        "        layers = [nn.Linear(size_in, size_out)]\n",
        "        if normalize:\n",
        "            layers.append(nn.BatchNorm1d(size_out))\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return layers\n",
        "\n",
        "    def _create_layer_disc(self, size_in, size_out, drop_out=True, act_func=True):\n",
        "        layers = [nn.Linear(size_in, size_out)]\n",
        "        if drop_out:\n",
        "            layers.append(nn.Dropout(0.4))\n",
        "        if act_func:\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return layers\n",
        "\n",
        "    def forward(self, input, labels):\n",
        "        if input.dim() == 2:\n",
        "            z = torch.cat((self.label_embedding(labels), input), -1)\n",
        "            x = self.generator(z)\n",
        "            x = x.view(x.size(0), *self.img_shape) #Em\n",
        "            return x\n",
        "        elif input.dim() == 4:\n",
        "            x = torch.cat((input.view(input.size(0), -1), self.label_embedding(labels)), -1)\n",
        "            return self.discriminator(x)\n",
        "\n",
        "    def loss(self, output, label):\n",
        "        return self.adv_loss(output, label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f1a5b73",
      "metadata": {
        "id": "4f1a5b73"
      },
      "source": [
        "### Arquitetura do paper F2U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbb8292a",
      "metadata": {
        "id": "cbb8292a"
      },
      "outputs": [],
      "source": [
        "class F2U_GAN(nn.Module):\n",
        "    def __init__(self, dataset=\"mnist\", img_size=28, latent_dim=128, condition=True, seed=None):\n",
        "        if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "        super(F2U_GAN, self).__init__()\n",
        "        if dataset == \"mnist\":\n",
        "            self.classes = 10\n",
        "            self.channels = 1\n",
        "        else:\n",
        "            raise NotImplementedError(\"Only MNIST is supported\")\n",
        "\n",
        "        self.condition = condition\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes) if condition else None\n",
        "        #self.label_embedding_disc = nn.Embedding(self.classes, self.img_size*self.img_size) if condition else None\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
        "        self.input_shape_gen = self.latent_dim + self.label_embedding.embedding_dim if condition else self.latent_dim\n",
        "        self.input_shape_disc = self.channels + self.classes if condition else self.channels\n",
        "\n",
        "        self.adv_loss = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "        # Generator (unchanged) To calculate output shape of convtranspose layers, we can use the formula:\n",
        "        # output_shape = (input_shape - 1) * stride - 2 * padding + kernel_size + output_padding (or dilation * (kernel_size - 1) + 1 inplace of kernel_size if using dilation)\n",
        "        self.generator = nn.Sequential(\n",
        "            nn.Linear(self.input_shape_gen, 256 * 7 * 7),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Unflatten(1, (256, 7, 7)),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1), # (256,7,7) -> (128,14,14)\n",
        "            nn.BatchNorm2d(128, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1), # (128,14,14) -> (64,28,28)\n",
        "            nn.BatchNorm2d(64, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64, self.channels, kernel_size=3, stride=1, padding=1), # (64,28,28) -> (1,28,28)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # Discriminator (corrected) To calculate output shape of conv layers, we can use the formula:\n",
        "        # output_shape = ⌊(input_shape - kernel_size + 2 * padding) / stride + 1⌋ (or (dilation * (kernel_size - 1) - 1) inplace of kernel_size if using dilation)\n",
        "        self.discriminator = nn.Sequential(\n",
        "        # Camada 1: (1,28,28) -> (32,13,13)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(self.input_shape_disc, 32, kernel_size=3, stride=2, padding=0)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Camada 2: (32,14,14) -> (64,7,7)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Camada 3: (64,7,7) -> (128,3,3)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=0)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Camada 4: (128,3,3) -> (256,1,1)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=0)),  # Padding 0 aqui!\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Achata e concatena com as labels\n",
        "        nn.Flatten(), # (256,1,1) -> (256*1*1,)\n",
        "        nn.utils.spectral_norm(nn.Linear(256 * 1 * 1, 1))  # 256 (features)\n",
        "        )\n",
        "\n",
        "    def forward(self, input, labels=None):\n",
        "        if input.dim() == 2:\n",
        "            # Generator forward pass (unchanged)\n",
        "            if self.condition:\n",
        "                embedded_labels = self.label_embedding(labels)\n",
        "                gen_input = torch.cat((input, embedded_labels), dim=1)\n",
        "                x = self.generator(gen_input)\n",
        "            else:\n",
        "                x = self.generator(input)\n",
        "            return x.view(-1, *self.img_shape)\n",
        "\n",
        "        elif input.dim() == 4:\n",
        "            # Discriminator forward pass\n",
        "            if self.condition:\n",
        "                embedded_labels = self.label_embedding(labels)\n",
        "                image_labels = embedded_labels.view(embedded_labels.size(0), self.label_embedding.embedding_dim, 1, 1).expand(-1, -1, self.img_size, self.img_size)\n",
        "                x = torch.cat((input, image_labels), dim=1)\n",
        "            else:\n",
        "                x = input\n",
        "            return self.discriminator(x)\n",
        "\n",
        "    def loss(self, output, label):\n",
        "        return self.adv_loss(output, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "decb2888",
      "metadata": {},
      "outputs": [],
      "source": [
        "class F2U_GAN_SlowDisc(nn.Module):\n",
        "    def __init__(self, dataset=\"mnist\", img_size=28, latent_dim=128, condition=True, seed=None):\n",
        "        if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "        super(F2U_GAN_SlowDisc, self).__init__()\n",
        "        if dataset == \"mnist\":\n",
        "            self.classes = 10\n",
        "            self.channels = 1\n",
        "        else:\n",
        "            raise NotImplementedError(\"Only MNIST is supported\")\n",
        "\n",
        "        self.condition = condition\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes) if condition else None\n",
        "        #self.label_embedding_disc = nn.Embedding(self.classes, self.img_size*self.img_size) if condition else None\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
        "        self.input_shape_gen = self.latent_dim + self.label_embedding.embedding_dim if condition else self.latent_dim\n",
        "        self.input_shape_disc = self.channels + self.classes if condition else self.channels\n",
        "\n",
        "        self.adv_loss = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "        # Generator (unchanged) To calculate output shape of convtranspose layers, we can use the formula:\n",
        "        # output_shape = (input_shape - 1) * stride - 2 * padding + kernel_size + output_padding (or dilation * (kernel_size - 1) + 1 inplace of kernel_size if using dilation)\n",
        "        self.generator = nn.Sequential(\n",
        "            nn.Linear(self.input_shape_gen, 256 * 7 * 7),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Unflatten(1, (256, 7, 7)),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1), # (256,7,7) -> (128,14,14)\n",
        "            nn.BatchNorm2d(128, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1), # (128,14,14) -> (64,28,28)\n",
        "            nn.BatchNorm2d(64, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64, self.channels, kernel_size=3, stride=1, padding=1), # (64,28,28) -> (1,28,28)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # Discriminator (corrected) To calculate output shape of conv layers, we can use the formula:\n",
        "        # output_shape = ⌊(input_shape - kernel_size + 2 * padding) / stride + 1⌋ (or (dilation * (kernel_size - 1) - 1) inplace of kernel_size if using dilation)\n",
        "        self.discriminator = nn.Sequential(\n",
        "        # Camada 1: (1,28,28) -> (32,13,13)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(self.input_shape_disc, 32, kernel_size=3, stride=2, padding=0)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Dropout2d(0.3),\n",
        "\n",
        "        # Camada 2: (32,14,14) -> (64,7,7)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Dropout2d(0.3),\n",
        "\n",
        "        # Camada 3: (64,7,7) -> (128,3,3)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=0)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Dropout2d(0.3),\n",
        "\n",
        "        # Camada 4: (128,3,3) -> (256,1,1)\n",
        "        nn.utils.spectral_norm(nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=0)),  # Padding 0 aqui!\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Achata e concatena com as labels\n",
        "        nn.Flatten(), # (256,1,1) -> (256*1*1,)\n",
        "        nn.utils.spectral_norm(nn.Linear(256 * 1 * 1, 1))  # 256 (features)\n",
        "        )\n",
        "\n",
        "    def forward(self, input, labels=None):\n",
        "        if input.dim() == 2:\n",
        "            # Generator forward pass (unchanged)\n",
        "            if self.condition:\n",
        "                embedded_labels = self.label_embedding(labels)\n",
        "                gen_input = torch.cat((input, embedded_labels), dim=1)\n",
        "                x = self.generator(gen_input)\n",
        "            else:\n",
        "                x = self.generator(input)\n",
        "            return x.view(-1, *self.img_shape)\n",
        "\n",
        "        elif input.dim() == 4:\n",
        "            # Discriminator forward pass\n",
        "            if self.condition:\n",
        "                embedded_labels = self.label_embedding(labels)\n",
        "                image_labels = embedded_labels.view(embedded_labels.size(0), self.label_embedding.embedding_dim, 1, 1).expand(-1, -1, self.img_size, self.img_size)\n",
        "                input = input + torch.randn_like(input) * 0.1\n",
        "                x = torch.cat((input, image_labels), dim=1)\n",
        "            else:\n",
        "                x = input\n",
        "            return self.discriminator(x)\n",
        "\n",
        "    def loss(self, output, label):\n",
        "        return self.adv_loss(output, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c52363e9",
      "metadata": {
        "id": "c52363e9"
      },
      "outputs": [],
      "source": [
        "class F2U_GAN_CIFAR(nn.Module):\n",
        "    def __init__(self, img_size=32, latent_dim=128, condition=True, seed=None):\n",
        "        if seed is not None:\n",
        "          torch.manual_seed(seed)\n",
        "        super(F2U_GAN_CIFAR, self).__init__()\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.classes = 10\n",
        "        self.channels = 3\n",
        "        self.condition = condition\n",
        "\n",
        "        # Embedding para condicionamento\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes) if self.condition else None\n",
        "\n",
        "        # Shapes de entrada\n",
        "        self.input_shape_gen = self.latent_dim + (self.classes if self.condition else 0)\n",
        "        self.input_shape_disc = self.channels + (self.classes if self.condition else 0)\n",
        "\n",
        "        # -----------------\n",
        "        #  Generator\n",
        "        # -----------------\n",
        "        self.generator = nn.Sequential(\n",
        "            nn.Linear(self.input_shape_gen, 512 * 4 * 4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Unflatten(1, (512, 4, 4)),                  # → (512,4,4)\n",
        "\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),  # → (256,8,8)\n",
        "            nn.BatchNorm2d(256, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # → (128,16,16)\n",
        "            nn.BatchNorm2d(128, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(128,  64, kernel_size=4, stride=2, padding=1),  # → ( 64,32,32)\n",
        "            nn.BatchNorm2d(64,  momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d( 64,   self.channels, kernel_size=3, stride=1, padding=1),  # → (3,32,32)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # -----------------\n",
        "        #  Discriminator\n",
        "        # -----------------\n",
        "        layers = []\n",
        "        in_ch = self.input_shape_disc\n",
        "        cfg = [\n",
        "            ( 64, 3, 1),  # → spatial stays 32\n",
        "            ( 64, 4, 2),  # → 16\n",
        "            (128, 3, 1),  # → 16\n",
        "            (128, 4, 2),  # → 8\n",
        "            (256, 4, 2),  # → 4\n",
        "        ]\n",
        "        for out_ch, k, s in cfg:\n",
        "            layers += [\n",
        "                nn.utils.spectral_norm(\n",
        "                    nn.Conv2d(in_ch, out_ch, kernel_size=k, stride=s, padding=1)\n",
        "                ),\n",
        "                nn.LeakyReLU(0.1, inplace=True)\n",
        "            ]\n",
        "            in_ch = out_ch\n",
        "\n",
        "        layers += [\n",
        "            nn.Flatten(),\n",
        "            nn.utils.spectral_norm(\n",
        "                nn.Linear(256 * 4 * 4, 1)\n",
        "            )\n",
        "        ]\n",
        "        self.discriminator = nn.Sequential(*layers)\n",
        "\n",
        "        # adversarial loss\n",
        "        self.adv_loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, input, labels=None):\n",
        "        # Generator pass\n",
        "        if input.dim() == 2 and input.size(1) == self.latent_dim:\n",
        "            if self.condition:\n",
        "                if labels is None:\n",
        "                    raise ValueError(\"Labels must be provided for conditional generation\")\n",
        "                embedded = self.label_embedding(labels)\n",
        "                gen_input = torch.cat((input, embedded), dim=1)\n",
        "            else:\n",
        "                gen_input = input\n",
        "            img = self.generator(gen_input)\n",
        "            return img\n",
        "\n",
        "        # Discriminator pass\n",
        "        elif input.dim() == 4 and input.size(1) == self.channels:\n",
        "            x = input\n",
        "            if self.condition:\n",
        "                if labels is None:\n",
        "                    raise ValueError(\"Labels must be provided for conditional discrimination\")\n",
        "                embedded = self.label_embedding(labels)\n",
        "                # criar mapa de labels e concatenar\n",
        "                lbl_map = embedded.view(-1, self.classes, 1, 1).expand(-1, self.classes, self.img_size, self.img_size)\n",
        "                x = torch.cat((x, lbl_map), dim=1)\n",
        "            return self.discriminator(x)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Input shape not recognized\")\n",
        "\n",
        "    def loss(self, logits, targets):\n",
        "        return self.adv_loss(logits.view(-1), targets.float().view(-1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "144a24f4",
      "metadata": {
        "id": "144a24f4"
      },
      "source": [
        "## Funções para geração de dataset e imagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3487d31",
      "metadata": {
        "id": "b3487d31"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn.functional as F\n",
        "import random # Needed for handling remainders if samples aren't perfectly divisible\n",
        "\n",
        "class GeneratedDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 generator,\n",
        "                 num_samples,\n",
        "                 latent_dim=100,\n",
        "                 num_classes=10, # Total classes the generator model knows\n",
        "                 desired_classes=None, # Optional: List of specific class indices to generate\n",
        "                 device=\"cpu\",\n",
        "                 image_col_name=\"image\",\n",
        "                 label_col_name=\"label\"):\n",
        "        \"\"\"\n",
        "        Generates a dataset using a conditional generative model, potentially\n",
        "        focusing on a subset of classes.\n",
        "\n",
        "        Args:\n",
        "            generator: The pre-trained generative model.\n",
        "            num_samples (int): Total number of images to generate across the desired classes.\n",
        "            latent_dim (int): Dimension of the latent space vector (z).\n",
        "            num_classes (int): The total number of classes the generator was trained on.\n",
        "                               This is crucial for correct label conditioning (e.g., one-hot dim).\n",
        "            desired_classes (list[int], optional): A list of integer class indices to generate.\n",
        "                                                  If None or empty, images for all classes\n",
        "                                                  (from 0 to num_classes-1) will be generated,\n",
        "                                                  distributed as evenly as possible.\n",
        "                                                  Defaults to None.\n",
        "            device (str): Device to run generation on ('cpu' or 'cuda').\n",
        "            image_col_name (str): Name for the image column in the output dictionary.\n",
        "            label_col_name (str): Name for the label column in the output dictionary.\n",
        "        \"\"\"\n",
        "        self.generator = generator\n",
        "        self.num_samples = num_samples\n",
        "        self.latent_dim = latent_dim\n",
        "        # Store the total number of classes the generator understands\n",
        "        self.total_num_classes = num_classes\n",
        "        self.device = device\n",
        "        self.model_type = type(self.generator).__name__ # Get generator class name\n",
        "        self.image_col_name = image_col_name\n",
        "        self.label_col_name = label_col_name\n",
        "\n",
        "        # Determine the actual classes to generate based on desired_classes\n",
        "        if desired_classes is not None and len(desired_classes) > 0:\n",
        "            # Validate that desired classes are within the generator's known range\n",
        "            if not all(0 <= c < self.total_num_classes for c in desired_classes):\n",
        "                raise ValueError(f\"All desired classes must be integers between 0 and {self.total_num_classes - 1}\")\n",
        "            # Use only the unique desired classes, sorted for consistency\n",
        "            self._actual_classes_to_generate = sorted(list(set(desired_classes)))\n",
        "        else:\n",
        "            # If no specific classes desired, generate all classes\n",
        "            self._actual_classes_to_generate = list(range(self.total_num_classes))\n",
        "\n",
        "        # The 'classes' attribute of the dataset reflects only those generated\n",
        "        self.classes = self._actual_classes_to_generate\n",
        "        self.num_generated_classes = len(self.classes) # Number of classes being generated\n",
        "\n",
        "        if self.num_generated_classes == 0 and self.num_samples > 0:\n",
        "             raise ValueError(\"Cannot generate samples with an empty list of desired classes.\")\n",
        "        elif self.num_samples == 0:\n",
        "             print(\"Warning: num_samples is 0. Dataset will be empty.\")\n",
        "             self.images = torch.empty(0) # Adjust shape if known\n",
        "             self.labels = torch.empty(0, dtype=torch.long)\n",
        "        else:\n",
        "             # Generate the data only if needed\n",
        "             self.images, self.labels = self.generate_data()\n",
        "\n",
        "\n",
        "    def generate_data(self):\n",
        "        \"\"\"Generates images and corresponding labels for the specified classes.\"\"\"\n",
        "        self.generator.eval()\n",
        "        self.generator.to(self.device)\n",
        "\n",
        "        # --- Create Labels ---\n",
        "        generated_labels_list = []\n",
        "        if self.num_generated_classes > 0:\n",
        "            # Distribute samples as evenly as possible among the desired classes\n",
        "            samples_per_class = self.num_samples // self.num_generated_classes\n",
        "            for cls in self._actual_classes_to_generate:\n",
        "                generated_labels_list.extend([cls] * samples_per_class)\n",
        "\n",
        "            # Handle remaining samples if num_samples is not perfectly divisible\n",
        "            num_remaining = self.num_samples - len(generated_labels_list)\n",
        "            if num_remaining > 0:\n",
        "                # Add remaining samples by randomly choosing from the desired classes\n",
        "                remainder_labels = random.choices(self._actual_classes_to_generate, k=num_remaining)\n",
        "                generated_labels_list.extend(remainder_labels)\n",
        "\n",
        "            # Shuffle labels for better distribution in batches later\n",
        "            random.shuffle(generated_labels_list)\n",
        "\n",
        "        # Convert labels list to tensor\n",
        "        labels = torch.tensor(generated_labels_list, dtype=torch.long, device=self.device)\n",
        "\n",
        "        # Double check label count (should match num_samples due to logic above)\n",
        "        if len(labels) != self.num_samples:\n",
        "             # This indicates an unexpected issue, potentially if num_generated_classes was 0 initially\n",
        "             # but num_samples > 0. Raise error or adjust. Let's adjust defensively.\n",
        "             print(f\"Warning: Label count mismatch. Expected {self.num_samples}, got {len(labels)}. Adjusting size.\")\n",
        "             if len(labels) > self.num_samples:\n",
        "                 labels = labels[:self.num_samples]\n",
        "             else:\n",
        "                 # Pad if too few (less likely with current logic unless num_generated_classes=0)\n",
        "                 num_needed = self.num_samples - len(labels)\n",
        "                 if self.num_generated_classes > 0:\n",
        "                      padding = torch.tensor(random.choices(self._actual_classes_to_generate, k=num_needed), dtype=torch.long, device=self.device)\n",
        "                      labels = torch.cat((labels, padding))\n",
        "                 # If no classes to generate from, labels tensor might remain smaller\n",
        "\n",
        "        # --- Create Latent Noise ---\n",
        "        z = torch.randn(self.num_samples, self.latent_dim, device=self.device)\n",
        "\n",
        "        # --- Generate Images in Batches ---\n",
        "        generated_images_list = []\n",
        "        # Consider making batch_size configurable\n",
        "        batch_size = min(1024, self.num_samples) if self.num_samples > 0 else 1\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, self.num_samples, batch_size):\n",
        "                z_batch = z[i : min(i + batch_size, self.num_samples)]\n",
        "                labels_batch = labels[i : min(i + batch_size, self.num_samples)]\n",
        "\n",
        "                # Skip if batch is empty (can happen if num_samples = 0)\n",
        "                if z_batch.shape[0] == 0:\n",
        "                    continue\n",
        "\n",
        "                # --- Condition the generator based on its type ---\n",
        "                if self.model_type == 'Generator': # Assumes input: concat(z, one_hot_label)\n",
        "                    # One-hot encode labels using the TOTAL number of classes the generator knows\n",
        "                    labels_one_hot_batch = F.one_hot(labels_batch, num_classes=self.total_num_classes).float()\n",
        "                    generator_input = torch.cat([z_batch, labels_one_hot_batch], dim=1)\n",
        "                    gen_imgs = self.generator(generator_input)\n",
        "                elif self.model_type in ('CGAN', 'F2U_GAN', 'F2U_GAN_CIFAR'): # Assumes input: z, label_index\n",
        "                    gen_imgs = self.generator(z_batch, labels_batch)\n",
        "                else:\n",
        "                    # Handle other potential generator architectures or raise an error\n",
        "                    raise NotImplementedError(f\"Generation logic not defined for model type: {self.model_type}\")\n",
        "\n",
        "                generated_images_list.append(gen_imgs.cpu()) # Move generated images to CPU\n",
        "\n",
        "        self.generator.cpu() # Move generator back to CPU after generation\n",
        "\n",
        "        # Concatenate all generated image batches\n",
        "        if generated_images_list:\n",
        "            all_gen_imgs = torch.cat(generated_images_list, dim=0)\n",
        "        else:\n",
        "            # If no images were generated (e.g., num_samples = 0)\n",
        "            # Create an empty tensor. Shape needs care - determine from generator or use placeholder.\n",
        "            # Let's attempt a placeholder [0, C, H, W] - requires knowing C, H, W.\n",
        "            # For now, a simple empty tensor. User might need to handle this downstream.\n",
        "            print(\"Warning: No images generated. Returning empty tensor for images.\")\n",
        "            all_gen_imgs = torch.empty(0)\n",
        "\n",
        "        return all_gen_imgs, labels.cpu() # Return images and labels (on CPU)\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the actual number of samples generated\n",
        "        return self.images.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= len(self):\n",
        "            raise IndexError(\"Dataset index out of range\")\n",
        "        return {\n",
        "            self.image_col_name: self.images[idx],\n",
        "            self.label_col_name: int(self.labels[idx]) # Return label as standard Python int\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1c3d341",
      "metadata": {
        "id": "b1c3d341"
      },
      "outputs": [],
      "source": [
        "class UnconditionalGeneratedDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 generator,\n",
        "                 num_samples,\n",
        "                 latent_dim=128,\n",
        "                 device=\"cpu\",\n",
        "                 image_col_name=\"image\"):\n",
        "        \"\"\"\n",
        "        Generates a dataset using an unconditional generative model.\n",
        "\n",
        "        Args:\n",
        "            generator: The pre-trained unconditional generative model.\n",
        "            num_samples (int): Total number of images to generate.\n",
        "            latent_dim (int): Dimension of the latent space vector (z).\n",
        "            device (str): Device to run generation on ('cpu' or 'cuda').\n",
        "            image_col_name (str): Name for the image column in the output dictionary.\n",
        "        \"\"\"\n",
        "        self.generator = generator\n",
        "        self.num_samples = num_samples\n",
        "        self.latent_dim = latent_dim\n",
        "        self.device = device\n",
        "        self.image_col_name = image_col_name\n",
        "\n",
        "        if self.num_samples < 0:\n",
        "            raise ValueError(\"num_samples must be non-negative\")\n",
        "        elif self.num_samples == 0:\n",
        "            print(\"Warning: num_samples is 0. Dataset will be empty.\")\n",
        "            self.images = torch.empty(0)\n",
        "        else:\n",
        "            self.images = self._generate_images()\n",
        "\n",
        "    def _generate_images(self):\n",
        "        self.generator.eval()\n",
        "        self.generator.to(self.device)\n",
        "\n",
        "        # Create latent noise\n",
        "        z = torch.randn(self.num_samples, self.latent_dim, device=self.device)\n",
        "\n",
        "        # Generate images in batches\n",
        "        generated_images = []\n",
        "        batch_size = min(1024, self.num_samples)\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, self.num_samples, batch_size):\n",
        "                z_batch = z[i : min(i + batch_size, self.num_samples)]\n",
        "                gen_imgs = self.generator(z_batch)\n",
        "                generated_images.append(gen_imgs.cpu())\n",
        "\n",
        "        self.generator.cpu()\n",
        "        return torch.cat(generated_images, dim=0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.images.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if idx >= len(self):\n",
        "            raise IndexError(\"Dataset index out of range\")\n",
        "        return { self.image_col_name: self.images[idx] }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9452cf54",
      "metadata": {
        "id": "9452cf54"
      },
      "outputs": [],
      "source": [
        "def generate_plot(net, device, round_number, client_id = None, examples_per_class: int=5, classes: int=10, latent_dim: int=100):\n",
        "    \"\"\"Gera plot de imagens de cada classe\"\"\"\n",
        "\n",
        "    net_type = type(net).__name__\n",
        "    net.to(device)\n",
        "    net.eval()\n",
        "    batch_size = examples_per_class * classes\n",
        "    dataset = \"mnist\" if  not net_type == \"F2U_GAN_CIFAR\" else \"cifar10\"\n",
        "\n",
        "    latent_vectors = torch.randn(batch_size, latent_dim, device=device)\n",
        "    labels = torch.tensor([i for i in range(classes) for _ in range(examples_per_class)], device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if net_type == \"Generator\":\n",
        "            labels_one_hot = torch.nn.functional.one_hot(labels, 10).float().to(device)\n",
        "            generated_images = net(torch.cat([latent_vectors, labels_one_hot], dim=1))\n",
        "        else:\n",
        "            generated_images = net(latent_vectors, labels)\n",
        "\n",
        "    # Criar uma figura com 10 linhas e 5 colunas de subplots\n",
        "    fig, axes = plt.subplots(classes, examples_per_class, figsize=(5, 9))\n",
        "\n",
        "    # Adiciona título no topo da figura\n",
        "    if isinstance(client_id, int):\n",
        "        fig.text(0.5, 0.98, f\"Round: {round_number} | Client: {client_id}\", ha=\"center\", fontsize=12)\n",
        "    else:\n",
        "        fig.text(0.5, 0.96, f\"Epoch: {round_number}\", ha=\"center\", fontsize=30)\n",
        "\n",
        "    # Exibir as imagens nos subplots\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if dataset == \"mnist\":\n",
        "            ax.imshow(generated_images[i, 0, :, :], cmap='gray')\n",
        "        else:\n",
        "            images = (generated_images[i] + 1)/2\n",
        "            ax.imshow(images.permute(1, 2, 0).clamp(0,1))\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "    # Ajustar o layout antes de calcular as posições\n",
        "    plt.tight_layout(rect=[0.05, 0, 1, 0.96])\n",
        "\n",
        "    # Reduzir espaço entre colunas\n",
        "    # plt.subplots_adjust(wspace=0.05)\n",
        "\n",
        "    # Adicionar os rótulos das classes corretamente alinhados\n",
        "    fig.canvas.draw()  # Atualiza a renderização para obter posições corretas\n",
        "    for row in range(classes):\n",
        "        # Obter posição do subplot em coordenadas da figura\n",
        "        bbox = axes[row, 0].get_window_extent(fig.canvas.get_renderer())\n",
        "        pos = fig.transFigure.inverted().transform([(bbox.x0, bbox.y0), (bbox.x1, bbox.y1)])\n",
        "        center_y = (pos[0, 1] + pos[1, 1]) / 2  # Centro exato da linha\n",
        "\n",
        "        # Adicionar o rótulo\n",
        "        fig.text(0.03, center_y, str(row), va='center', fontsize=22, color='black')\n",
        "\n",
        "    IN_COLAB = False\n",
        "    try:\n",
        "        # Tenta importar um módulo específico do Colab\n",
        "        import google.colab\n",
        "        IN_COLAB = True\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    if IN_COLAB:\n",
        "        if isinstance(client_id, int):\n",
        "            fig.savefig(os.path.join(save_dir, f\"{dataset}_{net_type}_r{round_number}_c{client_id}.png\"))\n",
        "            print(\"Imagem do cliente salva no drive\")\n",
        "        else:\n",
        "            fig.savefig(os.path.join(save_dir, f\"{dataset}{net_type}_r{round_number}.png\"))\n",
        "            print(\"Imagem do servidor salva no drive\")\n",
        "    else:\n",
        "        if isinstance(client_id, int):\n",
        "            fig.savefig(f\"{dataset}{net_type}_r{round_number}_c{client_id}.png\")\n",
        "            print(\"Imagem do cliente salva\")\n",
        "        else:\n",
        "            fig.savefig(f\"{dataset}{net_type}_r{round_number}.png\")\n",
        "            print(\"Imagem do servidor salva\")\n",
        "    plt.close(fig)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a88e7c6",
      "metadata": {
        "id": "3a88e7c6"
      },
      "outputs": [],
      "source": [
        "def plot_unconditional_generated(\n",
        "        generator,\n",
        "        device,\n",
        "        total_samples,\n",
        "        samples_per_row=5,\n",
        "        latent_dim=100,\n",
        "        save_path=None,\n",
        "        round_number=None):\n",
        "    \"\"\"\n",
        "    Generates and plots images from an unconditional generator in a grid.\n",
        "\n",
        "    Args:\n",
        "        generator: The unconditional torch generator model (z -> image).\n",
        "        device: Device to run generation on ('cpu' or 'cuda').\n",
        "        total_samples (int): Number of images to generate.\n",
        "        samples_per_row (int): Number of images per row in the grid.\n",
        "        latent_dim (int): Dimension of latent vector.\n",
        "        save_path (str, optional): Filepath to save the figure. If None, just shows plot.\n",
        "    \"\"\"\n",
        "\n",
        "    generator.eval()\n",
        "    generator.to(device)\n",
        "\n",
        "    # Sample latent vectors\n",
        "    z = torch.randn(total_samples, latent_dim, device=device)\n",
        "    with torch.no_grad():\n",
        "        imgs = generator(z)\n",
        "\n",
        "    # Determine grid size\n",
        "    cols = samples_per_row\n",
        "    rows = math.ceil(total_samples / cols)\n",
        "\n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(cols-2*cols/(rows+cols), rows-1*rows/(rows+cols)))\n",
        "    axes = axes.flatten() if total_samples > 1 else [axes]\n",
        "\n",
        "    fig.text(0.5, 0.99, f\"Round: {round_number}\", ha=\"center\", fontsize=11)\n",
        "\n",
        "    for idx in range(rows * cols):\n",
        "        ax = axes[idx]\n",
        "        ax.axis('off')\n",
        "        if idx < total_samples:\n",
        "            img = imgs[idx]\n",
        "            # Assume (C, H, W) and single-channel\n",
        "            ax.imshow(img[0], cmap='gray')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "        fig.savefig(save_path)\n",
        "        print(f\"Figure saved to {save_path}\")\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "    plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bd1a6ff",
      "metadata": {
        "id": "5bd1a6ff"
      },
      "source": [
        "## Importa Pacotes Federado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e7c02c2",
      "metadata": {
        "id": "3e7c02c2"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "    !pip install flwr_datasets\n",
        "    !pip install flwr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9793cd9a",
      "metadata": {
        "id": "9793cd9a"
      },
      "outputs": [],
      "source": [
        "from flwr_datasets.partitioner import DirichletPartitioner, IidPartitioner\n",
        "from flwr_datasets.visualization import plot_label_distributions\n",
        "from flwr_datasets import FederatedDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5ac2e55",
      "metadata": {
        "id": "a5ac2e55"
      },
      "source": [
        "## Particionador por classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3acd60f5",
      "metadata": {
        "id": "3acd60f5"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Flower Labs GmbH. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Class-based partitioner for Hugging Face Datasets.\"\"\"\n",
        "\n",
        "\n",
        "from collections import defaultdict\n",
        "import random\n",
        "from typing import Optional, List\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from flwr_datasets.partitioner.partitioner import Partitioner  # Assuming this is in the package structure\n",
        "\n",
        "\n",
        "class ClassPartitioner(Partitioner):\n",
        "    \"\"\"Partitions a dataset by class, ensuring each class appears in exactly one partition.\n",
        "\n",
        "    Attributes:\n",
        "        num_partitions (int): Total number of partitions to create\n",
        "        seed (int, optional): Random seed for reproducibility\n",
        "        label_column (str): Name of the column containing class labels\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_partitions: int,\n",
        "        seed: Optional[int] = None,\n",
        "        label_column: str = \"label\"\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self._num_partitions = num_partitions\n",
        "        self._seed = seed\n",
        "        self._label_column = label_column\n",
        "        self._partition_indices: Optional[List[List[int]]] = None\n",
        "\n",
        "    def _create_partitions(self) -> None:\n",
        "        \"\"\"Create class-based partitions and store indices.\"\"\"\n",
        "        # Extract labels from dataset\n",
        "        labels = self.dataset[self._label_column]\n",
        "\n",
        "        # Group indices by class\n",
        "        class_indices = defaultdict(list)\n",
        "        for idx, label in enumerate(labels):\n",
        "            class_indices[label].append(idx)\n",
        "\n",
        "        classes = list(class_indices.keys())\n",
        "        num_classes = len(classes)\n",
        "\n",
        "        # Validate number of partitions\n",
        "        if self._num_partitions > num_classes:\n",
        "            raise ValueError(\n",
        "                f\"Cannot create {self._num_partitions} partitions with only {num_classes} classes. \"\n",
        "                f\"Reduce partitions to ≤ {num_classes}.\"\n",
        "            )\n",
        "\n",
        "        # Shuffle classes for random distribution\n",
        "        rng = random.Random(self._seed)\n",
        "        rng.shuffle(classes)\n",
        "\n",
        "        # Split classes into partitions\n",
        "        partition_classes = np.array_split(classes, self._num_partitions)\n",
        "\n",
        "        # Create index lists for each partition\n",
        "        self._partition_indices = []\n",
        "        for class_group in partition_classes:\n",
        "            indices = []\n",
        "            for cls in class_group:\n",
        "                indices.extend(class_indices[cls])\n",
        "            self._partition_indices.append(indices)\n",
        "\n",
        "    @property\n",
        "    def dataset(self) -> Dataset:\n",
        "        return super().dataset\n",
        "\n",
        "    @dataset.setter\n",
        "    def dataset(self, value: Dataset) -> None:\n",
        "        # Use parent setter for basic validation\n",
        "        super(ClassPartitioner, ClassPartitioner).dataset.fset(self, value)\n",
        "\n",
        "        # Create partitions once dataset is set\n",
        "        self._create_partitions()\n",
        "\n",
        "    def load_partition(self, partition_id: int) -> Dataset:\n",
        "        \"\"\"Load a partition containing exclusive classes.\n",
        "\n",
        "        Args:\n",
        "            partition_id: The ID of the partition to load (0-based index)\n",
        "\n",
        "        Returns:\n",
        "            Dataset: Subset of the dataset containing only the specified partition's data\n",
        "        \"\"\"\n",
        "        if not self.is_dataset_assigned():\n",
        "            raise RuntimeError(\"Dataset must be assigned before loading partitions\")\n",
        "        if partition_id < 0 or partition_id >= self.num_partitions:\n",
        "            raise ValueError(f\"Invalid partition ID: {partition_id}\")\n",
        "\n",
        "        return self.dataset.select(self._partition_indices[partition_id])\n",
        "\n",
        "    @property\n",
        "    def num_partitions(self) -> int:\n",
        "        return self._num_partitions\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f\"ClassPartitioner(num_partitions={self._num_partitions}, \"\n",
        "                f\"seed={self._seed}, label_column='{self._label_column}')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1ee55f5",
      "metadata": {
        "id": "a1ee55f5"
      },
      "source": [
        "## Carrega e divide dados entre clientes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fdba10d",
      "metadata": {
        "id": "6fdba10d"
      },
      "outputs": [],
      "source": [
        "num_partitions = 4\n",
        "alpha_dir = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cd9c472",
      "metadata": {
        "id": "6cd9c472"
      },
      "source": [
        "Rodar somente o particionador desejado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42644935",
      "metadata": {
        "id": "42644935"
      },
      "outputs": [],
      "source": [
        "partitioner = ClassPartitioner(num_partitions=num_partitions, seed=42, label_column=\"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "312626b5",
      "metadata": {
        "id": "312626b5"
      },
      "outputs": [],
      "source": [
        "partitioner = DirichletPartitioner(\n",
        "    num_partitions=num_partitions,\n",
        "    partition_by=\"label\",\n",
        "    alpha=alpha_dir,\n",
        "    min_partition_size=0,\n",
        "    self_balancing=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8582a179",
      "metadata": {
        "id": "8582a179"
      },
      "outputs": [],
      "source": [
        "partitioner = IidPartitioner(\n",
        "    num_partitions=num_partitions\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3f9a435",
      "metadata": {
        "id": "a3f9a435"
      },
      "outputs": [],
      "source": [
        "fds = FederatedDataset(\n",
        "    dataset=\"mnist\",\n",
        "    partitioners={\"train\": partitioner}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d21553c",
      "metadata": {
        "id": "7d21553c"
      },
      "outputs": [],
      "source": [
        "fds = FederatedDataset(\n",
        "    dataset=\"cifar10\",\n",
        "    partitioners={\"train\": partitioner}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8abf0ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib.ticker import FuncFormatter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "026da6c7",
      "metadata": {
        "id": "026da6c7"
      },
      "outputs": [],
      "source": [
        "partitioner = fds.partitioners[\"train\"]\n",
        "figure, axis, dataframe = plot_label_distributions(\n",
        "    partitioner=partitioner,\n",
        "    label_name=\"label\",\n",
        "    title=\"Dir01\",\n",
        "    legend=False,\n",
        "    verbose_labels=True,\n",
        "    size_unit=\"absolute\",\n",
        "    partition_id_axis=\"x\",\n",
        "    legend_kwargs={'fontsize': 10, 'title_fontsize': 10},\n",
        "    figsize=(6, 5)\n",
        ")\n",
        "\n",
        "axis.title.set_fontsize(18)\n",
        "\n",
        "# 2. Modify the returned 'axis' object for labels and ticks\n",
        "# Set font size for the axis titles (e.g., \"Partition ID\", \"Count\")\n",
        "axis.xaxis.label.set_fontsize(18)\n",
        "axis.yaxis.label.set_fontsize(18)\n",
        "\n",
        "axis.yaxis.set_major_formatter(FuncFormatter(lambda y, _: int(y/1000)))\n",
        "#axis.set_ylabel(\"Count (x$10^3$)\", fontsize=16)\n",
        "\n",
        "axis.set_yticks([0, 5000, 10000, 15000, 20000])\n",
        "\n",
        "axis.set_ylabel(\"Count (x$10^3$)\", fontsize=18)\n",
        "\n",
        "# Set font size for the tick numbers on both axes\n",
        "axis.tick_params(axis='both', labelsize=20)\n",
        "\n",
        "# # 3. Adjust layout and show the final plot\n",
        "# figure.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93ff7171",
      "metadata": {
        "id": "93ff7171"
      },
      "outputs": [],
      "source": [
        "train_partitions = [fds.load_partition(i, split=\"train\") for i in range(num_partitions)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j-L_He1Qvz0e",
      "metadata": {
        "id": "j-L_He1Qvz0e"
      },
      "source": [
        "Rodar proxima celula somente se quiser testar com dataset reduzido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w2n6dMxcvx2k",
      "metadata": {
        "id": "w2n6dMxcvx2k"
      },
      "outputs": [],
      "source": [
        "# num_samples = [int(len(train_partition)/10) for train_partition in train_partitions]\n",
        "# train_partitions = [train_partition.select(range(n)) for train_partition, n in zip(train_partitions, num_samples)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1b7cf8f",
      "metadata": {
        "id": "d1b7cf8f"
      },
      "source": [
        "Cria dicionario de label para cliente para controle do dmax_mismatch. Tive que colocar aqui antes do apply_transform para não dar erro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e07fdcb9",
      "metadata": {
        "id": "e07fdcb9"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b106654b",
      "metadata": {
        "id": "b106654b"
      },
      "outputs": [],
      "source": [
        "min_lbl_count = 0.05\n",
        "class_labels = train_partitions[0].info.features[\"label\"]\n",
        "labels_str = class_labels.names\n",
        "label_to_client = {lbl: [] for lbl in labels_str}\n",
        "for idx, ds in enumerate(train_partitions):\n",
        "    counts = Counter(ds['label'])\n",
        "    for label, cnt in counts.items():\n",
        "        if cnt / len(ds) >= min_lbl_count:\n",
        "            label_to_client[class_labels.int2str(label)].append(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56dcbb9b",
      "metadata": {
        "id": "56dcbb9b"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Compose, ToTensor, Normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df48b029",
      "metadata": {
        "id": "df48b029"
      },
      "outputs": [],
      "source": [
        "pytorch_transforms = Compose([\n",
        "    ToTensor(),\n",
        "    Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "def apply_transforms(batch):\n",
        "    batch[\"image\"] = [pytorch_transforms(img) for img in batch[\"image\"]]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbbc667a",
      "metadata": {
        "id": "cbbc667a"
      },
      "outputs": [],
      "source": [
        "# Para CIFAR-10: 3 canais, normalização média=0.5 e std=0.5\n",
        "pytorch_transforms = Compose([\n",
        "    ToTensor(),\n",
        "    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "def apply_transforms(batch):\n",
        "    # batch[\"image\"] é uma lista de PIL.Image ou tensores em H×W×C\n",
        "    # aplicamos o mesmo transform a cada imagem e depois empilhamos\n",
        "    batch[\"img\"] = torch.stack([pytorch_transforms(img) for img in batch[\"img\"]])\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34de09aa",
      "metadata": {
        "id": "34de09aa"
      },
      "outputs": [],
      "source": [
        "train_partitions = [train_partition.with_transform(apply_transforms) for train_partition in train_partitions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MwJAQ213fi-w",
      "metadata": {
        "id": "MwJAQ213fi-w"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CuBEfRZ6fX8i",
      "metadata": {
        "id": "CuBEfRZ6fX8i"
      },
      "outputs": [],
      "source": [
        "test_frac = 0.2\n",
        "client_datasets = []\n",
        "\n",
        "for train_part in train_partitions:\n",
        "    total     = len(train_part)\n",
        "    test_size = int(total * test_frac)\n",
        "    train_size = total - test_size\n",
        "\n",
        "    client_train, client_test = random_split(\n",
        "        train_part,\n",
        "        [train_size, test_size],\n",
        "        generator=torch.Generator().manual_seed(42),\n",
        "    )\n",
        "\n",
        "    client_datasets.append({\n",
        "        \"train\": client_train,\n",
        "        \"test\":  client_test,\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0ae0635",
      "metadata": {
        "id": "b0ae0635"
      },
      "source": [
        "## Inicializa modelos e otimizadores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b818e92",
      "metadata": {
        "id": "1b818e92"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5be9636",
      "metadata": {
        "id": "b5be9636"
      },
      "source": [
        "Rodar somente o modelo desejado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e76e482",
      "metadata": {
        "id": "8e76e482"
      },
      "outputs": [],
      "source": [
        "models = [CGAN() for i in range(num_partitions)]\n",
        "gen = CGAN().to(device)\n",
        "optim_G = torch.optim.Adam(list(gen.generator.parameters())+list(gen.label_embedding.parameters()), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70debb0f",
      "metadata": {
        "id": "70debb0f"
      },
      "outputs": [],
      "source": [
        "models = [F2U_GAN(condition=True, seed=42) for i in range(num_partitions)]\n",
        "gen = F2U_GAN(condition=True, seed=42).to(device)\n",
        "optim_G = torch.optim.Adam(list(gen.generator.parameters())+list(gen.label_embedding.parameters()), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c52f5343",
      "metadata": {},
      "outputs": [],
      "source": [
        "models = [F2U_GAN_SlowDisc(condition=True, seed=42) for i in range(num_partitions)]\n",
        "gen = F2U_GAN(condition=True, seed=42).to(device)\n",
        "optim_G = torch.optim.Adam(list(gen.generator.parameters())+list(gen.label_embedding.parameters()), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a813dfe",
      "metadata": {
        "id": "9a813dfe"
      },
      "outputs": [],
      "source": [
        "models = [F2U_GAN_CIFAR(condition=True, seed=42) for i in range(num_partitions)]\n",
        "gen = F2U_GAN_CIFAR(condition=True, seed=42).to(device)\n",
        "optim_G = torch.optim.Adam(list(gen.generator.parameters())+list(gen.label_embedding.parameters()), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70f37272",
      "metadata": {
        "id": "70f37272"
      },
      "outputs": [],
      "source": [
        "optim_Ds = [\n",
        "    torch.optim.Adam(list(model.discriminator.parameters())+list(model.label_embedding.parameters()), lr=0.0002, betas=(0.5, 0.999))\n",
        "    for model in models\n",
        "]\n",
        "\n",
        "# scheduler_D = torch.optim.lr_scheduler.StepLR(optim_D, step_size=5, gamma=0.9)\n",
        "# scheduler_G = torch.optim.lr_scheduler.StepLR(optim_G, step_size=5, gamma=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e08c26a0",
      "metadata": {
        "id": "e08c26a0"
      },
      "source": [
        "Inicializa lambda para F2A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "893b45d4",
      "metadata": {
        "id": "893b45d4"
      },
      "outputs": [],
      "source": [
        "# initial λ* (unconstrained), wrap with ReLU to keep λ ≥ 0\n",
        "lambda_star = nn.Parameter(torch.tensor(0.1, device=device))\n",
        "relu = nn.ReLU()\n",
        "\n",
        "beta = 0.1  # same β as in the paper\n",
        "\n",
        "# now make your generator optimizer also update lambda_star\n",
        "# (so its gradient from the βλ² term can flow)\n",
        "optim_G = torch.optim.Adam(\n",
        "    list(gen.parameters()) + [lambda_star],\n",
        "    lr=2e-4, betas=(0.5, 0.999)\n",
        ") #ACHO QUE TA ERRADO AQUI, OPTIM_G PEGANDO TODOS PARAMETROS, NAO QUE VAI MUDAR ALGO POIS FAÇO INSTANCIACOES DIFERENTES PARA GE E DISC\n",
        "# optim_G = torch.optim.Adam(\n",
        "#     list(gen.generator.parameters())+list(gen.label_embedding.parameters()) + [lambda_star],\n",
        "#     lr=2e-4, betas=(0.5, 0.999)\n",
        "# ) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a3a7e9e",
      "metadata": {
        "id": "7a3a7e9e"
      },
      "source": [
        "# Treinamento dos modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b38a6962",
      "metadata": {
        "id": "b38a6962"
      },
      "source": [
        "## Cria chunks para o treinamento alternado entre discriminadora e geradora ser mais constante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b5d8adc",
      "metadata": {
        "id": "9b5d8adc"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2505ab00",
      "metadata": {
        "id": "2505ab00"
      },
      "source": [
        "Quanto menos chunks, mais dados em cada chunk e mais dados são treinados na discriminadora antes de treinar a geradora. No paper do F2U, não está claro como os treinamentos são alternados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FTvOVoSLVpta",
      "metadata": {
        "id": "FTvOVoSLVpta"
      },
      "outputs": [],
      "source": [
        "# prompt: set each train partition as the only first minimum lenght of the partitions samples, the partitions have same lenght\n",
        "\n",
        "min_len = min(len(p) for p in train_partitions)\n",
        "train_partitions = [p.select(range(min_len)) for p in train_partitions]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CVz-ThoCVfoh",
      "metadata": {
        "id": "CVz-ThoCVfoh"
      },
      "outputs": [],
      "source": [
        "for train_partition in train_partitions:\n",
        "  print(len(train_partition))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff747284",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_chunks = 100\n",
        "seed = 42  # escolha qualquer inteiro para reprodutibilidade\n",
        "client_chunks = []\n",
        "\n",
        "for train_partition in client_datasets:\n",
        "    dataset = train_partition[\"train\"]\n",
        "    n = len(dataset)\n",
        "\n",
        "    # 1) embaralha os índices com seed fixa\n",
        "    indices = list(range(n))\n",
        "    random.seed(seed)\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    # 2) calcula tamanho aproximado de cada chunk\n",
        "    chunk_size = math.ceil(n / num_chunks)\n",
        "\n",
        "    # 3) divide em chunks usando fatias dos índices embaralhados\n",
        "    chunks = []\n",
        "    for i in range(num_chunks):\n",
        "        start = i * chunk_size\n",
        "        end = min((i + 1) * chunk_size, n)\n",
        "        chunk_indices = indices[start:end]\n",
        "        chunks.append(Subset(dataset, chunk_indices))\n",
        "\n",
        "    client_chunks.append(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "o6WJTKp6B5vD",
      "metadata": {
        "id": "o6WJTKp6B5vD"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "client_test_loaders = [DataLoader(dataset=ds[\"test\"], batch_size=batch_size, shuffle=True) for ds in client_datasets]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ab8d65e",
      "metadata": {
        "id": "4ab8d65e"
      },
      "source": [
        "## Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e70bd3c8",
      "metadata": {
        "id": "e70bd3c8"
      },
      "outputs": [],
      "source": [
        "nets = [Net(42).to(device) for _ in range(num_partitions)]\n",
        "optims = [torch.optim.Adam(net.parameters(), lr=0.01) for net in nets]\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbc668cf",
      "metadata": {
        "id": "bbc668cf"
      },
      "outputs": [],
      "source": [
        "testpartition = fds.load_split(\"test\")\n",
        "testpartition = testpartition.with_transform(apply_transforms)\n",
        "testloader = DataLoader(testpartition, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e86ba4bc",
      "metadata": {
        "id": "e86ba4bc"
      },
      "source": [
        "Carregar modelo pré-treinado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d3c145b",
      "metadata": {
        "id": "3d3c145b"
      },
      "outputs": [],
      "source": [
        "global_net = Net(42).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b66f9a29",
      "metadata": {
        "id": "b66f9a29"
      },
      "outputs": [],
      "source": [
        "checkpoint_loaded = torch.load(\"../Experimentos/NB_F2U/GeraFed_4c_NIIDClass/MNIST/checkpoint_epoch100.pth\")\n",
        "\n",
        "global_net.load_state_dict(checkpoint_loaded['alvo_state_dict'])\n",
        "global_net.to(device)\n",
        "for optim, state in zip(optims, checkpoint_loaded['optimizer_alvo_state_dict']):\n",
        "    optim.load_state_dict(state)\n",
        "\n",
        "gen.load_state_dict(checkpoint_loaded[\"gen_state_dict\"])\n",
        "gen.to(device)\n",
        "optim_G.load_state_dict(checkpoint_loaded[\"optim_G_state_dict\"])\n",
        "\n",
        "for model, optim_d, state_model, state_optim in zip(models, optim_Ds, checkpoint_loaded[\"discs_state_dict\"], checkpoint_loaded[\"optim_Ds_state_dict:\"]):\n",
        "    model.load_state_dict(state_model)\n",
        "    model.to(device)\n",
        "    optim_d.load_state_dict(state_optim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa1265b7",
      "metadata": {
        "id": "aa1265b7"
      },
      "source": [
        "Não esquecer de reinicializar os modelos e otimizadores se for reinicializar o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d116bedf",
      "metadata": {
        "id": "d116bedf"
      },
      "outputs": [],
      "source": [
        "from flwr.server.strategy.aggregate import aggregate_inplace\n",
        "from flwr.common import FitRes, Status, Code, ndarrays_to_parameters\n",
        "from collections import OrderedDict, defaultdict\n",
        "from torch.utils.data import ConcatDataset\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac00db4",
      "metadata": {},
      "source": [
        "### GeraFed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1447e9f",
      "metadata": {
        "collapsed": true,
        "id": "c1447e9f"
      },
      "outputs": [],
      "source": [
        "wgan = False\n",
        "f2a = False\n",
        "epochs = 1\n",
        "losses_dict = {\"g_losses_chunk\": [],\n",
        "               \"d_losses_chunk\": [],\n",
        "               \"g_losses_round\": [],\n",
        "               \"d_losses_round\": [],\n",
        "               \"net_loss_chunk\": [],\n",
        "               \"net_acc_chunk\": [],\n",
        "               \"net_loss_round\": [],\n",
        "               \"net_acc_round\": [],\n",
        "               \"time_chunk\": [],\n",
        "               \"time_round\": [],\n",
        "               \"net_time\": [],\n",
        "               \"disc_time\": [],\n",
        "               \"gen_time\": [],\n",
        "               \"img_syn_time\": [],\n",
        "               \"track_mismatch_time\": []\n",
        "               }\n",
        "\n",
        "epoch_bar = tqdm(range(0, epochs), desc=\"Treinamento\", leave=True, position=0)\n",
        "\n",
        "batch_size_gen = 1\n",
        "batch_tam = 32\n",
        "extra_g_e = 20\n",
        "latent_dim = 128\n",
        "num_classes = 10\n",
        "if type(nets[0]).__name__ == \"Net\":\n",
        "  image = \"image\"\n",
        "else:\n",
        "  image = \"img\"\n",
        "\n",
        "if IN_COLAB:\n",
        "  acc_filename = os.path.join(save_dir,\"accuracy_report.txt\")\n",
        "  loss_filename = os.path.join(save_dir, \"losses.json\")\n",
        "  dmax_mismatch_log = os.path.join(save_dir, \"dmax_mismatch.txt\")\n",
        "  lambda_log = os.path.join(save_dir, \"lambda_log.txt\")\n",
        "\n",
        "else:\n",
        "  acc_filename = \"accuracy_report.txt\"\n",
        "  loss_filename = \"losses.json\"\n",
        "  dmax_mismatch_log = \"dmax_mismatch.txt\"\n",
        "  lambda_log = \"lambda_log.txt\"\n",
        "\n",
        "for epoch in epoch_bar:\n",
        "  epoch_start_time = time.time()\n",
        "  mismatch_count = 0\n",
        "  total_checked = 0\n",
        "  g_loss_c = 0.0\n",
        "  d_loss_c = 0.0\n",
        "  total_d_samples = 0  # Amostras totais processadas pelos discriminadores\n",
        "  total_g_samples = 0  # Amostras totais processadas pelo gerador\n",
        "\n",
        "  chunk_bar = tqdm(range(num_chunks), desc=\"Chunks\", leave=True, position=1)\n",
        "\n",
        "  for chunk_idx in chunk_bar:\n",
        "    chunk_start_time = time.time()\n",
        "    params = []\n",
        "    results = []\n",
        "    # ====================================================================\n",
        "    # Treino dos Discriminadores (clientes) no bloco atual\n",
        "    # ====================================================================\n",
        "    d_loss_b = 0\n",
        "    total_chunk_samples = 0\n",
        "\n",
        "\n",
        "    client_bar = tqdm(enumerate(zip(nets, models, client_chunks)), desc=\"Clients\", leave=True, position=2)\n",
        "\n",
        "    for cliente, (net, disc, chunks) in client_bar:\n",
        "      # Carregar o bloco atual do cliente\n",
        "      chunk_dataset = chunks[chunk_idx]\n",
        "      if len(chunk_dataset) == 0:\n",
        "        print(f\"Chunk {chunk_idx} for client {cliente} is empty, skipping.\")\n",
        "        continue\n",
        "      chunk_loader = DataLoader(chunk_dataset, batch_size=batch_tam, shuffle=True)\n",
        "      if chunk_idx == 0:\n",
        "        client_eval_time = time.time()\n",
        "        # Evaluation in client test\n",
        "        # Initialize counters\n",
        "        class_correct = defaultdict(int)\n",
        "        class_total = defaultdict(int)\n",
        "        predictions_counter = defaultdict(int)\n",
        "\n",
        "        global_net.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in client_test_loaders[cliente]:\n",
        "                images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "                outputs = global_net(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Update counts for each sample in batch\n",
        "                for true_label, pred_label in zip(labels, predicted):\n",
        "                    true_idx = true_label.item()\n",
        "                    pred_idx = pred_label.item()\n",
        "\n",
        "                    class_total[true_idx] += 1\n",
        "                    predictions_counter[pred_idx] += 1\n",
        "\n",
        "                    if true_idx == pred_idx:\n",
        "                        class_correct[true_idx] += 1\n",
        "\n",
        "            # Create results dictionary\n",
        "            results_metrics = {\n",
        "                \"class_metrics\": {},\n",
        "                \"overall_accuracy\": None,\n",
        "                \"prediction_distribution\": dict(predictions_counter)\n",
        "            }\n",
        "\n",
        "            # Calculate class-wise metrics\n",
        "            for i in range(num_classes):\n",
        "                metrics = {\n",
        "                    \"samples\": class_total[i],\n",
        "                    \"predictions\": predictions_counter[i],\n",
        "                    \"accuracy\": class_correct[i] / class_total[i] if class_total[i] > 0 else \"N/A\"\n",
        "                }\n",
        "                results_metrics[\"class_metrics\"][f\"class_{i}\"] = metrics\n",
        "\n",
        "            # Calculate overall accuracy\n",
        "            total_samples = sum(class_total.values())\n",
        "            results_metrics[\"overall_accuracy\"] = sum(class_correct.values()) / total_samples\n",
        "\n",
        "            # Save to txt file\n",
        "            with open(acc_filename, \"a\") as f:\n",
        "                f.write(f\"Epoch {epoch + 1} - Client {cliente}\\n\")\n",
        "                # Header with fixed widths\n",
        "                f.write(\"{:<10} {:<10} {:<10} {:<10}\\n\".format(\n",
        "                    \"Class\", \"Accuracy\", \"Samples\", \"Predictions\"))\n",
        "                f.write(\"-\"*45 + \"\\n\")\n",
        "\n",
        "                # Class rows with consistent formatting\n",
        "                for cls in range(num_classes):\n",
        "                    metrics = results_metrics[\"class_metrics\"][f\"class_{cls}\"]\n",
        "\n",
        "                    # Format accuracy (handle \"N/A\" case)\n",
        "                    accuracy = (f\"{metrics['accuracy']:.4f}\"\n",
        "                              if isinstance(metrics['accuracy'], float)\n",
        "                              else \"  N/A  \")\n",
        "\n",
        "                    f.write(\"{:<10} {:<10} {:<10} {:<10}\\n\".format(\n",
        "                        f\"Class {cls}\",\n",
        "                        accuracy,\n",
        "                        metrics['samples'],\n",
        "                        metrics['predictions']\n",
        "                    ))\n",
        "\n",
        "                # Footer with alignment\n",
        "                f.write(\"\\n{:<20} {:.4f}\".format(\"Overall Accuracy:\", results_metrics[\"overall_accuracy\"]))\n",
        "                f.write(\"\\n{:<20} {}\".format(\"Total Samples:\", total_samples))\n",
        "                f.write(\"\\n{:<20} {}\".format(\"Total Predictions:\", sum(predictions_counter.values())))\n",
        "                f.write(\"\\n{:<20} {:.4f}\".format(\"Client Evaluation Time:\", time.time() - client_eval_time))\n",
        "                f.write(\"\\n\")\n",
        "                f.write(\"\\n\")\n",
        "\n",
        "        print(\"Results saved to accuracy_report.txt\")\n",
        "\n",
        "      # Treinar o discriminador no bloco\n",
        "      net.load_state_dict(global_net.state_dict(), strict=True)\n",
        "      net.to(device)\n",
        "      net.train()\n",
        "      disc.to(device)\n",
        "      optim = optims[cliente]\n",
        "      optim_D = optim_Ds[cliente]\n",
        "\n",
        "      start_img_syn_time = time.time()\n",
        "      num_samples = int(13 * (math.exp(0.01*epoch) - 1) / (math.exp(0.01*50) - 1)) * 10\n",
        "      generated_dataset = GeneratedDataset(generator=gen.to(\"cpu\"), num_samples=num_samples, latent_dim=latent_dim, num_classes=10, device=\"cpu\", image_col_name=image)\n",
        "      gen.to(device)\n",
        "      cmb_ds = ConcatDataset([chunk_dataset, generated_dataset])\n",
        "      combined_dataloader= DataLoader(cmb_ds, batch_size=batch_tam, shuffle=True)\n",
        "\n",
        "      img_syn_time = time.time() - start_img_syn_time\n",
        "\n",
        "      batch_bar_net = tqdm(combined_dataloader, desc=\"Batches\", leave=True, position=3)\n",
        "      start_net_time = time.time()\n",
        "      for batch in batch_bar_net:\n",
        "        images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "        batch_size = images.size(0)\n",
        "        if batch_size == 1:\n",
        "          print(\"Batch size is 1, skipping batch\")\n",
        "          continue\n",
        "        optim.zero_grad()\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "      net_time = time.time() - start_net_time\n",
        "\n",
        "      batch_bar = tqdm(chunk_loader, desc=\"Batches\", leave=True, position=4)\n",
        "\n",
        "      start_disc_time = time.time()\n",
        "      for batch in batch_bar:\n",
        "          images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "          batch_size = images.size(0)\n",
        "          if batch_size == 1:\n",
        "            print(\"Batch size is 1, skipping batch\")\n",
        "            continue\n",
        "\n",
        "          real_ident = torch.full((batch_size, 1), 1., device=device)\n",
        "          fake_ident = torch.full((batch_size, 1), 0., device=device)\n",
        "\n",
        "          z_noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "          x_fake_labels = torch.randint(0, 10, (batch_size,), device=device)\n",
        "\n",
        "          # Train D\n",
        "          optim_D.zero_grad()\n",
        "\n",
        "          if wgan:\n",
        "            labels = torch.nn.functional.one_hot(labels, 10).float().to(device)\n",
        "            x_fake_l = torch.nn.functional.one_hot(x_fake_labels, 10).float()\n",
        "\n",
        "            # Adicionar labels ao images para treinamento do Discriminador\n",
        "            image_labels = labels.view(labels.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "            image_fake_labels = x_fake_l.view(x_fake_l.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "\n",
        "            images = torch.cat([images, image_labels], dim=1)\n",
        "\n",
        "            # Treinar Discriminador\n",
        "            z = torch.cat([z_noise, x_fake_l], dim=1)\n",
        "            fake_images = gen(z).detach()\n",
        "            fake_images = torch.cat([fake_images, image_fake_labels], dim=1)\n",
        "\n",
        "            d_loss = discriminator_loss(disc(images), disc(fake_images)) + 10 * gradient_penalty(disc, images, fake_images)\n",
        "\n",
        "          else:\n",
        "            # Dados Reais\n",
        "            y_real = disc(images, labels)\n",
        "            d_real_loss = disc.loss(y_real, real_ident)\n",
        "\n",
        "            # Dados Falsos\n",
        "            x_fake = gen(z_noise, x_fake_labels).detach()\n",
        "            y_fake_d = disc(x_fake, x_fake_labels)\n",
        "            d_fake_loss = disc.loss(y_fake_d, fake_ident)\n",
        "\n",
        "            # Loss total e backprop\n",
        "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "          d_loss.backward()\n",
        "          #torch.nn.utils.clip_grad_norm_(disc.discriminator.parameters(), max_norm=1.0)\n",
        "          optim_D.step()\n",
        "          d_loss_b += d_loss.item()\n",
        "          total_chunk_samples += 1\n",
        "      disc_time = time.time() - start_disc_time  \n",
        "\n",
        "      params.append(ndarrays_to_parameters([val.cpu().numpy() for _, val in net.state_dict().items()]))\n",
        "      results.append((cliente, FitRes(status=Status(code=Code.OK, message=\"Success\"), parameters=params[cliente], num_examples=len(chunk_loader.dataset), metrics={})))\n",
        "\n",
        "    aggregated_ndarrays = aggregate_inplace(results)\n",
        "\n",
        "    params_dict = zip(global_net.state_dict().keys(), aggregated_ndarrays)\n",
        "    state_dict = OrderedDict({k: torch.tensor(v).to(device) for k, v in params_dict})\n",
        "    global_net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # Evaluation\n",
        "    if chunk_idx % 10 == 0:\n",
        "        global_net.eval()\n",
        "        correct, loss = 0, 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in testloader:\n",
        "                images = batch[image].to(device)\n",
        "                labels = batch[\"label\"].to(device)\n",
        "                outputs = global_net(images)\n",
        "                loss += criterion(outputs, labels).item()\n",
        "                correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        accuracy = correct / len(testloader.dataset)\n",
        "        losses_dict[\"net_loss_chunk\"].append(loss / len(testloader))\n",
        "        losses_dict[\"net_acc_chunk\"].append(accuracy)\n",
        "\n",
        "\n",
        "    # Média da perda dos discriminadores neste chunk\n",
        "    avg_d_loss_chunk = d_loss_b / total_chunk_samples if total_chunk_samples > 0 else 0.0\n",
        "    losses_dict[\"d_losses_chunk\"].append(avg_d_loss_chunk)\n",
        "    d_loss_c += avg_d_loss_chunk * total_chunk_samples\n",
        "    total_d_samples += total_chunk_samples\n",
        "\n",
        "    chunk_g_loss = 0.0\n",
        "\n",
        "    epoch_gen_bar = tqdm(range(extra_g_e), desc=\"Gerador\", leave=True, position=2)\n",
        "\n",
        "    start_gen_time = time.time()\n",
        "    for g_epoch in epoch_gen_bar:\n",
        "      # Train G\n",
        "      optim_G.zero_grad()\n",
        "\n",
        "      # Gera dados falsos\n",
        "      z_noise = torch.randn(batch_size_gen, latent_dim, device=device)\n",
        "      x_fake_labels = torch.randint(0, 10, (batch_size_gen,), device=device)\n",
        "      label = int(x_fake_labels.item())\n",
        "\n",
        "      if wgan:\n",
        "        x_fake_labels = torch.nn.functional.one_hot(x_fake_labels, 10).float()\n",
        "        z_noise = torch.cat([z_noise, x_fake_labels], dim=1)\n",
        "        fake_images = gen(z_noise)\n",
        "\n",
        "        # Seleciona o melhor discriminador (Dmax)\n",
        "        image_fake_labels = x_fake_labels.view(x_fake_labels.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "        fake_images = torch.cat([fake_images, image_fake_labels], dim=1)\n",
        "\n",
        "        y_fake_gs = [model(fake_images.detach()) for model in models]\n",
        "\n",
        "      else:\n",
        "        x_fake = gen(z_noise, x_fake_labels)\n",
        "\n",
        "        if f2a:\n",
        "          y_fakes = []\n",
        "          for D in models:\n",
        "              D = D.to(device)\n",
        "              y_fakes.append(D(x_fake, x_fake_labels))  # each is [B,1]\n",
        "          # stack into [N_discriminators, B, 1]\n",
        "          y_stack = torch.stack(y_fakes, dim=0)\n",
        "\n",
        "          # 4) Compute λ = ReLU(lambda_star) to enforce λ ≥ 0\n",
        "          lam = relu(lambda_star)\n",
        "\n",
        "          # 5) Soft‐max weights across the 0th dim (discriminators)\n",
        "          #    we want S_i = exp(λ D_i) / sum_j exp(λ D_j)\n",
        "          #    shape remains [N, B, 1]\n",
        "          S = torch.softmax(lam * y_stack, dim=0)\n",
        "\n",
        "          # 6) Weighted sum: D_agg shape [B,1]\n",
        "          D_agg = (S * y_stack).sum(dim=0)\n",
        "\n",
        "          # 7) Compute your generator loss + β λ² regularizer\n",
        "          real_ident = torch.full((batch_size_gen, 1), 1., device=device)\n",
        "          adv_loss   = gen.loss(D_agg, real_ident)       # BCEWithLogitsLoss or whatever\n",
        "          reg_loss   = beta * lam.pow(2)                 # β λ²\n",
        "          g_loss     = adv_loss + reg_loss\n",
        "\n",
        "        else:\n",
        "          # Seleciona o melhor discriminador (Dmax)\n",
        "          y_fake_gs = [model(x_fake.detach(), x_fake_labels) for model in models]\n",
        "          y_fake_g_means = [torch.mean(y).item() for y in y_fake_gs]\n",
        "          dmax_index = y_fake_g_means.index(max(y_fake_g_means))\n",
        "          Dmax = models[dmax_index]\n",
        "\n",
        "          start_track_mismatch_time = time.time()\n",
        "          #Track mismatches\n",
        "          expected_indexes = label_to_client[class_labels.int2str(x_fake_labels.item())] ##PEGA SOMENTE A PRIMEIRA LABEL, SE BATCH_SIZE_GEN FOR DIFERENTE DE 1 VAI DAR ERRO\n",
        "          if dmax_index not in expected_indexes:\n",
        "              mismatch_count += 1\n",
        "              total_checked +=1\n",
        "              percent_mismatch =  mismatch_count / total_checked\n",
        "              with open(dmax_mismatch_log, \"a\") as mismatch_file:\n",
        "                  mismatch_file.write(f\"{epoch+1} {x_fake_labels.item()} {expected_indexes} {dmax_index} {percent_mismatch:.2f}\\n\")\n",
        "          else:\n",
        "              total_checked += 1\n",
        "              if g_epoch == extra_g_e - 1 and chunk_idx == num_chunks - 1:\n",
        "                percent_mismatch =  mismatch_count / total_checked\n",
        "                with open(dmax_mismatch_log, \"a\") as mismatch_file:\n",
        "                  mismatch_file.write(f\"{epoch+1} {x_fake_labels.item()} {expected_indexes} {dmax_index} {percent_mismatch:.2f}\\n\")\n",
        "          track_mismatch_time = time.time() - start_track_mismatch_time\n",
        "\n",
        "          # Calcula a perda do gerador\n",
        "          real_ident = torch.full((batch_size_gen, 1), 1., device=device)\n",
        "          if wgan:\n",
        "            y_fake_g = Dmax(fake_images)\n",
        "            g_loss = generator_loss(y_fake_g)\n",
        "\n",
        "          else:\n",
        "            y_fake_g = Dmax(x_fake, x_fake_labels)  # Detach explícito\n",
        "            g_loss = gen.loss(y_fake_g, real_ident)\n",
        "\n",
        "      g_loss.backward()\n",
        "      #torch.nn.utils.clip_grad_norm_(gen.generator.parameters(), max_norm=1.0)\n",
        "      optim_G.step()\n",
        "      gen.to(device)\n",
        "      chunk_g_loss += g_loss.item()\n",
        "    gen_time = time.time() - start_gen_time\n",
        "\n",
        "    losses_dict[\"g_losses_chunk\"].append(chunk_g_loss / extra_g_e)\n",
        "    g_loss_c += chunk_g_loss /extra_g_e\n",
        "\n",
        "    losses_dict[\"time_chunk\"].append(time.time() - chunk_start_time)\n",
        "    losses_dict[\"net_time\"].append(net_time)\n",
        "    losses_dict[\"disc_time\"].append(disc_time)\n",
        "    losses_dict[\"gen_time\"].append(gen_time)\n",
        "    losses_dict[\"img_syn_time\"].append(img_syn_time)\n",
        "    losses_dict[\"track_mismatch_time\"].append(track_mismatch_time)\n",
        "\n",
        "\n",
        "  g_loss_e = g_loss_c/num_chunks\n",
        "  d_loss_e = d_loss_c / total_d_samples if total_d_samples > 0 else 0.0\n",
        "\n",
        "  losses_dict[\"g_losses_round\"].append(g_loss_e)\n",
        "  losses_dict[\"d_losses_round\"].append(d_loss_e)\n",
        "\n",
        "  if (epoch+1)%2==0:\n",
        "      checkpoint = {\n",
        "            'epoch': epoch+1,  # número da última época concluída\n",
        "            'alvo_state_dict': global_net.state_dict(),\n",
        "            'optimizer_alvo_state_dict': [optim.state_dict() for optim in optims],\n",
        "            'gen_state_dict': gen.state_dict(),\n",
        "            'optim_G_state_dict': optim_G.state_dict(),\n",
        "            'discs_state_dict': [model.state_dict() for model in models],\n",
        "            'optim_Ds_state_dict:': [optim_d.state_dict() for optim_d in optim_Ds]\n",
        "          }\n",
        "      checkpoint_file = f\"checkpoint_epoch{epoch+1}.pth\"\n",
        "      if IN_COLAB:\n",
        "          checkpoint_file = os.path.join(save_dir, checkpoint_file)\n",
        "      torch.save(checkpoint, checkpoint_file)\n",
        "      print(f\"Global net saved to {checkpoint_file}\")\n",
        "\n",
        "      if f2a:\n",
        "        current_lambda_star = lambda_star.item()\n",
        "        current_lam         = F.relu(lambda_star).item()\n",
        "\n",
        "        with open(lambda_log, \"a\") as f:\n",
        "          f.write(f\"{current_lambda_star},{current_lam}\\n\")\n",
        "\n",
        "  correct, loss = 0, 0.0\n",
        "  global_net.eval()\n",
        "  with torch.no_grad():\n",
        "      for batch in testloader:\n",
        "          images = batch[image].to(device)\n",
        "          labels = batch[\"label\"].to(device)\n",
        "          outputs = global_net(images)\n",
        "          loss += criterion(outputs, labels).item()\n",
        "          correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "  accuracy = correct / len(testloader.dataset)\n",
        "  losses_dict[\"net_loss_round\"].append(loss / len(testloader))\n",
        "  losses_dict[\"net_acc_round\"].append(accuracy)\n",
        "\n",
        "  print(f\"Época {epoch+1} completa\")\n",
        "  generate_plot(gen, \"cpu\", epoch+1, latent_dim=128)\n",
        "  gen.to(device)\n",
        "\n",
        "  losses_dict[\"time_round\"].append(time.time() - epoch_start_time)\n",
        "\n",
        "  try:\n",
        "      with open(loss_filename, 'w', encoding='utf-8') as f:\n",
        "          json.dump(losses_dict, f, ensure_ascii=False, indent=4) # indent makes it readable\n",
        "      print(f\"Losses dict successfully saved to {loss_filename}\")\n",
        "  except Exception as e:\n",
        "      print(f\"Error saving losses dict to JSON: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4677e695",
      "metadata": {},
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26024cd1",
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoch in range(100):\n",
        "print(\"Epoch\", epoch, int(13 * (math.exp(0.01*epoch) - 1) / (math.exp(0.01*50) - 1)) * 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9aa99aa",
      "metadata": {},
      "source": [
        "### Somente Classificador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_OdHAvK0LQp3",
      "metadata": {
        "collapsed": true,
        "id": "_OdHAvK0LQp3"
      },
      "outputs": [],
      "source": [
        "epochs = 2\n",
        "losses_dict = {\"net_loss_chunk\": [],\n",
        "               \"net_acc_chunk\": [],\n",
        "               \"net_loss_round\": [],\n",
        "               \"net_acc_round\": [],\n",
        "               \"time_chunk\": [],\n",
        "               \"time_round\": []}\n",
        "\n",
        "epoch_bar = tqdm(range(0, epochs), desc=\"Treinamento\", leave=True, position=0)\n",
        "\n",
        "batch_tam = 32\n",
        "latent_dim = 128\n",
        "num_classes = 10\n",
        "if type(nets[0]).__name__ == \"Net\":\n",
        "  image = \"image\"\n",
        "else:\n",
        "  image = \"img\"\n",
        "\n",
        "if IN_COLAB:\n",
        "  acc_filename = os.path.join(save_dir,\"accuracy_report.txt\")\n",
        "  loss_filename = os.path.join(save_dir, \"losses.json\")\n",
        "else:\n",
        "  acc_filename = \"accuracy_report.txt\"\n",
        "  loss_filename = \"losses.json\"\n",
        "\n",
        "for epoch in epoch_bar:\n",
        "  epoch_start_time = time.time()\n",
        "\n",
        "  chunk_bar = tqdm(range(num_chunks), desc=\"Chunks\", leave=True, position=1)\n",
        "\n",
        "  for chunk_idx in chunk_bar:\n",
        "    params = []\n",
        "    results = []\n",
        "    chunk_start_time = time.time()\n",
        "    total_chunk_samples = 0\n",
        "\n",
        "    client_bar = tqdm(enumerate(zip(nets, client_chunks)), desc=\"Clients\", leave=True, position=2)\n",
        "\n",
        "    for cliente, (net, chunks) in client_bar:\n",
        "\n",
        "      if chunk_idx == 0:\n",
        "        client_eval_time = time.time()\n",
        "        # Evaluation in client test\n",
        "        # Initialize counters\n",
        "        class_correct = defaultdict(int)\n",
        "        class_total = defaultdict(int)\n",
        "        predictions_counter = defaultdict(int)\n",
        "\n",
        "        global_net.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in client_test_loaders[cliente]:\n",
        "                images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "                outputs = global_net(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                # Update counts for each sample in batch\n",
        "                for true_label, pred_label in zip(labels, predicted):\n",
        "                    true_idx = true_label.item()\n",
        "                    pred_idx = pred_label.item()\n",
        "\n",
        "                    class_total[true_idx] += 1\n",
        "                    predictions_counter[pred_idx] += 1\n",
        "\n",
        "                    if true_idx == pred_idx:\n",
        "                        class_correct[true_idx] += 1\n",
        "\n",
        "            # Create results dictionary\n",
        "            results_metrics = {\n",
        "                \"class_metrics\": {},\n",
        "                \"overall_accuracy\": None,\n",
        "                \"prediction_distribution\": dict(predictions_counter)\n",
        "            }\n",
        "\n",
        "            # Calculate class-wise metrics\n",
        "            for i in range(num_classes):\n",
        "                metrics = {\n",
        "                    \"samples\": class_total[i],\n",
        "                    \"predictions\": predictions_counter[i],\n",
        "                    \"accuracy\": class_correct[i] / class_total[i] if class_total[i] > 0 else \"N/A\"\n",
        "                }\n",
        "                results_metrics[\"class_metrics\"][f\"class_{i}\"] = metrics\n",
        "\n",
        "            # Calculate overall accuracy\n",
        "            total_samples = sum(class_total.values())\n",
        "            results_metrics[\"overall_accuracy\"] = sum(class_correct.values()) / total_samples\n",
        "\n",
        "            # Save to txt file\n",
        "            with open(acc_filename, \"a\") as f:\n",
        "                f.write(f\"Epoch {epoch + 1} - Client {cliente}\\n\")\n",
        "                # Header with fixed widths\n",
        "                f.write(\"{:<10} {:<10} {:<10} {:<10}\\n\".format(\n",
        "                    \"Class\", \"Accuracy\", \"Samples\", \"Predictions\"))\n",
        "                f.write(\"-\"*45 + \"\\n\")\n",
        "\n",
        "                # Class rows with consistent formatting\n",
        "                for cls in range(num_classes):\n",
        "                    metrics = results_metrics[\"class_metrics\"][f\"class_{cls}\"]\n",
        "\n",
        "                    # Format accuracy (handle \"N/A\" case)\n",
        "                    accuracy = (f\"{metrics['accuracy']:.4f}\"\n",
        "                              if isinstance(metrics['accuracy'], float)\n",
        "                              else \"  N/A  \")\n",
        "\n",
        "                    f.write(\"{:<10} {:<10} {:<10} {:<10}\\n\".format(\n",
        "                        f\"Class {cls}\",\n",
        "                        accuracy,\n",
        "                        metrics['samples'],\n",
        "                        metrics['predictions']\n",
        "                    ))\n",
        "\n",
        "                # Footer with alignment\n",
        "                f.write(\"\\n{:<20} {:.4f}\".format(\"Overall Accuracy:\", results_metrics[\"overall_accuracy\"]))\n",
        "                f.write(\"\\n{:<20} {}\".format(\"Total Samples:\", total_samples))\n",
        "                f.write(\"\\n{:<20} {}\".format(\"Total Predictions:\", sum(predictions_counter.values())))\n",
        "                f.write(\"\\n{:<20} {:.4f}\".format(\"Client Evaluation Time:\", time.time() - client_eval_time))\n",
        "                f.write(\"\\n\")\n",
        "                f.write(\"\\n\")\n",
        "\n",
        "        print(\"Results saved to accuracy_report.txt\")\n",
        "\n",
        "      # Carregar o bloco atual do cliente\n",
        "      chunk_dataset = chunks[chunk_idx]\n",
        "      if len(chunk_dataset) == 0:\n",
        "        print(f\"Chunk {chunk_idx} for client {cliente} is empty, skipping.\")\n",
        "        continue\n",
        "      chunk_loader = DataLoader(chunk_dataset, batch_size=batch_tam, shuffle=False)\n",
        "\n",
        "      net.load_state_dict(global_net.state_dict(), strict=True)\n",
        "      net.to(device)\n",
        "      net.train()\n",
        "      optim = optims[cliente]\n",
        "\n",
        "      batch_bar = tqdm(chunk_loader, desc=\"Batches\", leave=True, position=3)\n",
        "\n",
        "      for batch in batch_bar:\n",
        "        images, labels = batch[image].to(device), batch[\"label\"].to(device)\n",
        "        batch_size = images.size(0)\n",
        "        if batch_size == 1:\n",
        "          print(\"Batch size is 1, skipping batch\")\n",
        "          continue\n",
        "        optim.zero_grad()\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "\n",
        "      params.append(ndarrays_to_parameters([val.cpu().numpy() for _, val in net.state_dict().items()]))\n",
        "      results.append((cliente, FitRes(status=Status(code=Code.OK, message=\"Success\"), parameters=params[cliente], num_examples=len(chunk_loader.dataset), metrics={})))\n",
        "\n",
        "    aggregated_ndarrays = aggregate_inplace(results)\n",
        "\n",
        "    params_dict = zip(global_net.state_dict().keys(), aggregated_ndarrays)\n",
        "    state_dict = OrderedDict({k: torch.tensor(v).to(device) for k, v in params_dict})\n",
        "    global_net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    # Evaluation\n",
        "    if chunk_idx % 10 == 0:\n",
        "        global_net.eval()\n",
        "        correct, loss = 0, 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in testloader:\n",
        "                images = batch[image].to(device)\n",
        "                labels = batch[\"label\"].to(device)\n",
        "                outputs = global_net(images)\n",
        "                loss += criterion(outputs, labels).item()\n",
        "                correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        accuracy = correct / len(testloader.dataset)\n",
        "        losses_dict[\"net_loss_chunk\"].append(loss / len(testloader))\n",
        "        losses_dict[\"net_acc_chunk\"].append(accuracy)\n",
        "\n",
        "        losses_dict[\"time_chunk\"].append(time.time() - chunk_start_time)\n",
        "\n",
        "  correct, loss = 0, 0.0\n",
        "  global_net.eval()\n",
        "  with torch.no_grad():\n",
        "      for batch in testloader:\n",
        "          images = batch[image].to(device)\n",
        "          labels = batch[\"label\"].to(device)\n",
        "          outputs = global_net(images)\n",
        "          loss += criterion(outputs, labels).item()\n",
        "          correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "  accuracy = correct / len(testloader.dataset)\n",
        "  losses_dict[\"net_loss_round\"].append(loss / len(testloader))\n",
        "  losses_dict[\"net_acc_round\"].append(accuracy)\n",
        "\n",
        "\n",
        "  print(f\"Época {epoch+1} completa\")\n",
        "\n",
        "  losses_dict[\"time_round\"].append(time.time() - epoch_start_time)\n",
        "\n",
        "  try:\n",
        "      with open(loss_filename, 'w', encoding='utf-8') as f:\n",
        "          json.dump(losses_dict, f, ensure_ascii=False, indent=4) # indent makes it readable\n",
        "      print(f\"Losses dict successfully saved to {loss_filename}\")\n",
        "  except Exception as e:\n",
        "      print(f\"Error saving losses dict to JSON: {e}\")\n",
        "\n",
        "  if (epoch+1)%1==0:\n",
        "    checkpoint = {\n",
        "          'epoch': epoch+1,  # número da última época concluída\n",
        "          'alvo_state_dict': global_net.state_dict(),\n",
        "          'optimizer_alvo_state_dict': [optim.state_dict() for optim in optims],\n",
        "        }\n",
        "    checkpoint_file = f\"checkpoint_epoch{epoch+1}.pth\"\n",
        "    if IN_COLAB:\n",
        "        checkpoint_file = os.path.join(save_dir, checkpoint_file)\n",
        "    torch.save(checkpoint, checkpoint_file)\n",
        "    print(f\"Global net saved to {checkpoint_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44064765",
      "metadata": {},
      "source": [
        "### Somente Gerador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b7312a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "wgan = False\n",
        "f2a = False\n",
        "epochs = 3\n",
        "losses_dict = {\"g_losses_chunk\": [],\n",
        "               \"d_losses_chunk\": [],\n",
        "               \"g_losses_round\": [],\n",
        "               \"d_losses_round\": [],\n",
        "               \"time_chunk\": [],\n",
        "               \"time_round\": [],\n",
        "               \"disc_time\": [],\n",
        "               \"gen_time\": [],\n",
        "               \"img_syn_time\": [],\n",
        "               \"track_mismatch_time\": []\n",
        "               }\n",
        "\n",
        "epoch_bar = tqdm(range(0, epochs), desc=\"Treinamento\", leave=True, position=0)\n",
        "\n",
        "batch_size_gen = 1\n",
        "batch_tam = 32\n",
        "extra_g_e = 20\n",
        "latent_dim = 128\n",
        "num_classes = 10\n",
        "\n",
        "if IN_COLAB:\n",
        "  loss_filename = os.path.join(save_dir, \"losses.json\")\n",
        "  dmax_mismatch_log = os.path.join(save_dir, \"dmax_mismatch.txt\")\n",
        "  lambda_log = os.path.join(save_dir, \"lambda_log.txt\")\n",
        "\n",
        "else:\n",
        "  loss_filename = \"losses.json\"\n",
        "  dmax_mismatch_log = \"dmax_mismatch.txt\"\n",
        "  lambda_log = \"lambda_log.txt\"\n",
        "\n",
        "for epoch in epoch_bar:\n",
        "  epoch_start_time = time.time()\n",
        "  mismatch_count = 0\n",
        "  total_checked = 0\n",
        "  g_loss_c = 0.0\n",
        "  d_loss_c = 0.0\n",
        "  total_d_samples = 0  # Amostras totais processadas pelos discriminadores\n",
        "  total_g_samples = 0  # Amostras totais processadas pelo gerador\n",
        "\n",
        "  chunk_bar = tqdm(range(num_chunks), desc=\"Chunks\", leave=True, position=1)\n",
        "\n",
        "  for chunk_idx in chunk_bar:\n",
        "    chunk_start_time = time.time()\n",
        "    # ====================================================================\n",
        "    # Treino dos Discriminadores (clientes) no bloco atual\n",
        "    # ====================================================================\n",
        "    d_loss_b = 0\n",
        "    total_chunk_samples = 0\n",
        "\n",
        "\n",
        "    client_bar = tqdm(enumerate(zip(models, client_chunks)), desc=\"Clients\", leave=True, position=2)\n",
        "\n",
        "    for cliente, (disc, chunks) in client_bar:\n",
        "      # Carregar o bloco atual do cliente\n",
        "      chunk_dataset = chunks[chunk_idx]\n",
        "      if len(chunk_dataset) == 0:\n",
        "        print(f\"Chunk {chunk_idx} for client {cliente} is empty, skipping.\")\n",
        "        continue\n",
        "      chunk_loader = DataLoader(chunk_dataset, batch_size=batch_tam, shuffle=True)\n",
        "\n",
        "      # Treinar o discriminador no bloco\n",
        "      disc.to(device)\n",
        "      optim_D = optim_Ds[cliente]\n",
        "\n",
        "      batch_bar = tqdm(chunk_loader, desc=\"Batches\", leave=True, position=4)\n",
        "\n",
        "      start_disc_time = time.time()\n",
        "      for batch in batch_bar:\n",
        "          images, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "          batch_size = images.size(0)\n",
        "          if batch_size == 1:\n",
        "            print(\"Batch size is 1, skipping batch\")\n",
        "            continue\n",
        "\n",
        "          real_ident = torch.full((batch_size, 1), 1., device=device)\n",
        "          fake_ident = torch.full((batch_size, 1), 0., device=device)\n",
        "\n",
        "          z_noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "          x_fake_labels = torch.randint(0, 10, (batch_size,), device=device)\n",
        "\n",
        "          # Train D\n",
        "          optim_D.zero_grad()\n",
        "\n",
        "          if wgan:\n",
        "            labels = torch.nn.functional.one_hot(labels, 10).float().to(device)\n",
        "            x_fake_l = torch.nn.functional.one_hot(x_fake_labels, 10).float()\n",
        "\n",
        "            # Adicionar labels ao images para treinamento do Discriminador\n",
        "            image_labels = labels.view(labels.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "            image_fake_labels = x_fake_l.view(x_fake_l.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "\n",
        "            images = torch.cat([images, image_labels], dim=1)\n",
        "\n",
        "            # Treinar Discriminador\n",
        "            z = torch.cat([z_noise, x_fake_l], dim=1)\n",
        "            fake_images = gen(z).detach()\n",
        "            fake_images = torch.cat([fake_images, image_fake_labels], dim=1)\n",
        "\n",
        "            d_loss = discriminator_loss(disc(images), disc(fake_images)) + 10 * gradient_penalty(disc, images, fake_images)\n",
        "\n",
        "          else:\n",
        "            # Dados Reais\n",
        "            y_real = disc(images, labels)\n",
        "            d_real_loss = disc.loss(y_real, real_ident)\n",
        "\n",
        "            # Dados Falsos\n",
        "            x_fake = gen(z_noise, x_fake_labels).detach()\n",
        "            y_fake_d = disc(x_fake, x_fake_labels)\n",
        "            d_fake_loss = disc.loss(y_fake_d, fake_ident)\n",
        "\n",
        "            # Loss total e backprop\n",
        "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "          d_loss.backward()\n",
        "          #torch.nn.utils.clip_grad_norm_(disc.discriminator.parameters(), max_norm=1.0)\n",
        "          optim_D.step()\n",
        "          d_loss_b += d_loss.item()\n",
        "          total_chunk_samples += 1\n",
        "      disc_time = time.time() - start_disc_time  \n",
        "\n",
        "\n",
        "    # Média da perda dos discriminadores neste chunk\n",
        "    avg_d_loss_chunk = d_loss_b / total_chunk_samples if total_chunk_samples > 0 else 0.0\n",
        "    losses_dict[\"d_losses_chunk\"].append(avg_d_loss_chunk)\n",
        "    d_loss_c += avg_d_loss_chunk * total_chunk_samples\n",
        "    total_d_samples += total_chunk_samples\n",
        "\n",
        "    chunk_g_loss = 0.0\n",
        "\n",
        "    epoch_gen_bar = tqdm(range(extra_g_e), desc=\"Gerador\", leave=True, position=2)\n",
        "\n",
        "    start_gen_time = time.time()\n",
        "    for g_epoch in epoch_gen_bar:\n",
        "      # Train G\n",
        "      optim_G.zero_grad()\n",
        "\n",
        "      # Gera dados falsos\n",
        "      z_noise = torch.randn(batch_size_gen, latent_dim, device=device)\n",
        "      x_fake_labels = torch.randint(0, 10, (batch_size_gen,), device=device)\n",
        "      label = int(x_fake_labels.item())\n",
        "\n",
        "      if wgan:\n",
        "        x_fake_labels = torch.nn.functional.one_hot(x_fake_labels, 10).float()\n",
        "        z_noise = torch.cat([z_noise, x_fake_labels], dim=1)\n",
        "        fake_images = gen(z_noise)\n",
        "\n",
        "        # Seleciona o melhor discriminador (Dmax)\n",
        "        image_fake_labels = x_fake_labels.view(x_fake_labels.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "        fake_images = torch.cat([fake_images, image_fake_labels], dim=1)\n",
        "\n",
        "        y_fake_gs = [model(fake_images.detach()) for model in models]\n",
        "\n",
        "      else:\n",
        "        x_fake = gen(z_noise, x_fake_labels)\n",
        "\n",
        "        if f2a:\n",
        "          y_fakes = []\n",
        "          for D in models:\n",
        "              D = D.to(device)\n",
        "              y_fakes.append(D(x_fake, x_fake_labels))  # each is [B,1]\n",
        "          # stack into [N_discriminators, B, 1]\n",
        "          y_stack = torch.stack(y_fakes, dim=0)\n",
        "\n",
        "          # 4) Compute λ = ReLU(lambda_star) to enforce λ ≥ 0\n",
        "          lam = relu(lambda_star)\n",
        "\n",
        "          # 5) Soft‐max weights across the 0th dim (discriminators)\n",
        "          #    we want S_i = exp(λ D_i) / sum_j exp(λ D_j)\n",
        "          #    shape remains [N, B, 1]\n",
        "          S = torch.softmax(lam * y_stack, dim=0)\n",
        "\n",
        "          # 6) Weighted sum: D_agg shape [B,1]\n",
        "          D_agg = (S * y_stack).sum(dim=0)\n",
        "\n",
        "          # 7) Compute your generator loss + β λ² regularizer\n",
        "          real_ident = torch.full((batch_size_gen, 1), 1., device=device)\n",
        "          adv_loss   = gen.loss(D_agg, real_ident)       # BCEWithLogitsLoss or whatever\n",
        "          reg_loss   = beta * lam.pow(2)                 # β λ²\n",
        "          g_loss     = adv_loss + reg_loss\n",
        "\n",
        "        else:\n",
        "          # Seleciona o melhor discriminador (Dmax)\n",
        "          y_fake_gs = [model(x_fake.detach(), x_fake_labels) for model in models]\n",
        "          y_fake_g_means = [torch.mean(y).item() for y in y_fake_gs]\n",
        "          dmax_index = y_fake_g_means.index(max(y_fake_g_means))\n",
        "          Dmax = models[dmax_index]\n",
        "\n",
        "          start_track_mismatch_time = time.time()\n",
        "          #Track mismatches\n",
        "          expected_indexes = label_to_client[class_labels.int2str(x_fake_labels.item())] ##PEGA SOMENTE A PRIMEIRA LABEL, SE BATCH_SIZE_GEN FOR DIFERENTE DE 1 VAI DAR ERRO\n",
        "          if dmax_index not in expected_indexes:\n",
        "              mismatch_count += 1\n",
        "              total_checked +=1\n",
        "              percent_mismatch =  mismatch_count / total_checked\n",
        "              with open(dmax_mismatch_log, \"a\") as mismatch_file:\n",
        "                  mismatch_file.write(f\"{epoch+1} {x_fake_labels.item()} {expected_indexes} {dmax_index} {percent_mismatch:.2f}\\n\")\n",
        "          else:\n",
        "              total_checked += 1\n",
        "              if g_epoch == extra_g_e - 1 and chunk_idx == num_chunks - 1:\n",
        "                percent_mismatch =  mismatch_count / total_checked\n",
        "                with open(dmax_mismatch_log, \"a\") as mismatch_file:\n",
        "                  mismatch_file.write(f\"{epoch+1} {x_fake_labels.item()} {expected_indexes} {dmax_index} {percent_mismatch:.2f}\\n\")\n",
        "          track_mismatch_time = time.time() - start_track_mismatch_time\n",
        "\n",
        "          # Calcula a perda do gerador\n",
        "          real_ident = torch.full((batch_size_gen, 1), 1., device=device)\n",
        "          if wgan:\n",
        "            y_fake_g = Dmax(fake_images)\n",
        "            g_loss = generator_loss(y_fake_g)\n",
        "\n",
        "          else:\n",
        "            y_fake_g = Dmax(x_fake, x_fake_labels)  # Detach explícito\n",
        "            g_loss = gen.loss(y_fake_g, real_ident)\n",
        "\n",
        "      g_loss.backward()\n",
        "      #torch.nn.utils.clip_grad_norm_(gen.generator.parameters(), max_norm=1.0)\n",
        "      optim_G.step()\n",
        "      gen.to(device)\n",
        "      chunk_g_loss += g_loss.item()\n",
        "    gen_time = time.time() - start_gen_time\n",
        "\n",
        "    losses_dict[\"g_losses_chunk\"].append(chunk_g_loss / extra_g_e)\n",
        "    g_loss_c += chunk_g_loss /extra_g_e\n",
        "\n",
        "    losses_dict[\"time_chunk\"].append(time.time() - chunk_start_time)\n",
        "    losses_dict[\"disc_time\"].append(disc_time)\n",
        "    losses_dict[\"gen_time\"].append(gen_time)\n",
        "    losses_dict[\"track_mismatch_time\"].append(track_mismatch_time)\n",
        "\n",
        "\n",
        "  g_loss_e = g_loss_c/num_chunks\n",
        "  d_loss_e = d_loss_c / total_d_samples if total_d_samples > 0 else 0.0\n",
        "\n",
        "  losses_dict[\"g_losses_round\"].append(g_loss_e)\n",
        "  losses_dict[\"d_losses_round\"].append(d_loss_e)\n",
        "\n",
        "  if (epoch+1)%2==0:\n",
        "      checkpoint = {\n",
        "            'epoch': epoch+1,  # número da última época concluída\n",
        "            'gen_state_dict': gen.state_dict(),\n",
        "            'optim_G_state_dict': optim_G.state_dict(),\n",
        "            'discs_state_dict': [model.state_dict() for model in models],\n",
        "            'optim_Ds_state_dict:': [optim_d.state_dict() for optim_d in optim_Ds]\n",
        "          }\n",
        "      checkpoint_file = f\"checkpoint_epoch{epoch+1}.pth\"\n",
        "      if IN_COLAB:\n",
        "          checkpoint_file = os.path.join(save_dir, checkpoint_file)\n",
        "      torch.save(checkpoint, checkpoint_file)\n",
        "      print(f\"Global net saved to {checkpoint_file}\")\n",
        "\n",
        "      if f2a:\n",
        "        current_lambda_star = lambda_star.item()\n",
        "        current_lam         = F.relu(lambda_star).item()\n",
        "\n",
        "        with open(lambda_log, \"a\") as f:\n",
        "          f.write(f\"{current_lambda_star},{current_lam}\\n\")\n",
        "\n",
        "  print(f\"Época {epoch+1} completa\")\n",
        "  generate_plot(gen, \"cpu\", epoch+1, latent_dim=128)\n",
        "  gen.to(device)\n",
        "\n",
        "  losses_dict[\"time_round\"].append(time.time() - epoch_start_time)\n",
        "\n",
        "  try:\n",
        "      with open(loss_filename, 'w', encoding='utf-8') as f:\n",
        "          json.dump(losses_dict, f, ensure_ascii=False, indent=4) # indent makes it readable\n",
        "      print(f\"Losses dict successfully saved to {loss_filename}\")\n",
        "  except Exception as e:\n",
        "      print(f\"Error saving losses dict to JSON: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c3ce47d",
      "metadata": {
        "id": "2c3ce47d"
      },
      "source": [
        "# Gráficos de perda e acurácia"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01f7dbfb",
      "metadata": {
        "id": "01f7dbfb"
      },
      "source": [
        "## Le o arquivo de perda salvo no treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-by_-71kSOeu",
      "metadata": {
        "id": "-by_-71kSOeu"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c75c3fb9",
      "metadata": {},
      "outputs": [],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29ff7c31",
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(\"../../../FLEG_Experiments/valid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d6140f4",
      "metadata": {},
      "source": [
        "### Hardcode List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "648153d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "files = [\n",
        "    \"class_level0/metrics.json\",\n",
        "    \"class_level1/metrics.json\",\n",
        "    \"class_level1/3000_samples/metrics.json\",\n",
        "    \"class_level1/12000_samples/metrics.json\",\n",
        "    \"class_level1/D_samples/metrics.json\",\n",
        "    \"class_level2/metrics.json\",\n",
        "    \"class_level3/metrics.json\",\n",
        "    \"class_level4/metrics.json\",\n",
        "    \"gan_level1/metrics.json\",\n",
        "    \"gan_level2/metrics.json\",\n",
        "    \"gan_level3/metrics.json\",\n",
        "    \"gan_level4/metrics.json\",\n",
        "    \"class_patience100/metrics.json\",\n",
        "    \"class_patience1000/metrics.json\",\n",
        "    \"../iniciais/mnist_ClassPartitioner_fedavg_numchunks_100_fleg_trial1/metrics.json\",\n",
        "    \"../iniciais/mnist_ClassPartitioner_fedavg_numchunks_10_fleg_trial1/metrics.json\",\n",
        "    \"../iniciais/mnist_ClassPartitioner_fedavg_numchunks_50_fleg_trial1/metrics.json\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fed31822",
      "metadata": {},
      "outputs": [],
      "source": [
        "files = [\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks1_ganepoch40_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks10_ganepoch35_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks50_ganepoch30_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks200_ganepoch20_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg/class_level0/metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg/class_level1/metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg/class_level1/D_samples/metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg/class_level2/metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg/class_level3/metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg/class_level4/metrics.json\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "394e0b15",
      "metadata": {},
      "outputs": [],
      "source": [
        "files = [\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_100_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_100_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_100_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_100_ganepoch20_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_100_ganepoch20_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_100_ganepoch20_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_100_ganepoch30_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_100_ganepoch30_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_100_ganepoch30_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_50_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_50_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_50_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial1/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial2/metrics.json\",\n",
        "    \"cifar10_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial3/metrics.json\"\n",
        "\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch20_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch20_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch20_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch30_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch30_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch30_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial3/metrics.json\"\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial3/metrics.json\"\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial3/metrics.json\",\n",
        "\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial3/metrics.json\",\n",
        "\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial1/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial2/metrics.json\",\n",
        "    \"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial3/metrics.json\"\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f017ac26",
      "metadata": {},
      "outputs": [],
      "source": [
        "files = [\n",
        "    \"../../Tests_FedGenIA/Padrao_FedGenIA_DML-ICC/mnist_ClassPartitioner_fedavg_fedgenia_trial1/metrics.json\",\n",
        "    \"../../Tests_FedGenIA/Padrao_FedGenIA_DML-ICC/mnist_ClassPartitioner_fedavg_fedgenia_trial2/metrics.json\",\n",
        "    \"../../Tests_FedGenIA/Padrao_FedGenIA_DML-ICC/mnist_ClassPartitioner_fedavg_fedgenia_trial3/metrics.json\",\n",
        "\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/nb_100chunks/metrics.json\",\n",
        "\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/mnist_ClassPartitioner_fedavg_fedgenia_trial1/metrics.json\",\n",
        "\n",
        "    \"../../Experimentos/Flwr_run/FedGenIA_F2U/mnist/Class/fedavg/4_clients/metrics.json\",\n",
        "\n",
        "    \"../../Experimentos/Testing_gen_weights/Flwr_run/FedGenIA_F2U/mnist/Class/fedavg/4_clients/metrics.json\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce3233e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "files =[\n",
        "    #FedAvg\n",
        "    \"MNIST/Class/Trial1/metrics_fedavg.json\",\n",
        "    \"CIFAR10/Class/Trial1/metrics_fedavg.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/metrics_fedavg.json\",\n",
        "    \"CIFAR10/Dir05/Trial1/metrics_fedavg.json\",\n",
        "\n",
        "    # Chunked FedAvg\n",
        "    \"MNIST/Class/Trial1/losses_chunked_fedavg.json\",\n",
        "    \"CIFAR10/Class/Trial1/losses_chunked_fedavg.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/losses_chunked_fedavg.json\",\n",
        "    \"CIFAR10/Dir05/Trial1/losses_chunked_fedavg.json\",\n",
        "\n",
        "    \"CIFAR10/Class/Trial1/fedavg_50chunks_metrics.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/fedavg_50chunks_metrics.json\",\n",
        "    #\"CIFAR10/Dir05/Trial1/\n",
        "\n",
        "\n",
        "    # Chunked FedProx\n",
        "    \"MNIST/Class/Trial1/metrics_chunked_fedprox.json\",\n",
        "    \"CIFAR10/Class/Trial1/metrics_chunked_fedprox.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/metrics_chunked_fedprox.json\",\n",
        "    \"CIFAR10/Dir05/Trial1/metrics_chunked_fedprox.json\",\n",
        "\n",
        "    \"CIFAR10/Class/Trial1/fedprox_50chunks_metrics.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/fedprox_50chunks_metrics.json\",\n",
        "    #\"CIFAR10/Dir05/Trial1/metrics_chunked_fedprox.json\",\n",
        "\n",
        "\n",
        "    # Chunked Scaffold\n",
        "    \"MNIST/Class/Trial1/metrics_chunked_scaffold.json\",\n",
        "    \"CIFAR10/Class/Trial1/metrics_chunked_scaffold.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/metrics_chunked_scaffold.json\",\n",
        "    \"CIFAR10/Dir05/Trial1/metrics_chunked_scaffold.json\",\n",
        "\n",
        "    # FedGenIA\n",
        "    \"MNIST/Class/Trial1/metrics.json\",\n",
        "    \"CIFAR10/Class/Trial1/metrics.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/metrics.json\",\n",
        "    #\"CIFAR10/Dir05/Trial1/metrics.json\",\n",
        "    \"CIFAR10/Dir05/Trial2/metrics.json\",\n",
        "\n",
        "    \"CIFAR10/Class/Trial1/fedavg_fedgenia_50chunks_metrics.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/fedgenia_fedavg_50chunks_metrics.json\",\n",
        "\n",
        "\n",
        "    # FedGenIA + FedProx\n",
        "    \"MNIST/Class/Trial1/metrics_fedprox_fedgenia.json\",\n",
        "    \"CIFAR10/Class/Trial1/metrics_fedprox_fedgenia.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/metrics_fedprox_fedgenia.json\",\n",
        "    \"CIFAR10/Dir05/Trial1/metrics_fedprox_fedgenia.json\",\n",
        "\n",
        "    \"CIFAR10/Class/Trial1/fedgenia_fedprox_50chunks_metrics.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/fedgenia_fedprox_50chunks_metrics.json\",\n",
        "\n",
        "\n",
        "    # FedGenIA + Scaffold\n",
        "    \"MNIST/Class/Trial1/metrics_scaffold_fedgenia.json\",\n",
        "    \"CIFAR10/Class/Trial1/metrics_scaffold_fedgenia.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/metrics_scaffold_fedgenia.json\",\n",
        "    \"CIFAR10/Dir05/Trial1/metrics_scaffold_fedgenia.json\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4434eb27",
      "metadata": {},
      "outputs": [],
      "source": [
        "files = [\n",
        "    \"MNIST/Class/Trial1/losses_chunked_fedavg.json\",\n",
        "    \"MNIST/Dir01/Trial1/losses_chunked_fedavg.json\",\n",
        "    \"MNIST/Dir05/Trial1/losses_chunked_fedavg.json\",\n",
        "    \"losses_iid_mnist_chunked_fedavg.json\",\n",
        "    \"CIFAR10/Class/Trial1/losses_chunked_fedavg.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/losses_chunked_fedavg.json\",\n",
        "    \"CIFAR10/Dir05/Trial1/losses_chunked_fedavg.json\",\n",
        "    \"losses_iid_cifar_chunked_fedavg.json\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FaRDCz_cSJDf",
      "metadata": {
        "id": "FaRDCz_cSJDf"
      },
      "outputs": [],
      "source": [
        "files = [\n",
        "    \"MNIST/Class/Trial1/losses.json\",\n",
        "    \"MNIST/Class/Trial2/losses.json\",\n",
        "    \"MNIST/Class/Trial3/losses.json\",\n",
        "    # \"MNIST/Dir01/Trial1/losses.json\",\n",
        "    # \"MNIST/Dir01/Trial2/losses.json\",\n",
        "    # \"MNIST/Dir01/Trial3/losses.json\",\n",
        "    # \"MNIST/Dir05/Trial1/losses.json\",\n",
        "    # \"MNIST/Dir05/Trial2/losses.json\",\n",
        "    # \"MNIST/Dir05/Trial3/losses.json\",\n",
        "    \"CIFAR10/Class/Trial1/losses.json\",\n",
        "    \"CIFAR10/Class/Trial2/losses.json\",\n",
        "    \"CIFAR10/Class/Trial3/losses.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/losses.json\",\n",
        "    \"CIFAR10/Dir01/Trial2/losses.json\",\n",
        "    \"CIFAR10/Dir01/Trial3/losses.json\",\n",
        "    \"CIFAR10/Dir05/Trial1/losses.json\",\n",
        "    \"CIFAR10/Dir05/Trial2/losses.json\",\n",
        "    \"CIFAR10/Dir05/Trial3/losses.json\"\n",
        "]\n",
        "\n",
        "# if IN_COLAB:\n",
        "#   loss_filename = os.path.join(save_dir, loss_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73f49236",
      "metadata": {},
      "source": [
        "### Automatic Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53b8c419",
      "metadata": {},
      "outputs": [],
      "source": [
        "root = Path(\".\")  # or your experiment root\n",
        "files = list(root.glob(\"**/metrics.json\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49537f37",
      "metadata": {
        "id": "49537f37"
      },
      "outputs": [],
      "source": [
        "loaded_dicts = {}\n",
        "\n",
        "for file in files:\n",
        "    try:\n",
        "        with open(file, 'r', encoding='utf-8') as f:\n",
        "            loaded_dicts[str(file).replace(\"/\", \"_\")] = json.load(f)\n",
        "\n",
        "        print(f\"Dictionary successfully loaded from {file}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{file}' not found.\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Could not decode JSON from '{file}'. File might be corrupted or not JSON.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dictionary from JSON: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d24b634",
      "metadata": {
        "id": "8d24b634"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f0588a2",
      "metadata": {
        "id": "8f0588a2"
      },
      "outputs": [],
      "source": [
        "def parse_client_accuracies(log_path):\n",
        "   # Regex to match \"Round X - Cliente Y\" and \"Overall Accuracy:    Z.ZZZZ\"\n",
        "   header_re   = re.compile(r\"Epoch\\s+\\d+\\s*-\\s*Client\\s*(\\d+)\", re.IGNORECASE)\n",
        "   accuracy_re = re.compile(r\"Overall Accuracy:\\s*([\\d.]+)\")\n",
        "\n",
        "\n",
        "   # Now client → list of accuracies\n",
        "   client_accuracies = defaultdict(list)\n",
        "\n",
        "\n",
        "   with open(log_path, 'r', encoding='utf-8') as f:\n",
        "       current_client = None\n",
        "\n",
        "\n",
        "       for line in f:\n",
        "           # Detect the client header\n",
        "           hdr = header_re.search(line)\n",
        "           if hdr:\n",
        "               current_client = int(hdr.group(1))\n",
        "               continue\n",
        "\n",
        "\n",
        "           # Once we see the accuracy line, append and reset\n",
        "           if current_client is not None:\n",
        "               acc = accuracy_re.search(line)\n",
        "               if acc:\n",
        "                   client_accuracies[current_client].append(float(acc.group(1)))\n",
        "                   current_client = None\n",
        "\n",
        "\n",
        "   return dict(client_accuracies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f397ca9c",
      "metadata": {
        "id": "f397ca9c"
      },
      "outputs": [],
      "source": [
        "log_files = [\n",
        "    \"CIFAR10/Dir01/Trial1/local_accuracy_report.txt\",\n",
        "    \"CIFAR10/Dir01/Trial1/local_accuracy_report_chunked_fedavg.txt\",\n",
        "    \"CIFAR10/Dir01/Trial1/local_accuracy_report_chunked_fedprox.txt\",\n",
        "    \"CIFAR10/Dir01/Trial1/local_accuracy_report_fedprox_fedgenia.txt\",\n",
        "    \"CIFAR10/Dir01/Trial1/fedavg_50chunks_metrics.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/fedgenia_fedavg_50chunks_metrics.json\",\n",
        "    \"CIFAR10/Dir01/Trial1/fedprox_50chunks_local_accuracy_report.txt\",\n",
        "    \"CIFAR10/Dir01/Trial1/fedgenia_fedprox_50chunks_metrics.json\"\n",
        "]\n",
        "\n",
        "local_acc_dict = {}\n",
        "\n",
        "for file in log_files:\n",
        "    local_acc_dict[file.replace(\"/\", \"_\")] = parse_client_accuracies(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de16e414",
      "metadata": {},
      "source": [
        "## Obter estatisticas dos trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ac6a130",
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee9f0166",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Group dicts by experiment (e.g. MNIST_Class, CIFAR_Dir01, etc.)\n",
        "grouped = defaultdict(list)\n",
        "\n",
        "for key, metrics in loaded_dicts.items():\n",
        "    # Extract experiment part (remove trial name)\n",
        "    # Example: MNIST_Class_Trial1_losses.json → MNIST_Class\n",
        "    parts = key.split(\"_\")\n",
        "    experiment_name = \"_\".join(parts[:-2])  # remove 'TrialX' and 'losses.json'\n",
        "    grouped[experiment_name].append(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91c2c8ec",
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment_stats = {}\n",
        "\n",
        "for exp_name, trials in grouped.items():\n",
        "    stats = {}\n",
        "    metric_keys = trials[0].keys()  # assume all trials share same keys\n",
        "    \n",
        "    for key in metric_keys:\n",
        "        # Stack all trials' metric lists into a numpy array\n",
        "        values = [t[key] for t in trials if len(t[key]) > 0]\n",
        "\n",
        "        if not values:\n",
        "            continue\n",
        "\n",
        "        # Pad shorter lists if needed to align lengths (optional)\n",
        "        min_len = min(len(v) for v in values)\n",
        "        values = [v[:min_len] for v in values]  # truncate to shortest length\n",
        "\n",
        "        arr = np.array(values)  # shape = (num_trials, num_values)\n",
        "        \n",
        "        stats[key] = {\n",
        "            \"mean\": np.mean(arr, axis=0).tolist(),\n",
        "            \"median\": np.median(arr, axis=0).tolist(),\n",
        "            \"std\": np.std(arr, axis=0).tolist()\n",
        "        }\n",
        "\n",
        "    experiment_stats[exp_name] = stats\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b890d518",
      "metadata": {
        "id": "b890d518"
      },
      "source": [
        "## Funcao de plotagem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39493e97",
      "metadata": {
        "id": "39493e97"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import StrMethodFormatter\n",
        "from typing import Mapping, Iterable, Any, Literal, Union, List, Tuple\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "id": "c05bff13",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_series(\n",
        "    series: Mapping[str, Iterable[float]],\n",
        "    *,\n",
        "    x_values: Mapping[str, Iterable[float]] = None,\n",
        "    subplot_groups: List[List[str]] = None,\n",
        "    subplot_layout: Tuple[int, int] = None,\n",
        "    legend_subplot_index: Union[int, List[int], str] = 'all',\n",
        "    series_styles: Mapping[str, Mapping[str, Any]] = None,\n",
        "    xlim: Union[tuple[float, float], List[tuple[float, float]]] = None,\n",
        "    ylim: Union[tuple[float, float], List[tuple[float, float]]] = None,\n",
        "    first_step: Union[int, List[int]] = None,\n",
        "    xtick_step: Union[int, List[int]] = 1,\n",
        "    xtick_offset: int = 0,\n",
        "    num_xticks: Union[int, List[int]] = None,\n",
        "    num_yticks: Union[int, List[int]] = None,\n",
        "    y_ticks: Union[List[float], List[List[float]]] = None,\n",
        "    hide_inner_ticks: bool = False,\n",
        "    xlabel: Union[str, List[str]] = \"Epochs\",\n",
        "    ylabel: Union[str, List[str]] = \"Value\",\n",
        "    label_fontsize: float = None,\n",
        "    tick_fontsize: float = None,\n",
        "    title: Union[str, List[str]] = None,\n",
        "    title_fontsize: float = None,\n",
        "    figure_title: str = None,\n",
        "    figure_title_fontsize: float = 16,\n",
        "    figure_title_y: float = None,\n",
        "    row_labels: List[str] = None,\n",
        "    row_label_fontsize: float = None,\n",
        "    highlight: Mapping[str, Literal[\"max\", \"min\", \"both\"]] = None,\n",
        "    highlight_marker: str = \"o\",\n",
        "    highlight_markersize: float = 4,\n",
        "    highlight_color: str = None,\n",
        "    highlight_text_size: int = 8,\n",
        "    highlight_text_color: str = None,\n",
        "    highlight_arrow_color: str = None,\n",
        "    highlight_arrow_style: str = \"->\",\n",
        "    highlight_arrow_linewidth: float = 1,\n",
        "    highlight_text_offset_max: tuple[float, float] = (0.1, 0.2),\n",
        "    highlight_text_offset_min: tuple[float, float] = (0.1, -0.2),\n",
        "    highlight_style: Mapping[str, Mapping[str, Any]] = None,\n",
        "    legend_loc: str = 'best',\n",
        "    legend_fontsize: float = 10,\n",
        "    legend_kwargs: Mapping[str, Any] = None,\n",
        "    figsize: tuple[float, float] = (10, 5),\n",
        "    hspace: float = None,\n",
        "    vspace: float = None,\n",
        "    subplot_margins: dict = None,\n",
        "    save: bool = False,\n",
        "    plot_name: str = \"plot.pdf\",\n",
        "    level_markers: dict = None,\n",
        ") -> None:\n",
        "    if subplot_groups is None:\n",
        "        subplot_groups = [list(series.keys())]\n",
        "\n",
        "    num_plots = len(subplot_groups)\n",
        "\n",
        "    nrows, ncols = 0, 0\n",
        "    if subplot_layout:\n",
        "        nrows, ncols = subplot_layout\n",
        "        if nrows * ncols < num_plots:\n",
        "            raise ValueError(f\"Layout {subplot_layout} is too small for {num_plots} groups.\")\n",
        "    else:\n",
        "        nrows, ncols = num_plots, 1\n",
        "\n",
        "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize, squeeze=False)\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    def get_setting(value, index):\n",
        "        if isinstance(value, list):\n",
        "            return value[index] if index < len(value) else None\n",
        "        return value\n",
        "\n",
        "    for i, (ax, group) in enumerate(zip(axes, subplot_groups)):\n",
        "\n",
        "        row = i // ncols\n",
        "        col = i % ncols\n",
        "        is_bottom_row = (row == nrows - 1)\n",
        "        is_left_col = (col == 0)\n",
        "\n",
        "        n = 0\n",
        "        if group:\n",
        "            n = max(len(series.get(name, [])) for name in group)\n",
        "\n",
        "        for name in group:\n",
        "            if name not in series:\n",
        "                continue\n",
        "            ys = series[name]\n",
        "            xs = x_values.get(name, range(len(ys))) if x_values else range(len(ys))\n",
        "\n",
        "            raw_style = series_styles.get(name, {}) if series_styles else {}\n",
        "            style = raw_style.copy()\n",
        "            plot_label = style.pop('label', name)\n",
        "\n",
        "            line, = ax.plot(xs, ys, label=plot_label, **style)\n",
        "            \n",
        "            # line, = ax.plot(xs, ys, label=name, **style)\n",
        "            mode = highlight.get(name) if highlight else None\n",
        "            base_color = style.get('color', line.get_color())\n",
        "            mcolor = highlight_color or base_color\n",
        "\n",
        "            current_highlight_style = highlight_style.get(name, {}) if highlight_style else {}\n",
        "\n",
        "            if mode in (\"max\", \"both\"):\n",
        "                i_max = max(range(len(ys)), key=lambda j: ys[j])\n",
        "                ax.plot(i_max, ys[i_max], marker=highlight_marker, markersize=highlight_markersize, color=mcolor)\n",
        "                offset = current_highlight_style.get('highlight_offset_max', highlight_text_offset_max)\n",
        "                text_position = (i_max + offset[0], ys[i_max] + offset[1])\n",
        "                arrow_color = current_highlight_style.get('arrow_color', highlight_arrow_color or 'dimgrey')\n",
        "                arrow_style = current_highlight_style.get('arrow_style', highlight_arrow_style)\n",
        "                arrow_width = current_highlight_style.get('arrow_linewidth', highlight_arrow_linewidth)\n",
        "                text_color = current_highlight_style.get('text_color', highlight_text_color or 'black')\n",
        "                ax.annotate(f\"{ys[i_max]:.2f}\",\n",
        "                            xy=(i_max, ys[i_max]), \n",
        "                            xytext=text_position,\n",
        "                            arrowprops=dict(arrowstyle=arrow_style, color=arrow_color, linewidth=arrow_width),\n",
        "                            fontsize=highlight_text_size, \n",
        "                            color=text_color,\n",
        "                            va=\"bottom\", \n",
        "                            ha=\"center\")\n",
        "            if mode in (\"min\", \"both\"):\n",
        "                i_min = min(range(len(ys)), key=lambda j: ys[j])\n",
        "                ax.plot(i_min, ys[i_min], marker=highlight_marker, markersize=highlight_markersize, color=mcolor)\n",
        "                offset = current_highlight_style.get('highlight_offset_min', highlight_text_offset_min)\n",
        "                text_position = (i_min + offset[0], ys[i_min] + offset[1])\n",
        "                arrow_color = current_highlight_style.get('arrow_color', highlight_arrow_color or 'dimgrey')\n",
        "                arrow_style = current_highlight_style.get('arrow_style', highlight_arrow_style)\n",
        "                arrow_width = current_highlight_style.get('arrow_linewidth', highlight_arrow_linewidth)\n",
        "                text_color = current_highlight_style.get('text_color', highlight_text_color or 'black')\n",
        "                ax.annotate(f\"{ys[i_min]:.2f}\", \n",
        "                            xy=(i_min, ys[i_min]), \n",
        "                            xytext=text_position,\n",
        "                            arrowprops=dict(arrowstyle=arrow_style, color=arrow_color, linewidth=arrow_width),\n",
        "                            fontsize=highlight_text_size,\n",
        "                            color=text_color,\n",
        "                            va=\"top\", \n",
        "                            ha=\"center\")\n",
        "\n",
        "        if n > 0:\n",
        "            current_num_yticks = get_setting(num_yticks, i)\n",
        "            current_y_ticks = get_setting(y_ticks, i) # Assuming y_ticks could also be a list of lists\n",
        "            current_num_xticks = get_setting(num_xticks, i)\n",
        "            current_first_step = get_setting(first_step, i)\n",
        "            current_xtick_step = get_setting(xtick_step, i)\n",
        "\n",
        "            if current_num_yticks or current_y_ticks:\n",
        "                if current_num_yticks:\n",
        "                    # Determine the range for tick calculation\n",
        "                    current_ylim = get_setting(ylim, i)\n",
        "                    if current_ylim:\n",
        "                        # Base ticks on the specified limits\n",
        "                        min_y, max_y = current_ylim\n",
        "                    else:\n",
        "                        # Find the range across all series in this specific group\n",
        "                        min_y = float('inf')\n",
        "                        max_y = float('-inf')\n",
        "                        for name in group:\n",
        "                            if name in series and len(series[name]) > 0:\n",
        "                                min_y = min(min_y, min(series[name]))\n",
        "                                max_y = max(max_y, max(series[name]))\n",
        "\n",
        "                        # Ensure we have a reasonable range\n",
        "                        if min_y == float('inf') or max_y == float('-inf'):\n",
        "                            min_y, max_y = 0, 1.0\n",
        "                        \n",
        "                        # Optional: round the range for cleaner ticks\n",
        "                        min_y = math.floor(min_y * 10) / 10\n",
        "                        max_y = math.ceil(max_y * 10) / 10\n",
        "\n",
        "                    yticks = np.linspace(min_y, max_y, current_num_yticks)\n",
        "\n",
        "                    yticks = np.unique(yticks)\n",
        "                else:\n",
        "                    yticks = current_y_ticks\n",
        "                ax.set_yticks(yticks)\n",
        "                ax.yaxis.set_major_formatter(StrMethodFormatter('{x:.2f}'))\n",
        "\n",
        "            if current_num_xticks:\n",
        "                xticks = np.linspace(1, n, current_num_xticks)\n",
        "                ax.set_xticks(xticks.astype(int))\n",
        "            elif current_first_step is not None:\n",
        "                labels = [1]\n",
        "                # Use the per-subplot step, falling back to the default of 1 if not specified\n",
        "                step = current_xtick_step if current_xtick_step is not None else 1\n",
        "                next_label = 1 + current_first_step\n",
        "                while next_label <= n:\n",
        "                    labels.append(next_label)\n",
        "                    next_label += step\n",
        "                positions = [lbl - 1 for lbl in labels]\n",
        "                labels = [lbl + xtick_offset for lbl in labels]\n",
        "                ax.set_xticks(positions, labels)\n",
        "            elif current_xtick_step is not None and current_xtick_step > 0:\n",
        "                positions = list(range(0, n, current_xtick_step))\n",
        "                labels = [pos + 1 + xtick_offset for pos in positions]\n",
        "                ax.set_xticks(positions, labels)\n",
        "            \n",
        "        if hide_inner_ticks:\n",
        "            if not is_bottom_row:\n",
        "                ax.set_xticklabels([])\n",
        "            if not is_left_col:\n",
        "                ax.set_yticklabels([])\n",
        "\n",
        "        if num_xticks and xtick_offset != 0 and n > 0:\n",
        "            fig.canvas.draw()\n",
        "            current_ticks = ax.get_xticks()\n",
        "            new_labels = [int(tick) + xtick_offset for tick in current_ticks]\n",
        "            ax.set_xticklabels(new_labels)\n",
        "\n",
        "        if tick_fontsize:\n",
        "            ax.tick_params(axis='both', which='major', labelsize=tick_fontsize)\n",
        "\n",
        "        # X Label\n",
        "        x_text = get_setting(xlabel, i)\n",
        "        if isinstance(xlabel, list):\n",
        "            ax.set_xlabel(x_text, fontsize=label_fontsize)\n",
        "        elif is_bottom_row:\n",
        "            ax.set_xlabel(x_text, fontsize=label_fontsize)\n",
        "\n",
        "        # Y Label\n",
        "        y_text = get_setting(ylabel, i)\n",
        "        if isinstance(ylabel, list):\n",
        "            ax.set_ylabel(y_text, fontsize=label_fontsize)\n",
        "        elif is_left_col:\n",
        "            ax.set_ylabel(y_text, fontsize=label_fontsize)\n",
        "\n",
        "        # Title\n",
        "        ax.set_title(get_setting(title, i), fontsize=title_fontsize)\n",
        "\n",
        "        show_legend = False\n",
        "        if legend_subplot_index == 'all':\n",
        "            show_legend = True\n",
        "        elif isinstance(legend_subplot_index, list):\n",
        "            if i in legend_subplot_index:\n",
        "                show_legend = True\n",
        "        elif i == legend_subplot_index:\n",
        "            show_legend = True\n",
        "            \n",
        "        if show_legend:\n",
        "            base_kwargs = {'loc': legend_loc, 'fontsize': legend_fontsize}\n",
        "            if legend_kwargs:\n",
        "                base_kwargs.update(legend_kwargs)\n",
        "            ax.legend(**base_kwargs)\n",
        "\n",
        "        current_xlim = get_setting(xlim, i)\n",
        "        if current_xlim:\n",
        "            ax.set_xlim(*current_xlim)\n",
        "        elif n > 0:\n",
        "            # Set a sensible default xlim based on data\n",
        "            ax.set_xlim(0, n)\n",
        "        current_ylim = get_setting(ylim, i)\n",
        "        if current_ylim:\n",
        "            ax.set_ylim(*current_ylim)\n",
        "\n",
        "        if row_labels and (col == ncols - 1):\n",
        "            # Check if we have a label for this specific row\n",
        "            if row < len(row_labels) and row_labels[row]:\n",
        "                ax.text(\n",
        "                    1.05, 0.5, row_labels[row],  # x=1.05 (slightly outside right), y=0.5 (center)\n",
        "                    transform=ax.transAxes,      # Coordinates relative to the subplot\n",
        "                    rotation=270,                # Vertical rotation\n",
        "                    ha='left', \n",
        "                    va='center',\n",
        "                    fontsize=row_label_fontsize,\n",
        "                    fontweight='bold'            # Optional: make it bold to distinguish from data\n",
        "                )\n",
        "\n",
        "        if level_markers:\n",
        "            for label, x_pos in level_markers.items():\n",
        "                ax.axvline(\n",
        "                    x=x_pos, \n",
        "                    color='gray', \n",
        "                    linestyle='--', \n",
        "                    linewidth=1, \n",
        "                    alpha=0.5,\n",
        "                    zorder=0 # Put it behind the data lines\n",
        "                )\n",
        "\n",
        "                ax.text(\n",
        "                    x=x_pos, \n",
        "                    y=0.05, # Position: 5% from the bottom of the axis (0.0 to 1.0)\n",
        "                    s=label, \n",
        "                    transform=ax.get_xaxis_transform(), # Magic: X is data, Y is relative\n",
        "                    rotation=90,      # Vertical text looks neat for boundaries\n",
        "                    ha='right',       # Align right of the line (or 'center')\n",
        "                    va='bottom',\n",
        "                    fontsize=10,\n",
        "                    color='dimgrey',\n",
        "                    fontweight='bold'\n",
        "                )\n",
        "\n",
        "    if figure_title:\n",
        "        fig.suptitle(\n",
        "            figure_title, \n",
        "            fontsize=figure_title_fontsize,\n",
        "            y=figure_title_y or 0.98 # Default to slightly near the top\n",
        "        )\n",
        "\n",
        "    for j in range(num_plots, len(axes)):\n",
        "        axes[j].set_visible(False)\n",
        "\n",
        "    if hspace is not None or vspace is not None or subplot_margins:\n",
        "        margins = subplot_margins or {}\n",
        "        plt.subplots_adjust(\n",
        "            hspace=hspace or 0.3,  # Default horizontal spacing\n",
        "            wspace=vspace or 0.2,  # Default vertical spacing\n",
        "            left=margins.get('left', 0.1),\n",
        "            right=margins.get('right', 0.9),\n",
        "            top=margins.get('top', 0.9),\n",
        "            bottom=margins.get('bottom', 0.1)\n",
        "        )\n",
        "    else:\n",
        "        fig.tight_layout()\n",
        "\n",
        "    if save:\n",
        "        print(f\"Saving plot to {plot_name}\")\n",
        "        plt.savefig(plot_name)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "febb881b",
      "metadata": {},
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7df4d40",
      "metadata": {},
      "source": [
        "### Loss e Acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a663f1c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "  series = {\n",
        "      \"Class Loss Trial 1\": loaded_dict_mnist_class[\"net_loss_round\"],\n",
        "      \"Class Accuracy Trial 1\": loaded_dict_mnist_class[\"net_acc_round\"],\n",
        "      \"Dir01 Loss Trial 1\": loaded_dict_mnist_dir01[\"net_loss_round\"],\n",
        "      \"Dir01 Accuracy Trial 1\": loaded_dict_mnist_dir01[\"net_acc_round\"],\n",
        "      \"Dir05 Loss Trial 1\": loaded_dict_mnist_dir05[\"net_loss_round\"],\n",
        "      \"Dir05 Accuracy Trial 1\": loaded_dict_mnist_dir05[\"net_acc_round\"],\n",
        "      \"Class Loss Trial 2\": loaded_dict_mnist_class_trial2[\"net_loss_round\"],\n",
        "      \"Class Accuracy Trial 2\": loaded_dict_mnist_class_trial2[\"net_acc_round\"],\n",
        "      \"Dir01 Loss Trial 2\": loaded_dict_mnist_dir01_trial2[\"net_loss_round\"],\n",
        "      \"Dir01 Accuracy Trial 2\": loaded_dict_mnist_dir01_trial2[\"net_acc_round\"],\n",
        "      \"Dir05 Loss Trial 2\": loaded_dict_mnist_dir05_trial2[\"net_loss_round\"],\n",
        "      \"Dir05 Accuracy Trial 2\": loaded_dict_mnist_dir05_trial2[\"net_acc_round\"],\n",
        "  },\n",
        "  series_styles={\n",
        "      \"Class Loss Trial 1\": {\"color\": \"blue\", \"linestyle\": \"-\"},\n",
        "      \"Class Accuracy Trial 1\": {\"color\": \"blue\", \"linestyle\": \"--\"},\n",
        "      \"Dir01 Loss Trial 1\": {\"color\": \"orange\", \"linestyle\": \"-\"},\n",
        "      \"Dir01 Accuracy Trial 1\": {\"color\": \"orange\", \"linestyle\": \"--\"},\n",
        "      \"Dir05 Loss Trial 1\": {\"color\": \"green\", \"linestyle\": \"-\"},\n",
        "      \"Dir05 Accuracy Trial 1\": {\"color\": \"green\", \"linestyle\": \"--\"},\n",
        "      \"Class Loss Trial 2\": {\"color\": \"lightblue\", \"linestyle\": \"-\"},\n",
        "      \"Class Accuracy Trial 2\": {\"color\": \"lightblue\", \"linestyle\": \"--\"},\n",
        "      \"Dir01 Loss Trial 2\": {\"color\": \"yellow\", \"linestyle\": \"-\"},\n",
        "      \"Dir01 Accuracy Trial 2\": {\"color\": \"yellow\", \"linestyle\": \"--\"},\n",
        "      \"Dir05 Loss Trial 2\": {\"color\": \"lightgreen\", \"linestyle\": \"-\"},\n",
        "      \"Dir05 Accuracy Trial 2\": {\"color\": \"lightgreen\", \"linestyle\": \"--\"},\n",
        "  },\n",
        "  highlight = {\n",
        "      \"Accuracy\": \"max\"\n",
        "  },\n",
        "  highlight_markersize=4,\n",
        "  xtick_step=5,\n",
        "  first_step=4,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28b0d95c",
      "metadata": {},
      "source": [
        "### Local Acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "209bd071",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series = {\n",
        "        # \"Global - Chunked FedAvg\": loaded_dict_cifar_mnist[\"net_acc_round\"][:100],\n",
        "        # \"Global - FedGenIA\": loaded_dict_cifar_mnist_gerafed[\"net_acc_round\"][:100],\n",
        "\n",
        "        \"Client 0 - Chunked FedAvg\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_chunked_fedavg.txt\"][0],\n",
        "        \"Client 0 - Chunked FedProx\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_chunked_fedprox.txt\"][0],\n",
        "        \"Client 0 - FedGenIA\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report.txt\"][0],\n",
        "        \"Client 0 - FedGenIA + FedProx\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_fedprox_fedgenia.txt\"][0],\n",
        "\n",
        "        \"Client 1 - Chunked FedAvg\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_chunked_fedavg.txt\"][1],\n",
        "        \"Client 1 - Chunked FedProx\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_chunked_fedprox.txt\"][1],\n",
        "        \"Client 1 - FedGenIA\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report.txt\"][1],\n",
        "        \"Client 1 - FedGenIA + FedProx\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_fedprox_fedgenia.txt\"][1],\n",
        "\n",
        "        \"Chunked FedAvg\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_chunked_fedavg.txt\"][2],\n",
        "        \"Chunked FedProx\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_chunked_fedprox.txt\"][2],\n",
        "        \"FedGenIA\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report.txt\"][2],\n",
        "        \"FedGenIA + FedProx\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_fedprox_fedgenia.txt\"][2],\n",
        "\n",
        "        \"Client 3 - Chunked FedAvg\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_chunked_fedavg.txt\"][3],\n",
        "        \"Client 3 - Chunked FedProx\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_chunked_fedprox.txt\"][3],\n",
        "        \"Client 3 - FedGenIA\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report.txt\"][3],\n",
        "        \"Client 3 - FedGenIA + FedProx\": local_acc_dict[\"CIFAR10_Dir01_Trial1_local_accuracy_report_fedprox_fedgenia.txt\"][3],\n",
        "    },\n",
        "    series_styles = {\n",
        "        # \"Global - Chunked FedAvg\": {\"color\": \"lightblue\", \"linestyle\": \"-\"},\n",
        "        # \"Global - FedGenIA\": {\"color\": \"lightblue\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Client 0 - Chunked FedAvg\": {\"color\": \"cornflowerblue\", \"linestyle\": \"-\"},\n",
        "        \"Client 0 - Chunked FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"-\"},\n",
        "        \"Client 0 - FedGenIA\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"Client 0 - FedGenIA + FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Client 1 - Chunked FedAvg\": {\"color\": \"cornflowerblue\", \"linestyle\": \"-\"},\n",
        "        \"Client 1 - Chunked FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"-\"},\n",
        "        \"Client 1 - FedGenIA\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"Client 1 - FedGenIA + FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Chunked FedAvg\": {\"color\": \"cornflowerblue\", \"linestyle\": \"-\"},\n",
        "        \"Chunked FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"-\"},\n",
        "        \"FedGenIA\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"FedGenIA + FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Client 3 - Chunked FedAvg\": {\"color\": \"cornflowerblue\", \"linestyle\": \"-\"},\n",
        "        \"Client 3 - Chunked FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"-\"},\n",
        "        \"Client 3 - FedGenIA\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"Client 3 - FedGenIA + FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "    },\n",
        "    subplot_groups=[\n",
        "        [\"Client 0 - Chunked FedAvg\", \"Client 0 - Chunked FedProx\", \"Client 0 - FedGenIA\", \"Client 0 - FedGenIA + FedProx\"],\n",
        "        [\"Client 1 - Chunked FedAvg\", \"Client 1 - Chunked FedProx\", \"Client 1 - FedGenIA\", \"Client 1 - FedGenIA + FedProx\"],\n",
        "        [\"Chunked FedAvg\", \"Chunked FedProx\", \"FedGenIA\", \"FedGenIA + FedProx\"],\n",
        "        [\"Client 3 - Chunked FedAvg\", \"Client 3 - Chunked FedProx\", \"Client 3 - FedGenIA\", \"Client 3 - FedGenIA + FedProx\"]\n",
        "    ],\n",
        "    highlight={\n",
        "    #    \"Global - Chunked FedAvg\": \"max\",\n",
        "    #     \"Global - FedGenIA\": \"max\",\n",
        "\n",
        "        \"Client 0 - Chunked FedAvg\": \"max\",\n",
        "        \"Client 0 - Chunked FedProx\": \"max\",\n",
        "        \"Client 0 - FedGenIA\": \"max\",\n",
        "        \"Client 0 - FedGenIA + FedProx\": \"max\",\n",
        "\n",
        "        \"Client 1 - Chunked FedAvg\": \"max\",\n",
        "        \"Client 1 - Chunked FedProx\": \"max\",\n",
        "        \"Client 1 - FedGenIA\": \"max\",\n",
        "        \"Client 1 - FedGenIA + FedProx\": \"max\",\n",
        "\n",
        "        \"Chunked FedAvg\": \"max\",\n",
        "        \"Chunked FedProx\": \"max\",\n",
        "        \"FedGenIA\": \"max\",\n",
        "        \"FedGenIA + FedProx\": \"max\",\n",
        "\n",
        "        \"Client 3 - Chunked FedAvg\": \"max\",\n",
        "        \"Client 3 - Chunked FedProx\": \"max\",\n",
        "        \"Client 3 - FedGenIA\": \"max\",\n",
        "        \"Client 3 - FedGenIA + FedProx\": \"max\",\n",
        "    },\n",
        "    subplot_layout=(1,4),\n",
        "    figsize=(20, 2.65),\n",
        "    label_fontsize=16,\n",
        "    tick_fontsize=15,\n",
        "    highlight_markersize=6,\n",
        "    num_xticks=5,\n",
        "    num_yticks=[0,0,0,3,],\n",
        "    y_ticks=[[0,0.4,0.75], [0,0.4,0.75], [0.1,0.4,0.65], None],\n",
        "    ylim=[(0,0.75),(0,0.75),(0.1,0.65),(0,0.6)],\n",
        "    ylabel= [\"Accuracy\",\"\",\"\",\"\"],\n",
        "    highlight_text_size=15,\n",
        "    legend_subplot_index=2,\n",
        "    legend_fontsize=11.6,\n",
        "    legend_kwargs={\n",
        "        \"ncol\": 2,\n",
        "        \"columnspacing\": 0.6,\n",
        "        \"handletextpad\": 0.2,\n",
        "        \"borderpad\": 0.2,\n",
        "        \"bbox_to_anchor\": (0.024, 0.33),\n",
        "        \"handlelength\": 1,\n",
        "        \"labelspacing\": 0.3\n",
        "    },\n",
        "    title_fontsize=18,\n",
        "    title=[\"a) Client 0\", \"b) Client 1\", \"c) Client 2\", \"d) Client 3\"],\n",
        "    save=True,\n",
        "    plot_name=\"../figures/local_acc.pdf\",\n",
        "    highlight_style={\n",
        "        # \"Global - Chunked FedAvg\": {\"color\": \"blue\"},\n",
        "        # \"Global - FedGenIA\": {\"color\": \"blue\"},\n",
        "\n",
        "        \"Client 0 - Chunked FedAvg\": {\"highlight_offset_max\": (-16, 0.01)},\n",
        "        \"Client 0 - Chunked FedProx\": {\"highlight_offset_max\": (0, -0.3)},\n",
        "        \"Client 0 - FedGenIA\": {\"highlight_offset_max\": (-20, -0.5)},\n",
        "        \"Client 0 - FedGenIA + FedProx\": {\"highlight_offset_max\": (-40, -0.05)},\n",
        "\n",
        "        \"Client 1 - Chunked FedAvg\": {\"highlight_offset_max\": (0, 0.06)},\n",
        "        \"Client 1 - Chunked FedProx\": {\"highlight_offset_max\": (-17, 0)},\n",
        "        \"Client 1 - FedGenIA\": {\"highlight_offset_max\": (0, -0.45)},\n",
        "        \"Client 1 - FedGenIA + FedProx\": {\"highlight_offset_max\": (-15, -0.05)},\n",
        "\n",
        "        \"Chunked FedAvg\": {\"highlight_offset_max\": (10, -0.25)},\n",
        "        \"Chunked FedProx\": {\"highlight_offset_max\": (20, -0.3)},\n",
        "        \"FedGenIA\": {\"highlight_offset_max\": (0, -0.24)},\n",
        "        \"FedGenIA + FedProx\": {\"highlight_offset_max\": (17, -0.21)},\n",
        "\n",
        "        \"Client 3 - Chunked FedAvg\": {\"highlight_offset_max\": (-15, -0.14)},\n",
        "        \"Client 3 - Chunked FedProx\": {\"highlight_offset_max\": (-25, 0.14)},\n",
        "        \"Client 3 - FedGenIA\": {\"highlight_offset_max\": (-10, -0.25)},\n",
        "        \"Client 3 - FedGenIA + FedProx\": {\"highlight_offset_max\": (-15, 0.02)},\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8952ba7e",
      "metadata": {},
      "source": [
        "### Different distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf794d8a",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series={\n",
        "        \"IID\": loaded_dicts[\"losses_iid_mnist_chunked_fedavg.json\"][\"net_acc_round\"],\n",
        "        \"Dir05\": loaded_dicts[\"MNIST_Dir05_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"],\n",
        "        \"Dir01\": loaded_dicts[\"MNIST_Dir01_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"][:100],\n",
        "        \"Class\": loaded_dicts[\"MNIST_Class_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"][:100],\n",
        "        \"IID cifar\": loaded_dicts[\"losses_iid_cifar_chunked_fedavg.json\"][\"net_acc_round\"],\n",
        "        \"Dir05 cifar\": loaded_dicts[\"CIFAR10_Dir05_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"],\n",
        "        \"Dir01 cifar\": loaded_dicts[\"CIFAR10_Dir01_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"][:100],\n",
        "        \"Class cifar\": loaded_dicts[\"CIFAR10_Class_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"][:100],\n",
        "    },\n",
        "    subplot_groups=[\n",
        "        [\"IID\", \"Dir05\", \"Dir01\", \"Class\"]\n",
        "        ,[\"IID cifar\", \"Dir05 cifar\", \"Dir01 cifar\", \"Class cifar\"],\n",
        "    ],\n",
        "    legend_subplot_index=0,\n",
        "    title=[\"a) MNIST\", \"b) CIFAR-10\"],\n",
        "    title_fontsize=20,\n",
        "    highlight={\n",
        "        \"IID\": \"max\",\n",
        "        \"Dir05\": \"max\",\n",
        "        \"Dir01\": \"max\",\n",
        "        \"Class\": \"max\",\n",
        "        \"IID cifar\": \"max\",\n",
        "        \"Dir05 cifar\": \"max\",\n",
        "        \"Dir01 cifar\": \"max\",\n",
        "        \"Class cifar\": \"max\",\n",
        "    },\n",
        "    highlight_style={\n",
        "        \"IID\": {\"highlight_offset_max\": (5, -0.07)},\n",
        "        \"Dir05\": {\"highlight_offset_max\": (5, -0.081)},\n",
        "        \"Dir01\": {\"highlight_offset_max\": (-5, -0.069)},\n",
        "        \"Class\": {\"highlight_offset_max\": (5, -0.25)},\n",
        "        \"IID cifar\": {\"highlight_offset_max\": (-5, -0.2)},\n",
        "        \"Dir05 cifar\": {\"highlight_offset_max\": (0, -0.16)},\n",
        "        \"Dir01 cifar\": {\"highlight_offset_max\": (5, 0.07)},\n",
        "        \"Class cifar\": {\"highlight_offset_max\": (10, -0.04)},\n",
        "     }, \n",
        "    highlight_markersize=8,\n",
        "    xtick_step=5,\n",
        "    num_yticks=[3,3],\n",
        "    #y_ticks=[[0,0.5,1], [0.2,0.45,0.65]],\n",
        "    first_step=4,\n",
        "    ylabel=\"Accuracy\",\n",
        "    figsize=(15, 5.9),\n",
        "    highlight_text_size=20,\n",
        "    tick_fontsize=20,\n",
        "    label_fontsize=20,\n",
        "    legend_fontsize=18,\n",
        "    legend_kwargs={\n",
        "        \"ncol\": 2,\n",
        "        \"columnspacing\": 1,\n",
        "        \"handletextpad\": 0.5,\n",
        "        \"borderpad\": 0.2,\n",
        "        \"bbox_to_anchor\": (0.014, 0.5),\n",
        "        \"handlelength\": 2,\n",
        "        \"labelspacing\": 0.5\n",
        "    },\n",
        "    save=True,\n",
        "    plot_name=\"../figures/ACC_alvo.pdf\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7a1f8ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "losses = [\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/nb_losses/d_loss_c0_r0.json\",\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/nb_losses/d_loss_c1_r0.json\",\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/nb_losses/d_loss_c2_r0.json\",\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/nb_losses/d_loss_c3_r0.json\",\n",
        "\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/flwr_losses_depois/d_losses_c0_r1.json\",\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/flwr_losses_depois/d_losses_c1_r1.json\",\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/flwr_losses_depois/d_losses_c2_r1.json\",\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/flwr_losses_depois/d_losses_c3_r1.json\",\n",
        "\n",
        "    \"../../Tests_FedGenIA/Teste_pesos_exatos/d_loss_c1_r1.json\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89162806",
      "metadata": {},
      "outputs": [],
      "source": [
        "losses_dict = {}\n",
        "for file in losses:\n",
        "    with open(file, \"r\") as f:\n",
        "        losses_dict[file.replace(\"/\", \"_\")] = json.load(f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc847093",
      "metadata": {},
      "source": [
        "### GAN loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2181e9a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series={\n",
        "        \"c0_flwr\": losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_flwr_losses_depois_d_losses_c0_r1.json\"],\n",
        "        \"c1_flwr\": losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_flwr_losses_depois_d_losses_c1_r1.json\"],\n",
        "        \"c2_flwr\": losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_flwr_losses_depois_d_losses_c2_r1.json\"],\n",
        "        \"c3_flwr\": losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_flwr_losses_depois_d_losses_c3_r1.json\"],\n",
        "        \"c0_nb\": losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_losses_d_loss_c0_r0.json\"],\n",
        "        \"c1_nb\": losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_losses_d_loss_c1_r0.json\"],\n",
        "        \"c2_nb\": losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_losses_d_loss_c2_r0.json\"],\n",
        "        \"c3_nb\": losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_losses_d_loss_c3_r0.json\"],\n",
        "\n",
        "        \"c1_flwr_new\": losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_d_loss_c1_r1.json\"],\n",
        "\n",
        "        \"c0_flwr_mean\": [np.mean(losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_flwr_losses_depois_d_losses_c0_r1.json\"])]*156,\n",
        "        \"c1_flwr_mean\": [np.mean(losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_flwr_losses_depois_d_losses_c1_r1.json\"])]*156,\n",
        "        \"c2_flwr_mean\": [np.mean(losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_flwr_losses_depois_d_losses_c2_r1.json\"])]*156,\n",
        "        \"c3_flwr_mean\": [np.mean(losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_flwr_losses_depois_d_losses_c3_r1.json\"])]*156,\n",
        "        \"c0_nb_mean\": [np.mean(losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_losses_d_loss_c0_r0.json\"])]*156,\n",
        "        \"c1_nb_mean\": [np.mean(losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_losses_d_loss_c1_r0.json\"])]*156,\n",
        "        \"c2_nb_mean\": [np.mean(losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_losses_d_loss_c2_r0.json\"])]*156,\n",
        "        \"c3_nb_mean\": [np.mean(losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_losses_d_loss_c3_r0.json\"])]*156,\n",
        "\n",
        "        \"c1_flwr_new\": [np.mean(losses_dict[\".._.._Tests_FedGenIA_Teste_pesos_exatos_d_loss_c1_r1.json\"])]*156,\n",
        "\n",
        "    },\n",
        "    series_styles={\n",
        "        \"c0_flwr\": {\"color\": \"blue\", \"linestyle\": \"-\"},\n",
        "        \"c1_flwr\": {\"color\": \"green\", \"linestyle\": \"-\"},\n",
        "        \"c2_flwr\": {\"color\": \"yellow\", \"linestyle\": \"-\"},\n",
        "        \"c3_flwr\": {\"color\": \"red\", \"linestyle\": \"-\"},\n",
        "        \"c0_nb\": {\"color\": \"blue\", \"linestyle\": \"--\"},\n",
        "        \"c1_nb\": {\"color\": \"green\", \"linestyle\": \"--\"},\n",
        "        \"c2_nb\": {\"color\": \"yellow\", \"linestyle\": \"--\"},\n",
        "        \"c3_nb\": {\"color\": \"red\", \"linestyle\": \"--\"},\n",
        "        \"c1_flwr_new\": {\"color\": \"black\"},\n",
        "\n",
        "        \"c0_flwr_mean\": {\"color\": \"blue\", \"linestyle\": \"-\"},\n",
        "        \"c1_flwr_mean\": {\"color\": \"green\", \"linestyle\": \"-\"},\n",
        "        \"c2_flwr_mean\": {\"color\": \"yellow\", \"linestyle\": \"-\"},\n",
        "        \"c3_flwr_mean\": {\"color\": \"red\", \"linestyle\": \"-\"},\n",
        "        \"c0_nb_mean\": {\"color\": \"blue\", \"linestyle\": \"--\"},\n",
        "        \"c1_nb_mean\": {\"color\": \"green\", \"linestyle\": \"--\"},\n",
        "        \"c2_nb_mean\": {\"color\": \"yellow\", \"linestyle\": \"--\"},\n",
        "        \"c3_nb_mean\": {\"color\": \"red\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"c1_flwr_new_mean\": {\"color\": \"black\"}\n",
        "    },\n",
        "    num_xticks=20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17fca7c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series={\n",
        "        \"G_1_flwr\": loaded_dicts[\".._.._Experimentos_Flwr_run_FedGenIA_F2U_mnist_Class_fedavg_4_clients_metrics.json\"][\"g_loss_chunk\"],\n",
        "        \"D_1_flwr\": loaded_dicts[\".._.._Experimentos_Flwr_run_FedGenIA_F2U_mnist_Class_fedavg_4_clients_metrics.json\"][\"d_loss_chunk\"],\n",
        "\n",
        "        \"G_nb_new\": loaded_dicts[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_100chunks_metrics.json\"][\"g_losses_chunk\"],\n",
        "        \"D_nb_new\": loaded_dicts[\".._.._Tests_FedGenIA_Teste_pesos_exatos_nb_100chunks_metrics.json\"][\"d_losses_chunk\"],\n",
        "\n",
        "        \"G_flwr_genwgt\": loaded_dicts[\".._.._Experimentos_Testing_gen_weights_Flwr_run_FedGenIA_F2U_mnist_Class_fedavg_4_clients_metrics.json\"][\"g_loss_chunk\"],\n",
        "        \"D_flwr_genwgt\": loaded_dicts[\".._.._Experimentos_Testing_gen_weights_Flwr_run_FedGenIA_F2U_mnist_Class_fedavg_4_clients_metrics.json\"][\"d_loss_chunk\"],\n",
        "\n",
        "        \"G_nb_genwgt\": loaded_dicts[\".._.._Tests_FedGenIA_Teste_pesos_exatos_mnist_ClassPartitioner_fedavg_fedgenia_trial1_metrics.json\"][\"g_losses_chunk\"],\n",
        "        \"D_nb_genwgt\": loaded_dicts[\".._.._Tests_FedGenIA_Teste_pesos_exatos_mnist_ClassPartitioner_fedavg_fedgenia_trial1_metrics.json\"][\"d_losses_chunk\"]\n",
        "\n",
        "        # \"G_1\": loaded_dicts[\".._.._Tests_FedGenIA_Padrao_FedGenIA_DML-ICC_mnist_ClassPartitioner_fedavg_fedgenia_trial1_metrics.json\"][\"g_losses_chunk\"],\n",
        "        # \"D_1\": loaded_dicts[\".._.._Tests_FedGenIA_Padrao_FedGenIA_DML-ICC_mnist_ClassPartitioner_fedavg_fedgenia_trial1_metrics.json\"][\"d_losses_chunk\"],\n",
        "        # \"G_2\": loaded_dicts[\".._.._Tests_FedGenIA_Padrao_FedGenIA_DML-ICC_mnist_ClassPartitioner_fedavg_fedgenia_trial2_metrics.json\"][\"g_losses_chunk\"],\n",
        "        # \"D_2\": loaded_dicts[\".._.._Tests_FedGenIA_Padrao_FedGenIA_DML-ICC_mnist_ClassPartitioner_fedavg_fedgenia_trial2_metrics.json\"][\"d_losses_chunk\"],\n",
        "        # \"G_3\": loaded_dicts[\".._.._Tests_FedGenIA_Padrao_FedGenIA_DML-ICC_mnist_ClassPartitioner_fedavg_fedgenia_trial3_metrics.json\"][\"g_losses_chunk\"],\n",
        "        # \"D_3\": loaded_dicts[\".._.._Tests_FedGenIA_Padrao_FedGenIA_DML-ICC_mnist_ClassPartitioner_fedavg_fedgenia_trial3_metrics.json\"][\"d_losses_chunk\"],\n",
        "\n",
        "\n",
        "    },\n",
        "    series_styles={\n",
        "        \"G_1_flwr\": {\"color\": \"blue\", \"linestyle\": \"-\"},\n",
        "        \"D_1_flwr\": {\"color\": \"blue\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"G_nb_new\": {\"color\": \"black\", \"linestyle\": \"-\"},\n",
        "        \"D_nb_new\": {\"color\": \"black\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"G_flwr_genwgt\": {\"color\": \"red\", \"linestyle\": \"-\"},\n",
        "        \"D_flwr_genwgt\": {\"color\": \"red\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"G_nb_genwgt\": {\"color\": \"green\", \"linestyle\": \"-\"},\n",
        "        \"D_nb_genwgt\": {\"color\": \"green\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"G_1\": {\"color\": \"orange\", \"linestyle\": \"-\"},\n",
        "        \"D_1\": {\"color\": \"orange\", \"linestyle\": \"--\"},\n",
        "        \"G_2\": {\"color\": \"yellow\", \"linestyle\": \"-\"},\n",
        "        \"D_2\": {\"color\": \"yellow\", \"linestyle\": \"--\"},\n",
        "        \"G_3\": {\"color\": \"red\", \"linestyle\": \"-\"},\n",
        "        \"D_3\": {\"color\": \"red\", \"linestyle\": \"--\"},\n",
        "        \"G_500\": {\"color\": \"purple\", \"linestyle\": \"-\"},\n",
        "        \"D_500\": {\"color\": \"purple\", \"linestyle\": \"--\"},\n",
        "        \"G_1000\": {\"color\": \"brown\", \"linestyle\": \"-\"},\n",
        "        \"D_1000\": {\"color\": \"brown\", \"linestyle\": \"--\"},\n",
        "        \"G_5000\": {\"color\": \"pink\", \"linestyle\": \"-\"},\n",
        "        \"D_5000\": {\"color\": \"pink\", \"linestyle\": \"--\"},\n",
        "\n",
        "    },\n",
        "    xtick_step=5,\n",
        "    first_step=4,\n",
        "    ylabel=\"Loss\",\n",
        "    ylim=(0,0.7),\n",
        "    xlim=(90,110),\n",
        "    num_xticks=200\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7768e0ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "for key in loaded_dicts.keys():\n",
        "    print(f\"{key}: {len(loaded_dicts[key]['net_acc_round'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b608dfdb",
      "metadata": {},
      "source": [
        "### GeraFed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6a80e05",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series = {\n",
        "        \"Chunked FedAvg\": loaded_dicts[\"MNIST_Class_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"],\n",
        "        \"Chunked FedProx\": loaded_dicts[\"MNIST_Class_Trial1_metrics_chunked_fedprox.json\"][\"net_acc_round\"],\n",
        "        # \"Chunked SCAFFOLD\": loaded_dicts[\"MNIST_Class_Trial1_metrics_chunked_scaffold.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA\": loaded_dicts[\"MNIST_Class_Trial1_metrics.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA + FedProx\": loaded_dicts[\"MNIST_Class_Trial1_metrics_fedprox_fedgenia.json\"][\"net_acc_round\"],\n",
        "        # \"FedGenIA + SCAFFOLD mnistclass\": loaded_dicts[\"MNIST_Class_Trial1_metrics_scaffold_fedgenia.json\"][\"net_acc_round\"],\n",
        "\n",
        "        \"Chunked FedAvg cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"],\n",
        "        \"Chunked FedProx cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_metrics_chunked_fedprox.json\"][\"net_acc_round\"],\n",
        "        # \"Chunked SCAFFOLD cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_metrics_chunked_scaffold.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial2_metrics.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA + FedProx cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_metrics_fedprox_fedgenia.json\"][\"net_acc_round\"],\n",
        "        # \"FedGenIA + SCAFFOLD cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_metrics_scaffold_fedgenia.json\"][\"net_acc_round\"],\n",
        "\n",
        "        \"Chunked FedAvg cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"][:100],\n",
        "        \"Chunked FedProx cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_metrics_chunked_fedprox.json\"][\"net_acc_round\"],\n",
        "        # \"Chunked SCAFFOLD cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_metrics_chunked_scaffold.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_metrics.json\"][\"net_acc_round\"][:100],\n",
        "        \"FedGenIA + FedProx cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_metrics_fedprox_fedgenia.json\"][\"net_acc_round\"],\n",
        "        # \"FedGenIA + SCAFFOLD cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_metrics_scaffold_fedgenia.json\"][\"net_acc_round\"],\n",
        "\n",
        "        \"Chunked FedAvg cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"],\n",
        "        \"Chunked FedProx cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_metrics_chunked_fedprox.json\"][\"net_acc_round\"],\n",
        "        # \"Chunked SCAFFOLD cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_metrics_chunked_scaffold.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_metrics.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA + FedProx cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_metrics_fedprox_fedgenia.json\"][\"net_acc_round\"],\n",
        "        # \"FedGenIA + SCAFFOLD cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_metrics_scaffold_fedgenia.json\"][\"net_acc_round\"],\n",
        "        \"50chunks FedGenIA\": loaded_dicts[\".._.._cifar10_ClassPartitioner_fedavg_50chunks_fedgenia_metrics.json\"][\"net_acc_round\"]\n",
        "        },\n",
        "\n",
        "    series_styles={\n",
        "        \"Chunked FedAvg\": {\"color\": \"cornflowerblue\"},\n",
        "        \"Chunked FedProx\": {\"color\": \"sandybrown\"},\n",
        "        #\"Chunked SCAFFOLD\": {\"color\": \"yellowgreen\"},\n",
        "        \"FedGenIA\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"FedGenIA + FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "        #\"FedGenIA + SCAFFOLD\": {\"color\": \"yellowgreen\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Chunked FedAvg cifardir05\": {\"color\": \"cornflowerblue\"},\n",
        "        \"Chunked FedProx cifardir05\": {\"color\": \"sandybrown\"},\n",
        "        # \"Chunked SCAFFOLD cifardir05\": {\"color\": \"yellowgreen\"},\n",
        "        \"FedGenIA cifardir05\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"FedGenIA + FedProx cifardir05\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "        #\"FedGenIA + SCAFFOLD cifardir05\": {\"color\": \"yellowgreen\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Chunked FedAvg cifardir01\": {\"color\": \"cornflowerblue\"},\n",
        "        \"Chunked FedProx cifardir01\": {\"color\": \"sandybrown\"},\n",
        "        # \"Chunked SCAFFOLD cifardir01\": {\"color\": \"yellowgreen\"},\n",
        "        \"FedGenIA cifardir01\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"FedGenIA + FedProx cifardir01\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "        # \"FedGenIA + SCAFFOLD cifardir01\": {\"color\": \"yellowgreen\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Chunked FedAvg cifarclass\": {\"color\": \"cornflowerblue\"},\n",
        "        \"Chunked FedProx cifarclass\": {\"color\": \"sandybrown\"},\n",
        "        #\"Chunked SCAFFOLD cifarclass\": {\"color\": \"yellowgreen\"},\n",
        "        \"FedGenIA cifarclass\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"FedGenIA + FedProx cifarclass\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "        #\"FedGenIA + SCAFFOLD cifarclass\": {\"color\": \"yellowgreen\", \"linestyle\": \"--\"},\n",
        "        \"50chunks FedGenIA\": {\"color\": \"red\"}\n",
        "    },\n",
        "\n",
        "    subplot_groups=[\n",
        "                    [\"Chunked FedAvg\", \"Chunked FedProx\", \"Chunked SCAFFOLD\", \"FedGenIA\", \"FedGenIA + FedProx\", \"FedGenIA + SCAFFOLD\"],\n",
        "                    [\"Chunked FedAvg cifardir05\", \"Chunked FedProx cifardir05\", \"Chunked SCAFFOLD cifardir05\", \"FedGenIA cifardir05\", \"FedGenIA + FedProx cifardir05\", \"FedGenIA + SCAFFOLD cifardir05\"],\n",
        "                    [\"Chunked FedAvg cifardir01\", \"Chunked FedProx cifardir01\", \"Chunked SCAFFOLD cifardir01\", \"FedGenIA cifardir01\", \"FedGenIA + FedProx cifardir01\", \"FedGenIA + SCAFFOLD cifardir01\"],\n",
        "                    [\"Chunked FedAvg cifarclass\", \"Chunked FedProx cifarclass\", \"Chunked SCAFFOLD cifarclass\", \"FedGenIA cifarclass\", \"FedGenIA + FedProx cifarclass\", \"FedGenIA + SCAFFOLD cifarclass\", \"50chunks FedGenIA\"],\n",
        "                    ],\n",
        "    subplot_layout=(1,4),\n",
        "    figsize=(20,2.65),\n",
        "    highlight={\n",
        "        \"Chunked FedAvg\": \"max\",\n",
        "        \"Chunked FedProx\": \"max\",\n",
        "        #\"Chunked SCAFFOLD\": \"max\",\n",
        "        \"FedGenIA\": \"max\",\n",
        "        \"FedGenIA + FedProx\": \"max\",\n",
        "        #\"FedGenIA + SCAFFOLD\": \"max\",\n",
        "        \n",
        "        \"Chunked FedAvg cifardir05\": \"max\",\n",
        "        \"Chunked FedProx cifardir05\": \"max\",\n",
        "        # \"Chunked SCAFFOLD cifardir05\": \"max\",\n",
        "        \"FedGenIA cifardir05\": \"max\",\n",
        "        \"FedGenIA + FedProx cifardir05\": \"max\",\n",
        "        # \"FedGenIA + SCAFFOLD cifardir05\": \"max\",\n",
        "\n",
        "        \"Chunked FedAvg cifardir01\": \"max\",\n",
        "        \"Chunked FedProx cifardir01\": \"max\",\n",
        "        # \"Chunked SCAFFOLD cifardir01\": \"max\",\n",
        "        \"FedGenIA cifardir01\": \"max\",\n",
        "        \"FedGenIA + FedProx cifardir01\": \"max\",\n",
        "        # \"FedGenIA + SCAFFOLD cifardir01\": \"max\",\n",
        "\n",
        "        \"Chunked FedAvg cifarclass\": \"max\",\n",
        "        \"Chunked FedProx cifarclass\": \"max\",\n",
        "        # \"Chunked SCAFFOLD cifarclass\": \"max\",\n",
        "        \"FedGenIA cifarclass\": \"max\",\n",
        "        \"FedGenIA + FedProx cifarclass\": \"max\",\n",
        "        # \"FedGenIA + SCAFFOLD cifarclass\": \"max\",\n",
        "    },\n",
        "    highlight_style={\n",
        "        \"Chunked FedAvg\": {\"highlight_offset_max\": (-5, -0.40), 'arrow_color': 'cornflowerblue', 'arrow_style': '->', 'arrow_linewidth': 1},\n",
        "        \"Chunked FedProx\": {\"highlight_offset_max\": (8, -0.4), 'arrow_color': 'sandybrown', 'arrow_style': '->', 'arrow_linewidth': 1},\n",
        "        \"FedGenIA\": {\"highlight_offset_max\": (-7, -0.55), 'arrow_color': 'cornflowerblue', 'arrow_style': '->', 'arrow_linewidth': 1},\n",
        "        \"FedGenIA + FedProx\": {\"highlight_offset_max\": (-25, -0.45), 'arrow_color': 'sandybrown', 'arrow_style': '->', 'arrow_linewidth': 1},\n",
        "\n",
        "        \"Chunked FedAvg cifardir05\": {\"highlight_offset_max\": (5, -0.25),},\n",
        "        \"Chunked FedProx cifardir05\": {\"highlight_offset_max\": (-10, -0.35),},\n",
        "        \"FedGenIA cifardir05\": {\"highlight_offset_max\": (25, -0.20),},\n",
        "        \"FedGenIA + FedProx cifardir05\": {\"highlight_offset_max\": (0, -0.3)},\n",
        "\n",
        "        \"Chunked FedAvg cifardir01\": {\"highlight_offset_max\": (-5, -0.12)},\n",
        "        \"Chunked FedProx cifardir01\": {\"highlight_offset_max\": (-16, 0.02)},\n",
        "        \"FedGenIA cifardir01\": {\"highlight_offset_max\": (0, -0.2)},\n",
        "        \"FedGenIA + FedProx cifardir01\": {\"highlight_offset_max\": (0, -0.25)},\n",
        "\n",
        "        \"Chunked FedAvg cifarclass\": {\"highlight_offset_max\": (7, -0.27)},\n",
        "        \"Chunked FedProx cifarclass\": {\"highlight_offset_max\": (30, 0)},\n",
        "        \"FedGenIA cifarclass\": {\"highlight_offset_max\": (6.5, 0.1)},\n",
        "        \"FedGenIA + FedProx cifarclass\": {\"highlight_offset_max\": (20, 0)},\n",
        "     }, \n",
        "    num_xticks=5,\n",
        "    num_yticks=[None,None,3,3],\n",
        "    y_ticks=[[0,0.5,1], [0.2,0.45,0.65], None, None],\n",
        "    ylim=[(0,1.05), (0.2,0.65), (0.1, 0.6), (0,0.5)],\n",
        "    ylabel=[\"Accuracy\",\"\",\"\",\"\"],\n",
        "    title=[\"a) MNIST Class\", \"b) CIFAR Dir05\", \"c) CIFAR Dir01\", \"d) CIFAR Class\"],\n",
        "    legend_subplot_index=0,\n",
        "    label_fontsize=16,\n",
        "    tick_fontsize=15,\n",
        "    highlight_markersize=6,\n",
        "    highlight_text_size=15,\n",
        "    legend_fontsize=13,\n",
        "    legend_kwargs={\n",
        "        \"ncol\": 2,\n",
        "        \"columnspacing\": 0.4,\n",
        "        \"handletextpad\": 0.2,\n",
        "        \"borderpad\": 0.1,\n",
        "        \"bbox_to_anchor\": (1.0114, 0.4),\n",
        "        \"handlelength\": 1,\n",
        "        \"labelspacing\": 0.3\n",
        "    },\n",
        "    title_fontsize=18,\n",
        "    save=False,\n",
        "    plot_name=\"./FedGenIAxbaselines.pdf\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d0079b",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series = {\n",
        "        \"Chunked FedAvg\": loaded_dicts[\"MNIST_Class_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"],\n",
        "        \"Chunked FedProx\": loaded_dicts[\"MNIST_Class_Trial1_metrics_chunked_fedprox.json\"][\"net_acc_round\"],\n",
        "        # \"Chunked SCAFFOLD\": loaded_dicts[\"MNIST_Class_Trial1_metrics_chunked_scaffold.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA\": loaded_dicts[\"MNIST_Class_Trial1_metrics.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA + FedProx\": loaded_dicts[\"MNIST_Class_Trial1_metrics_fedprox_fedgenia.json\"][\"net_acc_round\"],\n",
        "        # \"FedGenIA + SCAFFOLD mnistclass\": loaded_dicts[\"MNIST_Class_Trial1_metrics_scaffold_fedgenia.json\"][\"net_acc_round\"],\n",
        "\n",
        "        \"Chunked FedAvg cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_losses_chunked_fedavg.json\"][\"net_acc_round\"],\n",
        "        \"Chunked FedProx cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_metrics_chunked_fedprox.json\"][\"net_acc_round\"],\n",
        "        # \"Chunked SCAFFOLD cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_metrics_chunked_scaffold.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial2_metrics.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA + FedProx cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_metrics_fedprox_fedgenia.json\"][\"net_acc_round\"],\n",
        "        # \"FedGenIA + SCAFFOLD cifardir05\": loaded_dicts[\"CIFAR10_Dir05_Trial1_metrics_scaffold_fedgenia.json\"][\"net_acc_round\"],\n",
        "\n",
        "        \"Chunked FedAvg cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_fedavg_50chunks_metrics.json\"][\"net_acc_round\"][:100],\n",
        "        \"Chunked FedProx cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_fedprox_50chunks_metrics.json\"][\"net_acc_round\"],\n",
        "        # \"Chunked SCAFFOLD cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_metrics_chunked_scaffold.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_fedgenia_fedavg_50chunks_metrics.json\"][\"net_acc_round\"][:100],\n",
        "        \"FedGenIA + FedProx cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_fedgenia_fedprox_50chunks_metrics.json\"][\"net_acc_round\"],\n",
        "        # \"FedGenIA + SCAFFOLD cifardir01\": loaded_dicts[\"CIFAR10_Dir01_Trial1_metrics_scaffold_fedgenia.json\"][\"net_acc_round\"],\n",
        "\n",
        "        \"Chunked FedAvg cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_fedavg_50chunks_metrics.json\"][\"net_acc_round\"],\n",
        "        \"Chunked FedProx cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_fedprox_50chunks_metrics.json\"][\"net_acc_round\"],\n",
        "        # \"Chunked SCAFFOLD cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_metrics_chunked_scaffold.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_fedavg_fedgenia_50chunks_metrics.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA + FedProx cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_fedgenia_fedprox_50chunks_metrics.json\"][\"net_acc_round\"],\n",
        "        # \"FedGenIA + SCAFFOLD cifarclass\": loaded_dicts[\"CIFAR10_Class_Trial1_metrics_scaffold_fedgenia.json\"][\"net_acc_round\"],\n",
        "        },\n",
        "\n",
        "    series_styles={\n",
        "        \"Chunked FedAvg\": {\"color\": \"cornflowerblue\"},\n",
        "        \"Chunked FedProx\": {\"color\": \"sandybrown\"},\n",
        "        #\"Chunked SCAFFOLD\": {\"color\": \"yellowgreen\"},\n",
        "        \"FedGenIA\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"FedGenIA + FedProx\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "        #\"FedGenIA + SCAFFOLD\": {\"color\": \"yellowgreen\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Chunked FedAvg cifardir05\": {\"color\": \"cornflowerblue\"},\n",
        "        \"Chunked FedProx cifardir05\": {\"color\": \"sandybrown\"},\n",
        "        # \"Chunked SCAFFOLD cifardir05\": {\"color\": \"yellowgreen\"},\n",
        "        \"FedGenIA cifardir05\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"FedGenIA + FedProx cifardir05\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "        #\"FedGenIA + SCAFFOLD cifardir05\": {\"color\": \"yellowgreen\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Chunked FedAvg cifardir01\": {\"color\": \"cornflowerblue\"},\n",
        "        \"Chunked FedProx cifardir01\": {\"color\": \"sandybrown\"},\n",
        "        # \"Chunked SCAFFOLD cifardir01\": {\"color\": \"yellowgreen\"},\n",
        "        \"FedGenIA cifardir01\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"FedGenIA + FedProx cifardir01\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "        # \"FedGenIA + SCAFFOLD cifardir01\": {\"color\": \"yellowgreen\", \"linestyle\": \"--\"},\n",
        "\n",
        "        \"Chunked FedAvg cifarclass\": {\"color\": \"cornflowerblue\"},\n",
        "        \"Chunked FedProx cifarclass\": {\"color\": \"sandybrown\"},\n",
        "        #\"Chunked SCAFFOLD cifarclass\": {\"color\": \"yellowgreen\"},\n",
        "        \"FedGenIA cifarclass\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"FedGenIA + FedProx cifarclass\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "        #\"FedGenIA + SCAFFOLD cifarclass\": {\"color\": \"yellowgreen\", \"linestyle\": \"--\"},\n",
        "        \"50chunks FedGenIA\": {\"color\": \"red\"}\n",
        "    },\n",
        "\n",
        "    subplot_groups=[\n",
        "                    [\"Chunked FedAvg\", \"Chunked FedProx\", \"Chunked SCAFFOLD\", \"FedGenIA\", \"FedGenIA + FedProx\", \"FedGenIA + SCAFFOLD\"],\n",
        "                    [\"Chunked FedAvg cifardir05\", \"Chunked FedProx cifardir05\", \"Chunked SCAFFOLD cifardir05\", \"FedGenIA cifardir05\", \"FedGenIA + FedProx cifardir05\", \"FedGenIA + SCAFFOLD cifardir05\"],\n",
        "                    [\"Chunked FedAvg cifardir01\", \"Chunked FedProx cifardir01\", \"Chunked SCAFFOLD cifardir01\", \"FedGenIA cifardir01\", \"FedGenIA + FedProx cifardir01\", \"FedGenIA + SCAFFOLD cifardir01\"],\n",
        "                    [\"Chunked FedAvg cifarclass\", \"Chunked FedProx cifarclass\", \"Chunked SCAFFOLD cifarclass\", \"FedGenIA cifarclass\", \"FedGenIA + FedProx cifarclass\", \"FedGenIA + SCAFFOLD cifarclass\", \"50chunks FedGenIA\"],\n",
        "                    ],\n",
        "    subplot_layout=(1,4),\n",
        "    figsize=(20,2.65),\n",
        "    highlight={\n",
        "        \"Chunked FedAvg\": \"max\",\n",
        "        \"Chunked FedProx\": \"max\",\n",
        "        #\"Chunked SCAFFOLD\": \"max\",\n",
        "        \"FedGenIA\": \"max\",\n",
        "        \"FedGenIA + FedProx\": \"max\",\n",
        "        #\"FedGenIA + SCAFFOLD\": \"max\",\n",
        "        \n",
        "        \"Chunked FedAvg cifardir05\": \"max\",\n",
        "        \"Chunked FedProx cifardir05\": \"max\",\n",
        "        # \"Chunked SCAFFOLD cifardir05\": \"max\",\n",
        "        \"FedGenIA cifardir05\": \"max\",\n",
        "        \"FedGenIA + FedProx cifardir05\": \"max\",\n",
        "        # \"FedGenIA + SCAFFOLD cifardir05\": \"max\",\n",
        "\n",
        "        \"Chunked FedAvg cifardir01\": \"max\",\n",
        "        \"Chunked FedProx cifardir01\": \"max\",\n",
        "        # \"Chunked SCAFFOLD cifardir01\": \"max\",\n",
        "        \"FedGenIA cifardir01\": \"max\",\n",
        "        \"FedGenIA + FedProx cifardir01\": \"max\",\n",
        "        # \"FedGenIA + SCAFFOLD cifardir01\": \"max\",\n",
        "\n",
        "        \"Chunked FedAvg cifarclass\": \"max\",\n",
        "        \"Chunked FedProx cifarclass\": \"max\",\n",
        "        # \"Chunked SCAFFOLD cifarclass\": \"max\",\n",
        "        \"FedGenIA cifarclass\": \"max\",\n",
        "        \"FedGenIA + FedProx cifarclass\": \"max\",\n",
        "        # \"FedGenIA + SCAFFOLD cifarclass\": \"max\",\n",
        "    },\n",
        "    highlight_style={\n",
        "        \"Chunked FedAvg\": {\"highlight_offset_max\": (-5, -0.40), 'arrow_color': 'cornflowerblue', 'arrow_style': '->', 'arrow_linewidth': 1},\n",
        "        \"Chunked FedProx\": {\"highlight_offset_max\": (8, -0.4), 'arrow_color': 'sandybrown', 'arrow_style': '->', 'arrow_linewidth': 1},\n",
        "        \"FedGenIA\": {\"highlight_offset_max\": (-7, -0.55), 'arrow_color': 'cornflowerblue', 'arrow_style': '->', 'arrow_linewidth': 1},\n",
        "        \"FedGenIA + FedProx\": {\"highlight_offset_max\": (-25, -0.45), 'arrow_color': 'sandybrown', 'arrow_style': '->', 'arrow_linewidth': 1},\n",
        "\n",
        "        \"Chunked FedAvg cifardir05\": {\"highlight_offset_max\": (5, -0.25),},\n",
        "        \"Chunked FedProx cifardir05\": {\"highlight_offset_max\": (-10, -0.35),},\n",
        "        \"FedGenIA cifardir05\": {\"highlight_offset_max\": (25, -0.20),},\n",
        "        \"FedGenIA + FedProx cifardir05\": {\"highlight_offset_max\": (0, -0.3)},\n",
        "\n",
        "        \"Chunked FedAvg cifardir01\": {\"highlight_offset_max\": (-5, -0.12)},\n",
        "        \"Chunked FedProx cifardir01\": {\"highlight_offset_max\": (-16, 0.02)},\n",
        "        \"FedGenIA cifardir01\": {\"highlight_offset_max\": (0, -0.2)},\n",
        "        \"FedGenIA + FedProx cifardir01\": {\"highlight_offset_max\": (0, -0.25)},\n",
        "\n",
        "        \"Chunked FedAvg cifarclass\": {\"highlight_offset_max\": (7, -0.27)},\n",
        "        \"Chunked FedProx cifarclass\": {\"highlight_offset_max\": (30, 0)},\n",
        "        \"FedGenIA cifarclass\": {\"highlight_offset_max\": (6.5, 0.1)},\n",
        "        \"FedGenIA + FedProx cifarclass\": {\"highlight_offset_max\": (20, 0)},\n",
        "     }, \n",
        "    num_xticks=5,\n",
        "    num_yticks=[None,None,3,3],\n",
        "    y_ticks=[[0,0.5,1], [0.2,0.45,0.65], None, None],\n",
        "    ylim=[(0,1.05), (0.2,0.65), (0.1, 0.6), (0,0.5)],\n",
        "    ylabel=[\"Accuracy\",\"\",\"\",\"\"],\n",
        "    title=[\"a) MNIST Class\", \"b) CIFAR Dir05\", \"c) CIFAR Dir01\", \"d) CIFAR Class\"],\n",
        "    legend_subplot_index=0,\n",
        "    label_fontsize=16,\n",
        "    tick_fontsize=15,\n",
        "    highlight_markersize=6,\n",
        "    highlight_text_size=15,\n",
        "    legend_fontsize=13,\n",
        "    legend_kwargs={\n",
        "        \"ncol\": 2,\n",
        "        \"columnspacing\": 0.4,\n",
        "        \"handletextpad\": 0.2,\n",
        "        \"borderpad\": 0.1,\n",
        "        \"bbox_to_anchor\": (1.0114, 0.4),\n",
        "        \"handlelength\": 1,\n",
        "        \"labelspacing\": 0.3\n",
        "    },\n",
        "    title_fontsize=18,\n",
        "    save=False,\n",
        "    plot_name=\"./FedGenIAxbaselines.pdf\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6e874a0",
      "metadata": {},
      "source": [
        "#### Aggregated Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eece0598",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series = {\n",
        "        \"MNIST Class\": experiment_stats[\"MNIST_Class\"][\"net_acc_round\"][\"std\"],\n",
        "        \"CIFAR Dir05\": experiment_stats[\"CIFAR10_Dir05\"][\"net_acc_round\"][\"std\"],\n",
        "        \"CIFAR Dir01\": experiment_stats[\"CIFAR10_Dir01\"][\"net_acc_round\"][\"std\"],\n",
        "        \"CIFAR Class\": experiment_stats[\"CIFAR10_Class\"][\"net_acc_round\"][\"std\"],\n",
        "        },\n",
        "    # series_styles={\n",
        "    #     \"Chunked FedAvg cifarclass\": {\"color\": \"cornflowerblue\"},\n",
        "    #     \"FedGenIA cifarclass\": {\"color\": \"sandybrown\"},\n",
        "    #     \"Chunked FedAvg cifardir05\": {\"color\": \"cornflowerblue\"},\n",
        "    #     \"FedGenIA cifardir05\": {\"color\": \"sandybrown\"},\n",
        "    #     \"Chunked FedAvg cifardir01\": {\"color\": \"cornflowerblue\"},\n",
        "    #     \"FedGenIA cifardir01\": {\"color\": \"sandybrown\"},\n",
        "    #     \"Chunked FedAvg\": {\"color\": \"cornflowerblue\"},\n",
        "    #     \"FedGenIA\": {\"color\": \"sandybrown\"},\n",
        "    # },\n",
        "    # subplot_groups=[\n",
        "    #                 [\"Chunked FedAvg\", \"FedGenIA\"],\n",
        "    #                 [\"Chunked FedAvg cifardir05\", \"FedGenIA cifardir05\"],\n",
        "    #                 [\"Chunked FedAvg cifardir01\", \"FedGenIA cifardir01\"],\n",
        "    #                 [\"Chunked FedAvg cifarclass\", \"FedGenIA cifarclass\"],],\n",
        "    #subplot_layout=(1,4),\n",
        "    figsize=(16,8),\n",
        "    # highlight={\n",
        "    #     \"Chunked FedAvg cifarclass\": \"max\",\n",
        "    #     \"FedGenIA cifarclass\": \"max\",\n",
        "    #     \"Chunked FedAvg cifardir05\": \"max\",\n",
        "    #     \"FedGenIA cifardir05\": \"max\",\n",
        "    #     \"Chunked FedAvg cifardir01\": \"max\",\n",
        "    #     \"FedGenIA cifardir01\": \"max\",\n",
        "    #     \"Chunked FedAvg\": \"max\",\n",
        "    #     \"FedGenIA\": \"max\",\n",
        "    # },\n",
        "    # highlight_style={\n",
        "    #     \"Chunked FedAvg cifarclass\": {\"highlight_offset_max\": (20, 0.02)},\n",
        "    #     \"FedGenIA cifarclass\": {\"highlight_offset_max\": (-15, 0.005)},\n",
        "    #     \"Chunked FedAvg cifardir05\": {\"highlight_offset_max\": (0, -0.23)},\n",
        "    #     \"FedGenIA cifardir05\": {\"highlight_offset_max\": (-5, -0.22)},\n",
        "    #     \"Chunked FedAvg cifardir01\": {\"highlight_offset_max\": (-5, -0.17)},\n",
        "    #     \"FedGenIA cifardir01\": {\"highlight_offset_max\": (-5, -0.16)},\n",
        "    #     \"Chunked FedAvg\": {\"highlight_offset_max\": (5, -0.35)},\n",
        "    #     \"FedGenIA\": {\"highlight_offset_max\": (-10, -0.4)},\n",
        "    #  }, \n",
        "    # num_xticks=5,\n",
        "    num_yticks=3,\n",
        "    ylabel=[\"Accuracy\"],\n",
        "    # title=[\"a) MNIST Class\", \"b) CIFAR Dir05\", \"c) CIFAR Dir01\", \"d) CIFAR Class\"],\n",
        "    legend_subplot_index=0,\n",
        "    label_fontsize=16,\n",
        "    tick_fontsize=15,\n",
        "    # highlight_markersize=6,\n",
        "    # highlight_text_size=14,\n",
        "    legend_fontsize=12,\n",
        "    title_fontsize=18,\n",
        "    xtick_step=10,\n",
        "    first_step=9\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68f94216",
      "metadata": {},
      "source": [
        "#### Comparing Trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a835bce",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series = {\n",
        "        \"Trial1\": loaded_dicts[\"CIFAR10_Class_Trial1_metrics.json\"][\"net_acc_round\"],\n",
        "        \"Trial2\": loaded_dicts[\"CIFAR10_Class_Trial2_metrics.json\"][\"net_acc_round\"],\n",
        "        \"Trial3\": loaded_dicts[\"CIFAR10_Class_Trial3_metrics.json\"][\"net_acc_round\"]\n",
        "        },\n",
        "    series_styles={\n",
        "        \"FedGenIA com agregação por chunk\": {\"color\": \"cornflowerblue\"},\n",
        "        \"FedGenIA com agregação só com primeiro chunk\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"Chunked FedAvg\": {\"color\": \"sandybrown\"},\n",
        "        \"CIFAR10 Class metrics\": {\"color\": \"cornflowerblue\"},\n",
        "        \"CIFAR10 Class losses\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"CIFAR10 Class alvo\": {\"color\": \"sandybrown\"},\n",
        "        \"CIFAR10 Dir01 metrics\": {\"color\": \"cornflowerblue\"},\n",
        "        \"CIFAR10 Dir01 losses\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"CIFAR10 Dir01 alvo\": {\"color\": \"sandybrown\"},\n",
        "        \"CIFAR10 Dir05 metrics\": {\"color\": \"cornflowerblue\"},\n",
        "        \"CIFAR10 Dir05 losses\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"CIFAR10 Dir05 alvo\": {\"color\": \"sandybrown\"},\n",
        "    },\n",
        "    subplot_layout=(1,1),\n",
        "    figsize=(20,10),\n",
        "    # highlight={\n",
        "    #     \"Chunked FedAvg cifarclass\": \"max\",\n",
        "    #     \"FedGenIA cifarclass\": \"max\",\n",
        "    #     \"Chunked FedAvg cifardir05\": \"max\",\n",
        "    #     \"FedGenIA cifardir05\": \"max\",\n",
        "    #     \"Chunked FedAvg cifardir01\": \"max\",\n",
        "    #     \"FedGenIA cifardir01\": \"max\",\n",
        "    #     \"Chunked FedAvg\": \"max\",\n",
        "    #     \"FedGenIA\": \"max\",\n",
        "    # },\n",
        "    # highlight_style={\n",
        "    #     \"Chunked FedAvg cifarclass\": {\"highlight_offset_max\": (20, 0.02)},\n",
        "    #     \"FedGenIA cifarclass\": {\"highlight_offset_max\": (-15, 0.005)},\n",
        "    #     \"Chunked FedAvg cifardir05\": {\"highlight_offset_max\": (0, -0.23)},\n",
        "    #     \"FedGenIA cifardir05\": {\"highlight_offset_max\": (-5, -0.22)},\n",
        "    #     \"Chunked FedAvg cifardir01\": {\"highlight_offset_max\": (-5, -0.17)},\n",
        "    #     \"FedGenIA cifardir01\": {\"highlight_offset_max\": (-5, -0.16)},\n",
        "    #     \"Chunked FedAvg\": {\"highlight_offset_max\": (5, -0.35)},\n",
        "    #     \"FedGenIA\": {\"highlight_offset_max\": (-10, -0.4)},\n",
        "    #  }, \n",
        "    # num_xticks=5,\n",
        "    num_yticks=4,\n",
        "    ylabel=[\"Accuracy\"],\n",
        "    title=[\"\"],\n",
        "    legend_subplot_index=0,\n",
        "    label_fontsize=16,\n",
        "    tick_fontsize=15,\n",
        "    highlight_markersize=6,\n",
        "    highlight_text_size=14,\n",
        "    legend_fontsize=12,\n",
        "    title_fontsize=18,\n",
        "    first_step=9,\n",
        "    xtick_step=10,\n",
        "    save=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0637fcc",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series = {\n",
        "        \"CIFAR10 Class metrics\": loaded_dicts[\"CIFAR10_Class_Trial1_metrics.json\"][\"net_acc_round\"],\n",
        "        \"CIFAR10 Class losses\": loaded_dicts[\"CIFAR10_Class_Trial1_losses.json\"][\"net_acc_round\"],\n",
        "        \"CIFAR10 Class alvo\": loaded_dicts[\"Alvo_4c_NIIDClass_CIFAR_losses.json\"][\"net_acc_round\"],\n",
        "        \"CIFAR10 Dir01 metrics\": loaded_dicts[\"CIFAR10_Dir01_Trial1_metrics.json\"][\"net_acc_round\"],\n",
        "        \"CIFAR10 Dir01 losses\": loaded_dicts[\"CIFAR10_Dir01_Trial1_losses.json\"][\"net_acc_round\"][:100],\n",
        "        \"CIFAR10 Dir01 alvo\": loaded_dicts[\"Alvo_4c_01Dir_CIFAR_losses.json\"][\"net_acc_round\"][:100],\n",
        "        \"CIFAR10 Dir05 metrics\": loaded_dicts[\"CIFAR10_Dir05_Trial1_metrics.json\"][\"net_acc_round\"],\n",
        "        \"CIFAR10 Dir05 losses\": loaded_dicts[\"CIFAR10_Dir05_Trial1_losses.json\"][\"net_acc_round\"],\n",
        "        \"CIFAR10 Dir05 alvo\": loaded_dicts[\"Alvo_4c_05Dir_CIFAR_losses.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA com agregação por chunk\": loaded_dicts[\"MNIST_Class_Trial1_metrics.json\"][\"net_acc_round\"],\n",
        "        \"FedGenIA com agregação só com primeiro chunk\": loaded_dicts[\"MNIST_Class_Trial1_losses.json\"][\"net_acc_round\"],\n",
        "        \"Chunked FedAvg\": loaded_dicts[\"Alvo_4c_NIIDClass_MNIST_losses.json\"][\"net_acc_round\"]\n",
        "        },\n",
        "    series_styles={\n",
        "        \"FedGenIA com agregação por chunk\": {\"color\": \"cornflowerblue\"},\n",
        "        \"FedGenIA com agregação só com primeiro chunk\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"Chunked FedAvg\": {\"color\": \"sandybrown\"},\n",
        "        \"CIFAR10 Class metrics\": {\"color\": \"cornflowerblue\"},\n",
        "        \"CIFAR10 Class losses\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"CIFAR10 Class alvo\": {\"color\": \"sandybrown\"},\n",
        "        \"CIFAR10 Dir01 metrics\": {\"color\": \"cornflowerblue\"},\n",
        "        \"CIFAR10 Dir01 losses\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"CIFAR10 Dir01 alvo\": {\"color\": \"sandybrown\"},\n",
        "        \"CIFAR10 Dir05 metrics\": {\"color\": \"cornflowerblue\"},\n",
        "        \"CIFAR10 Dir05 losses\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"CIFAR10 Dir05 alvo\": {\"color\": \"sandybrown\"},\n",
        "    },\n",
        "    subplot_groups=[\n",
        "                    [\"FedGenIA com agregação por chunk\", \"FedGenIA com agregação só com primeiro chunk\", \"Chunked FedAvg\"],\n",
        "                    [\"CIFAR10 Class metrics\", \"CIFAR10 Class losses\", \"CIFAR10 Class alvo\"],\n",
        "                    [\"CIFAR10 Dir01 metrics\", \"CIFAR10 Dir01 losses\", \"CIFAR10 Dir01 alvo\"],\n",
        "                    [\"CIFAR10 Dir05 metrics\", \"CIFAR10 Dir05 losses\", \"CIFAR10 Dir05 alvo\"],\n",
        "                    ],\n",
        "    subplot_layout=(2,2),\n",
        "    figsize=(20,10),\n",
        "    # highlight={\n",
        "    #     \"Chunked FedAvg cifarclass\": \"max\",\n",
        "    #     \"FedGenIA cifarclass\": \"max\",\n",
        "    #     \"Chunked FedAvg cifardir05\": \"max\",\n",
        "    #     \"FedGenIA cifardir05\": \"max\",\n",
        "    #     \"Chunked FedAvg cifardir01\": \"max\",\n",
        "    #     \"FedGenIA cifardir01\": \"max\",\n",
        "    #     \"Chunked FedAvg\": \"max\",\n",
        "    #     \"FedGenIA\": \"max\",\n",
        "    # },\n",
        "    # highlight_style={\n",
        "    #     \"Chunked FedAvg cifarclass\": {\"highlight_offset_max\": (20, 0.02)},\n",
        "    #     \"FedGenIA cifarclass\": {\"highlight_offset_max\": (-15, 0.005)},\n",
        "    #     \"Chunked FedAvg cifardir05\": {\"highlight_offset_max\": (0, -0.23)},\n",
        "    #     \"FedGenIA cifardir05\": {\"highlight_offset_max\": (-5, -0.22)},\n",
        "    #     \"Chunked FedAvg cifardir01\": {\"highlight_offset_max\": (-5, -0.17)},\n",
        "    #     \"FedGenIA cifardir01\": {\"highlight_offset_max\": (-5, -0.16)},\n",
        "    #     \"Chunked FedAvg\": {\"highlight_offset_max\": (5, -0.35)},\n",
        "    #     \"FedGenIA\": {\"highlight_offset_max\": (-10, -0.4)},\n",
        "    #  }, \n",
        "    # num_xticks=5,\n",
        "    num_yticks=4,\n",
        "    ylabel=[\"Accuracy\", \"Accuracy\", \"Accuracy\", \"Accuracy\"],\n",
        "    title=[\"MNIST Class\", \"CIFAR Class\", \"CIFAR Dir01\", \"CIFAR Dir05\"],\n",
        "    legend_subplot_index=0,\n",
        "    label_fontsize=16,\n",
        "    tick_fontsize=15,\n",
        "    highlight_markersize=6,\n",
        "    highlight_text_size=14,\n",
        "    legend_fontsize=12,\n",
        "    title_fontsize=18,\n",
        "    first_step=9,\n",
        "    xtick_step=10,\n",
        "    save=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af29f8a9",
      "metadata": {},
      "source": [
        "### Optim Compare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "933a5a75",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series = {\n",
        "        \"Adam_loss\": loaded_dict_mnist[\"net_loss_round\"],\n",
        "        \"Adam_GeraFed_loss\": loaded_dict_mnist_gerafed[\"net_loss_round\"],\n",
        "        \"Adam_reiniciando_loss\": loaded_dict_mnist_adam_reiniciando[\"net_loss_round\"],\n",
        "        \"Adam_reiniciando_GeraFed_loss\": loaded_dict_mnist_adam_reiniciando_gerafed[\"net_loss_round\"],\n",
        "        \"SGD_loss\": loaded_dict_mnist_sgd[\"net_loss_round\"],\n",
        "        \"SGD_GeraFed_loss\": loaded_dict_mnist_sgd_gerafed[\"net_loss_round\"],\n",
        "        \"Adam\": loaded_dict_mnist[\"net_acc_round\"],\n",
        "        \"Adam_GeraFed\": loaded_dict_mnist_gerafed[\"net_acc_round\"],\n",
        "        \"Adam_reiniciando\": loaded_dict_mnist_adam_reiniciando[\"net_acc_round\"],\n",
        "        \"Adam_reiniciando_GeraFed\": loaded_dict_mnist_adam_reiniciando_gerafed[\"net_acc_round\"],\n",
        "        \"SGD\": loaded_dict_mnist_sgd[\"net_acc_round\"],\n",
        "        \"SGD_GeraFed\": loaded_dict_mnist_sgd_gerafed[\"net_acc_round\"],\n",
        "    },\n",
        "    subplot_groups=[\n",
        "        [\"Adam_loss\", \"Adam_GeraFed_loss\", \"Adam_reiniciando_loss\", \"Adam_reiniciando_GeraFed_loss\", \"SGD_loss\", \"SGD_GeraFed_loss\"],\n",
        "        [\"Adam\", \"Adam_GeraFed\", \"Adam_reiniciando\", \"Adam_reiniciando_GeraFed\", \"SGD\", \"SGD_GeraFed\"]\n",
        "    ],\n",
        "    subplot_layout=(2, 1),\n",
        "    series_styles={\n",
        "        \"Adam_loss\": {\"color\": \"cornflowerblue\", \"linestyle\": \"-\"},\n",
        "        \"Adam_GeraFed_loss\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"Adam_reiniciando_loss\": {\"color\": \"darkturquoise\", \"linestyle\": \"-\"},\n",
        "        \"Adam_reiniciando_GeraFed_loss\": {\"color\": \"darkturquoise\", \"linestyle\": \"--\"},\n",
        "        \"SGD_loss\": {\"color\": \"yellowgreen\", \"linestyle\": \"-\"},\n",
        "        \"SGD_GeraFed_loss\": {\"color\": \"yellowgreen\", \"linestyle\": \"--\"},\n",
        "        \"Adam\": {\"color\": \"cornflowerblue\",  \"linestyle\": \"-\"},\n",
        "        \"Adam_GeraFed\": {\"color\": \"cornflowerblue\",  \"linestyle\": \"--\"},\n",
        "        \"Adam_reiniciando\": {\"color\": \"darkturquoise\",  \"linestyle\": \"-\"},\n",
        "        \"Adam_reiniciando_GeraFed\": {\"color\": \t\"darkturquoise\", \t\"linestyle\": \"--\"},\n",
        "        \"SGD\": {\"color\": \t\"yellowgreen\", \t\"linestyle\": \"-\"},\n",
        "        \"SGD_GeraFed\": {\"color\": \t\"yellowgreen\", \t\"linestyle\": \"--\"},\n",
        "    },\n",
        "    xlabel=[\"Épocas\", \"\"],\n",
        "    ylabel=[\"Loss\", \"Acurácia\"],\n",
        "    legend_subplot_index=1,\n",
        "    xtick_step=10,\n",
        "    first_step=9,\n",
        "    figsize=(8, 8),\n",
        "    legend_fontsize=8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8d902d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series={\"Class Adam\": loaded_dict_cifar_class[\"net_acc_round\"],\n",
        "            \"Dir01 Adam\": loaded_dict_cifar_dir01[\"net_acc_round\"][:100],\n",
        "            \"Dir05 Adam\": loaded_dict_cifar_dir05[\"net_acc_round\"],\n",
        "            \"Class SGD\": loaded_dict_cifar_class_sgd[\"net_acc_round\"],\n",
        "            \"Dir01 SGD\": loaded_dict_cifar_dir01_sgd[\"net_acc_round\"],\n",
        "            \"Dir05 SGD\": loaded_dict_cifar_dir05_sgd[\"net_acc_round\"],\n",
        "    },\n",
        "    series_styles={\n",
        "        \"Class Adam\": {\"color\": \"cornflowerblue\", \"linestyle\": \"-\"},\n",
        "        \"Dir01 Adam\": {\"color\": \"cornflowerblue\", \"linestyle\": \"--\"},\n",
        "        \"Dir05 Adam\": {\"color\": \"cornflowerblue\", \"linestyle\": \":\"},\n",
        "        \"Class SGD\": {\"color\": \"sandybrown\", \"linestyle\": \"-\"},\n",
        "        \"Dir01 SGD\": {\"color\": \"sandybrown\", \"linestyle\": \"--\"},\n",
        "        \"Dir05 SGD\": {\"color\": \"sandybrown\", \"linestyle\": \":\"},\n",
        "    },\n",
        "    highlight={\n",
        "        \"Class Adam\": \"max\",\n",
        "        \"Dir01 Adam\": \"max\",\n",
        "        \"Dir05 Adam\": \"max\",\n",
        "        \"Class SGD\": \"max\",\n",
        "        \"Dir01 SGD\": \"max\",\n",
        "        \"Dir05 SGD\": \"max\",\n",
        "    },\n",
        "    highlight_style={\n",
        "        \"Class Adam\": {\"highlight_offset_max\": (20, 0.02)},\n",
        "        \"Dir01 Adam\": {\"highlight_offset_max\": (-5, -0.17)},\n",
        "        \"Dir05 Adam\": {\"highlight_offset_max\": (0, -0.23)},\n",
        "        \"Class SGD\": {\"highlight_offset_max\": (20, 0.005)},\n",
        "        \"Dir01 SGD\": {\"highlight_offset_max\": (-5, -0.16)},\n",
        "        \"Dir05 SGD\": {\"highlight_offset_max\": (-5, -0.22)},\n",
        "     },\n",
        "    xtick_step=10,\n",
        "    first_step=9\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffc7684f",
      "metadata": {},
      "source": [
        "### FLEG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "id": "5ca04255",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_series(\n",
        "    series = {\"Test\": loaded_dicts[\"cifar10_ClassPartitioner_fedavg_numchunks100_ganepoch30_fleg_trial1_metrics.json\"][\"net_acc\"]},\n",
        "    num_xticks=10,\n",
        "    level_markers={\n",
        "        \"L1\": 16,\n",
        "        \"L2\": 31,\n",
        "        \"L3\": 42,\n",
        "        \"L4\": 54}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e00c7eaf",
      "metadata": {},
      "source": [
        "#### Level Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbaf5de6",
      "metadata": {},
      "outputs": [],
      "source": [
        "class_levels = [\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg_class_level0_metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg_class_level1_metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg_class_level2_metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg_class_level3_metrics.json\",\n",
        "    \"mnist_ClassPartition_fedavg_numchunks100_fleg_class_level4_metrics.json\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8532ea4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_dicts.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd512b6b",
      "metadata": {},
      "outputs": [],
      "source": [
        "net_acc_all_levels = [acc for id, d in loaded_dicts.items() for acc in d[\"net_acc\"] if id in class_levels]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6d0405d",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series={\n",
        "        \"FLEG\": net_acc_all_levels,\n",
        "        \"FedAvg\": loaded_dicts[\"class_patience100_metrics.json\"][\"net_acc\"],\n",
        "    },\n",
        "    num_xticks=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d09ba285",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "\n",
        "offset = 0\n",
        "for k in class_levels:\n",
        "    acc = loaded_dicts[k][\"net_acc\"]\n",
        "    epochs = range(offset, offset + len(acc))\n",
        "    plt.axvline(offset, linestyle=\":\", alpha=0.4)\n",
        "    plt.plot(epochs, acc, label=k.replace(\"_metrics.json\", \"\"))\n",
        "    offset += len(acc)\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Classifier training by level\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1743e1c",
      "metadata": {},
      "outputs": [],
      "source": [
        "level1_variants = [\n",
        "    \"class_level1_metrics.json\",\n",
        "    \"class_level1_3000_samples_metrics.json\",\n",
        "    \"class_level1_12000_samples_metrics.json\",\n",
        "    \"class_level1_D_samples_metrics.json\",\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0adce9f",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "offset = 0\n",
        "\n",
        "# ---- Level 0 ----\n",
        "acc0 = loaded_dicts[\"class_level0_metrics.json\"][\"net_acc\"]\n",
        "epochs = range(offset, offset + len(acc0))\n",
        "plt.plot(epochs, acc0, label=\"level0\")\n",
        "offset += len(acc0)\n",
        "\n",
        "# ---- Level 1 (variants) ----\n",
        "styles = [\"-\", \"--\", \"-.\", \":\"]\n",
        "for k, style in zip(level1_variants, styles):\n",
        "    acc = loaded_dicts[k][\"net_acc\"]\n",
        "    epochs = range(offset, offset + len(acc))\n",
        "    plt.plot(epochs, acc, linestyle=style, label=k.replace(\"_metrics.json\", \"\"))\n",
        "\n",
        "# assume same length → move offset once\n",
        "offset += len(acc)\n",
        "\n",
        "# ---- Levels 2–4 ----\n",
        "for k in class_levels[2:]:\n",
        "    acc = loaded_dicts[k][\"net_acc\"]\n",
        "    epochs = range(offset, offset + len(acc))\n",
        "    plt.plot(epochs, acc, label=k.replace(\"_metrics.json\", \"\"))\n",
        "    offset += len(acc)\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Classifier training – Level 1 variants comparison\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1223040a",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series={\n",
        "        \"Gen_Level1\": loaded_dicts[\"gan_level1_metrics_gan.json\"][\"g_losses_epoch\"],\n",
        "        \"Disc_Level1\": loaded_dicts[\"gan_level1_metrics_gan.json\"][\"d_losses_epoch\"],\n",
        "        \"Gen_Level2\": loaded_dicts[\"gan_level2_metrics.json\"][\"g_losses_epoch\"],\n",
        "        \"Disc_Level2\": loaded_dicts[\"gan_level2_metrics.json\"][\"d_losses_epoch\"],\n",
        "        \"Gen_Level3\": loaded_dicts[\"gan_level3_metrics.json\"][\"g_losses_epoch\"],\n",
        "        \"Disc_Level3\": loaded_dicts[\"gan_level3_metrics.json\"][\"d_losses_epoch\"],\n",
        "        \"Gen_Level4\": loaded_dicts[\"gan_level4_metrics.json\"][\"g_losses_epoch\"],\n",
        "        \"Disc_Level4\": loaded_dicts[\"gan_level4_metrics.json\"][\"d_losses_epoch\"],\n",
        "        },\n",
        "        series_styles={\n",
        "            \"Gen_Level1\": {\"color\": \"C0\"}\n",
        "        }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "678a85d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks1_ganepoch40_fleg_trial1_metrics.json\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0de7dca7",
      "metadata": {},
      "source": [
        "#### General Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fde31d7f",
      "metadata": {},
      "source": [
        "##### Automatic series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba4e04b3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8eaf043",
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_dicts.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27df01f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "pattern = re.compile(\n",
        "    r\"(cifar10|mnist)_\" \n",
        "    r\"(ClassPartitioner|Dirichlet_[0-9.]+)_\"\n",
        "    r\"fedavg_numchunks(\\d+)_\"\n",
        "    r\"ganepoch(\\d+)_\"\n",
        "    r\"fleg_trial(\\d+)\"\n",
        ")\n",
        "\n",
        "records = []\n",
        "\n",
        "for key, data in loaded_dicts.items():\n",
        "    m = pattern.search(key) \n",
        "    if not m:\n",
        "        continue\n",
        "    dataset, partitioner, numchunks, ganepoch, trial = m.groups()\n",
        "    records.append({\n",
        "        \"dataset\": dataset,\n",
        "        \"partitioner\": partitioner,\n",
        "        \"numchunks\": int(numchunks),\n",
        "        \"ganepoch\": int(ganepoch),\n",
        "        \"trial\": int(trial),\n",
        "        \"values\": np.array(data[\"net_acc\"])\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72455751",
      "metadata": {},
      "source": [
        "###### With mean trials calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "570e6565",
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bf8cc3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "groups = defaultdict(list)\n",
        "\n",
        "for r in records:\n",
        "    k = (\n",
        "        r[\"dataset\"],\n",
        "        r[\"partitioner\"],\n",
        "        r[\"numchunks\"],\n",
        "        r[\"ganepoch\"],\n",
        "    )\n",
        "    groups[k].append(r)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e72b37d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def select_median_top_trial(trials):\n",
        "    \"\"\"\n",
        "    trials: list of dicts with key 'values'\n",
        "    returns: list with best acc and selected trial dict\n",
        "    \"\"\"\n",
        "    # Compute top accuracy for each trial\n",
        "    scored = [\n",
        "        (np.max(t[\"values\"]), t)\n",
        "        for t in trials\n",
        "    ]\n",
        "\n",
        "    # Sort by top accuracy\n",
        "    scored.sort(key=lambda x: x[0])\n",
        "\n",
        "    # Pick median\n",
        "    median_idx = len(scored) // 2\n",
        "    return scored[median_idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f217229",
      "metadata": {},
      "outputs": [],
      "source": [
        "series_to_plot = {}\n",
        "\n",
        "for (dataset, part, numchunks, ganepoch), trials in groups.items():\n",
        "    chosen = select_median_top_trial(trials)[1]\n",
        "\n",
        "    label = (\n",
        "        f\"{dataset.upper()} \"\n",
        "        f\"{numchunks if numchunks > 1 else 'No'}Chunks \"\n",
        "        f\"{ganepoch}eGAN\"\n",
        "    )\n",
        "\n",
        "    series_to_plot[label] = chosen[\"values\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "750cb4ec",
      "metadata": {},
      "source": [
        "###### calculating best accuracies for each combination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be40f288",
      "metadata": {},
      "outputs": [],
      "source": [
        "results = []\n",
        "\n",
        "for (dataset, partitioner, numchunks, ganepoch), trials in groups.items():\n",
        "\n",
        "    best_acc, trial = select_median_top_trial(trials)\n",
        "\n",
        "    results.append({\n",
        "        \"dataset\": dataset,\n",
        "        \"partitioner\": partitioner,\n",
        "        \"numchunks\": numchunks,\n",
        "        \"ganepoch\": ganepoch,\n",
        "        \"best_accuracy\": float(best_acc),\n",
        "        \"trial\": trial[\"trial\"]\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f69f3b9",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c5a0266",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75c12c75",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.sort_values(\n",
        "    [\"dataset\", \"partitioner\", \"best_accuracy\"], ascending=[True, True, False]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f77576c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.style.hide(axis=\"index\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2bce6e9",
      "metadata": {},
      "source": [
        "###### Without mean trial calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4260f8ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "series_to_plot = {}\n",
        "\n",
        "for serie in records:\n",
        "    label = (\n",
        "        f\"{serie['dataset'].upper()} \"\n",
        "        f\"{serie['numchunks'] if serie['numchunks'] > 1 else 'No'}Chunks \"\n",
        "        f\"{serie['ganepoch']}eGAN \"\n",
        "        f\"Trial{serie['trial']}\"\n",
        "    )\n",
        "    series_to_plot[label] = serie[\"values\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7edb8ff",
      "metadata": {},
      "source": [
        "###### Subgroups and styles automation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df4536de",
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets = [\"cifar10\", \"mnist\"]\n",
        "numchunks_order = [1, 10, 50, 100, 200]\n",
        "\n",
        "subplot_groups_to_plot = []\n",
        "\n",
        "for dataset in datasets:\n",
        "    for nc in numchunks_order:\n",
        "        group = [\n",
        "            name for name in series_to_plot\n",
        "            if name.startswith(dataset.upper())\n",
        "            and (\n",
        "                (\"NoChunks\" in name and nc == 1) or\n",
        "                (f\"{nc}Chunks\" in name)\n",
        "            )\n",
        "        ]\n",
        "        subplot_groups_to_plot.append(sorted(group))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e265c69b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# One color per dataset\n",
        "ganepoch_colors = {\n",
        "    20: \"#61ADE3FF\",  # blue\n",
        "    25: \"#7DC378FF\",\n",
        "    30: \"#c96060\",  # red\n",
        "    35: \"#e090da\",\n",
        "    40: \"#f4e26c\"\n",
        "\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a3242d8",
      "metadata": {},
      "outputs": [],
      "source": [
        "series_styles_to_plot = {}\n",
        "\n",
        "for name in series_to_plot:\n",
        "    ganepoch = int(re.search(r\"(\\d+)eGAN\", name).group(1))\n",
        "\n",
        "    color = ganepoch_colors[ganepoch]\n",
        "\n",
        "    series_styles_to_plot[name] = {\n",
        "        \"color\": color,\n",
        "        \"linewidth\": 2.5,\n",
        "        \"alpha\": 0.9,\n",
        "        \"label\": f\"{ganepoch} GAN Epochs\"\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d692cd14",
      "metadata": {},
      "outputs": [],
      "source": [
        "column_titles = []\n",
        "numchunks_order = [1, 10, 50, 100, 200]\n",
        "\n",
        "# Cria títulos para a primeira linha (Top Row)\n",
        "for nc in numchunks_order:\n",
        "    title_text = f\"{nc} Chunks\" if nc > 1 else \"No Chunks (1)\"\n",
        "    column_titles.append(title_text)\n",
        "\n",
        "# Preenche o resto com None para a segunda linha (Bottom Row)\n",
        "# (Assumindo que temos 2 datasets = 2 linhas, total 10 plots)\n",
        "while len(column_titles) < 10:\n",
        "    column_titles.append(None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac9fe90",
      "metadata": {},
      "source": [
        "##### Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1b7c692",
      "metadata": {},
      "source": [
        "###### GAN Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d90ca96",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series=series_to_plot,\n",
        "    subplot_groups = subplot_groups_to_plot,\n",
        "    series_styles=series_styles_to_plot,\n",
        "\n",
        "    subplot_layout=(2,5),\n",
        "    figsize=(20,4),\n",
        "\n",
        "    figure_title=\"c) ClassPartition\",\n",
        "    figure_title_fontsize=14,\n",
        "    figure_title_y=0.95,\n",
        "\n",
        "    title=column_titles,\n",
        "    title_fontsize=13,\n",
        "\n",
        "    row_labels=[\"CIFAR10\", \"MNIST\"],\n",
        "    row_label_fontsize=12,\n",
        "\n",
        "    xlabel=\"Epochs\", \n",
        "    ylabel=\"Accuracy\",\n",
        "    label_fontsize=12,\n",
        "\n",
        "    tick_fontsize=11,\n",
        "    num_xticks=5,\n",
        "    first_step=4,\n",
        "\n",
        "    ylim=[(0, 0.4)] * 5 + [(0.1, 0.97)] * 5,\n",
        "    num_yticks=3,\n",
        "\n",
        "    legend_fontsize=12,\n",
        "    legend_subplot_index=[5,6,7,8,9],\n",
        "    legend_loc=\"lower right\",\n",
        "\n",
        "    legend_kwargs={\n",
        "        \"frameon\": False,\n",
        "        \"bbox_to_anchor\": (1.01, 0.0001),\n",
        "        \"borderpad\": 0.0001    \n",
        "    },\n",
        "\n",
        "    # legend_kwargs={\n",
        "    #     \"ncol\": 2,\n",
        "    #     \"columnspacing\": 0.4,\n",
        "    #     \"handletextpad\": 0.2,\n",
        "    #     \"borderpad\": 0.1,\n",
        "    #     \"bbox_to_anchor\": (1.0114, 0.4),\n",
        "    #     \"handlelength\": 1,\n",
        "    #     \"labelspacing\": 0.3\n",
        "    # }\n",
        "    \n",
        "    save=True,\n",
        "    plot_name=\"../figures/GAN_epochs_Class.pdf\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c33565da",
      "metadata": {},
      "source": [
        "###### Dir01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79a61d06",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series=series_to_plot,\n",
        "    subplot_groups = subplot_groups_to_plot,\n",
        "    series_styles=series_styles_to_plot,\n",
        "    subplot_layout=(2,5),\n",
        "    figsize=(20,10),\n",
        "    legend_fontsize=8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "075e3574",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series={\n",
        "        \"1 Chunk\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks_1_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"1 Chunk 40 gan_epochs\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks1_ganepoch40_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"10 Chunks\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks_10_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"10 Chunks 35 gan_epochs\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks10_ganepoch35_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"50 Chunks\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks_50_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"50 Chunks 30 gan_epochs\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks50_ganepoch30_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"100 Chunks\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks_100_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"200 Chunks\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks_200_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"200 Chunks 20 gan_epochs\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks200_ganepoch20_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "    },\n",
        "\n",
        "    series_styles={\n",
        "        \"1 Chunk\": {\"color\": \"C1\"},\n",
        "        \"1 Chunk 40 gan_epochs\": {\"color\": \"C1\", \"linestyle\": \"--\"},\n",
        "        \"10 Chunks\": {\"color\": \"C2\"},\n",
        "        \"10 Chunks 35 gan_epochs\": {\"color\": \"C2\", \"linestyle\": \"--\"},\n",
        "        \"50 Chunks\": {\"color\": \"C3\"},\n",
        "        \"50 Chunks 30 gan_epochs\": {\"color\": \"C3\", \"linestyle\": \"--\"},\n",
        "        \"100 Chunks\": {\"color\": \"C4\"},\n",
        "        \"200 Chunks\": {\"color\": \"C5\"},\n",
        "        \"200 Chunks 20 gan_epochs\": {\"color\": \"C5\", \"linestyle\": \"--\"},\n",
        "    },\n",
        "    num_xticks=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6c6f6a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series={\n",
        "        \"1 Chunk\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch25_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"1 Chunk 40 gan_epochs\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks_1_ganepoch40_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"10 Chunks\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch25_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"10 Chunks 35 gan_epochs\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks_10_ganepoch35_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"50 Chunks\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch25_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"50 Chunks 30 gan_epochs\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks_50_ganepoch30_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"100 Chunks 20 gan_epochs\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch20_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"100 Chunks\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch25_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"100 Chunks 30 gan_epochs\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks_100_ganepoch30_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"200 Chunks\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch25_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "        \"200 Chunks 20 gan_epochs\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks_200_ganepoch20_fleg_trial1_metrics.json\"][\"net_acc\"],\n",
        "    },\n",
        "    series_styles={\n",
        "        \"1 Chunk\": {\"color\": \"C0\"},\n",
        "        \"1 Chunk 40 gan_epochs\": {\"color\": \"C0\", \"linestyle\": \"--\"},\n",
        "        \"10 Chunks\": {\"color\": \"C1\"},\n",
        "        \"10 Chunks 35 gan_epochs\": {\"color\": \"C1\", \"linestyle\": \"--\"},\n",
        "        \"50 Chunks\": {\"color\": \"C2\"},\n",
        "        \"50 Chunks 30 gan_epochs\": {\"color\": \"C2\", \"linestyle\": \"--\"},\n",
        "        \"100 Chunks\": {\"color\": \"C3\"},\n",
        "        \"100 Chunks 20 gan_epochs\": {\"color\": \"C3\", \"linestyle\": \":\"},\n",
        "        \"100 Chunks 30 gan_epochs\": {\"color\": \"C3\", \"linestyle\": \"--\"},\n",
        "        \"200 Chunks\": {\"color\": \"C5\"},\n",
        "        \"200 Chunks 20 gan_epochs\": {\"color\": \"C5\", \"linestyle\": \":\"},\n",
        "    },\n",
        "    num_xticks=5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef3887ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(\n",
        "    series={\n",
        "        \"NB\": net_acc_all_levels,\n",
        "        \"PyFile\": loaded_dicts[\"mnist_ClassPartitioner_fedavg_numchunks_100_fleg_trial1_metrics.json\"][\"net_acc\"]\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5d66909",
      "metadata": {},
      "source": [
        "## Plot generator images per epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfa906d3",
      "metadata": {
        "id": "bfa906d3"
      },
      "outputs": [],
      "source": [
        "gen = F2U_GAN(condition=True).to(\"cpu\")\n",
        "checkpoint_loaded = torch.load(\"../Experimentos/NB_F2U/GeraFed_4c_01Dir/CIFAR/checkpoint_epoch100.pth\", map_location=\"cpu\")\n",
        "gen.load_state_dict(checkpoint_loaded[\"gen_state_dict\"])\n",
        "generate_plot(gen, \"cpu\", 50, latent_dim=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a95346fb",
      "metadata": {},
      "source": [
        "## Evaluate Times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3be75e38",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# A helper function to add labels on top of the bars\n",
        "def add_labels(rects, ax):\n",
        "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate(f'{height:.2f}', # Format the number to 2 decimal places\n",
        "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                    xytext=(0, 3),  # 3 points vertical offset\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center',\n",
        "                    va='bottom',\n",
        "                    fontsize=14) # Fontsize for the labels on bars\n",
        "\n",
        "# --- Main Code ---\n",
        "\n",
        "# Data for the bar plots\n",
        "labels = ['Classifier Training', 'Image Generation']\n",
        "first_epoch_a = [0.1, 0.02]\n",
        "last_epoch_a = [0.23, 0.3]\n",
        "first_epoch_b = [0.09, 0.03]\n",
        "last_epoch_b = [0.2, 0.42]\n",
        "\n",
        "# Setting the positions of the bars\n",
        "x = np.arange(len(labels))\n",
        "width = 0.35\n",
        "\n",
        "# Creating the figure and subplots\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 12))\n",
        "\n",
        "# --- Font sizes ---\n",
        "title_fontsize = 18\n",
        "label_fontsize = 14\n",
        "tick_fontsize = 12\n",
        "legend_fontsize = 12\n",
        "\n",
        "# --- Barplot a) ---\n",
        "# Capture the bar containers in variables (rects1a, rects2a)\n",
        "rects1a = ax1.bar(x - width/2, first_epoch_a, width, label='First Epoch', color=\"cornflowerblue\")\n",
        "rects2a = ax1.bar(x + width/2, last_epoch_a, width, label='Last Epoch', color=\"sandybrown\")\n",
        "\n",
        "# Add titles and labels\n",
        "ax1.set_ylabel('Time (s)', fontsize=label_fontsize)\n",
        "ax1.set_title('a)', fontsize=title_fontsize)\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(labels, fontsize=label_fontsize)\n",
        "ax1.tick_params(axis='y', labelsize=tick_fontsize)\n",
        "ax1.legend(fontsize=legend_fontsize)\n",
        "\n",
        "# Add the labels on top of the bars\n",
        "add_labels(rects1a, ax1)\n",
        "add_labels(rects2a, ax1)\n",
        "\n",
        "# --- Barplot b) ---\n",
        "# Capture the bar containers in variables (rects1b, rects2b)\n",
        "rects1b = ax2.bar(x - width/2, first_epoch_b, width, label='First Epoch', color=\"cornflowerblue\")\n",
        "rects2b = ax2.bar(x + width/2, last_epoch_b, width, label='Last Epoch', color=\"sandybrown\")\n",
        "\n",
        "# Add titles and labels\n",
        "ax2.set_ylabel('Time (s)', fontsize=label_fontsize)\n",
        "ax2.set_title('b)', fontsize=title_fontsize)\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels(labels, fontsize=label_fontsize)\n",
        "ax2.tick_params(axis='y', labelsize=tick_fontsize)\n",
        "ax2.legend(fontsize=legend_fontsize)\n",
        "\n",
        "# Add the labels on top of the bars\n",
        "add_labels(rects1b, ax2)\n",
        "add_labels(rects2b, ax2)\n",
        "\n",
        "# Adjust y-axis limits to make space for the labels\n",
        "ax1.set_ylim(0, ax1.get_ylim()[1] * 1.1)\n",
        "ax2.set_ylim(0, ax2.get_ylim()[1] * 1.1)\n",
        "\n",
        "# Adjust the layout\n",
        "fig.tight_layout(pad=3.0)\n",
        "\n",
        "# Show the figure\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed4a97a6",
      "metadata": {},
      "source": [
        "## Network Traffic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7df05c2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_weights(net):\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "def get_weights_gen(net):\n",
        "    return [val.cpu().numpy() for key, val in net.state_dict().items() if 'discriminator' in key or 'label' in key]\n",
        "\n",
        "\n",
        "def set_weights(net, parameters):\n",
        "    device = next(net.parameters()).device\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.tensor(v).to(device) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fe472b6",
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier_mnist = Net()\n",
        "classifier_cifar = Net_Cifar()\n",
        "GAN_MNIST = F2U_GAN()\n",
        "GAN_CIFAR = F2U_GAN_CIFAR()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "598a49cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier_mnist_params = get_weights(classifier_mnist)\n",
        "classifier_cifar_params = get_weights(classifier_cifar)\n",
        "GAN_MNIST_disc_params = get_weights_gen(GAN_MNIST)\n",
        "GAN_CIFAR_disc_params = get_weights_gen(GAN_CIFAR)\n",
        "GAN_MNIST_gen_params = [val.cpu().numpy() for key, val in GAN_MNIST.state_dict().items() if 'generator' in key or 'label' in key]\n",
        "GAN_CIFAR_gen_params = [val.cpu().numpy() for key, val in GAN_CIFAR.state_dict().items() if 'generator' in key or 'label' in key]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "016519d1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cumulative step plot for upload/download traffic over rounds.\n",
        "import numpy as np\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b0672bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_model_size_mb(params, divisor=10**6):\n",
        "    buffer = io.BytesIO()\n",
        "    np.savez(buffer, *params)\n",
        "    return len(buffer.getvalue()) / divisor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d83f0db2",
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier_mnist_MB = get_model_size_mb(classifier_mnist_params)\n",
        "classifier_cifar_MB = get_model_size_mb(classifier_cifar_params)\n",
        "disc_mnist_MB       = get_model_size_mb(GAN_MNIST_disc_params)\n",
        "disc_cifar_MB       = get_model_size_mb(GAN_CIFAR_disc_params)\n",
        "gen_mnist_MB        = get_model_size_mb(GAN_MNIST_gen_params)\n",
        "gen_cifar_MB        = get_model_size_mb(GAN_CIFAR_gen_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "015b4532",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "# Per-epoch traffic (GB)\n",
        "upload_per_epoch_gerafed_mnist = (classifier_mnist_MB + disc_mnist_MB)/10 #/1000 pra Giga e x100 por epoch por cause do chunk.\n",
        "download_per_epoch_gerafed_mnist = (classifier_mnist_MB + gen_mnist_MB)/10\n",
        "\n",
        "upload_per_epoch_gerafed_cifar = (classifier_cifar_MB + disc_cifar_MB)/10 #/1000 pra Giga e x100 por epoch por cause do chunk.\n",
        "download_per_epoch_gerafed_cifar = (classifier_cifar_MB + gen_cifar_MB)/10\n",
        "\n",
        "\n",
        "upload_per_epoch_chunkedfedavg_mnist = classifier_mnist_MB/10\n",
        "download_per_epoch_chunkedfedavg_mnist = classifier_mnist_MB/10\n",
        "\n",
        "upload_per_epoch_chunkedfedavg_cifar = classifier_cifar_MB/10\n",
        "download_per_epoch_chunkedfedavg_cifar = classifier_cifar_MB/10\n",
        "\n",
        "\n",
        "# Cumulative arrays with an initial 0 so the plot has horizontal lines before first epoch\n",
        "x = np.arange(0, epochs + 1)  # 0..epochs inclusive\n",
        "\n",
        "cum_upload_gerafed_mnist = np.insert(np.cumsum(np.full(epochs, upload_per_epoch_gerafed_mnist)), 0, 0)\n",
        "cum_download_gerafed_mnist = np.insert(np.cumsum(np.full(epochs, download_per_epoch_gerafed_mnist)), 0, 0)\n",
        "\n",
        "cum_upload_gerafed_cifar = np.insert(np.cumsum(np.full(epochs, upload_per_epoch_gerafed_cifar)), 0, 0)\n",
        "cum_download_gerafed_cifar = np.insert(np.cumsum(np.full(epochs, download_per_epoch_gerafed_cifar)), 0, 0)\n",
        "\n",
        "\n",
        "cum_upload_chunkedfedavg_mnist = np.insert(np.cumsum(np.full(epochs, upload_per_epoch_chunkedfedavg_mnist)), 0, 0)\n",
        "cum_download_chunkedfedavg_mnist = np.insert(np.cumsum(np.full(epochs, download_per_epoch_chunkedfedavg_mnist)), 0, 0)\n",
        "\n",
        "cum_upload_chunkedfedavg_cifar = np.insert(np.cumsum(np.full(epochs, upload_per_epoch_chunkedfedavg_cifar)), 0, 0)\n",
        "cum_download_chunkedfedavg_cifar = np.insert(np.cumsum(np.full(epochs, download_per_epoch_chunkedfedavg_cifar)), 0, 0)\n",
        "\n",
        "\n",
        "cum_upload_and_download_chunkedfedavg_mnist = cum_upload_chunkedfedavg_mnist + cum_download_chunkedfedavg_mnist\n",
        "\n",
        "cum_upload_and_download_chunkedfedavg_cifar = cum_upload_chunkedfedavg_cifar + cum_download_chunkedfedavg_cifar\n",
        "\n",
        "\n",
        "total_upload_GB_gerafed_mnist = cum_upload_gerafed_mnist[-1]\n",
        "total_download_GB_gerafed_mnist = cum_download_gerafed_mnist[-1]\n",
        "\n",
        "total_upload_GB_gerafed_cifar = cum_upload_gerafed_cifar[-1]\n",
        "total_download_GB_gerafed_cifar = cum_download_gerafed_cifar[-1]\n",
        "\n",
        "\n",
        "total_upload_GB_chunkedfedavg_mnist = cum_upload_chunkedfedavg_mnist[-1]\n",
        "total_download_GB_chunkedfedavg_mnist = cum_download_chunkedfedavg_mnist[-1]\n",
        "\n",
        "total_upload_GB_chunkedfedavg_cifar = cum_upload_chunkedfedavg_cifar[-1]\n",
        "total_download_GB_chunkedfedavg_cifar = cum_download_chunkedfedavg_cifar[-1]\n",
        "\n",
        "total_upload_and_download_chunkedfedavg_mnist = total_upload_GB_chunkedfedavg_mnist + total_download_GB_chunkedfedavg_mnist\n",
        "\n",
        "total_upload_and_download_chunkedfedavg_cifar = total_upload_GB_chunkedfedavg_cifar + total_download_GB_chunkedfedavg_cifar\n",
        "\n",
        "\n",
        "# Single step plot (cumulative). Using where='post' so the vertical jumps happen at integer epochs.\n",
        "plt.figure(figsize=(20, 3.8))\n",
        "\n",
        "plt.step(x, cum_upload_gerafed_mnist, where='post', label=\"FedGenIA upload\", color=\"palevioletred\", linestyle='--', linewidth=6)\n",
        "plt.step(x, cum_download_gerafed_mnist, where='post', label=\"FedGenIA download\", color=\"yellowgreen\", linestyle='--', linewidth=6)\n",
        "plt.step(x, cum_upload_and_download_chunkedfedavg_mnist, where='post', label=\"Chunked FedAvg upload and download\", color=\"cornflowerblue\", linewidth=6)\n",
        "\n",
        "# plt.step(x, cum_upload_gerafed_cifar, where='post', label=\"GeraFed upload\", color=\"cornflowerblue\")\n",
        "# plt.step(x, cum_download_gerafed_cifar, where='post', label=\"GeraFed download\", color=\"royalblue\")\n",
        "# plt.step(x, cum_upload_and_download_chunkedfedavg_cifar, where='post', label=\"Chunked FedAvg upload and download\", color=\"sandybrown\")\n",
        "\n",
        "# plt.step(x, cum_download_chunkedfedavg, where='post', label=\"Chunked FedAvg download\", color=\"peru\")\n",
        "plt.xlim(0, epochs)\n",
        "plt.xticks(np.arange(0, epochs+1, max(1, epochs//10)), fontsize=26)\n",
        "plt.yticks(fontsize=26)\n",
        "plt.xlabel(\"Epoch\", fontsize=28)\n",
        "plt.ylabel(\"Cumulative GB\", fontsize=28)\n",
        "plt.grid(True)\n",
        "plt.legend(fontsize=23, loc='lower right', ncol=3, handlelength=2.5, handleheight=1.5, handletextpad=0.7)\n",
        "plt.yscale(\"log\")\n",
        "plt.tight_layout()\n",
        "\n",
        "# Annotate final totals on the right side\n",
        "# plt.annotate(f\"{total_upload_GB_gerafed_mnist:.0f} GB\", xy=(epochs, total_upload_GB_gerafed_mnist),\n",
        "#              xytext=(epochs-5, total_upload_GB_gerafed_mnist + max(1, total_upload_GB_gerafed_mnist*0.02)),\n",
        "#              arrowprops=dict(arrowstyle=\"->\"), fontsize=14, va=\"bottom\")\n",
        "# plt.annotate(f\"{total_download_GB_gerafed_mnist:.0f} GB\", xy=(epochs, total_download_GB_gerafed_mnist),\n",
        "#              xytext=(epochs-5, total_download_GB_gerafed_mnist + max(1, total_download_GB_gerafed_mnist*0.02)),\n",
        "#              arrowprops=dict(arrowstyle=\"->\"), fontsize=12, va=\"bottom\")\n",
        "# plt.annotate(f\"{total_upload_and_download_chunkedfedavg_mnist:.0f} GB\", xy=(epochs, total_upload_and_download_chunkedfedavg_mnist),\n",
        "#              xytext=(epochs-5, total_upload_and_download_chunkedfedavg_mnist + max(1, total_upload_and_download_chunkedfedavg_mnist*0.02)),\n",
        "#              arrowprops=dict(arrowstyle=\"->\"), fontsize=9, va=\"bottom\")\n",
        "\n",
        "# plt.annotate(f\"{total_upload_GB_gerafed_cifar:.0f} GB\", xy=(epochs, total_upload_GB_gerafed_cifar),\n",
        "#              xytext=(epochs-5, total_upload_GB_gerafed_cifar + max(1, total_upload_GB_gerafed_cifar*0.02)),\n",
        "#              arrowprops=dict(arrowstyle=\"->\"), fontsize=9, va=\"bottom\")\n",
        "# plt.annotate(f\"{total_download_GB_gerafed_cifar:.0f} GB\", xy=(epochs, total_download_GB_gerafed_cifar),\n",
        "#              xytext=(epochs-5, total_download_GB_gerafed_cifar + max(1, total_download_GB_gerafed_cifar*0.02)),\n",
        "#              arrowprops=dict(arrowstyle=\"->\"), fontsize=9, va=\"bottom\")\n",
        "# plt.annotate(f\"{total_upload_and_download_chunkedfedavg_cifar:.0f} GB\", xy=(epochs, total_upload_and_download_chunkedfedavg_cifar),\n",
        "#              xytext=(epochs-5, total_upload_and_download_chunkedfedavg_cifar + max(1, total_upload_and_download_chunkedfedavg_cifar*0.02)),\n",
        "#              arrowprops=dict(arrowstyle=\"->\"), fontsize=9, va=\"bottom\")\n",
        "\n",
        "plt.savefig(\"../../../DML-ICC/Figures/network_traffic.pdf\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d66fca29",
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir(\"../figures/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b605738",
      "metadata": {},
      "source": [
        "## Number of Synthetic Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e65e16b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f302686",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate x (epoch) values from 0 to 100\n",
        "epochs = np.arange(0, 101)\n",
        "\n",
        "# Calculate y values for each epoch\n",
        "y_values = [int(13 * (math.exp(0.01*epoch) - 1) / (math.exp(0.01*50) - 1) * 10) for epoch in epochs]\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(12, 2))\n",
        "plt.plot(epochs, y_values, color='cornflowerblue', linewidth=5)\n",
        "plt.xlabel(\"Epoch\", fontsize=18)\n",
        "plt.ylabel(\"|S|\", fontsize=18)\n",
        "plt.xticks(fontsize=16, ticks=np.linspace(0,100,5))\n",
        "plt.yticks(fontsize=16, ticks=[0, 88, 175, 267, 350])\n",
        "plt.xlim(0, 100)\n",
        "plt.ylim(0, 350)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeeddbca",
      "metadata": {
        "id": "aeeddbca"
      },
      "source": [
        "# Compara treino de classificador em dados reais, sintéticos e misturados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c400df8",
      "metadata": {
        "id": "6c400df8"
      },
      "outputs": [],
      "source": [
        "nets = [Net().to(device) for _ in range(num_partitions)]\n",
        "optims = [torch.optim.SGD(net.parameters(), lr=0.01) for net in nets]\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2117f9e5",
      "metadata": {
        "id": "2117f9e5"
      },
      "outputs": [],
      "source": [
        "for i, (net, optim) in enumerate(zip(nets, optims)):\n",
        "    net.train()\n",
        "    for epoch in range(50):\n",
        "        for data in trainloaders[i]:\n",
        "            inputs, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "            optim.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optim.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7ad2d72",
      "metadata": {
        "id": "c7ad2d72"
      },
      "outputs": [],
      "source": [
        "testpartition = fds.load_split(\"test\")\n",
        "testpartition = testpartition.with_transform(apply_transforms)\n",
        "testloader = DataLoader(testpartition, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abfbb983",
      "metadata": {
        "id": "abfbb983"
      },
      "outputs": [],
      "source": [
        "accuracies = []\n",
        "for net in nets:\n",
        "    correct, loss = 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "    accuracy = correct / len(testloader.dataset)\n",
        "    accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eedc9b7",
      "metadata": {
        "id": "0eedc9b7"
      },
      "outputs": [],
      "source": [
        "accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea7a7b0",
      "metadata": {
        "id": "5ea7a7b0"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "num_samples = 1000\n",
        "latent_dim = 128\n",
        "\n",
        "# gen = F2U_GAN()\n",
        "# gen.load_state_dict(torch.load(\"gen_round50.pt\", map_location=torch.device('cpu')))\n",
        "\n",
        "# Create the dataset and dataloader\n",
        "generated_dataset = GeneratedDataset(generator=gen.to(\"cpu\"), num_samples=num_samples, latent_dim=latent_dim, num_classes=10, device=\"cpu\")\n",
        "generated_dataloader = DataLoader(generated_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bc9f7fe",
      "metadata": {
        "id": "3bc9f7fe"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import ConcatDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99e1cbfd",
      "metadata": {
        "id": "99e1cbfd"
      },
      "outputs": [],
      "source": [
        "combined_dataloaders = []\n",
        "for train_partition in train_partitions:\n",
        "    # Ensure the partition is transformed\n",
        "    cmb_ds = ConcatDataset([train_partition, generated_dataset])\n",
        "    combined_dataloaders.append(DataLoader(cmb_ds, batch_size=batch_size, shuffle=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85df355d",
      "metadata": {
        "id": "85df355d"
      },
      "outputs": [],
      "source": [
        "nets = [Net().to(device) for _ in range(num_partitions)]\n",
        "optims = [torch.optim.Adam(net.parameters(), lr=0.01) for net in nets]\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ea13f13",
      "metadata": {
        "id": "9ea13f13"
      },
      "outputs": [],
      "source": [
        "for i, (net, optim) in enumerate(zip(nets, optims)):\n",
        "    net.train()\n",
        "    for epoch in range(50):\n",
        "        for data in combined_dataloaders[i]:\n",
        "            inputs, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "            optim.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optim.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9818e23a",
      "metadata": {
        "id": "9818e23a"
      },
      "outputs": [],
      "source": [
        "accuracies = []\n",
        "for net in nets:\n",
        "    correct, loss = 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "    accuracy = correct / len(testloader.dataset)\n",
        "    accuracies.append(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2b2cb6d",
      "metadata": {
        "id": "c2b2cb6d"
      },
      "outputs": [],
      "source": [
        "accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff260823",
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Definindo x e N\n",
        "x = list(range(1, 101))\n",
        "den = math.exp(0.01 * 50) - 1\n",
        "N = [int(13 * (math.exp(0.01 * (xi - 1)) - 1) / den) * 1000 for xi in x]\n",
        "y = [390*xi for xi in x]\n",
        "\n",
        "# Plot\n",
        "plt.figure()\n",
        "plt.plot(x, N)\n",
        "plt.plot(x, y)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"N\")\n",
        "plt.title(\"Plot de N = int(13 * (exp(0.01*(x-1)) - 1)/(exp(0.5) - 1)) * 1000\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "6d8c276e",
        "314c3604"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gerafed",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
