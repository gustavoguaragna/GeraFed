{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flwr_datasets.partitioner import DirichletPartitioner\n",
    "from flwr_datasets import FederatedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_partitions = 4\n",
    "alpha_dir = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioner = DirichletPartitioner(\n",
    "    num_partitions=num_partitions,\n",
    "    partition_by=\"label\",\n",
    "    alpha=alpha_dir,\n",
    "    min_partition_size=0,\n",
    "    self_balancing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds = FederatedDataset(\n",
    "    dataset=\"mnist\",\n",
    "    partitioners={\"train\": partitioner}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_partitions = [fds.load_partition(i, split=\"train\") for i in range(num_partitions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rodar proxima celula somente se quiser testar com dataset reduzido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = [int(len(train_partition)/10) for train_partition in train_partitions]\n",
    "train_partitions = [train_partition.select(range(n)) for train_partition, n in zip(train_partitions, num_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ToTensor, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_transforms = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "def apply_transforms(batch):\n",
    "    batch[\"image\"] = [pytorch_transforms(img) for img in batch[\"image\"]]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_partitions = [train_partition.with_transform(apply_transforms) for train_partition in train_partitions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "trainloaders = [DataLoader(train_partition, batch_size=batch_size, shuffle=True) for train_partition in train_partitions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch as torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGAN(nn.Module):\n",
    "    def __init__(self, dataset=\"mnist\", img_size=28, latent_dim=100):\n",
    "        super(CGAN, self).__init__()\n",
    "        if dataset == \"mnist\":\n",
    "            self.classes = 10\n",
    "            self.channels = 1\n",
    "        self.img_size = img_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
    "        self.label_embedding = nn.Embedding(self.classes, self.classes)\n",
    "        self.adv_loss = nn.BCELoss()\n",
    "\n",
    "\n",
    "        self.generator = nn.Sequential(\n",
    "            *self._create_layer_gen(self.latent_dim + self.classes, 128, False),\n",
    "            *self._create_layer_gen(128, 256),\n",
    "            *self._create_layer_gen(256, 512),\n",
    "            *self._create_layer_gen(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(self.img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.discriminator = nn.Sequential(\n",
    "            *self._create_layer_disc(self.classes + int(np.prod(self.img_shape)), 1024, False, True),\n",
    "            *self._create_layer_disc(1024, 512, True, True),\n",
    "            *self._create_layer_disc(512, 256, True, True),\n",
    "            *self._create_layer_disc(256, 128, False, False),\n",
    "            *self._create_layer_disc(128, 1, False, False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def _create_layer_gen(self, size_in, size_out, normalize=True):\n",
    "        layers = [nn.Linear(size_in, size_out)]\n",
    "        if normalize:\n",
    "            layers.append(nn.BatchNorm1d(size_out))\n",
    "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        return layers\n",
    "\n",
    "    def _create_layer_disc(self, size_in, size_out, drop_out=True, act_func=True):\n",
    "        layers = [nn.Linear(size_in, size_out)]\n",
    "        if drop_out:\n",
    "            layers.append(nn.Dropout(0.4))\n",
    "        if act_func:\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "        return layers\n",
    "\n",
    "    def forward(self, input, labels):\n",
    "        if input.dim() == 2:\n",
    "            z = torch.cat((self.label_embedding(labels), input), -1)\n",
    "            x = self.generator(z)\n",
    "            x = x.view(x.size(0), *self.img_shape) #Em\n",
    "            return x\n",
    "        elif input.dim() == 4:\n",
    "            x = torch.cat((input.view(input.size(0), -1), self.label_embedding(labels)), -1)\n",
    "            return self.discriminator(x)\n",
    "\n",
    "    def loss(self, output, label):\n",
    "        return self.adv_loss(output, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [CGAN() for i in range(num_partitions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_Ds = [\n",
    "    torch.optim.Adam(model.discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "    for model in models\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plot(net, device, round_number, client_id = None, examples_per_class: int=5, classes: int=10, latent_dim: int=100, server: bool=False):\n",
    "    \"\"\"Gera plot de imagens de cada classe\"\"\"\n",
    "    if server:\n",
    "        import matplotlib\n",
    "        matplotlib.use(\"Agg\")\n",
    "        import matplotlib.pyplot as plt\n",
    "    else:\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "    net_type = type(net).__name__\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    batch_size = examples_per_class * classes\n",
    "\n",
    "    latent_vectors = torch.randn(batch_size, latent_dim, device=device)\n",
    "    labels = torch.tensor([i for i in range(classes) for _ in range(examples_per_class)], device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if net_type == \"Generator\":\n",
    "            labels_one_hot = torch.nn.functional.one_hot(labels, 10).float().to(device)\n",
    "            generated_images = net(torch.cat([latent_vectors, labels_one_hot], dim=1))\n",
    "        else:\n",
    "            generated_images = net(latent_vectors, labels).cpu()\n",
    "\n",
    "    # Criar uma figura com 10 linhas e 5 colunas de subplots\n",
    "    fig, axes = plt.subplots(classes, examples_per_class, figsize=(5, 9))\n",
    "\n",
    "    # Adiciona título no topo da figura\n",
    "    if client_id:\n",
    "        fig.text(0.5, 0.98, f\"Round: {round_number} | Client: {client_id}\", ha=\"center\", fontsize=12)\n",
    "    else:\n",
    "        fig.text(0.5, 0.98, f\"Round: {round_number}\", ha=\"center\", fontsize=12)\n",
    "\n",
    "    # Exibir as imagens nos subplots\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(generated_images[i, 0, :, :], cmap='gray')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    # Ajustar o layout antes de calcular as posições\n",
    "    plt.tight_layout(rect=[0.05, 0, 1, 0.96])\n",
    "\n",
    "    # Reduzir espaço entre colunas\n",
    "    # plt.subplots_adjust(wspace=0.05)\n",
    "\n",
    "    # Adicionar os rótulos das classes corretamente alinhados\n",
    "    fig.canvas.draw()  # Atualiza a renderização para obter posições corretas\n",
    "    for row in range(classes):\n",
    "        # Obter posição do subplot em coordenadas da figura\n",
    "        bbox = axes[row, 0].get_window_extent(fig.canvas.get_renderer())\n",
    "        pos = fig.transFigure.inverted().transform([(bbox.x0, bbox.y0), (bbox.x1, bbox.y1)])\n",
    "        center_y = (pos[0, 1] + pos[1, 1]) / 2  # Centro exato da linha\n",
    "\n",
    "        # Adicionar o rótulo\n",
    "        fig.text(0.04, center_y, str(row), va='center', fontsize=12, color='black')\n",
    "\n",
    "    fig.savefig(f\"mnist_CGAN_r{round_number}_f2a.png\")\n",
    "    plt.close(fig)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = CGAN().to(device)\n",
    "optim_G = torch.optim.Adam(gen.generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "\n",
    "# scheduler_D = torch.optim.lr_scheduler.StepLR(optim_D, step_size=5, gamma=0.9)\n",
    "# scheduler_G = torch.optim.lr_scheduler.StepLR(optim_G, step_size=5, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flwr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mflwr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstrategy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maggregate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m aggregate_inplace\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mflwr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FitRes, Status, Code, ndarrays_to_parameters\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OrderedDict\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flwr'"
     ]
    }
   ],
   "source": [
    "from flwr.server.strategy.aggregate import aggregate_inplace\n",
    "from flwr.common import FitRes, Status, Code, ndarrays_to_parameters\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GeneratedDataset(Dataset):\n",
    "    def __init__(self, generator, num_samples, latent_dim, num_classes, device):\n",
    "        self.generator = generator\n",
    "        self.num_samples = num_samples\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.device = device\n",
    "        self.model = type(self.generator).__name__\n",
    "        self.images, self.labels = self.generate_data()\n",
    "        self.classes = [i for i in range(self.num_classes)]\n",
    "\n",
    "\n",
    "    def generate_data(self):\n",
    "        self.generator.eval()\n",
    "        labels = torch.tensor([i for i in range(self.num_classes) for _ in range(self.num_samples // self.num_classes)], device=self.device)\n",
    "        if self.model == 'Generator':\n",
    "            labels_one_hot = F.one_hot(labels, self.num_classes).float().to(self.device) #\n",
    "        z = torch.randn(self.num_samples, self.latent_dim, device=self.device)\n",
    "        with torch.no_grad():\n",
    "            if self.model == 'Generator':\n",
    "                gen_imgs = self.generator(torch.cat([z, labels_one_hot], dim=1))\n",
    "            elif self.model == 'CGAN' or self.model==\"F2U_GAN\":\n",
    "                gen_imgs = self.generator(z, labels)\n",
    "\n",
    "        return gen_imgs.cpu(), labels.cpu()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 2\n",
    "epochs = 2\n",
    "latent_dim = 100\n",
    "accuracies = []\n",
    "g_losses_e = [[] for _ in range(num_partitions)]\n",
    "d_losses_e = [[] for _ in range(num_partitions)]\n",
    "g_losses_b = [[] for _ in range(num_partitions)]\n",
    "d_losses_b = [[] for _ in range(num_partitions)]\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "global_net = CGAN().to(device)\n",
    "\n",
    "round_bar = tqdm(range(rounds), desc=\"Rodadas\", leave=True, position=0)\n",
    "\n",
    "for round in round_bar:\n",
    "    \n",
    "    print(f\"\\n🔸 Round {round+1}/{rounds}\")\n",
    "\n",
    "    acc = 0\n",
    "\n",
    "    params = []\n",
    "    results = []\n",
    "\n",
    "    client_bar = tqdm(enumerate(zip(models, trainloaders, g_losses_e, d_losses_e, g_losses_b, d_losses_b)), desc=\"Clientes\", leave=False, position=1)\n",
    "    \n",
    "    for i, (model, trainloader, g_loss_e, d_loss_e, g_loss_b, d_loss_b) in client_bar:\n",
    "        print(f\"\\n🔹 Client {i+1}/{num_partitions}\")\n",
    "        model.load_state_dict(global_net.state_dict(), strict=True)\n",
    "        model.to(device) # move model to GPU if available\n",
    "        model.train() # set model to training mode\n",
    "        optim_G = torch.optim.Adam(model.generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "        optim_D = torch.optim.Adam(model.discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
    "\n",
    "        epoch_bar = tqdm(range(epochs), desc=\"Epocas locais\", leave=False, position=2)\n",
    "\n",
    "        for epoch in epoch_bar:\n",
    "\n",
    "            print(f\"\\n🔹 Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "            for batch in trainloader:\n",
    "                print(f\"\\n🔸 Batch {trainloader.batch_sampler.sampler.indices[0]}/{len(trainloader)}\")\n",
    "                images = batch[\"image\"].to(device)\n",
    "                labels = batch[\"label\"].to(device)\n",
    "\n",
    "                batch_size = images.size(0)\n",
    "                if batch_size == 1:\n",
    "                    print(f\"Batch size is 1, skipping...\")\n",
    "                    continue\n",
    "                real_ident = torch.full((batch_size, 1), 1., device=device)\n",
    "                fake_ident = torch.full((batch_size, 1), 0., device=device)\n",
    "\n",
    "                # Train Discriminator\n",
    "                optim_D.zero_grad()\n",
    "\n",
    "                # Real images\n",
    "                y_real = model(images, labels)\n",
    "                d_real_loss = model.loss(y_real, real_ident)\n",
    "\n",
    "                # Fake images\n",
    "                z_noise = torch.randn(batch_size, latent_dim, device=device)\n",
    "                x_fake_labels = torch.randint(0, 10, (batch_size,), device=device)\n",
    "                y_fake_d = model(x_fake.detach(), x_fake_labels)\n",
    "                d_fake_loss = model.loss(y_fake_d, fake_ident)\n",
    "\n",
    "                #Loss calculation\n",
    "                d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "                d_loss.backward()\n",
    "                optim_D.step()\n",
    "                \n",
    "                # Train Generator\n",
    "                optim_G.zero_grad()\n",
    "                \n",
    "                z_noise = torch.randn(batch_size, latent_dim, device=device)\n",
    "                x_fake_labels = torch.randint(0, 10, (batch_size,), device=device)\n",
    "\n",
    "                x_fake = model(z_noise, x_fake_labels)\n",
    "\n",
    "                y_fake_g = model(x_fake, x_fake_labels)\n",
    "\n",
    "                g_loss = model.loss(y_fake_g, real_ident)\n",
    "                g_loss.backward()\n",
    "                optim_G.step()\n",
    "\n",
    "                g_loss_b.append(g_loss.item())\n",
    "                d_loss_b.append(d_loss.item())\n",
    "            \n",
    "            g_loss_e.append(np.mean(g_loss_b[epoch*len(trainloader):(epoch+1)*len(trainloader)]))\n",
    "            d_loss_e.append(np.mean(d_loss_b[epoch*len(trainloader):(epoch+1)*len(trainloader)]))\n",
    "\n",
    "\n",
    "            #epoch_bar.set_postfix_str(f\"Client {models.index(model)+1}/{num_partitions}\")\n",
    "        params.append(ndarrays_to_parameters([val.cpu().numpy() for _, val in model.state_dict().items()]))\n",
    "        results.append((i, FitRes(status=Status(code=Code.OK, message=\"Success\"), parameters=params[i], num_examples=len(trainloader.dataset), metrics={})))\n",
    "\n",
    "    # Agrega modelos\n",
    "\n",
    "    aggregated_ndarrays = aggregate_inplace(results)\n",
    "  \n",
    "    params_dict = zip(global_net.state_dict().keys(), aggregated_ndarrays)\n",
    "    state_dict = OrderedDict({k: torch.tensor(v).to(device) for k, v in params_dict})\n",
    "    global_net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    figura = generate_plot(net=global_net.generator, device=\"cpu\", round_number=round, latent_dim=128)\n",
    "\n",
    "    # Create the dataset and dataloader\n",
    "    generated_dataset = GeneratedDataset(generator=global_net.generator, num_samples=num_samples, latent_dim=latent_dim, num_classes=10, device=\"cpu\")\n",
    "    generated_dataloader = DataLoader(generated_dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "\n",
    "    net = Net()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "    net.train()\n",
    "    for epoch in range(5):\n",
    "        for data in trainloader:\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    correct, loss = 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in testloader:\n",
    "            images = batch[0]\n",
    "            labels = batch[1]\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "    accuracy = correct / len(testloader.dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
