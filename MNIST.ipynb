{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bewK05okXn9u"
      },
      "source": [
        "## Treinamento modelo classificador e geradora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Vda6HdlXn90"
      },
      "source": [
        "### Centralizado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcekFyKmXn90"
      },
      "source": [
        "#### Importacoes, carregamento dos dados, definicao da rede classificadora e treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yQq3sXpTXn92"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2HQ8Sih1Xn_c"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E7ZYEUmkXn_h"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "P3JP3W75Xn_i"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(16*4*4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16*4*4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mVt9PtdGXn_j"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gxtofuOWXn_m"
      },
      "outputs": [],
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Load the training and test datasets\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "trainset_reduzido = torch.utils.data.random_split(trainset, [1000, len(trainset) - 1000])[0]\n",
        "# Create data loaders\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "trainloader_reduzido = DataLoader(trainset_reduzido, batch_size=BATCH_SIZE, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QISJ5_duXn_n"
      },
      "source": [
        "##### Salvando imagens MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ON7L-wrUXn_o"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpOrcDK2Xn_o"
      },
      "outputs": [],
      "source": [
        "# Function to save a random sample of images\n",
        "def save_random_samples(dataset, num_samples=10, folder='Imagens Testes/mnist_samples', balanced=False, classes=None):\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "\n",
        "    if classes is None:\n",
        "        classes = [int(c.split()[0]) for c in dataset.classes]  # Use all classes if none are specified\n",
        "\n",
        "    if balanced:\n",
        "        # Get the number of classes\n",
        "        num_classes = len(classes)\n",
        "        samples_per_class = -(-num_samples // num_classes)  # Round up division\n",
        "        indices = []\n",
        "        class_counts = {i: 0 for i in classes}\n",
        "\n",
        "        # Shuffle the dataset\n",
        "        shuffled_indices = list(range(len(dataset)))\n",
        "        random.shuffle(shuffled_indices)\n",
        "\n",
        "        for idx in shuffled_indices:\n",
        "            img = dataset[idx][0]\n",
        "            label = int(dataset[idx][1])\n",
        "            if label in classes and class_counts[label] < samples_per_class:\n",
        "                indices.append(idx)\n",
        "                class_counts[label] += 1\n",
        "            if len(indices) >= num_samples:\n",
        "                break\n",
        "    else:\n",
        "        indices = []\n",
        "        while len(indices) < num_samples:\n",
        "            idx = random.randint(0, len(dataset) - 1)\n",
        "            if int(dataset[idx][1]) in classes:\n",
        "                indices.append(idx)\n",
        "    for i, idx in enumerate(indices):\n",
        "        img, label = dataset[idx]\n",
        "        img = (img * 0.5 + 0.5) * 255  # Denormalize the image\n",
        "        img = img.byte().numpy().transpose(1, 2, 0).squeeze()  # Convert to numpy array\n",
        "        img = Image.fromarray(img)\n",
        "        img.save(os.path.join(folder, f'mnist_sample_{i}_label_{label}.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoanL3q-Xn_p"
      },
      "outputs": [],
      "source": [
        "save_random_samples(trainset, num_samples=2048, balanced=True, classes=[], folder=\"Imagens Testes/mnist_samples_{i}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTkej1xYXn_p"
      },
      "source": [
        "#### Definicao da GAN e funcoes de treino e teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "j9zuYSTUXn_p"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yihGlxjjXn_p"
      },
      "outputs": [],
      "source": [
        "class CGAN(nn.Module):\n",
        "    def __init__(self, dataset=\"mnist\", img_size=28, latent_dim=100):\n",
        "        super(CGAN, self).__init__()\n",
        "        if dataset == \"mnist\":\n",
        "            self.classes = 10\n",
        "            self.channels = 1\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes)\n",
        "        self.adv_loss = torch.nn.BCELoss()\n",
        "\n",
        "\n",
        "        self.generator = nn.Sequential(\n",
        "            *self._create_layer_gen(self.latent_dim + self.classes, 128, False),\n",
        "            *self._create_layer_gen(128, 256),\n",
        "            *self._create_layer_gen(256, 512),\n",
        "            *self._create_layer_gen(512, 1024),\n",
        "            nn.Linear(1024, int(np.prod(self.img_shape))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.discriminator = nn.Sequential(\n",
        "            *self._create_layer_disc(self.classes + int(np.prod(self.img_shape)), 1024, False, True),\n",
        "            *self._create_layer_disc(1024, 512, True, True),\n",
        "            *self._create_layer_disc(512, 256, True, True),\n",
        "            *self._create_layer_disc(256, 128, False, False),\n",
        "            *self._create_layer_disc(128, 1, False, False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def _create_layer_gen(self, size_in, size_out, normalize=True):\n",
        "        layers = [nn.Linear(size_in, size_out)]\n",
        "        if normalize:\n",
        "            layers.append(nn.BatchNorm1d(size_out))\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return layers\n",
        "\n",
        "    def _create_layer_disc(self, size_in, size_out, drop_out=True, act_func=True):\n",
        "        layers = [nn.Linear(size_in, size_out)]\n",
        "        if drop_out:\n",
        "            layers.append(nn.Dropout(0.4))\n",
        "        if act_func:\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return layers\n",
        "\n",
        "    def forward(self, input, labels):\n",
        "        if input.dim() == 2:\n",
        "            z = torch.cat((self.label_embedding(labels), input), -1)\n",
        "            x = self.generator(z)\n",
        "            x = x.view(x.size(0), *self.img_shape) #Em\n",
        "            return x\n",
        "        elif input.dim() == 4:\n",
        "            x = torch.cat((input.view(input.size(0), -1), self.label_embedding(labels)), -1)\n",
        "            return self.discriminator(x)\n",
        "\n",
        "    def loss(self, output, label):\n",
        "        return self.adv_loss(output, label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUPN43l4Xn_r"
      },
      "source": [
        "##### WGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXzJElIeXn_w"
      },
      "outputs": [],
      "source": [
        "# Configurações\n",
        "LATENT_DIM = 128\n",
        "LEARNING_RATE = 0.0002\n",
        "BETA1 = 0.5\n",
        "BETA2 = 0.9\n",
        "GP_SCALE = 10\n",
        "NUM_CHANNELS = 1\n",
        "NUM_CLASSES = 10\n",
        "EPOCHS = 50\n",
        "# Camada de Convolução para o Discriminador\n",
        "def conv_block(in_channels, out_channels, kernel_size=5, stride=2, padding=2, use_bn=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)]\n",
        "    if use_bn:\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\n",
        "    layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# Discriminador\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            conv_block(NUM_CHANNELS + NUM_CLASSES, 64, use_bn=False),\n",
        "            conv_block(64, 128, use_bn=True),\n",
        "            conv_block(128, 256, use_bn=True),\n",
        "            conv_block(256, 512, use_bn=True),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 2 * 2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Camada de upsample para o Gerador\n",
        "def upsample_block(in_channels, out_channels, kernel_size=3, stride=1, padding=1, use_bn=True):\n",
        "    layers = [\n",
        "        nn.Upsample(scale_factor=2),\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
        "        nn.BatchNorm2d(out_channels) if use_bn else nn.Identity(),\n",
        "        nn.LeakyReLU(0.2, inplace=True)\n",
        "    ]\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# Gerador\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=128):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim + NUM_CLASSES, 4 * 4 * 256),\n",
        "            nn.BatchNorm1d(4 * 4 * 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Unflatten(1, (256, 4, 4)),\n",
        "            upsample_block(256, 128),\n",
        "            upsample_block(128, 64),\n",
        "            upsample_block(64, 32),\n",
        "            nn.Conv2d(32, NUM_CHANNELS, kernel_size=5, stride=1, padding=0),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fPY0beuXoBV"
      },
      "source": [
        "#### Geração de Dados Sintéticos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c-l-6raaXoBW"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class GeneratedDataset(Dataset):\n",
        "    def __init__(self, generator, num_samples, latent_dim, num_classes, device):\n",
        "        self.generator = generator\n",
        "        self.num_samples = num_samples\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.device = device\n",
        "        self.model = type(self.generator).__name__\n",
        "        self.images, self.labels = self.generate_data()\n",
        "        self.classes = [i for i in range(self.num_classes)]\n",
        "\n",
        "\n",
        "    def generate_data(self):\n",
        "        self.generator.eval()\n",
        "        labels = torch.tensor([i for i in range(self.num_classes) for _ in range(self.num_samples // self.num_classes)], device=self.device)\n",
        "        if self.model == 'Generator':\n",
        "            labels_one_hot = F.one_hot(labels, self.num_classes).float().to(self.device) #\n",
        "        z = torch.randn(self.num_samples, self.latent_dim, device=self.device)\n",
        "        with torch.no_grad():\n",
        "            if self.model == 'Generator':\n",
        "                gen_imgs = self.generator(torch.cat([z, labels_one_hot], dim=1))\n",
        "            elif self.model == 'CGAN' or self.model==\"F2U_GAN\":\n",
        "                gen_imgs = self.generator(z, labels)\n",
        "\n",
        "        return gen_imgs.cpu(), labels.cpu()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.labels[idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abkIz6SPXoBW"
      },
      "source": [
        "##### WGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cEGGzm2XoBW"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "num_samples = 10000\n",
        "latent_dim = 128\n",
        "\n",
        "G = Generator(latent_dim=128).to(\"cpu\")\n",
        "G.load_state_dict(torch.load(\"wgan_43e_128b_0.0002lr.pth\", map_location=torch.device('cpu'))[\"generator\"])\n",
        "\n",
        "# Create the dataset and dataloader\n",
        "generated_dataset = GeneratedDataset(generator=G, num_samples=num_samples, latent_dim=latent_dim, num_classes=10, device=\"cpu\")\n",
        "generated_dataloader = DataLoader(generated_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGU4X9cFXoBX"
      },
      "source": [
        "##### CGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dR8Apn1XXoBX"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "num_samples = 60000\n",
        "latent_dim = 100\n",
        "\n",
        "gan = CGAN()\n",
        "gan.load_state_dict(torch.load(\"CGAN_50epochs.pth\", map_location=torch.device('cpu')))\n",
        "\n",
        "# Create the dataset and dataloader\n",
        "generated_dataset = GeneratedDataset(generator=gan, num_samples=num_samples, latent_dim=latent_dim, num_classes=10, device=\"cpu\")\n",
        "generated_dataloader = DataLoader(generated_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HtLisLGfvm6z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "6086a998-d447-443c-ab81-b5abd11ef958"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'GeneratedDataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8e3da252685a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create the dataset and dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgenerated_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGeneratedDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mgenerated_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GeneratedDataset' is not defined"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "num_samples = 6000\n",
        "latent_dim = 128\n",
        "\n",
        "# Create the dataset and dataloader\n",
        "generated_dataset = GeneratedDataset(generator=net.to(\"cpu\"), num_samples=num_samples, latent_dim=latent_dim, num_classes=10, device=\"cpu\")\n",
        "generated_dataloader = DataLoader(generated_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9407SFvSXoBX"
      },
      "source": [
        "Salvando imagens CGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zEozbb5XoBX"
      },
      "outputs": [],
      "source": [
        "save_random_samples(generated_dataset, num_samples=2048, balanced=True, folder='Imagens Testes/cgan_samples_niid_0.7acc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjkOWq3mXoBY"
      },
      "outputs": [],
      "source": [
        "net = Net()\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
        "net.train()\n",
        "for epoch in range(5):\n",
        "    for data in generated_dataloader:\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSQ_NYB_XoBY"
      },
      "outputs": [],
      "source": [
        "correct, loss = 0, 0.0\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in testloader:\n",
        "        images = batch[0]\n",
        "        labels = batch[1]\n",
        "        outputs = net(images)\n",
        "        loss += criterion(outputs, labels).item()\n",
        "        correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "accuracy = correct / len(testloader.dataset)\n",
        "loss = loss / len(testloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Er2sYOlBXoBY",
        "outputId": "e0267b7a-a546-4d4b-c7e6-c892d6f9cfee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.1387"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFt_vSA_XoBY"
      },
      "source": [
        "#### Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class F2U_GAN(nn.Module):\n",
        "    def __init__(self, dataset=\"mnist\", img_size=28, latent_dim=128):\n",
        "        super(F2U_GAN, self).__init__()\n",
        "        if dataset == \"mnist\":\n",
        "            self.classes = 10\n",
        "            self.channels = 1\n",
        "        else:\n",
        "            raise NotImplementedError(\"Only MNIST is supported\")\n",
        "\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes)\n",
        "        self.adv_loss = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "        # Generator (unchanged)\n",
        "        self.generator = nn.Sequential(\n",
        "            nn.Linear(self.latent_dim + self.classes, 256 * 7 * 7),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Unflatten(1, (256, 7, 7)),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64, self.channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        # Discriminator (corrected)\n",
        "        self.discriminator = nn.Sequential(\n",
        "        # Camada 1: 28x28 -> 14x14\n",
        "        nn.utils.spectral_norm(nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Camada 2: 14x14 -> 7x7\n",
        "        nn.utils.spectral_norm(nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Camada 3: 7x7 -> 3x3\n",
        "        nn.utils.spectral_norm(nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Camada 4: 3x3 -> 1x1\n",
        "        nn.utils.spectral_norm(nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=0)),  # Padding 0 aqui!\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        # Achata e concatena com as labels\n",
        "        nn.Flatten(),\n",
        "        nn.utils.spectral_norm(nn.Linear(256 * 1 * 1 + 10, 1))  # 256 (features) + 10 (labels) = 266\n",
        "        )\n",
        "\n",
        "    def forward(self, input, labels):\n",
        "        if input.dim() == 2:\n",
        "            # Generator forward pass (unchanged)\n",
        "            embedded_labels = self.label_embedding(labels)\n",
        "            gen_input = torch.cat((input, embedded_labels), dim=1)\n",
        "            x = self.generator(gen_input)\n",
        "            return x.view(-1, *self.img_shape)\n",
        "\n",
        "        elif input.dim() == 4:\n",
        "            # Discriminator forward pass\n",
        "            features = self.discriminator[0:-1](input)  # Output shape: (batch, 256*1*1)\n",
        "            embedded_labels = self.label_embedding(labels)\n",
        "            combined = torch.cat((features, embedded_labels), dim=1)\n",
        "            return self.discriminator[-1](combined)\n",
        "\n",
        "    def loss(self, output, label):\n",
        "        return self.adv_loss(output, label)"
      ],
      "metadata": {
        "id": "tzsbaI8GwOgB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gen(net, trainloader, epochs, lr, device, latent_dim=128):\n",
        "    net.to(device)\n",
        "    optim_G = torch.optim.Adam(net.generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "    optim_D = torch.optim.Adam(net.discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "    g_losses = []\n",
        "    d_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for batch_idx, (images, labels) in enumerate(trainloader):  # Direct unpacking\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            batch_size = images.size(0)\n",
        "            real_ident = torch.full((batch_size, 1), 1.0, device=device)\n",
        "            fake_ident = torch.full((batch_size, 1), 0.0, device=device)\n",
        "\n",
        "            # Train Discriminator\n",
        "            net.zero_grad()\n",
        "            # Real images\n",
        "            y_real = net(images, labels)\n",
        "            d_real_loss = net.loss(y_real, real_ident)\n",
        "            # Fake images\n",
        "            z_noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "            x_fake_labels = torch.randint(0, 10, (batch_size,), device=device)\n",
        "            x_fake = net(z_noise, x_fake_labels).detach()\n",
        "            y_fake_d = net(x_fake, x_fake_labels)\n",
        "            d_fake_loss = net.loss(y_fake_d, fake_ident)\n",
        "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "            d_loss.backward()\n",
        "            optim_D.step()\n",
        "\n",
        "            # Train Generator\n",
        "            net.zero_grad()\n",
        "            z_noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "            x_fake_labels = torch.randint(0, 10, (batch_size,), device=device)\n",
        "            x_fake = net(z_noise, x_fake_labels)\n",
        "            y_fake_g = net(x_fake, x_fake_labels)\n",
        "            g_loss = net.loss(y_fake_g, real_ident)\n",
        "            g_loss.backward()\n",
        "            optim_G.step()\n",
        "\n",
        "            # Log losses\n",
        "            g_losses.append(g_loss.item())\n",
        "            d_losses.append(d_loss.item())\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f'Epoch {epoch} [{batch_idx}/{len(trainloader)}] Loss_D: {d_loss.item():.4f} Loss_G: {g_loss.item():.4f}')\n",
        "\n",
        "    return g_losses, d_losses"
      ],
      "metadata": {
        "id": "mYikf7STyatT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5jW6ykXwXoBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5d2cfb7-e353-4dac-98c3-e37cfdd9d366",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 [0/469] Loss_D: 0.7181 Loss_G: 0.6932\n",
            "Epoch 0 [100/469] Loss_D: 0.0063 Loss_G: 5.1557\n",
            "Epoch 0 [200/469] Loss_D: 0.0025 Loss_G: 6.1760\n",
            "Epoch 0 [300/469] Loss_D: 0.0023 Loss_G: 6.3671\n",
            "Epoch 0 [400/469] Loss_D: 0.0069 Loss_G: 5.1070\n",
            "Epoch 1 [0/469] Loss_D: 0.0031 Loss_G: 6.2588\n",
            "Epoch 1 [100/469] Loss_D: 0.0013 Loss_G: 6.8984\n",
            "Epoch 1 [200/469] Loss_D: 0.0008 Loss_G: 7.4234\n",
            "Epoch 1 [300/469] Loss_D: 0.0005 Loss_G: 7.8841\n",
            "Epoch 1 [400/469] Loss_D: 0.0004 Loss_G: 8.0675\n",
            "Epoch 2 [0/469] Loss_D: 0.0004 Loss_G: 7.7968\n",
            "Epoch 2 [100/469] Loss_D: 0.7860 Loss_G: 0.7490\n",
            "Epoch 2 [200/469] Loss_D: 0.4582 Loss_G: 1.3498\n",
            "Epoch 2 [300/469] Loss_D: 0.4698 Loss_G: 1.2759\n",
            "Epoch 2 [400/469] Loss_D: 0.5945 Loss_G: 0.9642\n",
            "Epoch 3 [0/469] Loss_D: 0.7098 Loss_G: 0.7743\n",
            "Epoch 3 [100/469] Loss_D: 0.6718 Loss_G: 0.8441\n",
            "Epoch 3 [200/469] Loss_D: 0.5835 Loss_G: 0.8562\n",
            "Epoch 3 [300/469] Loss_D: 0.5720 Loss_G: 0.9292\n",
            "Epoch 3 [400/469] Loss_D: 0.6273 Loss_G: 0.9294\n",
            "Epoch 4 [0/469] Loss_D: 0.6203 Loss_G: 0.8154\n",
            "Epoch 4 [100/469] Loss_D: 0.5857 Loss_G: 0.7810\n",
            "Epoch 4 [200/469] Loss_D: 0.5946 Loss_G: 0.9239\n",
            "Epoch 4 [300/469] Loss_D: 0.5860 Loss_G: 0.9076\n",
            "Epoch 4 [400/469] Loss_D: 0.6080 Loss_G: 0.6582\n",
            "Epoch 5 [0/469] Loss_D: 0.6089 Loss_G: 0.8075\n",
            "Epoch 5 [100/469] Loss_D: 0.6237 Loss_G: 0.6521\n",
            "Epoch 5 [200/469] Loss_D: 0.6033 Loss_G: 0.9113\n",
            "Epoch 5 [300/469] Loss_D: 0.6138 Loss_G: 0.7837\n",
            "Epoch 5 [400/469] Loss_D: 0.6133 Loss_G: 0.8611\n",
            "Epoch 6 [0/469] Loss_D: 0.6362 Loss_G: 1.0028\n",
            "Epoch 6 [100/469] Loss_D: 0.6227 Loss_G: 0.8690\n",
            "Epoch 6 [200/469] Loss_D: 0.6190 Loss_G: 0.7934\n",
            "Epoch 6 [300/469] Loss_D: 0.6250 Loss_G: 0.7414\n",
            "Epoch 6 [400/469] Loss_D: 0.6160 Loss_G: 0.7453\n",
            "Epoch 7 [0/469] Loss_D: 0.6200 Loss_G: 0.7150\n",
            "Epoch 7 [100/469] Loss_D: 0.6215 Loss_G: 0.7927\n",
            "Epoch 7 [200/469] Loss_D: 0.6095 Loss_G: 0.9031\n",
            "Epoch 7 [300/469] Loss_D: 0.5824 Loss_G: 0.8596\n",
            "Epoch 7 [400/469] Loss_D: 0.6147 Loss_G: 0.9158\n",
            "Epoch 8 [0/469] Loss_D: 0.6304 Loss_G: 0.7971\n",
            "Epoch 8 [100/469] Loss_D: 0.6183 Loss_G: 0.8255\n",
            "Epoch 8 [200/469] Loss_D: 0.6252 Loss_G: 0.7880\n",
            "Epoch 8 [300/469] Loss_D: 0.6532 Loss_G: 0.7771\n",
            "Epoch 8 [400/469] Loss_D: 0.6625 Loss_G: 0.7552\n",
            "Epoch 9 [0/469] Loss_D: 0.6569 Loss_G: 0.8012\n",
            "Epoch 9 [100/469] Loss_D: 0.6300 Loss_G: 0.7572\n",
            "Epoch 9 [200/469] Loss_D: 0.6150 Loss_G: 0.8880\n",
            "Epoch 9 [300/469] Loss_D: 0.6096 Loss_G: 0.9209\n",
            "Epoch 9 [400/469] Loss_D: 0.6358 Loss_G: 0.7389\n",
            "Epoch 10 [0/469] Loss_D: 0.6361 Loss_G: 0.7637\n",
            "Epoch 10 [100/469] Loss_D: 0.6081 Loss_G: 0.8505\n",
            "Epoch 10 [200/469] Loss_D: 0.6340 Loss_G: 1.0227\n",
            "Epoch 10 [300/469] Loss_D: 0.6314 Loss_G: 0.8015\n",
            "Epoch 10 [400/469] Loss_D: 0.6351 Loss_G: 0.8682\n",
            "Epoch 11 [0/469] Loss_D: 0.6490 Loss_G: 0.8335\n",
            "Epoch 11 [100/469] Loss_D: 0.6386 Loss_G: 0.7864\n",
            "Epoch 11 [200/469] Loss_D: 0.6261 Loss_G: 0.7888\n",
            "Epoch 11 [300/469] Loss_D: 0.6496 Loss_G: 0.7743\n",
            "Epoch 11 [400/469] Loss_D: 0.6251 Loss_G: 0.8194\n",
            "Epoch 12 [0/469] Loss_D: 0.6524 Loss_G: 0.7560\n",
            "Epoch 12 [100/469] Loss_D: 0.6375 Loss_G: 0.8123\n",
            "Epoch 12 [200/469] Loss_D: 0.6614 Loss_G: 0.7388\n",
            "Epoch 12 [300/469] Loss_D: 0.6520 Loss_G: 0.8359\n",
            "Epoch 12 [400/469] Loss_D: 0.6129 Loss_G: 0.8392\n",
            "Epoch 13 [0/469] Loss_D: 0.6463 Loss_G: 0.6834\n",
            "Epoch 13 [100/469] Loss_D: 0.6621 Loss_G: 0.7608\n",
            "Epoch 13 [200/469] Loss_D: 0.6113 Loss_G: 0.7597\n",
            "Epoch 13 [300/469] Loss_D: 0.6420 Loss_G: 0.8760\n",
            "Epoch 13 [400/469] Loss_D: 0.6322 Loss_G: 0.9273\n",
            "Epoch 14 [0/469] Loss_D: 0.6536 Loss_G: 0.8119\n",
            "Epoch 14 [100/469] Loss_D: 0.6209 Loss_G: 0.8004\n",
            "Epoch 14 [200/469] Loss_D: 0.6651 Loss_G: 0.7076\n",
            "Epoch 14 [300/469] Loss_D: 0.6719 Loss_G: 0.8778\n",
            "Epoch 14 [400/469] Loss_D: 0.6644 Loss_G: 0.7445\n",
            "Epoch 15 [0/469] Loss_D: 0.6555 Loss_G: 0.8129\n",
            "Epoch 15 [100/469] Loss_D: 0.6520 Loss_G: 0.7504\n",
            "Epoch 15 [200/469] Loss_D: 0.6603 Loss_G: 0.7726\n",
            "Epoch 15 [300/469] Loss_D: 0.6800 Loss_G: 0.7751\n",
            "Epoch 15 [400/469] Loss_D: 0.6401 Loss_G: 0.7026\n",
            "Epoch 16 [0/469] Loss_D: 0.6671 Loss_G: 0.7801\n",
            "Epoch 16 [100/469] Loss_D: 0.6604 Loss_G: 0.7830\n",
            "Epoch 16 [200/469] Loss_D: 0.6592 Loss_G: 0.6717\n",
            "Epoch 16 [300/469] Loss_D: 0.6480 Loss_G: 0.7526\n",
            "Epoch 16 [400/469] Loss_D: 0.6447 Loss_G: 0.8229\n",
            "Epoch 17 [0/469] Loss_D: 0.6621 Loss_G: 0.7265\n",
            "Epoch 17 [100/469] Loss_D: 0.6972 Loss_G: 0.8192\n",
            "Epoch 17 [200/469] Loss_D: 0.6821 Loss_G: 0.7151\n",
            "Epoch 17 [300/469] Loss_D: 0.6582 Loss_G: 0.7373\n",
            "Epoch 17 [400/469] Loss_D: 0.6514 Loss_G: 0.6888\n",
            "Epoch 18 [0/469] Loss_D: 0.6469 Loss_G: 0.7391\n",
            "Epoch 18 [100/469] Loss_D: 0.6427 Loss_G: 0.7760\n",
            "Epoch 18 [200/469] Loss_D: 0.6786 Loss_G: 0.6420\n",
            "Epoch 18 [300/469] Loss_D: 0.6704 Loss_G: 0.7647\n",
            "Epoch 18 [400/469] Loss_D: 0.6617 Loss_G: 0.7567\n",
            "Epoch 19 [0/469] Loss_D: 0.6521 Loss_G: 0.7180\n",
            "Epoch 19 [100/469] Loss_D: 0.6728 Loss_G: 0.7616\n",
            "Epoch 19 [200/469] Loss_D: 0.7001 Loss_G: 0.8250\n",
            "Epoch 19 [300/469] Loss_D: 0.6727 Loss_G: 0.7683\n",
            "Epoch 19 [400/469] Loss_D: 0.6645 Loss_G: 0.7175\n",
            "Epoch 20 [0/469] Loss_D: 0.6621 Loss_G: 0.8005\n",
            "Epoch 20 [100/469] Loss_D: 0.6556 Loss_G: 0.7427\n",
            "Epoch 20 [200/469] Loss_D: 0.6729 Loss_G: 0.7888\n",
            "Epoch 20 [300/469] Loss_D: 0.6725 Loss_G: 0.7173\n",
            "Epoch 20 [400/469] Loss_D: 0.6599 Loss_G: 0.7739\n",
            "Epoch 21 [0/469] Loss_D: 0.6442 Loss_G: 0.8266\n",
            "Epoch 21 [100/469] Loss_D: 0.6702 Loss_G: 0.6724\n",
            "Epoch 21 [200/469] Loss_D: 0.6726 Loss_G: 0.7502\n",
            "Epoch 21 [300/469] Loss_D: 0.6607 Loss_G: 0.6890\n",
            "Epoch 21 [400/469] Loss_D: 0.6691 Loss_G: 0.7447\n",
            "Epoch 22 [0/469] Loss_D: 0.6672 Loss_G: 0.7385\n",
            "Epoch 22 [100/469] Loss_D: 0.6738 Loss_G: 0.7256\n",
            "Epoch 22 [200/469] Loss_D: 0.6665 Loss_G: 0.6826\n",
            "Epoch 22 [300/469] Loss_D: 0.6816 Loss_G: 0.7425\n",
            "Epoch 22 [400/469] Loss_D: 0.6779 Loss_G: 0.7765\n",
            "Epoch 23 [0/469] Loss_D: 0.6563 Loss_G: 0.7332\n",
            "Epoch 23 [100/469] Loss_D: 0.6631 Loss_G: 0.7671\n",
            "Epoch 23 [200/469] Loss_D: 0.6613 Loss_G: 0.8049\n",
            "Epoch 23 [300/469] Loss_D: 0.6741 Loss_G: 0.7296\n",
            "Epoch 23 [400/469] Loss_D: 0.6626 Loss_G: 0.7681\n",
            "Epoch 24 [0/469] Loss_D: 0.6740 Loss_G: 0.7613\n",
            "Epoch 24 [100/469] Loss_D: 0.7102 Loss_G: 0.7674\n",
            "Epoch 24 [200/469] Loss_D: 0.6567 Loss_G: 0.7503\n",
            "Epoch 24 [300/469] Loss_D: 0.6778 Loss_G: 0.7437\n",
            "Epoch 24 [400/469] Loss_D: 0.6683 Loss_G: 0.7248\n",
            "Epoch 25 [0/469] Loss_D: 0.6795 Loss_G: 0.7601\n",
            "Epoch 25 [100/469] Loss_D: 0.6541 Loss_G: 0.7683\n",
            "Epoch 25 [200/469] Loss_D: 0.6888 Loss_G: 0.7284\n",
            "Epoch 25 [300/469] Loss_D: 0.6725 Loss_G: 0.7241\n",
            "Epoch 25 [400/469] Loss_D: 0.6731 Loss_G: 0.7191\n",
            "Epoch 26 [0/469] Loss_D: 0.6876 Loss_G: 0.7415\n",
            "Epoch 26 [100/469] Loss_D: 0.6543 Loss_G: 0.7516\n",
            "Epoch 26 [200/469] Loss_D: 0.6699 Loss_G: 0.7664\n",
            "Epoch 26 [300/469] Loss_D: 0.6824 Loss_G: 0.7169\n",
            "Epoch 26 [400/469] Loss_D: 0.6578 Loss_G: 0.7209\n",
            "Epoch 27 [0/469] Loss_D: 0.6671 Loss_G: 0.8248\n",
            "Epoch 27 [100/469] Loss_D: 0.6752 Loss_G: 0.7161\n",
            "Epoch 27 [200/469] Loss_D: 0.6588 Loss_G: 0.7902\n",
            "Epoch 27 [300/469] Loss_D: 0.6484 Loss_G: 0.7606\n",
            "Epoch 27 [400/469] Loss_D: 0.6721 Loss_G: 0.7585\n",
            "Epoch 28 [0/469] Loss_D: 0.6804 Loss_G: 0.7327\n",
            "Epoch 28 [100/469] Loss_D: 0.6682 Loss_G: 0.7110\n",
            "Epoch 28 [200/469] Loss_D: 0.6725 Loss_G: 0.7308\n",
            "Epoch 28 [300/469] Loss_D: 0.6873 Loss_G: 0.7327\n",
            "Epoch 28 [400/469] Loss_D: 0.6663 Loss_G: 0.7241\n",
            "Epoch 29 [0/469] Loss_D: 0.6798 Loss_G: 0.6940\n",
            "Epoch 29 [100/469] Loss_D: 0.6703 Loss_G: 0.7122\n",
            "Epoch 29 [200/469] Loss_D: 0.6861 Loss_G: 0.7115\n",
            "Epoch 29 [300/469] Loss_D: 0.6655 Loss_G: 0.7692\n",
            "Epoch 29 [400/469] Loss_D: 0.6753 Loss_G: 0.7372\n",
            "Epoch 30 [0/469] Loss_D: 0.6692 Loss_G: 0.7237\n",
            "Epoch 30 [100/469] Loss_D: 0.6819 Loss_G: 0.7438\n",
            "Epoch 30 [200/469] Loss_D: 0.6889 Loss_G: 0.7536\n",
            "Epoch 30 [300/469] Loss_D: 0.6753 Loss_G: 0.7189\n",
            "Epoch 30 [400/469] Loss_D: 0.6911 Loss_G: 0.7374\n",
            "Epoch 31 [0/469] Loss_D: 0.6740 Loss_G: 0.7298\n",
            "Epoch 31 [100/469] Loss_D: 0.6872 Loss_G: 0.7608\n",
            "Epoch 31 [200/469] Loss_D: 0.6729 Loss_G: 0.7511\n",
            "Epoch 31 [300/469] Loss_D: 0.6671 Loss_G: 0.7261\n",
            "Epoch 31 [400/469] Loss_D: 0.6726 Loss_G: 0.7342\n",
            "Epoch 32 [0/469] Loss_D: 0.6772 Loss_G: 0.7451\n",
            "Epoch 32 [100/469] Loss_D: 0.6655 Loss_G: 0.7524\n",
            "Epoch 32 [200/469] Loss_D: 0.6814 Loss_G: 0.7472\n",
            "Epoch 32 [300/469] Loss_D: 0.6771 Loss_G: 0.7649\n",
            "Epoch 32 [400/469] Loss_D: 0.6708 Loss_G: 0.7136\n",
            "Epoch 33 [0/469] Loss_D: 0.6644 Loss_G: 0.7465\n",
            "Epoch 33 [100/469] Loss_D: 0.6793 Loss_G: 0.7813\n",
            "Epoch 33 [200/469] Loss_D: 0.6757 Loss_G: 0.7545\n",
            "Epoch 33 [300/469] Loss_D: 0.6792 Loss_G: 0.6861\n",
            "Epoch 33 [400/469] Loss_D: 0.6837 Loss_G: 0.7278\n",
            "Epoch 34 [0/469] Loss_D: 0.6681 Loss_G: 0.7482\n",
            "Epoch 34 [100/469] Loss_D: 0.6646 Loss_G: 0.7549\n",
            "Epoch 34 [200/469] Loss_D: 0.6662 Loss_G: 0.7435\n",
            "Epoch 34 [300/469] Loss_D: 0.6750 Loss_G: 0.7285\n",
            "Epoch 34 [400/469] Loss_D: 0.6714 Loss_G: 0.7185\n",
            "Epoch 35 [0/469] Loss_D: 0.6644 Loss_G: 0.7497\n",
            "Epoch 35 [100/469] Loss_D: 0.6849 Loss_G: 0.7016\n",
            "Epoch 35 [200/469] Loss_D: 0.6771 Loss_G: 0.6967\n",
            "Epoch 35 [300/469] Loss_D: 0.6720 Loss_G: 0.7644\n",
            "Epoch 35 [400/469] Loss_D: 0.6736 Loss_G: 0.7385\n",
            "Epoch 36 [0/469] Loss_D: 0.6735 Loss_G: 0.7579\n",
            "Epoch 36 [100/469] Loss_D: 0.6838 Loss_G: 0.7555\n",
            "Epoch 36 [200/469] Loss_D: 0.6767 Loss_G: 0.7413\n",
            "Epoch 36 [300/469] Loss_D: 0.6688 Loss_G: 0.7193\n",
            "Epoch 36 [400/469] Loss_D: 0.6846 Loss_G: 0.7336\n",
            "Epoch 37 [0/469] Loss_D: 0.6777 Loss_G: 0.7194\n",
            "Epoch 37 [100/469] Loss_D: 0.6923 Loss_G: 0.6921\n",
            "Epoch 37 [200/469] Loss_D: 0.6804 Loss_G: 0.7091\n",
            "Epoch 37 [300/469] Loss_D: 0.6892 Loss_G: 0.6937\n",
            "Epoch 37 [400/469] Loss_D: 0.6883 Loss_G: 0.7042\n",
            "Epoch 38 [0/469] Loss_D: 0.6797 Loss_G: 0.7346\n",
            "Epoch 38 [100/469] Loss_D: 0.6613 Loss_G: 0.7465\n",
            "Epoch 38 [200/469] Loss_D: 0.6780 Loss_G: 0.6995\n",
            "Epoch 38 [300/469] Loss_D: 0.6738 Loss_G: 0.7487\n",
            "Epoch 38 [400/469] Loss_D: 0.6755 Loss_G: 0.7407\n",
            "Epoch 39 [0/469] Loss_D: 0.6773 Loss_G: 0.6975\n",
            "Epoch 39 [100/469] Loss_D: 0.6992 Loss_G: 0.7254\n",
            "Epoch 39 [200/469] Loss_D: 0.6863 Loss_G: 0.7398\n",
            "Epoch 39 [300/469] Loss_D: 0.6696 Loss_G: 0.7476\n",
            "Epoch 39 [400/469] Loss_D: 0.6765 Loss_G: 0.7487\n",
            "Epoch 40 [0/469] Loss_D: 0.6679 Loss_G: 0.7226\n",
            "Epoch 40 [100/469] Loss_D: 0.6785 Loss_G: 0.7322\n",
            "Epoch 40 [200/469] Loss_D: 0.6863 Loss_G: 0.6865\n",
            "Epoch 40 [300/469] Loss_D: 0.6816 Loss_G: 0.7241\n",
            "Epoch 40 [400/469] Loss_D: 0.6727 Loss_G: 0.7015\n",
            "Epoch 41 [0/469] Loss_D: 0.6797 Loss_G: 0.7170\n",
            "Epoch 41 [100/469] Loss_D: 0.6774 Loss_G: 0.7367\n",
            "Epoch 41 [200/469] Loss_D: 0.6953 Loss_G: 0.6550\n",
            "Epoch 41 [300/469] Loss_D: 0.6677 Loss_G: 0.7387\n",
            "Epoch 41 [400/469] Loss_D: 0.6922 Loss_G: 0.6729\n",
            "Epoch 42 [0/469] Loss_D: 0.6771 Loss_G: 0.7327\n",
            "Epoch 42 [100/469] Loss_D: 0.6782 Loss_G: 0.7256\n",
            "Epoch 42 [200/469] Loss_D: 0.6895 Loss_G: 0.6948\n",
            "Epoch 42 [300/469] Loss_D: 0.6828 Loss_G: 0.7080\n",
            "Epoch 42 [400/469] Loss_D: 0.6719 Loss_G: 0.7398\n",
            "Epoch 43 [0/469] Loss_D: 0.6811 Loss_G: 0.7675\n",
            "Epoch 43 [100/469] Loss_D: 0.6878 Loss_G: 0.7784\n",
            "Epoch 43 [200/469] Loss_D: 0.6800 Loss_G: 0.7330\n",
            "Epoch 43 [300/469] Loss_D: 0.6845 Loss_G: 0.6633\n",
            "Epoch 43 [400/469] Loss_D: 0.6775 Loss_G: 0.7247\n",
            "Epoch 44 [0/469] Loss_D: 0.6892 Loss_G: 0.7534\n",
            "Epoch 44 [100/469] Loss_D: 0.6955 Loss_G: 0.6559\n",
            "Epoch 44 [200/469] Loss_D: 0.6942 Loss_G: 0.7015\n",
            "Epoch 44 [300/469] Loss_D: 0.6685 Loss_G: 0.7013\n",
            "Epoch 44 [400/469] Loss_D: 0.6816 Loss_G: 0.6884\n",
            "Epoch 45 [0/469] Loss_D: 0.6847 Loss_G: 0.6953\n",
            "Epoch 45 [100/469] Loss_D: 0.6821 Loss_G: 0.7573\n",
            "Epoch 45 [200/469] Loss_D: 0.6771 Loss_G: 0.7203\n",
            "Epoch 45 [300/469] Loss_D: 0.7029 Loss_G: 0.7046\n",
            "Epoch 45 [400/469] Loss_D: 0.6762 Loss_G: 0.7011\n",
            "Epoch 46 [0/469] Loss_D: 0.6745 Loss_G: 0.7330\n",
            "Epoch 46 [100/469] Loss_D: 0.6705 Loss_G: 0.7269\n",
            "Epoch 46 [200/469] Loss_D: 0.6932 Loss_G: 0.7041\n",
            "Epoch 46 [300/469] Loss_D: 0.6744 Loss_G: 0.7112\n",
            "Epoch 46 [400/469] Loss_D: 0.6710 Loss_G: 0.7144\n",
            "Epoch 47 [0/469] Loss_D: 0.6734 Loss_G: 0.7339\n",
            "Epoch 47 [100/469] Loss_D: 0.6808 Loss_G: 0.7035\n",
            "Epoch 47 [200/469] Loss_D: 0.6807 Loss_G: 0.7391\n",
            "Epoch 47 [300/469] Loss_D: 0.6797 Loss_G: 0.7220\n",
            "Epoch 47 [400/469] Loss_D: 0.6807 Loss_G: 0.7390\n",
            "Epoch 48 [0/469] Loss_D: 0.6744 Loss_G: 0.6990\n",
            "Epoch 48 [100/469] Loss_D: 0.6813 Loss_G: 0.6969\n",
            "Epoch 48 [200/469] Loss_D: 0.6790 Loss_G: 0.7594\n",
            "Epoch 48 [300/469] Loss_D: 0.6751 Loss_G: 0.7237\n",
            "Epoch 48 [400/469] Loss_D: 0.6739 Loss_G: 0.7072\n",
            "Epoch 49 [0/469] Loss_D: 0.6756 Loss_G: 0.7351\n",
            "Epoch 49 [100/469] Loss_D: 0.6879 Loss_G: 0.6916\n",
            "Epoch 49 [200/469] Loss_D: 0.7007 Loss_G: 0.7589\n",
            "Epoch 49 [300/469] Loss_D: 0.6867 Loss_G: 0.6963\n",
            "Epoch 49 [400/469] Loss_D: 0.6939 Loss_G: 0.7093\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.6932345628738403,\n",
              "  0.6940631866455078,\n",
              "  0.6970234513282776,\n",
              "  0.6921588182449341,\n",
              "  0.7129023671150208,\n",
              "  0.7367963790893555,\n",
              "  0.7230703830718994,\n",
              "  0.7236500382423401,\n",
              "  0.7391718626022339,\n",
              "  0.8155508637428284,\n",
              "  0.8161193132400513,\n",
              "  0.8467808961868286,\n",
              "  0.9436367154121399,\n",
              "  1.0618613958358765,\n",
              "  1.202244520187378,\n",
              "  1.3445934057235718,\n",
              "  1.5080993175506592,\n",
              "  1.6519203186035156,\n",
              "  1.84756338596344,\n",
              "  2.0632262229919434,\n",
              "  2.2933597564697266,\n",
              "  2.5300352573394775,\n",
              "  2.9487855434417725,\n",
              "  2.9705281257629395,\n",
              "  2.8426804542541504,\n",
              "  2.6452910900115967,\n",
              "  2.8577880859375,\n",
              "  3.234549045562744,\n",
              "  3.5730955600738525,\n",
              "  3.769247531890869,\n",
              "  3.9251537322998047,\n",
              "  4.007890701293945,\n",
              "  4.132706642150879,\n",
              "  4.2082109451293945,\n",
              "  3.8459830284118652,\n",
              "  2.851133108139038,\n",
              "  3.5348143577575684,\n",
              "  3.9909279346466064,\n",
              "  3.9786620140075684,\n",
              "  4.145727157592773,\n",
              "  4.226710319519043,\n",
              "  4.102727890014648,\n",
              "  4.06276273727417,\n",
              "  3.9471304416656494,\n",
              "  3.517674684524536,\n",
              "  3.942707061767578,\n",
              "  4.23388147354126,\n",
              "  4.401651382446289,\n",
              "  4.492425918579102,\n",
              "  4.383926868438721,\n",
              "  4.273608684539795,\n",
              "  4.079308032989502,\n",
              "  2.7326645851135254,\n",
              "  3.9619221687316895,\n",
              "  3.9955430030822754,\n",
              "  3.105095386505127,\n",
              "  3.3566575050354004,\n",
              "  3.5045299530029297,\n",
              "  3.617893934249878,\n",
              "  3.529998779296875,\n",
              "  3.6521410942077637,\n",
              "  3.668198585510254,\n",
              "  3.9988489151000977,\n",
              "  4.309165000915527,\n",
              "  4.511591911315918,\n",
              "  4.635463714599609,\n",
              "  4.689793586730957,\n",
              "  4.745963096618652,\n",
              "  4.822450637817383,\n",
              "  4.7390289306640625,\n",
              "  4.670200347900391,\n",
              "  4.79448938369751,\n",
              "  4.68030309677124,\n",
              "  3.51751446723938,\n",
              "  4.628317832946777,\n",
              "  5.022589206695557,\n",
              "  5.095361709594727,\n",
              "  5.031167984008789,\n",
              "  4.916048526763916,\n",
              "  4.825255393981934,\n",
              "  4.773579120635986,\n",
              "  4.775064468383789,\n",
              "  4.808017730712891,\n",
              "  4.712568283081055,\n",
              "  4.561239719390869,\n",
              "  3.8319902420043945,\n",
              "  4.34125280380249,\n",
              "  4.5704240798950195,\n",
              "  4.190956115722656,\n",
              "  3.701812267303467,\n",
              "  3.8093764781951904,\n",
              "  3.557638645172119,\n",
              "  3.8689334392547607,\n",
              "  4.332521438598633,\n",
              "  4.675537586212158,\n",
              "  4.872964382171631,\n",
              "  4.989577293395996,\n",
              "  5.058019161224365,\n",
              "  5.108309268951416,\n",
              "  5.125799179077148,\n",
              "  5.155735969543457,\n",
              "  5.175102233886719,\n",
              "  5.182003021240234,\n",
              "  5.198963165283203,\n",
              "  5.241432189941406,\n",
              "  4.971522331237793,\n",
              "  4.309427261352539,\n",
              "  4.320262432098389,\n",
              "  4.814133167266846,\n",
              "  4.974416732788086,\n",
              "  5.038789749145508,\n",
              "  4.876391410827637,\n",
              "  4.447683334350586,\n",
              "  4.86030912399292,\n",
              "  5.135042190551758,\n",
              "  5.258857727050781,\n",
              "  5.317997932434082,\n",
              "  5.3017578125,\n",
              "  5.3751935958862305,\n",
              "  5.335330963134766,\n",
              "  5.356157302856445,\n",
              "  5.376513481140137,\n",
              "  5.375951290130615,\n",
              "  5.352541923522949,\n",
              "  5.417381286621094,\n",
              "  5.471778869628906,\n",
              "  5.460122585296631,\n",
              "  5.4760637283325195,\n",
              "  5.429866313934326,\n",
              "  5.4379963874816895,\n",
              "  5.453033447265625,\n",
              "  5.5231781005859375,\n",
              "  5.61440896987915,\n",
              "  5.714967250823975,\n",
              "  5.809174060821533,\n",
              "  5.888888359069824,\n",
              "  5.927906036376953,\n",
              "  5.977505683898926,\n",
              "  5.982845306396484,\n",
              "  6.030350208282471,\n",
              "  6.013774394989014,\n",
              "  6.0048909187316895,\n",
              "  6.012109756469727,\n",
              "  5.958586692810059,\n",
              "  5.930912017822266,\n",
              "  5.936016082763672,\n",
              "  5.931676864624023,\n",
              "  5.9937543869018555,\n",
              "  6.02394962310791,\n",
              "  6.048994064331055,\n",
              "  6.083306312561035,\n",
              "  6.103928089141846,\n",
              "  6.058022499084473,\n",
              "  6.090073108673096,\n",
              "  6.141941070556641,\n",
              "  6.181268215179443,\n",
              "  6.171566963195801,\n",
              "  6.055902004241943,\n",
              "  5.8674211502075195,\n",
              "  5.938872337341309,\n",
              "  5.99913215637207,\n",
              "  6.076704502105713,\n",
              "  6.10682487487793,\n",
              "  6.029284477233887,\n",
              "  5.520102024078369,\n",
              "  5.979622840881348,\n",
              "  6.109692096710205,\n",
              "  5.632183074951172,\n",
              "  5.029831886291504,\n",
              "  4.705112457275391,\n",
              "  4.7568359375,\n",
              "  4.84083890914917,\n",
              "  5.053364276885986,\n",
              "  5.348700523376465,\n",
              "  5.409677505493164,\n",
              "  5.511605739593506,\n",
              "  5.435378074645996,\n",
              "  5.36468505859375,\n",
              "  5.457165718078613,\n",
              "  5.518806457519531,\n",
              "  5.5769124031066895,\n",
              "  5.671835899353027,\n",
              "  5.7254743576049805,\n",
              "  5.762361526489258,\n",
              "  5.831166744232178,\n",
              "  5.894664287567139,\n",
              "  5.873116493225098,\n",
              "  5.829751491546631,\n",
              "  5.8766093254089355,\n",
              "  5.924100875854492,\n",
              "  5.898504734039307,\n",
              "  5.934776306152344,\n",
              "  5.960935592651367,\n",
              "  5.982842922210693,\n",
              "  5.964664459228516,\n",
              "  5.999755859375,\n",
              "  5.968377113342285,\n",
              "  6.0028462409973145,\n",
              "  6.065929412841797,\n",
              "  6.106735706329346,\n",
              "  6.17603874206543,\n",
              "  6.122302055358887,\n",
              "  6.111589431762695,\n",
              "  6.098943710327148,\n",
              "  6.111396789550781,\n",
              "  6.115451335906982,\n",
              "  6.056797504425049,\n",
              "  5.974728584289551,\n",
              "  5.739530086517334,\n",
              "  4.467153072357178,\n",
              "  4.170536994934082,\n",
              "  4.665867805480957,\n",
              "  4.959281921386719,\n",
              "  4.851855278015137,\n",
              "  4.740461826324463,\n",
              "  4.497714996337891,\n",
              "  4.5125603675842285,\n",
              "  4.669001579284668,\n",
              "  4.8498148918151855,\n",
              "  5.083630561828613,\n",
              "  5.250208854675293,\n",
              "  5.312568664550781,\n",
              "  5.312793254852295,\n",
              "  5.259697437286377,\n",
              "  5.2629899978637695,\n",
              "  5.314897060394287,\n",
              "  5.387109756469727,\n",
              "  5.360713958740234,\n",
              "  5.3539557456970215,\n",
              "  5.2857346534729,\n",
              "  5.302974224090576,\n",
              "  5.37435245513916,\n",
              "  5.448237895965576,\n",
              "  5.501396179199219,\n",
              "  5.575133323669434,\n",
              "  5.659400939941406,\n",
              "  5.6464152336120605,\n",
              "  5.714986324310303,\n",
              "  5.785472393035889,\n",
              "  5.851027488708496,\n",
              "  5.919072151184082,\n",
              "  5.9725751876831055,\n",
              "  6.020812511444092,\n",
              "  5.988332748413086,\n",
              "  5.9699387550354,\n",
              "  5.974605560302734,\n",
              "  5.993521690368652,\n",
              "  6.026069641113281,\n",
              "  6.0641632080078125,\n",
              "  6.078526973724365,\n",
              "  6.077366352081299,\n",
              "  6.079174041748047,\n",
              "  6.097017288208008,\n",
              "  6.131161689758301,\n",
              "  6.189846992492676,\n",
              "  6.206533432006836,\n",
              "  6.226718902587891,\n",
              "  6.265293121337891,\n",
              "  6.304521560668945,\n",
              "  6.330930709838867,\n",
              "  6.360580921173096,\n",
              "  6.364356994628906,\n",
              "  6.398194313049316,\n",
              "  6.410999298095703,\n",
              "  6.3976545333862305,\n",
              "  6.41436767578125,\n",
              "  6.414967060089111,\n",
              "  6.434113502502441,\n",
              "  6.446389198303223,\n",
              "  6.444016933441162,\n",
              "  6.417046546936035,\n",
              "  6.181588172912598,\n",
              "  4.822357177734375,\n",
              "  5.369560241699219,\n",
              "  5.618797302246094,\n",
              "  5.013365745544434,\n",
              "  4.5599188804626465,\n",
              "  4.706754684448242,\n",
              "  4.902948379516602,\n",
              "  4.832090377807617,\n",
              "  5.230930328369141,\n",
              "  5.496861457824707,\n",
              "  5.494227409362793,\n",
              "  5.622775077819824,\n",
              "  5.737137794494629,\n",
              "  5.857913970947266,\n",
              "  5.954626083374023,\n",
              "  5.887430667877197,\n",
              "  5.5791778564453125,\n",
              "  5.679948329925537,\n",
              "  5.941194534301758,\n",
              "  6.131742000579834,\n",
              "  6.23411750793457,\n",
              "  6.239613056182861,\n",
              "  6.16776704788208,\n",
              "  6.190568447113037,\n",
              "  6.26590633392334,\n",
              "  6.316429138183594,\n",
              "  6.408319473266602,\n",
              "  6.39016056060791,\n",
              "  6.3670501708984375,\n",
              "  6.312047958374023,\n",
              "  6.330458641052246,\n",
              "  6.302644729614258,\n",
              "  6.33011531829834,\n",
              "  6.348968982696533,\n",
              "  6.20135498046875,\n",
              "  6.090561389923096,\n",
              "  6.211155891418457,\n",
              "  6.319694995880127,\n",
              "  6.44863748550415,\n",
              "  6.481139659881592,\n",
              "  6.469356536865234,\n",
              "  6.50688362121582,\n",
              "  6.487371444702148,\n",
              "  6.499513626098633,\n",
              "  6.458169937133789,\n",
              "  6.434225082397461,\n",
              "  6.334527969360352,\n",
              "  6.217569351196289,\n",
              "  6.227505683898926,\n",
              "  6.184620380401611,\n",
              "  5.893474578857422,\n",
              "  5.863926887512207,\n",
              "  5.938907146453857,\n",
              "  5.942204475402832,\n",
              "  6.000185966491699,\n",
              "  6.056143760681152,\n",
              "  6.106986045837402,\n",
              "  6.147096157073975,\n",
              "  6.211760997772217,\n",
              "  6.255691051483154,\n",
              "  6.288006782531738,\n",
              "  6.305300712585449,\n",
              "  6.282032489776611,\n",
              "  5.6935882568359375,\n",
              "  9.7085599899292,\n",
              "  5.571035385131836,\n",
              "  3.559715986251831,\n",
              "  2.3972008228302,\n",
              "  3.4356517791748047,\n",
              "  4.277077674865723,\n",
              "  4.222370147705078,\n",
              "  3.6921072006225586,\n",
              "  3.736510992050171,\n",
              "  3.567171573638916,\n",
              "  3.502561569213867,\n",
              "  3.5622265338897705,\n",
              "  3.8487815856933594,\n",
              "  4.127790451049805,\n",
              "  4.3868303298950195,\n",
              "  4.46900749206543,\n",
              "  4.436339378356934,\n",
              "  4.363402366638184,\n",
              "  4.247621059417725,\n",
              "  4.313634872436523,\n",
              "  4.3297247886657715,\n",
              "  4.391165733337402,\n",
              "  4.503114700317383,\n",
              "  4.527116775512695,\n",
              "  4.4709296226501465,\n",
              "  4.483508586883545,\n",
              "  4.490667343139648,\n",
              "  4.5487494468688965,\n",
              "  4.611049175262451,\n",
              "  4.695556640625,\n",
              "  4.741705894470215,\n",
              "  4.795544624328613,\n",
              "  4.8438920974731445,\n",
              "  4.846824645996094,\n",
              "  4.890341758728027,\n",
              "  4.89002799987793,\n",
              "  4.890774250030518,\n",
              "  4.933917045593262,\n",
              "  4.955580711364746,\n",
              "  4.968336582183838,\n",
              "  4.953347206115723,\n",
              "  4.947240352630615,\n",
              "  4.880845069885254,\n",
              "  4.8301591873168945,\n",
              "  4.811079978942871,\n",
              "  4.853896617889404,\n",
              "  4.896246433258057,\n",
              "  4.95540189743042,\n",
              "  5.002750873565674,\n",
              "  5.06392765045166,\n",
              "  5.113397598266602,\n",
              "  5.149272918701172,\n",
              "  5.165021896362305,\n",
              "  5.211165904998779,\n",
              "  5.200242042541504,\n",
              "  5.247058391571045,\n",
              "  5.215766906738281,\n",
              "  5.129247665405273,\n",
              "  4.9037556648254395,\n",
              "  4.9088945388793945,\n",
              "  4.924319267272949,\n",
              "  4.921675205230713,\n",
              "  4.98975944519043,\n",
              "  5.063535690307617,\n",
              "  5.1069512367248535,\n",
              "  5.166276931762695,\n",
              "  5.192387580871582,\n",
              "  5.246386528015137,\n",
              "  5.253390312194824,\n",
              "  5.311202049255371,\n",
              "  5.325743198394775,\n",
              "  5.311555862426758,\n",
              "  5.346187591552734,\n",
              "  5.362884521484375,\n",
              "  5.3662190437316895,\n",
              "  5.428359031677246,\n",
              "  5.4658522605896,\n",
              "  5.482580661773682,\n",
              "  5.511551856994629,\n",
              "  5.524564266204834,\n",
              "  5.533088684082031,\n",
              "  5.582614898681641,\n",
              "  5.582332611083984,\n",
              "  5.610943794250488,\n",
              "  5.632668495178223,\n",
              "  5.609767913818359,\n",
              "  5.625999450683594,\n",
              "  5.63808536529541,\n",
              "  5.650524616241455,\n",
              "  5.673308372497559,\n",
              "  5.674560546875,\n",
              "  5.652441501617432,\n",
              "  5.713483810424805,\n",
              "  5.735289096832275,\n",
              "  5.737433433532715,\n",
              "  5.6569342613220215,\n",
              "  5.676812171936035,\n",
              "  5.71068000793457,\n",
              "  5.745800018310547,\n",
              "  5.756641387939453,\n",
              "  5.7967610359191895,\n",
              "  5.791779041290283,\n",
              "  5.818432807922363,\n",
              "  5.870165824890137,\n",
              "  5.884607315063477,\n",
              "  5.877790451049805,\n",
              "  5.837421417236328,\n",
              "  5.876711845397949,\n",
              "  5.861566543579102,\n",
              "  5.9510016441345215,\n",
              "  5.883078098297119,\n",
              "  5.881106376647949,\n",
              "  5.8691182136535645,\n",
              "  5.856435775756836,\n",
              "  5.8235321044921875,\n",
              "  5.798633098602295,\n",
              "  5.836585521697998,\n",
              "  5.888467788696289,\n",
              "  5.932372093200684,\n",
              "  5.938716888427734,\n",
              "  5.9813690185546875,\n",
              "  6.014449596405029,\n",
              "  6.023953437805176,\n",
              "  6.057485580444336,\n",
              "  6.082541465759277,\n",
              "  6.098853588104248,\n",
              "  6.110201835632324,\n",
              "  6.130629062652588,\n",
              "  6.161794662475586,\n",
              "  6.161731243133545,\n",
              "  6.2100653648376465,\n",
              "  6.223029613494873,\n",
              "  6.228250026702881,\n",
              "  6.258783340454102,\n",
              "  6.249017715454102,\n",
              "  6.2838454246521,\n",
              "  6.272995948791504,\n",
              "  6.290193557739258,\n",
              "  6.282866477966309,\n",
              "  6.306277275085449,\n",
              "  6.304980278015137,\n",
              "  6.321169853210449,\n",
              "  6.33282470703125,\n",
              "  6.334125518798828,\n",
              "  6.376631259918213,\n",
              "  6.355925559997559,\n",
              "  6.366675853729248,\n",
              "  6.377683162689209,\n",
              "  6.4023051261901855,\n",
              "  6.412359714508057,\n",
              "  6.430570602416992,\n",
              "  6.419442176818848,\n",
              "  6.42569637298584,\n",
              "  6.441844940185547,\n",
              "  6.431131839752197,\n",
              "  6.425472259521484,\n",
              "  6.427014350891113,\n",
              "  6.46319580078125,\n",
              "  6.452733039855957,\n",
              "  6.488692283630371,\n",
              "  6.470215797424316,\n",
              "  6.481273651123047,\n",
              "  6.441946506500244,\n",
              "  6.300040245056152,\n",
              "  6.174402236938477,\n",
              "  6.158501625061035,\n",
              "  6.201911926269531,\n",
              "  6.223696708679199,\n",
              "  6.244544506072998,\n",
              "  6.289339542388916,\n",
              "  6.293398857116699,\n",
              "  6.308090686798096,\n",
              "  6.333573341369629,\n",
              "  6.343181610107422,\n",
              "  6.3540358543396,\n",
              "  6.3695573806762695,\n",
              "  6.401716232299805,\n",
              "  6.402462482452393,\n",
              "  6.421384811401367,\n",
              "  6.438270092010498,\n",
              "  6.446917533874512,\n",
              "  6.454305648803711,\n",
              "  6.46202278137207,\n",
              "  6.472568988800049,\n",
              "  6.489398956298828,\n",
              "  6.497273921966553,\n",
              "  6.497828483581543,\n",
              "  6.50152587890625,\n",
              "  6.49293327331543,\n",
              "  6.504753112792969,\n",
              "  6.53312873840332,\n",
              "  6.532641410827637,\n",
              "  6.554145336151123,\n",
              "  6.551973342895508,\n",
              "  6.558803558349609,\n",
              "  6.573506832122803,\n",
              "  6.580084800720215,\n",
              "  6.598328590393066,\n",
              "  6.595143795013428,\n",
              "  6.594592094421387,\n",
              "  6.624378204345703,\n",
              "  6.621151447296143,\n",
              "  6.6238203048706055,\n",
              "  6.648015975952148,\n",
              "  6.649321556091309,\n",
              "  6.670420169830322,\n",
              "  6.668768882751465,\n",
              "  6.6796979904174805,\n",
              "  6.686774730682373,\n",
              "  6.694460868835449,\n",
              "  6.6944451332092285,\n",
              "  6.728204727172852,\n",
              "  6.725341320037842,\n",
              "  6.751936912536621,\n",
              "  6.743847846984863,\n",
              "  6.74619197845459,\n",
              "  6.754162788391113,\n",
              "  6.766621112823486,\n",
              "  6.796314239501953,\n",
              "  6.789869785308838,\n",
              "  6.830575466156006,\n",
              "  6.805499076843262,\n",
              "  6.812736511230469,\n",
              "  6.888251304626465,\n",
              "  6.884608268737793,\n",
              "  6.892106533050537,\n",
              "  6.88621187210083,\n",
              "  6.893198013305664,\n",
              "  6.869581699371338,\n",
              "  6.89553689956665,\n",
              "  6.901273727416992,\n",
              "  6.8931708335876465,\n",
              "  6.89393949508667,\n",
              "  6.898446083068848,\n",
              "  6.906905651092529,\n",
              "  6.897453784942627,\n",
              "  6.9143877029418945,\n",
              "  6.904197692871094,\n",
              "  6.9168548583984375,\n",
              "  6.91133451461792,\n",
              "  6.935039520263672,\n",
              "  6.944199562072754,\n",
              "  6.945608615875244,\n",
              "  6.964729309082031,\n",
              "  6.972325325012207,\n",
              "  6.965967178344727,\n",
              "  6.98642110824585,\n",
              "  6.990816116333008,\n",
              "  6.9894185066223145,\n",
              "  6.994109153747559,\n",
              "  6.998802661895752,\n",
              "  7.0197038650512695,\n",
              "  7.020925998687744,\n",
              "  7.01873254776001,\n",
              "  7.02126932144165,\n",
              "  7.031739234924316,\n",
              "  7.040257453918457,\n",
              "  7.01881742477417,\n",
              "  7.025956630706787,\n",
              "  7.0471954345703125,\n",
              "  7.056937217712402,\n",
              "  7.060888767242432,\n",
              "  7.065445899963379,\n",
              "  7.0803728103637695,\n",
              "  7.086280345916748,\n",
              "  7.0734477043151855,\n",
              "  7.103588104248047,\n",
              "  7.094801902770996,\n",
              "  7.1184587478637695,\n",
              "  7.118556022644043,\n",
              "  7.121779441833496,\n",
              "  7.129899024963379,\n",
              "  7.134486675262451,\n",
              "  7.141701698303223,\n",
              "  7.132537364959717,\n",
              "  7.121467590332031,\n",
              "  7.105086326599121,\n",
              "  7.043028354644775,\n",
              "  7.096403121948242,\n",
              "  7.063146114349365,\n",
              "  7.415775299072266,\n",
              "  7.257174968719482,\n",
              "  7.204354763031006,\n",
              "  7.191105842590332,\n",
              "  7.165641784667969,\n",
              "  7.177357196807861,\n",
              "  7.178873062133789,\n",
              "  7.188300609588623,\n",
              "  7.205626487731934,\n",
              "  7.192618370056152,\n",
              "  7.199091911315918,\n",
              "  7.20424222946167,\n",
              "  7.216792106628418,\n",
              "  7.219124794006348,\n",
              "  7.22761344909668,\n",
              "  7.225259304046631,\n",
              "  7.219854831695557,\n",
              "  7.231788635253906,\n",
              "  7.245034217834473,\n",
              "  7.2402167320251465,\n",
              "  7.259891986846924,\n",
              "  7.257506370544434,\n",
              "  7.272333145141602,\n",
              "  7.275491714477539,\n",
              "  7.288700103759766,\n",
              "  7.297332763671875,\n",
              "  7.297334671020508,\n",
              "  7.290274620056152,\n",
              "  7.295567512512207,\n",
              "  7.29740047454834,\n",
              "  7.300754547119141,\n",
              "  7.309206962585449,\n",
              "  7.316938877105713,\n",
              "  7.331146240234375,\n",
              "  7.333836078643799,\n",
              "  7.332804203033447,\n",
              "  7.3300275802612305,\n",
              "  7.342933654785156,\n",
              "  7.344602108001709,\n",
              "  7.376430034637451,\n",
              "  7.376534938812256,\n",
              "  7.362955093383789,\n",
              "  7.377368450164795,\n",
              "  7.378619194030762,\n",
              "  7.38078498840332,\n",
              "  7.401733875274658,\n",
              "  7.384548187255859,\n",
              "  7.40549898147583,\n",
              "  7.417774200439453,\n",
              "  7.408932209014893,\n",
              "  7.405928611755371,\n",
              "  7.416180610656738,\n",
              "  7.399749279022217,\n",
              "  7.423373222351074,\n",
              "  7.407901763916016,\n",
              "  7.408262252807617,\n",
              "  7.407921314239502,\n",
              "  7.437726974487305,\n",
              "  7.422657012939453,\n",
              "  7.41950798034668,\n",
              "  7.429203987121582,\n",
              "  7.41880989074707,\n",
              "  7.4481306076049805,\n",
              "  7.430060386657715,\n",
              "  7.421133041381836,\n",
              "  7.4522504806518555,\n",
              "  7.450848579406738,\n",
              "  7.452281475067139,\n",
              "  7.456451892852783,\n",
              "  7.464931488037109,\n",
              "  7.46933650970459,\n",
              "  7.473599433898926,\n",
              "  7.476114273071289,\n",
              "  7.4830498695373535,\n",
              "  7.4762864112854,\n",
              "  7.480677127838135,\n",
              "  7.478707313537598,\n",
              "  7.488508224487305,\n",
              "  7.485396862030029,\n",
              "  7.475800514221191,\n",
              "  7.498254776000977,\n",
              "  7.490970611572266,\n",
              "  7.5141496658325195,\n",
              "  7.492279052734375,\n",
              "  7.491120338439941,\n",
              "  7.514883041381836,\n",
              "  7.5089263916015625,\n",
              "  7.521751403808594,\n",
              "  7.510829925537109,\n",
              "  7.542445182800293,\n",
              "  7.525589942932129,\n",
              "  7.533851623535156,\n",
              "  7.557626724243164,\n",
              "  7.540156364440918,\n",
              "  7.541882514953613,\n",
              "  7.55790376663208,\n",
              "  7.544223785400391,\n",
              "  7.536923885345459,\n",
              "  7.541547775268555,\n",
              "  7.560569763183594,\n",
              "  7.536810874938965,\n",
              "  7.553038597106934,\n",
              "  7.572846412658691,\n",
              "  7.565717697143555,\n",
              "  7.567168235778809,\n",
              "  7.57265567779541,\n",
              "  7.588369369506836,\n",
              "  7.586423873901367,\n",
              "  7.5695648193359375,\n",
              "  7.59039306640625,\n",
              "  7.591824054718018,\n",
              "  7.591608047485352,\n",
              "  7.589600563049316,\n",
              "  7.605615615844727,\n",
              "  7.613186836242676,\n",
              "  7.636629104614258,\n",
              "  7.634132385253906,\n",
              "  7.645108222961426,\n",
              "  7.648180961608887,\n",
              "  7.641526222229004,\n",
              "  7.658213138580322,\n",
              "  7.656940937042236,\n",
              "  7.637228012084961,\n",
              "  7.659637451171875,\n",
              "  7.6705732345581055,\n",
              "  7.664633750915527,\n",
              "  7.662165641784668,\n",
              "  7.672823429107666,\n",
              "  7.646777153015137,\n",
              "  7.649417877197266,\n",
              "  7.639561653137207,\n",
              "  7.624079704284668,\n",
              "  7.631150722503662,\n",
              "  7.788814544677734,\n",
              "  7.715449810028076,\n",
              "  7.717593193054199,\n",
              "  7.711018085479736,\n",
              "  7.702913761138916,\n",
              "  7.660961151123047,\n",
              "  7.7109527587890625,\n",
              "  7.8955912590026855,\n",
              "  7.907751083374023,\n",
              "  7.761239051818848,\n",
              "  7.762391090393066,\n",
              "  7.740985870361328,\n",
              "  7.7382636070251465,\n",
              "  7.722890853881836,\n",
              "  7.681648254394531,\n",
              "  7.66152286529541,\n",
              "  7.752958297729492,\n",
              "  7.611602783203125,\n",
              "  7.604837417602539,\n",
              "  7.739995002746582,\n",
              "  7.884147644042969,\n",
              "  7.887465000152588,\n",
              "  7.860842704772949,\n",
              "  7.859105110168457,\n",
              "  7.865653038024902,\n",
              "  7.827458381652832,\n",
              "  7.8394775390625,\n",
              "  7.8603668212890625,\n",
              "  7.853636741638184,\n",
              "  7.883993625640869,\n",
              "  7.884743690490723,\n",
              "  7.886302471160889,\n",
              "  7.905268669128418,\n",
              "  7.886054992675781,\n",
              "  7.8875508308410645,\n",
              "  7.87585973739624,\n",
              "  7.881953239440918,\n",
              "  7.8868608474731445,\n",
              "  7.887991428375244,\n",
              "  7.893979072570801,\n",
              "  7.86204719543457,\n",
              "  7.878931999206543,\n",
              "  7.876467704772949,\n",
              "  7.893490791320801,\n",
              "  7.869538307189941,\n",
              "  7.868710994720459,\n",
              "  7.871468544006348,\n",
              "  7.849638938903809,\n",
              "  7.862748146057129,\n",
              "  7.8321685791015625,\n",
              "  7.835597991943359,\n",
              "  7.8212738037109375,\n",
              "  7.810049057006836,\n",
              "  7.826900959014893,\n",
              "  7.835005283355713,\n",
              "  7.844918251037598,\n",
              "  7.83567476272583,\n",
              "  7.804264068603516,\n",
              "  7.826955318450928,\n",
              "  7.8478569984436035,\n",
              "  7.86649751663208,\n",
              "  7.829051971435547,\n",
              "  7.816769599914551,\n",
              "  7.863495826721191,\n",
              "  7.867970943450928,\n",
              "  7.905497074127197,\n",
              "  7.887040615081787,\n",
              "  7.89161491394043,\n",
              "  7.851008415222168,\n",
              "  7.917623996734619,\n",
              "  7.895495414733887,\n",
              "  7.921055793762207,\n",
              "  7.91391658782959,\n",
              "  7.888391017913818,\n",
              "  7.872268199920654,\n",
              "  7.87612771987915,\n",
              "  7.885272026062012,\n",
              "  7.900888442993164,\n",
              "  7.905755043029785,\n",
              "  7.8701581954956055,\n",
              "  7.905200958251953,\n",
              "  7.896845817565918,\n",
              "  7.904839515686035,\n",
              "  7.929675102233887,\n",
              "  7.911291122436523,\n",
              "  7.933932304382324,\n",
              "  7.960348606109619,\n",
              "  7.94704532623291,\n",
              "  7.93869161605835,\n",
              "  7.956707954406738,\n",
              "  7.940392017364502,\n",
              "  7.94174337387085,\n",
              "  7.949321746826172,\n",
              "  7.961724281311035,\n",
              "  7.964096546173096,\n",
              "  7.96753454208374,\n",
              "  7.9810991287231445,\n",
              "  7.9661545753479,\n",
              "  7.98079776763916,\n",
              "  7.964959144592285,\n",
              "  7.992361068725586,\n",
              "  7.968274116516113,\n",
              "  7.969473838806152,\n",
              "  7.960616111755371,\n",
              "  7.997238636016846,\n",
              "  7.96832799911499,\n",
              "  8.16430377960205,\n",
              "  8.106142044067383,\n",
              "  8.112560272216797,\n",
              "  8.076034545898438,\n",
              "  8.060260772705078,\n",
              "  8.053262710571289,\n",
              "  8.047578811645508,\n",
              "  8.069986343383789,\n",
              "  8.062703132629395,\n",
              "  8.054636001586914,\n",
              "  8.070837020874023,\n",
              "  8.062170028686523,\n",
              "  8.06191635131836,\n",
              "  8.083975791931152,\n",
              "  8.067514419555664,\n",
              "  8.06692886352539,\n",
              "  8.063405990600586,\n",
              "  8.077604293823242,\n",
              "  8.067620277404785,\n",
              "  8.082666397094727,\n",
              "  8.086557388305664,\n",
              "  8.092275619506836,\n",
              "  8.07973575592041,\n",
              "  8.089649200439453,\n",
              "  8.080698013305664,\n",
              "  8.087176322937012,\n",
              "  8.105386734008789,\n",
              "  8.074775695800781,\n",
              "  8.081750869750977,\n",
              "  8.082233428955078,\n",
              "  8.090843200683594,\n",
              "  8.115460395812988,\n",
              "  8.101215362548828,\n",
              "  8.107824325561523,\n",
              "  8.09853744506836,\n",
              "  8.097464561462402,\n",
              "  8.101619720458984,\n",
              "  8.104724884033203,\n",
              "  8.115775108337402,\n",
              "  8.116600036621094,\n",
              "  8.130105972290039,\n",
              "  8.125910758972168,\n",
              "  8.136432647705078,\n",
              "  8.131969451904297,\n",
              "  8.129565238952637,\n",
              "  8.13430404663086,\n",
              "  8.114119529724121,\n",
              "  8.123336791992188,\n",
              "  8.140974044799805,\n",
              "  8.137945175170898,\n",
              "  8.142463684082031,\n",
              "  8.144062042236328,\n",
              "  8.139566421508789,\n",
              "  8.177436828613281,\n",
              "  8.140291213989258,\n",
              "  8.164701461791992,\n",
              "  8.163878440856934,\n",
              "  8.15945053100586,\n",
              "  8.14082145690918,\n",
              "  8.152536392211914,\n",
              "  8.123228073120117,\n",
              "  8.044827461242676,\n",
              "  8.044317245483398,\n",
              "  8.087702751159668,\n",
              "  8.143658638000488,\n",
              "  8.101981163024902,\n",
              "  8.05135726928711,\n",
              "  8.055364608764648,\n",
              "  8.114532470703125,\n",
              "  8.080509185791016,\n",
              "  7.930171966552734,\n",
              "  8.004324913024902,\n",
              "  8.161552429199219,\n",
              "  7.89315938949585,\n",
              "  7.924568176269531,\n",
              "  7.930882453918457,\n",
              "  7.826812744140625,\n",
              "  7.785081386566162,\n",
              "  7.7901201248168945,\n",
              "  7.784623146057129,\n",
              "  7.764280796051025,\n",
              "  7.7790093421936035,\n",
              "  7.797900676727295,\n",
              "  7.796811103820801,\n",
              "  7.840132236480713,\n",
              "  7.8109588623046875,\n",
              "  7.805377960205078,\n",
              "  7.813371658325195,\n",
              "  7.828091621398926,\n",
              "  7.849059104919434,\n",
              "  7.852875232696533,\n",
              "  7.844213485717773,\n",
              "  7.8557939529418945,\n",
              "  7.856815338134766,\n",
              "  7.855219841003418,\n",
              "  7.887144088745117,\n",
              "  7.887202262878418,\n",
              "  7.887556552886963,\n",
              "  7.883974552154541,\n",
              "  7.9043660163879395,\n",
              "  7.902142524719238,\n",
              "  7.915139675140381,\n",
              "  7.9270853996276855,\n",
              "  7.926797866821289,\n",
              "  7.930309295654297,\n",
              "  7.9337968826293945,\n",
              "  7.939910888671875,\n",
              "  7.9427361488342285,\n",
              "  7.9511399269104,\n",
              "  7.952807426452637,\n",
              "  7.975449085235596,\n",
              "  7.970205307006836,\n",
              "  7.9741950035095215,\n",
              "  7.985748291015625,\n",
              "  7.909553527832031,\n",
              "  7.664872169494629,\n",
              "  7.5244598388671875,\n",
              "  7.494133949279785,\n",
              "  7.4998016357421875,\n",
              "  7.480268955230713,\n",
              "  7.479301452636719,\n",
              "  7.493352890014648,\n",
              "  7.508533477783203,\n",
              "  7.519608974456787,\n",
              "  7.542121887207031,\n",
              "  7.57033109664917,\n",
              "  7.567907333374023,\n",
              "  7.581243515014648,\n",
              "  7.611085414886475,\n",
              "  7.615908145904541,\n",
              "  7.633162498474121,\n",
              "  7.6624674797058105,\n",
              "  7.660423755645752,\n",
              "  7.642381191253662,\n",
              "  7.464260101318359,\n",
              "  7.28726863861084,\n",
              "  7.292227268218994,\n",
              "  7.283564567565918,\n",
              "  7.160425186157227,\n",
              "  7.1947550773620605,\n",
              "  7.246901512145996,\n",
              "  7.261456489562988,\n",
              "  7.276185989379883,\n",
              "  7.270275115966797,\n",
              "  7.165497303009033,\n",
              "  ...],\n",
              " [0.7181283235549927,\n",
              "  0.6917865872383118,\n",
              "  0.6741997003555298,\n",
              "  0.6641300320625305,\n",
              "  0.6541121006011963,\n",
              "  0.6372179985046387,\n",
              "  0.6271653175354004,\n",
              "  0.6247653961181641,\n",
              "  0.6009223461151123,\n",
              "  0.5722471475601196,\n",
              "  0.5514783263206482,\n",
              "  0.543888509273529,\n",
              "  0.49947476387023926,\n",
              "  0.45265424251556396,\n",
              "  0.3914709985256195,\n",
              "  0.33859825134277344,\n",
              "  0.29110729694366455,\n",
              "  0.25478628277778625,\n",
              "  0.21209606528282166,\n",
              "  0.17570333182811737,\n",
              "  0.1475253850221634,\n",
              "  0.15032270550727844,\n",
              "  0.10738301277160645,\n",
              "  0.09836359322071075,\n",
              "  0.09311402589082718,\n",
              "  0.10844019055366516,\n",
              "  0.0897044837474823,\n",
              "  0.07124850153923035,\n",
              "  0.05436333268880844,\n",
              "  0.042047783732414246,\n",
              "  0.03196176514029503,\n",
              "  0.02890029177069664,\n",
              "  0.025444993749260902,\n",
              "  0.022368723526597023,\n",
              "  0.027575496584177017,\n",
              "  0.16715069115161896,\n",
              "  0.07592476904392242,\n",
              "  0.05215025693178177,\n",
              "  0.04429934546351433,\n",
              "  0.036360226571559906,\n",
              "  0.028696101158857346,\n",
              "  0.020239343866705894,\n",
              "  0.021050579845905304,\n",
              "  0.022120295092463493,\n",
              "  0.03258579224348068,\n",
              "  0.023681901395320892,\n",
              "  0.019871708005666733,\n",
              "  0.017748763784766197,\n",
              "  0.0163776446133852,\n",
              "  0.01643834263086319,\n",
              "  0.015858421102166176,\n",
              "  0.018591849133372307,\n",
              "  0.509699285030365,\n",
              "  0.09349057078361511,\n",
              "  0.09311768412590027,\n",
              "  0.10592618584632874,\n",
              "  0.08769842237234116,\n",
              "  0.057252347469329834,\n",
              "  0.04308607429265976,\n",
              "  0.039900150150060654,\n",
              "  0.04232238605618477,\n",
              "  0.04145161807537079,\n",
              "  0.027890115976333618,\n",
              "  0.02108323946595192,\n",
              "  0.017977597191929817,\n",
              "  0.016330603510141373,\n",
              "  0.01532671321183443,\n",
              "  0.011947196908295155,\n",
              "  0.010579168796539307,\n",
              "  0.015614734962582588,\n",
              "  0.011473308317363262,\n",
              "  0.010483317077159882,\n",
              "  0.011279885657131672,\n",
              "  0.14401832222938538,\n",
              "  0.03393477201461792,\n",
              "  0.0324244499206543,\n",
              "  0.027002627030014992,\n",
              "  0.019227560609579086,\n",
              "  0.016530662775039673,\n",
              "  0.01305372454226017,\n",
              "  0.009804931469261646,\n",
              "  0.009851420298218727,\n",
              "  0.009373858571052551,\n",
              "  0.008785301819443703,\n",
              "  0.011529108509421349,\n",
              "  0.12605947256088257,\n",
              "  0.05722830444574356,\n",
              "  0.054746318608522415,\n",
              "  0.03608878701925278,\n",
              "  0.03009185567498207,\n",
              "  0.02593620866537094,\n",
              "  0.03487902134656906,\n",
              "  0.03481684997677803,\n",
              "  0.015903664752840996,\n",
              "  0.010208896361291409,\n",
              "  0.014142494648694992,\n",
              "  0.009970352053642273,\n",
              "  0.008018692955374718,\n",
              "  0.008647611364722252,\n",
              "  0.00890878401696682,\n",
              "  0.006254066713154316,\n",
              "  0.005986897740513086,\n",
              "  0.0056605213321745396,\n",
              "  0.005834342446178198,\n",
              "  0.007120101246982813,\n",
              "  0.007028906140476465,\n",
              "  0.012778833508491516,\n",
              "  0.017401637509465218,\n",
              "  0.01141626201570034,\n",
              "  0.012046806514263153,\n",
              "  0.009754176251590252,\n",
              "  0.008603167720139027,\n",
              "  0.015081409364938736,\n",
              "  0.009084658697247505,\n",
              "  0.00892791710793972,\n",
              "  0.009468491189181805,\n",
              "  0.007972793653607368,\n",
              "  0.006658161990344524,\n",
              "  0.004933563992381096,\n",
              "  0.008977936580777168,\n",
              "  0.004874971229583025,\n",
              "  0.005033975467085838,\n",
              "  0.00441034696996212,\n",
              "  0.00505329854786396,\n",
              "  0.004446438979357481,\n",
              "  0.004303311929106712,\n",
              "  0.006358087062835693,\n",
              "  0.0046482509933412075,\n",
              "  0.007852908223867416,\n",
              "  0.004187394864857197,\n",
              "  0.003578322008252144,\n",
              "  0.003772231750190258,\n",
              "  0.003423270070925355,\n",
              "  0.0031353349331766367,\n",
              "  0.002933839336037636,\n",
              "  0.002640410326421261,\n",
              "  0.0028193939942866564,\n",
              "  0.0029518697410821915,\n",
              "  0.0031472486443817616,\n",
              "  0.00332931918092072,\n",
              "  0.003277914598584175,\n",
              "  0.0025512611027806997,\n",
              "  0.0028295679949223995,\n",
              "  0.0031741568818688393,\n",
              "  0.002593165962025523,\n",
              "  0.0030259378254413605,\n",
              "  0.0024630760308355093,\n",
              "  0.0030561822932213545,\n",
              "  0.003442527027800679,\n",
              "  0.002829726319760084,\n",
              "  0.002723125973716378,\n",
              "  0.0022947320248931646,\n",
              "  0.0030570439994335175,\n",
              "  0.002423554193228483,\n",
              "  0.0023112110793590546,\n",
              "  0.0028569516725838184,\n",
              "  0.002130475826561451,\n",
              "  0.0023829988203942776,\n",
              "  0.0032670912332832813,\n",
              "  0.002910396084189415,\n",
              "  0.00274893781170249,\n",
              "  0.0024628043174743652,\n",
              "  0.002165833255276084,\n",
              "  0.0028330490458756685,\n",
              "  0.07276173681020737,\n",
              "  0.011903466656804085,\n",
              "  0.022538846358656883,\n",
              "  0.019823970273137093,\n",
              "  0.013289298862218857,\n",
              "  0.008169627748429775,\n",
              "  0.008634152822196484,\n",
              "  0.007925164885818958,\n",
              "  0.008263688534498215,\n",
              "  0.00524600176140666,\n",
              "  0.005087199155241251,\n",
              "  0.004627760499715805,\n",
              "  0.006990293972194195,\n",
              "  0.00516542000696063,\n",
              "  0.004407821223139763,\n",
              "  0.003738125553354621,\n",
              "  0.0040166862308979034,\n",
              "  0.004060893319547176,\n",
              "  0.003550419583916664,\n",
              "  0.004548112861812115,\n",
              "  0.0032638348639011383,\n",
              "  0.0032395978923887014,\n",
              "  0.005571445915848017,\n",
              "  0.004294494166970253,\n",
              "  0.0026588174514472485,\n",
              "  0.0031716381199657917,\n",
              "  0.0037859249860048294,\n",
              "  0.0029306262731552124,\n",
              "  0.002728597493842244,\n",
              "  0.002750282408669591,\n",
              "  0.003457071725279093,\n",
              "  0.00216096849180758,\n",
              "  0.003160624299198389,\n",
              "  0.0026137279346585274,\n",
              "  0.0023290221579372883,\n",
              "  0.002762055490165949,\n",
              "  0.0024575626011937857,\n",
              "  0.0022586616687476635,\n",
              "  0.002024484798312187,\n",
              "  0.0029804552905261517,\n",
              "  0.0025100973434746265,\n",
              "  0.0019158705836161971,\n",
              "  0.0032373513095080853,\n",
              "  0.002933941315859556,\n",
              "  0.0024609942920506,\n",
              "  0.01847383938729763,\n",
              "  0.03267129510641098,\n",
              "  0.015063869766891003,\n",
              "  0.013456041924655437,\n",
              "  0.0171609316021204,\n",
              "  0.011313541792333126,\n",
              "  0.015383406542241573,\n",
              "  0.008604944683611393,\n",
              "  0.009519988670945168,\n",
              "  0.009431937709450722,\n",
              "  0.0063203973695635796,\n",
              "  0.006338455714285374,\n",
              "  0.008334808982908726,\n",
              "  0.006064462009817362,\n",
              "  0.006860503926873207,\n",
              "  0.005713796708732843,\n",
              "  0.0047143748961389065,\n",
              "  0.00458392221480608,\n",
              "  0.00725405290722847,\n",
              "  0.005157702602446079,\n",
              "  0.007423641625791788,\n",
              "  0.0058258590288460255,\n",
              "  0.003934456035494804,\n",
              "  0.004185862373560667,\n",
              "  0.0049582296051084995,\n",
              "  0.0032914276234805584,\n",
              "  0.003935231827199459,\n",
              "  0.004627947695553303,\n",
              "  0.0031332899816334248,\n",
              "  0.0028109310660511255,\n",
              "  0.0025128277484327555,\n",
              "  0.0023791431449353695,\n",
              "  0.0027081319130957127,\n",
              "  0.002566463779658079,\n",
              "  0.00398971326649189,\n",
              "  0.002646178938448429,\n",
              "  0.003296848153695464,\n",
              "  0.002429928397759795,\n",
              "  0.002211820799857378,\n",
              "  0.0020286529324948788,\n",
              "  0.0026133782230317593,\n",
              "  0.0033193703275173903,\n",
              "  0.002672456204891205,\n",
              "  0.0022043734788894653,\n",
              "  0.00175945064984262,\n",
              "  0.0020105447620153427,\n",
              "  0.0015643187798559666,\n",
              "  0.0025083026848733425,\n",
              "  0.0018677252810448408,\n",
              "  0.0017433376051485538,\n",
              "  0.001730152522213757,\n",
              "  0.0014728946844115853,\n",
              "  0.001749422401189804,\n",
              "  0.0017871959134936333,\n",
              "  0.00169547856785357,\n",
              "  0.0020668143406510353,\n",
              "  0.0018194697331637144,\n",
              "  0.0014175005489960313,\n",
              "  0.0012747618602588773,\n",
              "  0.002047861460596323,\n",
              "  0.0013057177420705557,\n",
              "  0.0014566720928996801,\n",
              "  0.0019692976493388414,\n",
              "  0.025026606395840645,\n",
              "  0.026624327525496483,\n",
              "  0.015609098598361015,\n",
              "  0.015701528638601303,\n",
              "  0.02075311169028282,\n",
              "  0.02207185886800289,\n",
              "  0.015881642699241638,\n",
              "  0.015012025833129883,\n",
              "  0.007341513875871897,\n",
              "  0.006827789358794689,\n",
              "  0.009790640324354172,\n",
              "  0.004624067340046167,\n",
              "  0.00456506060436368,\n",
              "  0.003642754629254341,\n",
              "  0.0033142613247036934,\n",
              "  0.0053391363471746445,\n",
              "  0.0037481822073459625,\n",
              "  0.004330157767981291,\n",
              "  0.003774572629481554,\n",
              "  0.0027551017701625824,\n",
              "  0.0034676515497267246,\n",
              "  0.003185414709150791,\n",
              "  0.00427622627466917,\n",
              "  0.0022410391829907894,\n",
              "  0.0020787245593965054,\n",
              "  0.0022083851508796215,\n",
              "  0.0019755340181291103,\n",
              "  0.0024694488383829594,\n",
              "  0.002281789667904377,\n",
              "  0.0025652197655290365,\n",
              "  0.0022838572040200233,\n",
              "  0.0031913351267576218,\n",
              "  0.002166604157537222,\n",
              "  0.002069162204861641,\n",
              "  0.0019436627626419067,\n",
              "  0.0022899964824318886,\n",
              "  0.0023371633142232895,\n",
              "  0.0026584502775222063,\n",
              "  0.002261302899569273,\n",
              "  0.002314903773367405,\n",
              "  0.002337831072509289,\n",
              "  0.0019885189831256866,\n",
              "  0.0020602992735803127,\n",
              "  0.001953430939465761,\n",
              "  0.0023922291584312916,\n",
              "  0.001684816088527441,\n",
              "  0.0023822078946977854,\n",
              "  0.002198814880102873,\n",
              "  0.0018240201752632856,\n",
              "  0.0019644652493298054,\n",
              "  0.002966654486954212,\n",
              "  0.0026035611517727375,\n",
              "  0.0032740067690610886,\n",
              "  0.0024584666825830936,\n",
              "  0.00274889194406569,\n",
              "  0.002180888317525387,\n",
              "  0.0021784924902021885,\n",
              "  0.0022681625559926033,\n",
              "  0.001920105773024261,\n",
              "  0.0016950576100498438,\n",
              "  0.0019242463167756796,\n",
              "  0.0019950452260673046,\n",
              "  0.0019927998073399067,\n",
              "  0.006485735531896353,\n",
              "  0.5703802704811096,\n",
              "  1.7418088912963867,\n",
              "  0.03728760778903961,\n",
              "  0.0810130313038826,\n",
              "  0.2824430465698242,\n",
              "  0.12140998244285583,\n",
              "  0.08061445504426956,\n",
              "  0.12529629468917847,\n",
              "  0.12607765197753906,\n",
              "  0.08496735990047455,\n",
              "  0.053074911236763,\n",
              "  0.055599771440029144,\n",
              "  0.0425589494407177,\n",
              "  0.04119599983096123,\n",
              "  0.02781522646546364,\n",
              "  0.02669074386358261,\n",
              "  0.027599560096859932,\n",
              "  0.022489044815301895,\n",
              "  0.024363677948713303,\n",
              "  0.02462172694504261,\n",
              "  0.02058989927172661,\n",
              "  0.01671675220131874,\n",
              "  0.017617512494325638,\n",
              "  0.016091909259557724,\n",
              "  0.021772228181362152,\n",
              "  0.01643889769911766,\n",
              "  0.01760048046708107,\n",
              "  0.014784754253923893,\n",
              "  0.015088716521859169,\n",
              "  0.013264494016766548,\n",
              "  0.0139700872823596,\n",
              "  0.014205718412995338,\n",
              "  0.013955015689134598,\n",
              "  0.011710617691278458,\n",
              "  0.011125119403004646,\n",
              "  0.014214552938938141,\n",
              "  0.011505568400025368,\n",
              "  0.009586264379322529,\n",
              "  0.011520438827574253,\n",
              "  0.00970822386443615,\n",
              "  0.010323945432901382,\n",
              "  0.009824564680457115,\n",
              "  0.010148155502974987,\n",
              "  0.010119999758899212,\n",
              "  0.010494345799088478,\n",
              "  0.010560369119048119,\n",
              "  0.010780850425362587,\n",
              "  0.010430213063955307,\n",
              "  0.009084098041057587,\n",
              "  0.00888521783053875,\n",
              "  0.008804666809737682,\n",
              "  0.00788344256579876,\n",
              "  0.008298374712467194,\n",
              "  0.007321862503886223,\n",
              "  0.007389632053673267,\n",
              "  0.007648087572306395,\n",
              "  0.007835812866687775,\n",
              "  0.007915577851235867,\n",
              "  0.009657644666731358,\n",
              "  0.007882868871092796,\n",
              "  0.007474842481315136,\n",
              "  0.007937213405966759,\n",
              "  0.007785526569932699,\n",
              "  0.007935412228107452,\n",
              "  0.006876703351736069,\n",
              "  0.006948862224817276,\n",
              "  0.0073393178172409534,\n",
              "  0.007800689898431301,\n",
              "  0.006004146300256252,\n",
              "  0.006326018832623959,\n",
              "  0.006453990936279297,\n",
              "  0.0076737296767532825,\n",
              "  0.006341352127492428,\n",
              "  0.006081882398575544,\n",
              "  0.005561584606766701,\n",
              "  0.0051516517996788025,\n",
              "  0.005040803924202919,\n",
              "  0.005420980509370565,\n",
              "  0.004578239284455776,\n",
              "  0.005599162541329861,\n",
              "  0.004875010810792446,\n",
              "  0.0044694566167891026,\n",
              "  0.0047602406702935696,\n",
              "  0.004892646335065365,\n",
              "  0.004921415820717812,\n",
              "  0.0047672507353127,\n",
              "  0.004322369582951069,\n",
              "  0.004590287804603577,\n",
              "  0.004544749855995178,\n",
              "  0.004341636784374714,\n",
              "  0.0052540055476129055,\n",
              "  0.00518372468650341,\n",
              "  0.005017641931772232,\n",
              "  0.004875182174146175,\n",
              "  0.004199526738375425,\n",
              "  0.0036836876533925533,\n",
              "  0.004538755863904953,\n",
              "  0.004163040779531002,\n",
              "  0.0037590847350656986,\n",
              "  0.004216931760311127,\n",
              "  0.003716621082276106,\n",
              "  0.003938073292374611,\n",
              "  0.0038413514848798513,\n",
              "  0.0034582773223519325,\n",
              "  0.0035904208198189735,\n",
              "  0.004398467019200325,\n",
              "  0.004238707944750786,\n",
              "  0.003783673979341984,\n",
              "  0.003709500189870596,\n",
              "  0.0034368871711194515,\n",
              "  0.0030693651642650366,\n",
              "  0.003322016913443804,\n",
              "  0.0037091257981956005,\n",
              "  0.0034999523777514696,\n",
              "  0.0036125273909419775,\n",
              "  0.00322199915535748,\n",
              "  0.0036413194611668587,\n",
              "  0.003571521956473589,\n",
              "  0.003987279254943132,\n",
              "  0.0037077993620187044,\n",
              "  0.003221324412152171,\n",
              "  0.0034170253202319145,\n",
              "  0.0038505662232637405,\n",
              "  0.0032110228203237057,\n",
              "  0.0034331600181758404,\n",
              "  0.0029880846850574017,\n",
              "  0.0034166460391134024,\n",
              "  0.0035029533319175243,\n",
              "  0.0027368732262402773,\n",
              "  0.0031039812602102757,\n",
              "  0.0027580144815146923,\n",
              "  0.0027470658533275127,\n",
              "  0.0027332310564816,\n",
              "  0.0030980482697486877,\n",
              "  0.0029145386070013046,\n",
              "  0.002732919529080391,\n",
              "  0.002891646232455969,\n",
              "  0.0026598996482789516,\n",
              "  0.002452495042234659,\n",
              "  0.0026027432177215815,\n",
              "  0.0031794370152056217,\n",
              "  0.00223582168109715,\n",
              "  0.0024422723799943924,\n",
              "  0.0025551391299813986,\n",
              "  0.0027818153612315655,\n",
              "  0.0026256260462105274,\n",
              "  0.002632287098094821,\n",
              "  0.002305945847183466,\n",
              "  0.0021610381081700325,\n",
              "  0.002299968618899584,\n",
              "  0.0025809877552092075,\n",
              "  0.002528016222640872,\n",
              "  0.002510750200599432,\n",
              "  0.0024649514816701412,\n",
              "  0.002602525521069765,\n",
              "  0.0023798902984708548,\n",
              "  0.0020453149918466806,\n",
              "  0.002040630904957652,\n",
              "  0.0022848090156912804,\n",
              "  0.0020813278388231993,\n",
              "  0.0022628253791481256,\n",
              "  0.002020037267357111,\n",
              "  0.002212750492617488,\n",
              "  0.002500257920473814,\n",
              "  0.002712378976866603,\n",
              "  0.0029025438707321882,\n",
              "  0.0021114437840878963,\n",
              "  0.0022595273330807686,\n",
              "  0.002432613167911768,\n",
              "  0.0022441395558416843,\n",
              "  0.0022302386350929737,\n",
              "  0.002930202055722475,\n",
              "  0.0025119443889707327,\n",
              "  0.0019195881905034184,\n",
              "  0.002168748527765274,\n",
              "  0.0020629367791116238,\n",
              "  0.0020499187521636486,\n",
              "  0.002256033243611455,\n",
              "  0.0021837130188941956,\n",
              "  0.002408521482720971,\n",
              "  0.002128880936652422,\n",
              "  0.0020690385717898607,\n",
              "  0.002094961702823639,\n",
              "  0.0018679075874388218,\n",
              "  0.0020316187292337418,\n",
              "  0.0018298670183867216,\n",
              "  0.0024342024698853493,\n",
              "  0.0017768517136573792,\n",
              "  0.002158472314476967,\n",
              "  0.002133975038304925,\n",
              "  0.0017275010468438268,\n",
              "  0.0019479973707348108,\n",
              "  0.0017953150672838092,\n",
              "  0.00211548013612628,\n",
              "  0.0019741503056138754,\n",
              "  0.0016304075252264738,\n",
              "  0.0016176044009625912,\n",
              "  0.001791335642337799,\n",
              "  0.0019880884792655706,\n",
              "  0.001910694525577128,\n",
              "  0.0018269785214215517,\n",
              "  0.0015724332770332694,\n",
              "  0.001799074001610279,\n",
              "  0.0018024254823103547,\n",
              "  0.0016901812050491571,\n",
              "  0.0016551960725337267,\n",
              "  0.0018070766236633062,\n",
              "  0.0015659388154745102,\n",
              "  0.0014177054399624467,\n",
              "  0.0017920909449458122,\n",
              "  0.0016496677417308092,\n",
              "  0.0016196321230381727,\n",
              "  0.0016243376303464174,\n",
              "  0.0015506015624850988,\n",
              "  0.001452338183298707,\n",
              "  0.0013868751702830195,\n",
              "  0.0016354736872017384,\n",
              "  0.0014565865276381373,\n",
              "  0.001510224537923932,\n",
              "  0.0018220667261630297,\n",
              "  0.0014243859332054853,\n",
              "  0.001552429050207138,\n",
              "  0.001504606450907886,\n",
              "  0.001383976312354207,\n",
              "  0.0013257195241749287,\n",
              "  0.0015161060728132725,\n",
              "  0.0016037436434999108,\n",
              "  0.0013366072671487927,\n",
              "  0.001416896004229784,\n",
              "  0.0014198533026501536,\n",
              "  0.0013403977500274777,\n",
              "  0.0014005908742547035,\n",
              "  0.0016735689714550972,\n",
              "  0.0013256756355986,\n",
              "  0.001408901298418641,\n",
              "  0.001289905747398734,\n",
              "  0.0014189777430146933,\n",
              "  0.0012690031435340643,\n",
              "  0.0012478446587920189,\n",
              "  0.0012551560066640377,\n",
              "  0.0012563189957290888,\n",
              "  0.0013457596069201827,\n",
              "  0.0012170188128948212,\n",
              "  0.0012245348189026117,\n",
              "  0.0012755958596244454,\n",
              "  0.001294857356697321,\n",
              "  0.001290470827370882,\n",
              "  0.0012153442949056625,\n",
              "  0.0012756146024912596,\n",
              "  0.0011842717649415135,\n",
              "  0.0011865576962009072,\n",
              "  0.001237048301845789,\n",
              "  0.0013450141996145248,\n",
              "  0.001247200882062316,\n",
              "  0.0011422698153182864,\n",
              "  0.0010859838221222162,\n",
              "  0.0012274429900571704,\n",
              "  0.001137077808380127,\n",
              "  0.001127493567764759,\n",
              "  0.0012128064408898354,\n",
              "  0.0010474033188074827,\n",
              "  0.0011372956214472651,\n",
              "  0.0010935557074844837,\n",
              "  0.001147354720160365,\n",
              "  0.001089717959985137,\n",
              "  0.0010513911256566644,\n",
              "  0.0010799078736454248,\n",
              "  0.0010602852562442422,\n",
              "  0.0008925151196308434,\n",
              "  0.0010248529724776745,\n",
              "  0.0010791351087391376,\n",
              "  0.0011488813906908035,\n",
              "  0.0011210496304556727,\n",
              "  0.0009558653691783547,\n",
              "  0.001145192887634039,\n",
              "  0.001037324545904994,\n",
              "  0.0009382445132359862,\n",
              "  0.0013609090819954872,\n",
              "  0.0009628141997382045,\n",
              "  0.0010049662087112665,\n",
              "  0.0008975584642030299,\n",
              "  0.0011038960656151175,\n",
              "  0.0011757176835089922,\n",
              "  0.0009458698332309723,\n",
              "  0.001128172385506332,\n",
              "  0.0009693483007140458,\n",
              "  0.0009797713719308376,\n",
              "  0.0009678443893790245,\n",
              "  0.0009436034015379846,\n",
              "  0.001023976132273674,\n",
              "  0.0010191684123128653,\n",
              "  0.0009542158804833889,\n",
              "  0.000972671783529222,\n",
              "  0.0009375311201438308,\n",
              "  0.000996455317363143,\n",
              "  0.0009918627329170704,\n",
              "  0.0009250843431800604,\n",
              "  0.0010244189761579037,\n",
              "  0.0009244719985872507,\n",
              "  0.000919199432246387,\n",
              "  0.0009505402413196862,\n",
              "  0.000843173183966428,\n",
              "  0.0008555154199711978,\n",
              "  0.0008582405280321836,\n",
              "  0.0008800869109109044,\n",
              "  0.000925552798435092,\n",
              "  0.0009653258603066206,\n",
              "  0.000873128476087004,\n",
              "  0.0009165719384327531,\n",
              "  0.0009549277601763606,\n",
              "  0.0007969436119310558,\n",
              "  0.0009206491522490978,\n",
              "  0.0008772415458224714,\n",
              "  0.0008725222432985902,\n",
              "  0.0008068002061918378,\n",
              "  0.00082553387619555,\n",
              "  0.0008521333220414817,\n",
              "  0.0008376485202461481,\n",
              "  0.0008318643667735159,\n",
              "  0.0008931029005907476,\n",
              "  0.0007608870510011911,\n",
              "  0.0009208262781612575,\n",
              "  0.0008355570025742054,\n",
              "  0.0008418363868258893,\n",
              "  0.0008706179796718061,\n",
              "  0.0007236841483972967,\n",
              "  0.0007276844698935747,\n",
              "  0.0008005991694517434,\n",
              "  0.0007668056059628725,\n",
              "  0.0008366032270714641,\n",
              "  0.0009712993050925434,\n",
              "  0.0008168707136064768,\n",
              "  0.0008589536300860345,\n",
              "  0.0007692446233704686,\n",
              "  0.0007500489591620862,\n",
              "  0.0008367642294615507,\n",
              "  0.0007882661884650588,\n",
              "  0.0007747324416413903,\n",
              "  0.0007836455479264259,\n",
              "  0.0008118209661915898,\n",
              "  0.0008426264394074678,\n",
              "  0.0009579230681993067,\n",
              "  0.000750409031752497,\n",
              "  0.0007417285232804716,\n",
              "  0.0006887211347930133,\n",
              "  0.0007224173750728369,\n",
              "  0.0008366455440409482,\n",
              "  0.000779485737439245,\n",
              "  0.0007213308126665652,\n",
              "  0.000725610472727567,\n",
              "  0.0007735384278930724,\n",
              "  0.0008003603434190154,\n",
              "  0.0007570236339233816,\n",
              "  0.0007807738147675991,\n",
              "  0.0006873458623886108,\n",
              "  0.000823810463771224,\n",
              "  0.0007390255341306329,\n",
              "  0.0007557357312180102,\n",
              "  0.0008375236066058278,\n",
              "  0.0008121461141854525,\n",
              "  0.0007195313228294253,\n",
              "  0.0006484065088443458,\n",
              "  0.0007592543843202293,\n",
              "  0.0009697870118543506,\n",
              "  0.0006403849693015218,\n",
              "  0.0007227562600746751,\n",
              "  0.0006794417276978493,\n",
              "  0.0007310951477847993,\n",
              "  0.0007473287987522781,\n",
              "  0.0007341185119003057,\n",
              "  0.0006363559514284134,\n",
              "  0.0006926745409145951,\n",
              "  0.0007871452253311872,\n",
              "  0.0007468152907676995,\n",
              "  0.0007689069025218487,\n",
              "  0.0006678178906440735,\n",
              "  0.0006806711899116635,\n",
              "  0.0007575084455311298,\n",
              "  0.0006801722338423133,\n",
              "  0.0007334353867918253,\n",
              "  0.0006579749751836061,\n",
              "  0.0007565902778878808,\n",
              "  0.0006675467593595386,\n",
              "  0.000667918415274471,\n",
              "  0.0006288293516263366,\n",
              "  0.0006090858951210976,\n",
              "  0.0007247061585076153,\n",
              "  0.0006842818693257868,\n",
              "  0.0007368093356490135,\n",
              "  0.0006512360996566713,\n",
              "  0.0006621003849431872,\n",
              "  0.0005988841294310987,\n",
              "  0.0006253015017136931,\n",
              "  0.0006034075049683452,\n",
              "  0.0006462231394834816,\n",
              "  0.0005378759233281016,\n",
              "  0.000631312548648566,\n",
              "  0.0005620194133371115,\n",
              "  0.0006276933709159493,\n",
              "  0.0006172313587740064,\n",
              "  0.0007058598566800356,\n",
              "  0.0006504581542685628,\n",
              "  0.0005811760202050209,\n",
              "  0.0006419811397790909,\n",
              "  0.0006379508995451033,\n",
              "  0.0006539169116877019,\n",
              "  0.0007293655653484166,\n",
              "  0.0006699598161503673,\n",
              "  0.0006252966704778373,\n",
              "  0.0005702981143258512,\n",
              "  0.000613794254604727,\n",
              "  0.0005455972859635949,\n",
              "  0.0005529240588657558,\n",
              "  0.0004842046764679253,\n",
              "  0.0005908100283704698,\n",
              "  0.0005940977134741843,\n",
              "  0.0005840958328917623,\n",
              "  0.0006085712811909616,\n",
              "  0.0006386794848367572,\n",
              "  0.0005770623683929443,\n",
              "  0.0005599807482212782,\n",
              "  0.0006198114133439958,\n",
              "  0.0005142648005858064,\n",
              "  0.0005144176539033651,\n",
              "  0.0005333776352927089,\n",
              "  0.0005562180886045098,\n",
              "  0.0006170353153720498,\n",
              "  0.0006163943326100707,\n",
              "  0.0005664989585056901,\n",
              "  0.0005894561181776226,\n",
              "  0.0005908546736463904,\n",
              "  0.0006430366775020957,\n",
              "  0.0005522723076865077,\n",
              "  0.000509197183419019,\n",
              "  0.0005085741286166012,\n",
              "  0.0004753998655360192,\n",
              "  0.0005583159509114921,\n",
              "  0.0005675394786521792,\n",
              "  0.000592402764596045,\n",
              "  0.0005799898644909263,\n",
              "  0.0005370085709728301,\n",
              "  0.0005649559898301959,\n",
              "  0.00047163001727312803,\n",
              "  0.000558810424990952,\n",
              "  0.0005624900222755969,\n",
              "  0.0005285905790515244,\n",
              "  0.0004897444741800427,\n",
              "  0.00046074515557847917,\n",
              "  0.0006060887826606631,\n",
              "  0.0005129859782755375,\n",
              "  0.0005330427666194737,\n",
              "  0.0005172835080884397,\n",
              "  0.0005463523557409644,\n",
              "  0.0005046443548053503,\n",
              "  0.0005093002109788358,\n",
              "  0.0004767657956108451,\n",
              "  0.0005718953907489777,\n",
              "  0.0005575945251621306,\n",
              "  0.0005573343951255083,\n",
              "  0.000549132120795548,\n",
              "  0.0004949402064085007,\n",
              "  0.00048412688192911446,\n",
              "  0.0004372172988951206,\n",
              "  0.0005859700031578541,\n",
              "  0.0004996128263883293,\n",
              "  0.0005692406557500362,\n",
              "  0.00047897768672555685,\n",
              "  0.000502944749314338,\n",
              "  0.000490353093482554,\n",
              "  0.0004607145965564996,\n",
              "  0.0005335631431080401,\n",
              "  0.0005201636231504381,\n",
              "  0.0005679046735167503,\n",
              "  0.0005315000889822841,\n",
              "  0.00044485076796263456,\n",
              "  0.0005123887094669044,\n",
              "  0.000504353258293122,\n",
              "  0.00039862061385065317,\n",
              "  0.00046332605415955186,\n",
              "  0.00044722482562065125,\n",
              "  0.00044782087206840515,\n",
              "  0.0004870456177741289,\n",
              "  0.0005764318630099297,\n",
              "  0.00045747534022666514,\n",
              "  0.00046659624786116183,\n",
              "  0.00044634175719693303,\n",
              "  0.0005158635322004557,\n",
              "  0.0004862737550865859,\n",
              "  0.0004682903818320483,\n",
              "  0.0005206270143389702,\n",
              "  0.00042746341205202043,\n",
              "  0.0004527573473751545,\n",
              "  0.0004697806143667549,\n",
              "  0.000414258916862309,\n",
              "  0.0004190521140117198,\n",
              "  0.00039419697714038193,\n",
              "  0.0004598908999469131,\n",
              "  0.00040861376328393817,\n",
              "  0.0004658545658458024,\n",
              "  0.0004902238724753261,\n",
              "  0.0005155044491402805,\n",
              "  0.0005241024191491306,\n",
              "  0.0004063831875100732,\n",
              "  0.0004730677464976907,\n",
              "  0.00044111552415415645,\n",
              "  0.00048629558295942843,\n",
              "  0.0004043383232783526,\n",
              "  0.0004504631506279111,\n",
              "  0.0004896194441244006,\n",
              "  0.00046211728476919234,\n",
              "  0.00044744511251337826,\n",
              "  0.00043287177686579525,\n",
              "  0.0005092775681987405,\n",
              "  0.0004190011532045901,\n",
              "  0.00048437522491440177,\n",
              "  0.00041966192657127976,\n",
              "  0.000458654947578907,\n",
              "  0.000448204722488299,\n",
              "  0.00040272201295010746,\n",
              "  0.0004777371359523386,\n",
              "  0.0004692652728408575,\n",
              "  0.00040682920371182263,\n",
              "  0.00039374586776830256,\n",
              "  0.0004388937377370894,\n",
              "  0.00045392150059342384,\n",
              "  0.0003959887253586203,\n",
              "  0.00040658278157934546,\n",
              "  0.0004011649580206722,\n",
              "  0.00039314490277320147,\n",
              "  0.00041504116961732507,\n",
              "  0.000380827987100929,\n",
              "  0.0005181180313229561,\n",
              "  0.00039687418029643595,\n",
              "  0.00039099843706935644,\n",
              "  0.00039615470450371504,\n",
              "  0.00039237181772477925,\n",
              "  0.0004330775118432939,\n",
              "  0.00043142744107171893,\n",
              "  0.00040156461182050407,\n",
              "  0.00042144881444983184,\n",
              "  0.00035667556221596897,\n",
              "  0.0003982114139944315,\n",
              "  0.0004105640109628439,\n",
              "  0.00044331152457743883,\n",
              "  0.0004141677636653185,\n",
              "  0.000456761074019596,\n",
              "  0.0004190322360955179,\n",
              "  0.00044779045856557786,\n",
              "  0.00039524963358417153,\n",
              "  0.00037007222999818623,\n",
              "  0.00041590878390707076,\n",
              "  0.00036853953497484326,\n",
              "  0.0004370003007352352,\n",
              "  0.000349781388649717,\n",
              "  0.0003963655326515436,\n",
              "  0.00039258477045223117,\n",
              "  0.00042381888488307595,\n",
              "  0.000345678417943418,\n",
              "  0.00037312746280804276,\n",
              "  0.0003424958267714828,\n",
              "  0.00039784025284461677,\n",
              "  0.0003972907143179327,\n",
              "  0.0004329032963141799,\n",
              "  0.0004396742442622781,\n",
              "  0.00040052394615486264,\n",
              "  0.00038905252586118877,\n",
              "  0.00032757356530055404,\n",
              "  0.0003907025675289333,\n",
              "  0.00039589437074027956,\n",
              "  0.00035022629890590906,\n",
              "  0.00033155761775560677,\n",
              "  0.00040433643152937293,\n",
              "  0.0003804307780228555,\n",
              "  0.0003381081041879952,\n",
              "  0.00040236624772660434,\n",
              "  0.0003273774345871061,\n",
              "  0.0004316257545724511,\n",
              "  0.00036831889883615077,\n",
              "  0.00038273402606137097,\n",
              "  0.0003926499921362847,\n",
              "  0.00037554732989519835,\n",
              "  0.00038553407648578286,\n",
              "  0.0003848700725939125,\n",
              "  0.0003932704566977918,\n",
              "  0.00040220297523774207,\n",
              "  0.00038563518319278955,\n",
              "  0.00043914528214372694,\n",
              "  0.0004063152882736176,\n",
              "  0.0003823961887974292,\n",
              "  0.00037718325620517135,\n",
              "  0.0003978560562245548,\n",
              "  0.0003564594080671668,\n",
              "  0.00040520020411349833,\n",
              "  0.0003855703107547015,\n",
              "  0.0004248450859449804,\n",
              "  0.00041674234671518207,\n",
              "  0.0004020680207759142,\n",
              "  0.0004323161847423762,\n",
              "  0.00045217268052510917,\n",
              "  0.000469137798063457,\n",
              "  0.0004661087295971811,\n",
              "  0.00043928096420131624,\n",
              "  0.00042043073335662484,\n",
              "  0.0003888346254825592,\n",
              "  0.0004175248905085027,\n",
              "  0.0004602267290465534,\n",
              "  0.0004186734149698168,\n",
              "  0.0004266260948497802,\n",
              "  0.0004263651790097356,\n",
              "  0.000412164896260947,\n",
              "  0.0004158180090598762,\n",
              "  0.0004283097805455327,\n",
              "  0.00040044033084996045,\n",
              "  0.0003790708433371037,\n",
              "  0.00042829872108995914,\n",
              "  0.00040274718776345253,\n",
              "  0.0003777109959628433,\n",
              "  0.0004136271891184151,\n",
              "  0.00042094182572327554,\n",
              "  0.00042633331031538546,\n",
              "  0.0004032879660371691,\n",
              "  0.0004523717798292637,\n",
              "  0.0004024106601718813,\n",
              "  0.0004104171530343592,\n",
              "  0.00045239587780088186,\n",
              "  0.00040369556518271565,\n",
              "  0.00040832371450960636,\n",
              "  0.0003826709871646017,\n",
              "  0.0004253906663507223,\n",
              "  0.0004193436761852354,\n",
              "  0.0004136145580559969,\n",
              "  0.0003347083693370223,\n",
              "  0.000376749288989231,\n",
              "  0.00041133639751933515,\n",
              "  0.00043979976908303797,\n",
              "  0.0004939526552334428,\n",
              "  0.0004769967927131802,\n",
              "  0.0005204869084991515,\n",
              "  0.0004990041488781571,\n",
              "  0.000541163666639477,\n",
              "  0.000521609908901155,\n",
              "  0.0005364159005694091,\n",
              "  0.0005436943029053509,\n",
              "  0.0005311716813594103,\n",
              "  0.0004799898888450116,\n",
              "  0.0005356117035262287,\n",
              "  0.0004602856351993978,\n",
              "  0.0004975517513230443,\n",
              "  0.0005099409609101713,\n",
              "  0.0004767439095303416,\n",
              "  0.0005070198094472289,\n",
              "  0.0004848931566812098,\n",
              "  0.0005021405522711575,\n",
              "  0.0005546711618080735,\n",
              "  0.0005808105925098062,\n",
              "  0.0006295278435572982,\n",
              "  0.00058496103156358,\n",
              "  0.0006378980469889939,\n",
              "  0.0006805621087551117,\n",
              "  0.0006510780076496303,\n",
              "  0.0006181527860462666,\n",
              "  0.0006335712969303131,\n",
              "  0.0005982137518003583,\n",
              "  0.0008291996782645583,\n",
              "  ...])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "net = F2U_GAN()\n",
        "train_gen(net=net,\n",
        "      trainloader=trainloader,\n",
        "      epochs=50,\n",
        "      lr=0.0001,\n",
        "      device=\"cuda\",\n",
        "      latent_dim=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GOjPqx2oXoBZ"
      },
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(), 'F2U_GAN_50epochs.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCs7kMrjXoBZ"
      },
      "source": [
        "##### WGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xfvrkD1XoBa"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihvzrqgrXoBa"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "445r_BCSXoBa"
      },
      "outputs": [],
      "source": [
        "# Inicializar modelos\n",
        "D = Discriminator().to(device)\n",
        "G = Generator(latent_dim=LATENT_DIM).to(device)\n",
        "# Otimizadores\n",
        "optimizer_D = optim.Adam(D.parameters(), lr=LEARNING_RATE, betas=(BETA1, BETA2))\n",
        "optimizer_G = optim.Adam(G.parameters(), lr=LEARNING_RATE, betas=(BETA1, BETA2))\n",
        "\n",
        "scheduler_D = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=5, gamma=0.9)\n",
        "scheduler_G = torch.optim.lr_scheduler.StepLR(optimizer_G, step_size=5, gamma=0.9)\n",
        "\n",
        " # Função de perda Wasserstein\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    return fake_output.mean() - real_output.mean()\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return -fake_output.mean()\n",
        "\n",
        "# Função para calcular Gradient Penalty\n",
        "def gradient_penalty(D, real_samples, fake_samples):\n",
        "    alpha = torch.rand(real_samples.size(0), 1, 1, 1, device=device)\n",
        "    interpolated = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n",
        "    d_interpolated = D(interpolated)\n",
        "    gradients = torch.autograd.grad(outputs=d_interpolated, inputs=interpolated,\n",
        "                                    grad_outputs=torch.ones_like(d_interpolated),\n",
        "                                    create_graph=True, retain_graph=True)[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    return ((gradients.norm(2, dim=1) - 1) ** 2).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0HlgddkXoBb",
        "outputId": "86604d07-247f-4632-81bf-414a7463a137"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'LEARNING_RATE' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m gan \u001b[38;5;241m=\u001b[39m CGAN(latent_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 2\u001b[0m optimizer_D \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(gan\u001b[38;5;241m.\u001b[39mdiscriminator\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[43mLEARNING_RATE\u001b[49m, betas\u001b[38;5;241m=\u001b[39m(BETA1, BETA2))\n\u001b[1;32m      3\u001b[0m optimizer_G \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(gan\u001b[38;5;241m.\u001b[39mgenerator\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE, betas\u001b[38;5;241m=\u001b[39m(BETA1, BETA2))\n\u001b[1;32m      5\u001b[0m scheduler_D \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer_D, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'LEARNING_RATE' is not defined"
          ]
        }
      ],
      "source": [
        "gan = CGAN(latent_dim=128).to(device)\n",
        "optimizer_D = torch.optim.Adam(gan.discriminator.parameters(), lr=LEARNING_RATE, betas=(BETA1, BETA2))\n",
        "optimizer_G = torch.optim.Adam(gan.generator.parameters(), lr=LEARNING_RATE, betas=(BETA1, BETA2))\n",
        "\n",
        "scheduler_D = torch.optim.lr_scheduler.StepLR(optim_D, step_size=5, gamma=0.9)\n",
        "scheduler_G = torch.optim.lr_scheduler.StepLR(optimizer_G, step_size=5, gamma=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUGhPPWsXoBb"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7M7HXKbXoBc"
      },
      "outputs": [],
      "source": [
        "# Treinamento\n",
        "historico_metricas = []\n",
        "wgan = True\n",
        "epoch_bar = tqdm(range(EPOCHS), desc=\"Treinamento\", leave=True, position=0)\n",
        "for epoch in epoch_bar:\n",
        "\n",
        "    print(f\"\\n🔹 Epoch {epoch+1}/{EPOCHS}\")\n",
        "    G_loss = 0\n",
        "    D_loss = 0\n",
        "    batches = 0\n",
        "\n",
        "    batch_bar = tqdm(trainloader_reduzido, desc=\"Batches\", leave=False, position=1)\n",
        "\n",
        "    start_time = time.time()\n",
        "    for real_images, labels in batch_bar:\n",
        "        real_images = real_images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch = real_images.size(0)\n",
        "        fake_labels = torch.randint(0, NUM_CLASSES, (batch,), device=device)\n",
        "        z = torch.randn(batch, LATENT_DIM).to(device)\n",
        "        optimizer_D.zero_grad()\n",
        "        if wgan:\n",
        "            labels = torch.nn.functional.one_hot(labels, NUM_CLASSES).float().to(device)\n",
        "            fake_labels = torch.nn.functional.one_hot(fake_labels, NUM_CLASSES).float()\n",
        "\n",
        "            # Adicionar labels ao real_images para treinamento do Discriminador\n",
        "            image_labels = labels.view(labels.size(0), NUM_CLASSES, 1, 1).expand(-1, -1, 28, 28)\n",
        "            image_fake_labels = fake_labels.view(fake_labels.size(0), NUM_CLASSES, 1, 1).expand(-1, -1, 28, 28)\n",
        "\n",
        "            real_images = torch.cat([real_images, image_labels], dim=1)\n",
        "\n",
        "            # Treinar Discriminador\n",
        "            z = torch.cat([z, fake_labels], dim=1)\n",
        "            fake_images = G(z).detach()\n",
        "            fake_images = torch.cat([fake_images, image_fake_labels], dim=1)\n",
        "\n",
        "            D(real_images)\n",
        "            loss_D = discriminator_loss(D(real_images), D(fake_images)) + GP_SCALE * gradient_penalty(D, real_images, fake_images)\n",
        "\n",
        "        else:\n",
        "            real_ident = torch.full((batch, 1), 1., device=device)\n",
        "            fake_ident = torch.full((batch, 1), 0., device=device)\n",
        "            x_fake = gan(z, fake_labels)\n",
        "\n",
        "            y_real = gan(real_images, labels)\n",
        "            d_real_loss = gan.loss(y_real, real_ident)\n",
        "            y_fake_d = gan(x_fake.detach(), fake_labels)\n",
        "            d_fake_loss = gan.loss(y_fake_d, fake_ident)\n",
        "            loss_D = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "        loss_D.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # z = torch.randn(batch, LATENT_DIM).to(device)\n",
        "        # z = torch.cat([z, fake_labels], dim=1)\n",
        "        if wgan:\n",
        "            fake_images = G(z)\n",
        "            loss_G = generator_loss(D(torch.cat([fake_images, image_fake_labels], dim=1)))\n",
        "        else:\n",
        "            y_fake_g = gan(x_fake, fake_labels)\n",
        "            loss_G = gan.loss(y_fake_g, real_ident)\n",
        "\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        G_loss += loss_G.item()\n",
        "        D_loss += loss_D.item()\n",
        "        batches += BATCH_SIZE\n",
        "\n",
        "    avg_epoch_G_loss = G_loss/batches\n",
        "    avg_epoch_D_loss = D_loss/batches\n",
        "    # Create the dataset and dataloader\n",
        "    if wgan:\n",
        "        generated_dataset = GeneratedDataset(generator=G, num_samples=10000, latent_dim=LATENT_DIM, num_classes=10, device=device)\n",
        "    else:\n",
        "        generated_dataset = GeneratedDataset(generator=gan, num_samples=10000, latent_dim=LATENT_DIM, num_classes=10, device=device)\n",
        "    generated_dataloader = DataLoader(generated_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    net = Net()\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
        "    net.train()\n",
        "    for _ in range(5):\n",
        "        for data in generated_dataloader:\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    net.eval()\n",
        "    correct, loss = 0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images = batch[0]\n",
        "            labels = batch[1]\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "    accuracy = correct / len(testloader.dataset)\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "\n",
        "    epoch_bar.set_postfix({\n",
        "        \"D_loss\": f\"{avg_epoch_D_loss:.4f}\",\n",
        "        \"G_loss\": f\"{avg_epoch_G_loss:.4f}\",\n",
        "        \"Acc\": f\"{accuracy:.4f}\"\n",
        "    })\n",
        "\n",
        "    with open(\"Treino_GAN.txt\", \"a\") as f:\n",
        "            f.write(f\"Epoca: {epoch+1}, D_loss: {avg_epoch_D_loss:.4f}, G_loss: {avg_epoch_G_loss:.4f}, Acc: {accuracy:.4f}, Tempo: {total_time:.4f}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #Atualiza o learning_rate\n",
        "    scheduler_G.step()\n",
        "    scheduler_D.step()\n",
        "    print(f\"Após Epoch {epoch+1}, LR_G: {optimizer_G.param_groups[0]['lr']:.6f}, LR_D: {optimizer_D.param_groups[0]['lr']:.6f}\")\n",
        "    if wgan:\n",
        "         # Salvar modelo a cada época\n",
        "        torch.save({\"generator\": G.state_dict(), \"discriminator\": D.state_dict()}, f\"wgan_{epoch+1}e_{BATCH_SIZE}b_{LEARNING_RATE}lr.pth\")\n",
        "    else:\n",
        "        torch.save(gan.state_dict(), f\"cgan_{epoch+1}e_{BATCH_SIZE}b_{LEARNING_RATE}lr.pth\")\n",
        "\n",
        "print(\"✅ Treinamento Concluído!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8n9eIqhXoCF"
      },
      "outputs": [],
      "source": [
        "torch.save({\"generator\": G.state_dict(), \"discriminator\": D.state_dict()}, \"wgan_29e_64b_0.002lr.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyhBKXfHXoCI"
      },
      "source": [
        "##### Ajuste de hiperparametro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMuI-AbbXoCI"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8lgBKXqXoCI"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import optuna\n",
        "from optuna.importance import get_param_importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89xbKVJMXoCJ"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model=\"cgan\"\n",
        "EPOCHS = 5\n",
        "# Função Objetiva (a ser otimizada pelo Optuna)\n",
        "def objective(trial):\n",
        "    # Escolher os hiperparâmetros dentro de um intervalo\n",
        "    batch_size = trial.suggest_int(\"batch_size\", 16, 1024)\n",
        "    latent_dim = trial.suggest_int(\"latent_dim\", 10, 1000)\n",
        "    lr = trial.suggest_float(\"learning_rate\", 0.0001, 0.05, log=True)\n",
        "    beta1 = trial.suggest_float(\"beta1\", 0.0, 0.9)\n",
        "    beta2 = trial.suggest_float(\"beta2\", 0.8, 0.999)\n",
        "    global model\n",
        "    model = model.lower()\n",
        "    if model==\"wgan\":\n",
        "        gp_scale = trial.suggest_int(\"gp_scale\", 0, 100)\n",
        "\n",
        "    # Criar DataLoader com batch_size otimizado\n",
        "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Criar novos modelos e otimizadores\n",
        "    if model == \"wgan\":\n",
        "        D = Discriminator().to(device)\n",
        "        G = Generator(latent_dim=latent_dim).to(device)\n",
        "        optimizer_D = optim.Adam(D.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "        optimizer_G = optim.Adam(G.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "\n",
        "        G.train()\n",
        "        D.train()\n",
        "    elif model == \"cgan\":\n",
        "        gan = CGAN(latent_dim=latent_dim).to(device)\n",
        "        optimizer_D = torch.optim.Adam(gan.discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "        optimizer_G = torch.optim.Adam(gan.generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "\n",
        "    scheduler_D = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=5, gamma=0.9)\n",
        "    scheduler_G = torch.optim.lr_scheduler.StepLR(optimizer_G, step_size=5, gamma=0.9)\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_batches = 0\n",
        "\n",
        "    # Treinar por algumas épocas\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_loss = 0.0\n",
        "        epoch_batches = 0\n",
        "        progress_bar = tqdm(trainloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "\n",
        "        for real_images, labels in progress_bar:\n",
        "            real_images = real_images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            fake_labels = torch.randint(0, NUM_CLASSES, (real_images.size(0),), device=device)\n",
        "            z = torch.randn(real_images.size(0), latent_dim).to(device)\n",
        "            optimizer_D.zero_grad()\n",
        "            if model==\"wgan\":\n",
        "                labels = torch.nn.functional.one_hot(labels, NUM_CLASSES).float().to(device)\n",
        "                fake_labels = torch.nn.functional.one_hot(fake_labels, NUM_CLASSES).float()\n",
        "\n",
        "                # Adicionar labels ao real_images para treinamento do Discriminador\n",
        "                image_labels = labels.view(labels.size(0), NUM_CLASSES, 1, 1).expand(-1, -1, 28, 28)\n",
        "                image_fake_labels = fake_labels.view(fake_labels.size(0), NUM_CLASSES, 1, 1).expand(-1, -1, 28, 28)\n",
        "\n",
        "                real_images = torch.cat([real_images, image_labels], dim=1)\n",
        "\n",
        "                # Treinar Discriminador\n",
        "                z = torch.cat([z, labels], dim=1)\n",
        "                fake_images = G(z).detach()\n",
        "                fake_images = torch.cat([fake_images, image_labels], dim=1)\n",
        "\n",
        "                loss_D = discriminator_loss(D(real_images), D(fake_images)) + gp_scale * gradient_penalty(D, real_images, fake_images)\n",
        "\n",
        "\n",
        "            else:\n",
        "                real_ident = torch.full((real_images.size(0), 1), 1., device=device)\n",
        "                fake_ident = torch.full((real_images.size(0), 1), 0., device=device)\n",
        "                x_fake = gan(z, fake_labels)\n",
        "\n",
        "                y_real = gan(real_images, labels)\n",
        "                d_real_loss = gan.loss(y_real, real_ident)\n",
        "                y_fake_d = gan(x_fake.detach(), fake_labels)\n",
        "                d_fake_loss = gan.loss(y_fake_d, fake_ident)\n",
        "                loss_D = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "            loss_D.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "\n",
        "            # Treinar Gerador\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            if model==\"wgan\":\n",
        "                fake_images = G(z)\n",
        "                loss_G = generator_loss(D(torch.cat([fake_images, image_fake_labels], dim=1)))\n",
        "            else:\n",
        "                y_fake_g = gan(x_fake, fake_labels)\n",
        "                loss_G = gan.loss(y_fake_g, real_ident)\n",
        "\n",
        "            loss_G.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            epoch_loss += loss_G.item()\n",
        "            total_loss += loss_G.item()\n",
        "            total_batches += 1\n",
        "            epoch_batches += 1\n",
        "\n",
        "            progress_bar.set_postfix(d_loss=loss_D.item(), g_loss=loss_G.item())\n",
        "\n",
        "        # Calcular a loss média dessa época\n",
        "        epoch_avg_loss = epoch_loss / epoch_batches\n",
        "        # Reporta a loss média da época para pruning\n",
        "        trial.report(epoch_avg_loss, epoch)\n",
        "        if trial.should_prune() and epoch >=3:\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "        scheduler_G.step()\n",
        "        scheduler_D.step()\n",
        "        print(f\"Após Epoch {epoch+1}, LR_G: {optimizer_G.param_groups[0]['lr']:.6f}, LR_D: {optimizer_D.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "\n",
        "\n",
        "    avg_loss = total_loss / total_batches\n",
        "\n",
        "    return avg_loss  # Optuna tentará minimizar essa métrica\n",
        "\n",
        "# Criar estudo do Optuna e otimizar hiperparâmetros\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "# Exibir os melhores hiperparâmetros encontrados\n",
        "print(\"\\n🔹 Melhores Hiperparâmetros Encontrados:\")\n",
        "print(study.best_params)\n",
        "\n",
        "importance = get_param_importances(study)\n",
        "print(\"Hyperparameter Importances:\")\n",
        "for param, imp in importance.items():\n",
        "    print(f\"{param}: {imp:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt2EiBMCXoCL"
      },
      "source": [
        "#### Teste para qualidade visual das imagens geradas pelo modelo generativo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Hdas7twXoCM"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByyDvVxcXoCM"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "latent_dim = 128\n",
        "# random.seed(seed)\n",
        "# np.random.seed(seed)\n",
        "#torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "path = \"\"\n",
        "device = \"cpu\"\n",
        "net = CGAN(dataset=\"mnist\", latent_dim=latent_dim).to(device)\n",
        "net.load_state_dict(torch.load(f'{path}/model_round_5_mnist.pt'))\n",
        "# G = Generator(latent_dim=128)\n",
        "# G.load_state_dict(torch.load(\"wgan_5e_512b_0.002lr_0.5B1_0.9B2_10gp_128_ld.pth\")[\"generator\"])\n",
        "#net = CGAN()\n",
        "#net.load_state_dict(torch.load('CGAN_50epochs.pth'))\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "#net.eval()\n",
        "G.eval()\n",
        "# Assuming netG is your generator model, classes is the total number of classes, and latent_dim is the latent vector size\n",
        "examples_per_class = 5\n",
        "classes = 10\n",
        "batch_size = examples_per_class * classes  # Generate enough images to have `examples_per_class` for each class\n",
        "\n",
        "# Generate latent vectors and corresponding labels\n",
        "latent_vectors = torch.randn(batch_size, latent_dim, device=device)\n",
        "labels = torch.tensor([i for i in range(classes) for _ in range(examples_per_class)], device=device)\n",
        "labels = torch.nn.functional.one_hot(labels, NUM_CLASSES).float().to(device)\n",
        "\n",
        "# Generate images\n",
        "with torch.no_grad():\n",
        "    #generated_images = net(latent_vectors, labels)\n",
        "    generated_images = G(torch.cat([latent_vectors, labels], dim=1))\n",
        "\n",
        "# Criar uma figura com 10 linhas e 5 colunas de subplots\n",
        "fig, axes = plt.subplots(classes, examples_per_class, figsize=(5, 9))\n",
        "\n",
        "#fig.text(0.5, 0.98, f\"Round: {round_number} | Client: {client_id}\", ha=\"center\", fontsize=12)\n",
        "\n",
        "fig.text(0.5, 0.98, f\"Round: {5}\", ha=\"center\", fontsize=12)\n",
        "\n",
        "# Exibir as imagens nos subplots\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(generated_images[i, 0, :, :], cmap='gray')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "# Ajustar o layout antes de calcular as posições\n",
        "plt.tight_layout(rect=[0.05, 0, 1, 0.96])\n",
        "\n",
        "# Reduzir espaço entre colunas\n",
        "# plt.subplots_adjust(wspace=0.05)\n",
        "\n",
        "# Adicionar os rótulos das classes corretamente alinhados\n",
        "fig.canvas.draw()  # Atualiza a renderização para obter posições corretas\n",
        "for row in range(classes):\n",
        "    # Obter posição do subplot em coordenadas da figura\n",
        "    bbox = axes[row, 0].get_window_extent(fig.canvas.get_renderer())\n",
        "    pos = fig.transFigure.inverted().transform([(bbox.x0, bbox.y0), (bbox.x1, bbox.y1)])\n",
        "    center_y = (pos[0, 1] + pos[1, 1]) / 2  # Centro exato da linha\n",
        "\n",
        "    # Adicionar o rótulo\n",
        "    fig.text(0.04, center_y, str(row), va='center', fontsize=12, color='black')\n",
        "    plt.savefig(f\"{path}teste.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtY4KCiWXoCO"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import Image as IPImage, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6PlY_TYXoCP"
      },
      "outputs": [],
      "source": [
        "def create_gif(image_files, output_path, duration=200):\n",
        "    \"\"\"\n",
        "    Cria um GIF animado a partir de uma sequência de imagens.\n",
        "\n",
        "    Args:\n",
        "        image_files (list): Lista de caminhos das imagens.\n",
        "        output_path (str): Caminho para salvar o GIF.\n",
        "        duration (int): Tempo de exibição de cada frame (em ms).\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    frames = [Image.open(img) for img in image_files]  # Carregar imagens\n",
        "    frames[0].save(output_path, format=\"GIF\", save_all=True, append_images=frames[1:], duration=duration, loop=0)\n",
        "    display(IPImage(filename=output_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txiXYjHEXoCP"
      },
      "outputs": [],
      "source": [
        "# Exemplo de uso\n",
        "image_files = [\"../imagens geradas/mnist_CGAN_r0_100e_64_100z_10c_0.0001lr_niid_01dir.png\",\n",
        "               \"../imagens geradas/mnist_CGAN_r1_100e_64_100z_10c_0.0001lr_niid_01dir.png\",\n",
        "               \"../imagens geradas/mnist_CGAN_r2_100e_64_100z_10c_0.0001lr_niid_01dir.png\",\n",
        "               \"../imagens geradas/mnist_CGAN_r3_100e_64_100z_10c_0.0001lr_niid_01dir.png\",\n",
        "               \"../imagens geradas/mnist_CGAN_r4_100e_64_100z_10c_0.0001lr_niid_01dir.png\"]\n",
        "create_gif(image_files, \"global.gif\", duration=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ra5PcELgXoCQ"
      },
      "outputs": [],
      "source": [
        "def create_federated_collage(\n",
        "    agg_image_paths,       # Lista de caminhos para as imagens grandes (1 por round)\n",
        "    clients_image_paths,   # Lista de listas: para cada round, lista de caminhos de imagens de clientes\n",
        "    big_scale=2,           # Escala da imagem grande em relação à imagem pequena\n",
        "    small_size=(500, 900),   # Tamanho desejado para cada imagem pequena (largura, altura)\n",
        "    h_gap=0,               # Espaço horizontal entre bloco de imagens\n",
        "    background_color=(255, 255, 255),\n",
        "    save_path=\"collage.png\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Cria um mosaico onde cada round tem:\n",
        "      - 1 imagem \"agregada\" (maior) à esquerda\n",
        "      - N imagens de cliente empilhadas verticalmente à direita\n",
        "\n",
        "    Parâmetros:\n",
        "      agg_image_paths      : lista de strings (caminhos) para as imagens agregadas (1 por round)\n",
        "      clients_image_paths  : lista de listas de strings. Cada sublista é a lista de caminhos das imagens de cada cliente daquele round\n",
        "      big_scale            : fator de escala da imagem grande em relação às pequenas\n",
        "      small_size           : (largura, altura) desejado para cada imagem pequena\n",
        "      background_color     : cor de fundo do mosaico (RGB)\n",
        "      save_path            : caminho do arquivo final a ser salvo\n",
        "\n",
        "    Retorna:\n",
        "      Um objeto PIL.Image com o mosaico criado.\n",
        "    \"\"\"\n",
        "    # Verifica se temos a mesma quantidade de rounds em agg_image_paths e clients_image_paths\n",
        "    assert len(agg_image_paths) == len(clients_image_paths), \\\n",
        "        \"Número de imagens agregadas deve bater com número de listas de clientes.\"\n",
        "\n",
        "    # Carrega todas as imagens agregadas (rounds)\n",
        "    agg_images = []\n",
        "    for path in agg_image_paths:\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        agg_images.append(img)\n",
        "\n",
        "    # Carrega todas as imagens de clientes\n",
        "    # clients_image_paths é lista de listas, cada sublista para um round\n",
        "    client_images = []\n",
        "    for round_paths in clients_image_paths:\n",
        "        imgs = [Image.open(p).convert(\"RGB\") for p in round_paths]\n",
        "        client_images.append(imgs)\n",
        "\n",
        "    # Dimensiona as imagens pequenas para small_size\n",
        "    # e as grandes para (big_scale * small_size)\n",
        "    small_w, small_h = small_size\n",
        "    big_w, big_h = big_scale * small_w, big_scale * small_h\n",
        "\n",
        "    # Faz o resize de todas as imagens\n",
        "    for i, img in enumerate(agg_images):\n",
        "        agg_images[i] = img.resize((big_w, big_h), Image.Resampling.LANCZOS)\n",
        "\n",
        "    for i, imgs in enumerate(client_images):\n",
        "        resized_list = []\n",
        "        for im in imgs:\n",
        "            resized_list.append(im.resize((small_w, small_h), Image.Resampling.LANCZOS))\n",
        "        client_images[i] = resized_list\n",
        "\n",
        "    # Calcula quantos rounds e quantos clientes\n",
        "    num_rounds = len(agg_images)\n",
        "\n",
        "    # Para cada round, vamos colocar:\n",
        "    # - Imagem grande (largura big_w, altura big_h)\n",
        "    # - N clientes empilhados (cada um small_h de altura, total N * small_h)\n",
        "    # A largura de cada \"bloco\" de round = (big_w + small_w)\n",
        "    # A altura do bloco = max(big_h, N * small_h) (para acomodar todas as imagens)\n",
        "\n",
        "    # Descobre o número máximo de clientes em qualquer round (para dimensionar corretamente)\n",
        "    max_clients = max(len(imgs) for imgs in client_images)\n",
        "\n",
        "    # Altura total do bloco para cada round\n",
        "    block_h = max(big_h + small_h, max_clients * small_h)\n",
        "    block_w = big_w + small_w  # Largura do bloco do round\n",
        "\n",
        "    # Largura total = num_rounds * block_w\n",
        "    # Altura total = block_h (vamos colocar rounds lado a lado)\n",
        "    total_w = num_rounds * block_w  + h_gap*2*num_rounds-1\n",
        "    total_h = block_h\n",
        "\n",
        "    # Cria imagem de fundo\n",
        "    collage = Image.new(\"RGB\", (total_w, total_h), color=background_color)\n",
        "\n",
        "    # Posiciona cada round\n",
        "    for r in range(num_rounds):\n",
        "        # Posição x para este round\n",
        "        x_offset = r * block_w + 2*r*h_gap\n",
        "\n",
        "        # Coloca a imagem grande (agg)\n",
        "        collage.paste(agg_images[r], (x_offset, small_h))\n",
        "\n",
        "        # Agora empilha as imagens de cliente ao lado (à direita da imagem grande)\n",
        "        y_offset = 0\n",
        "        for c_img in client_images[r]:\n",
        "            collage.paste(c_img, (x_offset + big_w + h_gap, y_offset))\n",
        "            y_offset += small_h\n",
        "\n",
        "    # Salva o resultado\n",
        "    collage.save(save_path)\n",
        "    print(f\"Mosaico criado e salvo em: {save_path}\")\n",
        "\n",
        "    return collage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoP558u6XoCR"
      },
      "outputs": [],
      "source": [
        "path = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p8mhqvHXoCR"
      },
      "outputs": [],
      "source": [
        "agg_image_paths = [f\"{path}mnist_CGAN_r{i}_10e_64b_100z_4c_0.0001lr_niid_01dir.png\" for i in range(10, 20)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wWETQNqXoCS"
      },
      "outputs": [],
      "source": [
        "client_image_paths = [[f\"{path}mnist_CGAN_r{i}_10e_64b_100z_4c_0.0001lr_niid_01dir_cliente{j}.png\" for j in range(4)] for i in range(11, 21)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJztr1mtXoCT"
      },
      "outputs": [],
      "source": [
        "create_federated_collage(\n",
        "    agg_image_paths=agg_image_paths,\n",
        "    clients_image_paths=client_image_paths,\n",
        "    big_scale=2,\n",
        "    small_size=(500, 900),\n",
        "    h_gap=80,\n",
        "    background_color=(255, 255, 255),\n",
        "    save_path=f\"{path}CGAN_evol.png\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu8-avfIXoCT"
      },
      "source": [
        "### FID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI2FOV2rXoCU"
      },
      "source": [
        "### Importacoes, classes e configuracoes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7zeFBY8XoCV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjVnx-3FXoCX"
      },
      "outputs": [],
      "source": [
        "batch_size = 50\n",
        "num_cpus = os.cpu_count()\n",
        "num_workers = min(8, num_cpus,0)\n",
        "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
        "dims = 2048"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iz1K-r-OXoCY"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhtBYnxkXoCY"
      },
      "outputs": [],
      "source": [
        "def _inception_v3(*args, **kwargs):\n",
        "    \"\"\"Wraps `torchvision.models.inception_v3`\"\"\"\n",
        "    try:\n",
        "        version = tuple(map(int, torchvision.__version__.split(\".\")[:2]))\n",
        "    except ValueError:\n",
        "        # Just a caution against weird version strings\n",
        "        version = (0,)\n",
        "\n",
        "    # Skips default weight inititialization if supported by torchvision\n",
        "    # version. See https://github.com/mseitzer/pytorch-fid/issues/28.\n",
        "    if version >= (0, 6):\n",
        "        kwargs[\"init_weights\"] = False\n",
        "\n",
        "    # Backwards compatibility: `weights` argument was handled by `pretrained`\n",
        "    # argument prior to version 0.13.\n",
        "    if version < (0, 13) and \"weights\" in kwargs:\n",
        "        if kwargs[\"weights\"] == \"DEFAULT\":\n",
        "            kwargs[\"pretrained\"] = True\n",
        "        elif kwargs[\"weights\"] is None:\n",
        "            kwargs[\"pretrained\"] = False\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"weights=={} not supported in torchvision {}\".format(\n",
        "                    kwargs[\"weights\"], torchvision.__version__\n",
        "                )\n",
        "            )\n",
        "        del kwargs[\"weights\"]\n",
        "\n",
        "    return torchvision.models.inception_v3(*args, **kwargs)\n",
        "\n",
        "\n",
        "def fid_inception_v3():\n",
        "    \"\"\"Build pretrained Inception model for FID computation\n",
        "\n",
        "    The Inception model for FID computation uses a different set of weights\n",
        "    and has a slightly different structure than torchvision's Inception.\n",
        "\n",
        "    This method first constructs torchvision's Inception and then patches the\n",
        "    necessary parts that are different in the FID Inception model.\n",
        "    \"\"\"\n",
        "    inception = _inception_v3(num_classes=1008, aux_logits=False, weights=None)\n",
        "    inception.Mixed_5b = FIDInceptionA(192, pool_features=32)\n",
        "    inception.Mixed_5c = FIDInceptionA(256, pool_features=64)\n",
        "    inception.Mixed_5d = FIDInceptionA(288, pool_features=64)\n",
        "    inception.Mixed_6b = FIDInceptionC(768, channels_7x7=128)\n",
        "    inception.Mixed_6c = FIDInceptionC(768, channels_7x7=160)\n",
        "    inception.Mixed_6d = FIDInceptionC(768, channels_7x7=160)\n",
        "    inception.Mixed_6e = FIDInceptionC(768, channels_7x7=192)\n",
        "    inception.Mixed_7b = FIDInceptionE_1(1280)\n",
        "    inception.Mixed_7c = FIDInceptionE_2(2048)\n",
        "\n",
        "    state_dict = load_state_dict_from_url(\"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\", progress=True)\n",
        "    inception.load_state_dict(state_dict)\n",
        "    return inception\n",
        "\n",
        "\n",
        "class FIDInceptionA(torchvision.models.inception.InceptionA):\n",
        "    \"\"\"InceptionA block patched for FID computation\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, pool_features):\n",
        "        super(FIDInceptionA, self).__init__(in_channels, pool_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "\n",
        "        branch5x5 = self.branch5x5_1(x)\n",
        "        branch5x5 = self.branch5x5_2(branch5x5)\n",
        "\n",
        "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
        "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
        "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
        "\n",
        "        # Patch: Tensorflow's average pool does not use the padded zero's in\n",
        "        # its average calculation\n",
        "        branch_pool = F.avg_pool2d(\n",
        "            x, kernel_size=3, stride=1, padding=1, count_include_pad=False\n",
        "        )\n",
        "        branch_pool = self.branch_pool(branch_pool)\n",
        "\n",
        "        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "\n",
        "class FIDInceptionC(torchvision.models.inception.InceptionC):\n",
        "    \"\"\"InceptionC block patched for FID computation\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, channels_7x7):\n",
        "        super(FIDInceptionC, self).__init__(in_channels, channels_7x7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "\n",
        "        branch7x7 = self.branch7x7_1(x)\n",
        "        branch7x7 = self.branch7x7_2(branch7x7)\n",
        "        branch7x7 = self.branch7x7_3(branch7x7)\n",
        "\n",
        "        branch7x7dbl = self.branch7x7dbl_1(x)\n",
        "        branch7x7dbl = self.branch7x7dbl_2(branch7x7dbl)\n",
        "        branch7x7dbl = self.branch7x7dbl_3(branch7x7dbl)\n",
        "        branch7x7dbl = self.branch7x7dbl_4(branch7x7dbl)\n",
        "        branch7x7dbl = self.branch7x7dbl_5(branch7x7dbl)\n",
        "\n",
        "        # Patch: Tensorflow's average pool does not use the padded zero's in\n",
        "        # its average calculation\n",
        "        branch_pool = F.avg_pool2d(\n",
        "            x, kernel_size=3, stride=1, padding=1, count_include_pad=False\n",
        "        )\n",
        "        branch_pool = self.branch_pool(branch_pool)\n",
        "\n",
        "        outputs = [branch1x1, branch7x7, branch7x7dbl, branch_pool]\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "\n",
        "class FIDInceptionE_1(torchvision.models.inception.InceptionE):\n",
        "    \"\"\"First InceptionE block patched for FID computation\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels):\n",
        "        super(FIDInceptionE_1, self).__init__(in_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "\n",
        "        branch3x3 = self.branch3x3_1(x)\n",
        "        branch3x3 = [\n",
        "            self.branch3x3_2a(branch3x3),\n",
        "            self.branch3x3_2b(branch3x3),\n",
        "        ]\n",
        "        branch3x3 = torch.cat(branch3x3, 1)\n",
        "\n",
        "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
        "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
        "        branch3x3dbl = [\n",
        "            self.branch3x3dbl_3a(branch3x3dbl),\n",
        "            self.branch3x3dbl_3b(branch3x3dbl),\n",
        "        ]\n",
        "        branch3x3dbl = torch.cat(branch3x3dbl, 1)\n",
        "\n",
        "        # Patch: Tensorflow's average pool does not use the padded zero's in\n",
        "        # its average calculation\n",
        "        branch_pool = F.avg_pool2d(\n",
        "            x, kernel_size=3, stride=1, padding=1, count_include_pad=False\n",
        "        )\n",
        "        branch_pool = self.branch_pool(branch_pool)\n",
        "\n",
        "        outputs = [branch1x1, branch3x3, branch3x3dbl, branch_pool]\n",
        "        return torch.cat(outputs, 1)\n",
        "\n",
        "\n",
        "class FIDInceptionE_2(torchvision.models.inception.InceptionE):\n",
        "    \"\"\"Second InceptionE block patched for FID computation\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels):\n",
        "        super(FIDInceptionE_2, self).__init__(in_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "\n",
        "        branch3x3 = self.branch3x3_1(x)\n",
        "        branch3x3 = [\n",
        "            self.branch3x3_2a(branch3x3),\n",
        "            self.branch3x3_2b(branch3x3),\n",
        "        ]\n",
        "        branch3x3 = torch.cat(branch3x3, 1)\n",
        "\n",
        "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
        "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
        "        branch3x3dbl = [\n",
        "            self.branch3x3dbl_3a(branch3x3dbl),\n",
        "            self.branch3x3dbl_3b(branch3x3dbl),\n",
        "        ]\n",
        "        branch3x3dbl = torch.cat(branch3x3dbl, 1)\n",
        "\n",
        "        # Patch: The FID Inception model uses max pooling instead of average\n",
        "        # pooling. This is likely an error in this specific Inception\n",
        "        # implementation, as other Inception models use average pooling here\n",
        "        # (which matches the description in the paper).\n",
        "        branch_pool = F.max_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
        "        branch_pool = self.branch_pool(branch_pool)\n",
        "\n",
        "        outputs = [branch1x1, branch3x3, branch3x3dbl, branch_pool]\n",
        "        return torch.cat(outputs, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgZPF8WdXoCZ"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VC2LlVt4XoCa"
      },
      "outputs": [],
      "source": [
        "class InceptionV3(nn.Module):\n",
        "    \"\"\"Pretrained InceptionV3 network returning feature maps\"\"\"\n",
        "\n",
        "    # Index of default block of inception to return,\n",
        "    # corresponds to output of final average pooling\n",
        "    DEFAULT_BLOCK_INDEX = 3\n",
        "\n",
        "    # Maps feature dimensionality to their output blocks indices\n",
        "    BLOCK_INDEX_BY_DIM = {\n",
        "        64: 0,  # First max pooling features\n",
        "        192: 1,  # Second max pooling featurs\n",
        "        768: 2,  # Pre-aux classifier features\n",
        "        2048: 3,  # Final average pooling features\n",
        "    }\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        output_blocks=(DEFAULT_BLOCK_INDEX,),\n",
        "        resize_input=True,\n",
        "        normalize_input=True,\n",
        "        requires_grad=False,\n",
        "        use_fid_inception=True,\n",
        "    ):\n",
        "        \"\"\"Build pretrained InceptionV3\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        output_blocks : list of int\n",
        "            Indices of blocks to return features of. Possible values are:\n",
        "                - 0: corresponds to output of first max pooling\n",
        "                - 1: corresponds to output of second max pooling\n",
        "                - 2: corresponds to output which is fed to aux classifier\n",
        "                - 3: corresponds to output of final average pooling\n",
        "        resize_input : bool\n",
        "            If true, bilinearly resizes input to width and height 299 before\n",
        "            feeding input to model. As the network without fully connected\n",
        "            layers is fully convolutional, it should be able to handle inputs\n",
        "            of arbitrary size, so resizing might not be strictly needed\n",
        "        normalize_input : bool\n",
        "            If true, scales the input from range (0, 1) to the range the\n",
        "            pretrained Inception network expects, namely (-1, 1)\n",
        "        requires_grad : bool\n",
        "            If true, parameters of the model require gradients. Possibly useful\n",
        "            for finetuning the network\n",
        "        use_fid_inception : bool\n",
        "            If true, uses the pretrained Inception model used in Tensorflow's\n",
        "            FID implementation. If false, uses the pretrained Inception model\n",
        "            available in torchvision. The FID Inception model has different\n",
        "            weights and a slightly different structure from torchvision's\n",
        "            Inception model. If you want to compute FID scores, you are\n",
        "            strongly advised to set this parameter to true to get comparable\n",
        "            results.\n",
        "        \"\"\"\n",
        "        super(InceptionV3, self).__init__()\n",
        "\n",
        "        self.resize_input = resize_input\n",
        "        self.normalize_input = normalize_input\n",
        "        self.output_blocks = sorted(output_blocks)\n",
        "        self.last_needed_block = max(output_blocks)\n",
        "\n",
        "        assert self.last_needed_block <= 3, \"Last possible output block index is 3\"\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "\n",
        "        if use_fid_inception:\n",
        "            inception = fid_inception_v3()\n",
        "        else:\n",
        "            inception = _inception_v3(weights=\"DEFAULT\")\n",
        "\n",
        "        # Block 0: input to maxpool1\n",
        "        block0 = [\n",
        "            inception.Conv2d_1a_3x3,\n",
        "            inception.Conv2d_2a_3x3,\n",
        "            inception.Conv2d_2b_3x3,\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        ]\n",
        "        self.blocks.append(nn.Sequential(*block0))\n",
        "\n",
        "        # Block 1: maxpool1 to maxpool2\n",
        "        if self.last_needed_block >= 1:\n",
        "            block1 = [\n",
        "                inception.Conv2d_3b_1x1,\n",
        "                inception.Conv2d_4a_3x3,\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            ]\n",
        "            self.blocks.append(nn.Sequential(*block1))\n",
        "\n",
        "        # Block 2: maxpool2 to aux classifier\n",
        "        if self.last_needed_block >= 2:\n",
        "            block2 = [\n",
        "                inception.Mixed_5b,\n",
        "                inception.Mixed_5c,\n",
        "                inception.Mixed_5d,\n",
        "                inception.Mixed_6a,\n",
        "                inception.Mixed_6b,\n",
        "                inception.Mixed_6c,\n",
        "                inception.Mixed_6d,\n",
        "                inception.Mixed_6e,\n",
        "            ]\n",
        "            self.blocks.append(nn.Sequential(*block2))\n",
        "\n",
        "        # Block 3: aux classifier to final avgpool\n",
        "        if self.last_needed_block >= 3:\n",
        "            block3 = [\n",
        "                inception.Mixed_7a,\n",
        "                inception.Mixed_7b,\n",
        "                inception.Mixed_7c,\n",
        "                nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
        "            ]\n",
        "            self.blocks.append(nn.Sequential(*block3))\n",
        "\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = requires_grad\n",
        "\n",
        "    def forward(self, inp):\n",
        "        \"\"\"Get Inception feature maps\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        inp : torch.autograd.Variable\n",
        "            Input tensor of shape Bx3xHxW. Values are expected to be in\n",
        "            range (0, 1)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List of torch.autograd.Variable, corresponding to the selected output\n",
        "        block, sorted ascending by index\n",
        "        \"\"\"\n",
        "        outp = []\n",
        "        x = inp\n",
        "\n",
        "        if self.resize_input:\n",
        "            x = F.interpolate(x, size=(299, 299), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "        if self.normalize_input:\n",
        "            x = 2 * x - 1  # Scale from range (0, 1) to range (-1, 1)\n",
        "\n",
        "        for idx, block in enumerate(self.blocks):\n",
        "            x = block(x)\n",
        "            if idx in self.output_blocks:\n",
        "                outp.append(x)\n",
        "\n",
        "            if idx == self.last_needed_block:\n",
        "                break\n",
        "\n",
        "        return outp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tOV_I6AXoCc"
      },
      "source": [
        "#### Calculo da distribuicao gerada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snRXJWMYXoCc"
      },
      "outputs": [],
      "source": [
        "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36YTdjuXXoCc"
      },
      "outputs": [],
      "source": [
        "model = InceptionV3([block_idx]).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIXrWCu6XoCd"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDvQF-u3XoCd"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2Ia0an8XoCd"
      },
      "outputs": [],
      "source": [
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYgFFYEcXoCd"
      },
      "outputs": [],
      "source": [
        "class ImagePathDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, files, transforms=None):\n",
        "        self.files = files\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        path = self.files[i]\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        if self.transforms is not None:\n",
        "            img = self.transforms(img)\n",
        "        return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI3bQrqaXoCd"
      },
      "source": [
        "Por imagens geradas prontas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOUTdiayXoCe"
      },
      "outputs": [],
      "source": [
        "path = \"../imagens geradas/cgan_samples\"\n",
        "path = pathlib.Path(path)\n",
        "files = sorted(file for file in path.glob(\"*.png\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCrv8my3XoCe"
      },
      "outputs": [],
      "source": [
        "pred_arr = np.empty((len(files), dims))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0LGyDp9XoCe"
      },
      "outputs": [],
      "source": [
        "dataset = ImagePathDataset(files, transforms=torchvision.transforms.ToTensor())\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtFXwOHQXoCe"
      },
      "source": [
        "Por modelo pre-treinado gerando imagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiwYtDuvXoCe"
      },
      "outputs": [],
      "source": [
        "class CGAN(nn.Module):\n",
        "    def __init__(self, dataset=\"mnist\", img_size=28, latent_dim=100):\n",
        "        super(CGAN, self).__init__()\n",
        "        if dataset == \"mnist\":\n",
        "            self.classes = 10\n",
        "            self.channels = 1\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes)\n",
        "        self.adv_loss = torch.nn.BCELoss()\n",
        "\n",
        "\n",
        "        self.generator = nn.Sequential(\n",
        "            *self._create_layer_gen(self.latent_dim + self.classes, 128, False),\n",
        "            *self._create_layer_gen(128, 256),\n",
        "            *self._create_layer_gen(256, 512),\n",
        "            *self._create_layer_gen(512, 1024),\n",
        "            nn.Linear(1024, int(np.prod(self.img_shape))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.discriminator = nn.Sequential(\n",
        "            *self._create_layer_disc(self.classes + int(np.prod(self.img_shape)), 1024, False, True),\n",
        "            *self._create_layer_disc(1024, 512, True, True),\n",
        "            *self._create_layer_disc(512, 256, True, True),\n",
        "            *self._create_layer_disc(256, 128, False, False),\n",
        "            *self._create_layer_disc(128, 1, False, False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        #self._initialize_weights()\n",
        "\n",
        "    def _create_layer_gen(self, size_in, size_out, normalize=True):\n",
        "        layers = [nn.Linear(size_in, size_out)]\n",
        "        if normalize:\n",
        "            layers.append(nn.BatchNorm1d(size_out))\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return layers\n",
        "\n",
        "    def _create_layer_disc(self, size_in, size_out, drop_out=True, act_func=True):\n",
        "        layers = [nn.Linear(size_in, size_out)]\n",
        "        if drop_out:\n",
        "            layers.append(nn.Dropout(0.4))\n",
        "        if act_func:\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return layers\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        # Itera sobre todos os módulos da rede geradora\n",
        "        for m in self.generator:\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "    def forward(self, input, labels):\n",
        "        if input.dim() == 2:\n",
        "            z = torch.cat((self.label_embedding(labels), input), -1)\n",
        "            x = self.generator(z)\n",
        "            x = x.view(x.size(0), *self.img_shape) #Em\n",
        "            return x\n",
        "        elif input.dim() == 4:\n",
        "            x = torch.cat((input.view(input.size(0), -1), self.label_embedding(labels)), -1)\n",
        "            return self.discriminator(x)\n",
        "\n",
        "    def loss(self, output, label):\n",
        "        return self.adv_loss(output, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UnF0P-uXoCf"
      },
      "outputs": [],
      "source": [
        "cgan = CGAN()\n",
        "cgan.load_state_dict(torch.load(\"CGAN_50epochs.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU6PYq0JXoCf"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms.functional import to_pil_image\n",
        "from datasets import Dataset, Features, ClassLabel\n",
        "from datasets import Image as IMG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YmuBLHNXoCf"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class GeneratedDataset(Dataset):\n",
        "    def __init__(self, generator, num_samples, latent_dim, num_classes, device):\n",
        "        self.generator = generator\n",
        "        self.num_samples = num_samples\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.device = device\n",
        "        self.model = type(self.generator).__name__\n",
        "        self.images = self.generate_data()\n",
        "        self.classes = [i for i in range(self.num_classes)]\n",
        "\n",
        "\n",
        "    def generate_data(self):\n",
        "        gen_imgs = {}\n",
        "        self.generator.eval()\n",
        "        labels = {c: torch.tensor([c for i in range(self.num_samples)], device=self.device) for c in range(self.num_classes)}\n",
        "        for c, label in labels.items():\n",
        "          if self.model == 'Generator':\n",
        "              labels_one_hot = F.one_hot(label, self.num_classes).float().to(self.device) #\n",
        "          z = torch.randn(self.num_samples, self.latent_dim, device=self.device)\n",
        "          with torch.no_grad():\n",
        "              if self.model == 'Generator':\n",
        "                  gen_imgs_class = self.generator(torch.cat([z, labels_one_hot], dim=1))\n",
        "              elif self.model == 'CGAN':\n",
        "                  gen_imgs_class = self.generator(z, label)\n",
        "          gen_imgs[c] = gen_imgs_class\n",
        "\n",
        "        return gen_imgs\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples * self.num_classes\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Mapear o índice global para (classe, índice interno)\n",
        "        class_idx = idx // self.num_samples\n",
        "        sample_idx = idx % self.num_samples\n",
        "        # Retorna apenas a imagem (sem o rótulo)\n",
        "        return self.images[class_idx][sample_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIh5F0qqXoCf"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "num_samples = 2048\n",
        "latent_dim = 100\n",
        "\n",
        "# Create the dataset and dataloader\n",
        "generated_dataset = GeneratedDataset(generator=cgan, num_samples=num_samples, latent_dim=latent_dim, num_classes=10, device=\"cpu\")\n",
        "gen_dataset = generated_dataset.images\n",
        "\n",
        "for c in gen_dataset.keys():\n",
        "    gen_dataset[c] = (gen_dataset[c] + 1) / 2\n",
        "    gen_dataset[c] = gen_dataset[c].repeat(1, 3, 1, 1)\n",
        "# # Ajustar para o intervalo [0, 1]\n",
        "# gen_dataset = (gen_dataset + 1) / 2\n",
        "# Expandir o canal para RGB (replicando o canal 1 para 3)\n",
        "# gen_dataset = gen_dataset.repeat(1, 3, 1, 1)  # Agora tem shape [2050, 3, 28, 28]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceinxLQKXoCf"
      },
      "outputs": [],
      "source": [
        "dataloaders = [torch.utils.data.DataLoader(gen_dataset[c], batch_size=batch_size, num_workers=num_workers, shuffle=False) for c in range(10)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwsjJ5fsXoCh"
      },
      "source": [
        "Calculo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQweQMlEXoCh"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2x0DraxXoCi"
      },
      "outputs": [],
      "source": [
        "mus_gen = []\n",
        "sigmas_gen = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgtpBE95XoCl"
      },
      "outputs": [],
      "source": [
        "for c in range(10):\n",
        "  pred_arr = np.empty((len(gen_dataset[c]), dims))\n",
        "  start_idx = 0\n",
        "  for batch in tqdm(dataloaders[c]):\n",
        "          batch = batch.to(device)\n",
        "\n",
        "          with torch.no_grad():\n",
        "              pred = model(batch)[0]\n",
        "\n",
        "          # If model output is not scalar, apply global spatial average pooling.\n",
        "          # This happens if you choose a dimensionality not equal 2048.\n",
        "          if pred.size(2) != 1 or pred.size(3) != 1:\n",
        "              pred = F.adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
        "\n",
        "          pred = pred.squeeze(3).squeeze(2).cpu().numpy()\n",
        "\n",
        "          pred_arr[start_idx : start_idx + pred.shape[0]] = pred\n",
        "\n",
        "          start_idx = start_idx + pred.shape[0]\n",
        "  mus_gen.append(np.mean(pred_arr, axis=0))\n",
        "  sigmas_gen.append(np.cov(pred_arr, rowvar=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_w71nZ8XoCl"
      },
      "source": [
        "Calculo da distribuicao real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsx4vJ9BXoCm"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWEAlYaGXoCm"
      },
      "outputs": [],
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Load the training and test datasets\n",
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "trainset_reduzido = torch.utils.data.random_split(trainset, [1000, len(trainset) - 1000])[0]\n",
        "# Create data loaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "trainloader_reduzido = torch.utils.data.DataLoader(trainset_reduzido, batch_size=128, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ODa5VTrXoCm"
      },
      "outputs": [],
      "source": [
        "testset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8js9LM5qXoCm"
      },
      "source": [
        "Pegando imagens sem salvar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgwQDuAyXoCn"
      },
      "outputs": [],
      "source": [
        "def select_samples_per_class(dataset, num_samples):\n",
        "    \"\"\"\n",
        "    Selects a specified number of samples per class from the dataset and returns them as tensors.\n",
        "\n",
        "    Parameters:\n",
        "    dataset (torch.utils.data.Dataset): The dataset to select samples from.\n",
        "    num_samples (int): The number of samples to select per class.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary where each key corresponds to a class and the value is a tensor of shape [num_samples, 1, 28, 28].\n",
        "    \"\"\"\n",
        "    class_samples = {i: [] for i in range(len(dataset.classes))}\n",
        "    class_counts = {i: 0 for i in range(len(dataset.classes))}\n",
        "\n",
        "    for img, label in dataset:\n",
        "        if class_counts[label] < num_samples:\n",
        "            class_samples[label].append(img)\n",
        "            class_counts[label] += 1\n",
        "        if all(count >= num_samples for count in class_counts.values()):\n",
        "            break\n",
        "    else:\n",
        "        print(\"Warning: Not all classes have the requested number of samples.\")\n",
        "\n",
        "    # Convert lists of tensors to a single tensor per class\n",
        "    for label in class_samples:\n",
        "        if class_samples[label]:  # Check if the list is not empty\n",
        "            class_samples[label] = torch.stack(class_samples[label], dim=0)\n",
        "            class_samples[label] = (class_samples[label] + 1) / 2\n",
        "            class_samples[label] = class_samples[label].repeat(1, 3, 1, 1)\n",
        "        else:\n",
        "            # Handle empty classes if necessary; here we leave an empty tensor\n",
        "            class_samples[label] = torch.Tensor()\n",
        "\n",
        "    return class_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxtmTmD6XoCn"
      },
      "outputs": [],
      "source": [
        "img_reais = select_samples_per_class(testset, 800)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_r4SNe9XoCv"
      },
      "outputs": [],
      "source": [
        "dataloaders = [torch.utils.data.DataLoader(img_reais[c], batch_size=batch_size, num_workers=num_workers, shuffle=False) for c in range(10)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXFM_KcOXoCw"
      },
      "source": [
        "Salvando imagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4HPBo8iXoCw"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRy47-hWXoCw"
      },
      "outputs": [],
      "source": [
        "# Function to save a random sample of images\n",
        "def save_random_samples(dataset, num_samples=10, folder='Imagens Testes/mnist_samples', balanced=False, classes=None):\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "\n",
        "    if classes is None:\n",
        "        classes = [int(c.split()[0]) for c in dataset.classes]  # Use all classes if none are specified\n",
        "\n",
        "    if balanced:\n",
        "        # Get the number of classes\n",
        "        num_classes = len(classes)\n",
        "        samples_per_class = -(-num_samples // num_classes)  # Round up division\n",
        "        indices = []\n",
        "        class_counts = {i: 0 for i in classes}\n",
        "\n",
        "        # Shuffle the dataset\n",
        "        shuffled_indices = list(range(len(dataset)))\n",
        "        random.shuffle(shuffled_indices)\n",
        "\n",
        "        for idx in shuffled_indices:\n",
        "            img = dataset[idx][0]\n",
        "            label = int(dataset[idx][1])\n",
        "            if label in classes and class_counts[label] < samples_per_class:\n",
        "                indices.append(idx)\n",
        "                class_counts[label] += 1\n",
        "            if len(indices) >= num_samples:\n",
        "                break\n",
        "    else:\n",
        "        indices = []\n",
        "        while len(indices) < num_samples:\n",
        "            idx = random.randint(0, len(dataset) - 1)\n",
        "            if int(dataset[idx][1]) in classes:\n",
        "                indices.append(idx)\n",
        "    for i, idx in enumerate(indices):\n",
        "        img, label = dataset[idx]\n",
        "        img = (img * 0.5 + 0.5) * 255  # Denormalize the image\n",
        "        img = img.byte().numpy().transpose(1, 2, 0).squeeze()  # Convert to numpy array\n",
        "        img = Image.fromarray(img)\n",
        "        img.save(os.path.join(folder, f'mnist_sample_{i}_label_{label}.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhEt3LNsXoCx"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "  save_random_samples(trainset, num_samples=2050, folder=f'Imagens Testes/mnist_samples_{i}', balanced=True, classes=[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXpIFPDtXoCx"
      },
      "outputs": [],
      "source": [
        "pathes = [f\"Imagens Testes/mnist_samples_{i}\" for i in range(10)]\n",
        "pathes = [pathlib.Path(path) for path in pathes]\n",
        "files = [sorted(file for file in path.glob(\"*.png\")) for path in pathes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-U4U3uYZXoCx"
      },
      "outputs": [],
      "source": [
        "datasets = [ImagePathDataset(file, transforms=torchvision.transforms.ToTensor()) for file in files]\n",
        "dataloaders = [torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False) for dataset in datasets]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVRjN1RbXoCx"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OHeQeC6XoCx"
      },
      "source": [
        "Calulo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeivOPmZXoCy"
      },
      "outputs": [],
      "source": [
        "mus_real = []\n",
        "sigmas_real = []\n",
        "for c in range(10):\n",
        "  model = InceptionV3([block_idx]).to(device)\n",
        "  model.eval()\n",
        "  pred_arr = np.empty((len(img_reais[0]), dims))\n",
        "  start_idx = 0\n",
        "  for batch in tqdm(dataloaders[c]):\n",
        "          batch = batch.to(device)\n",
        "\n",
        "          with torch.no_grad():\n",
        "              pred = model(batch)[0]\n",
        "\n",
        "          # If model output is not scalar, apply global spatial average pooling.\n",
        "          # This happens if you choose a dimensionality not equal 2048.\n",
        "          if pred.size(2) != 1 or pred.size(3) != 1:\n",
        "              pred = F.adaptive_avg_pool2d(pred, output_size=(1, 1))\n",
        "\n",
        "          pred = pred.squeeze(3).squeeze(2).cpu().numpy()\n",
        "\n",
        "          pred_arr[start_idx : start_idx + pred.shape[0]] = pred\n",
        "\n",
        "          start_idx = start_idx + pred.shape[0]\n",
        "  mus_real.append(np.mean(pred_arr, axis=0))\n",
        "  sigmas_real.append(np.cov(pred_arr, rowvar=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXa0TM2lXoCy"
      },
      "source": [
        "Calculo FID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XtoaLpPXoCy"
      },
      "outputs": [],
      "source": [
        "from scipy import linalg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAGo9hN6XoCz"
      },
      "outputs": [],
      "source": [
        "mus_gen = [np.atleast_1d(mu_gen) for mu_gen in mus_gen]\n",
        "mus_real = [np.atleast_1d(mu_real) for mu_real in mus_real]\n",
        "\n",
        "sigmas_gen = [np.atleast_2d(sigma_gen) for sigma_gen in sigmas_gen]\n",
        "sigmas_real = [np.atleast_2d(sigma_real) for sigma_real in sigmas_real]\n",
        "\n",
        "for mu_gen, mu_real, sigma_gen, sigma_real in zip(mus_gen, mus_real, sigmas_gen, sigmas_real):\n",
        "  assert (\n",
        "      mu_gen.shape == mu_real.shape\n",
        "  ), \"Training and test mean vectors have different lengths\"\n",
        "  assert (\n",
        "      sigma_gen.shape == sigma_real.shape\n",
        "  ), \"Training and test covariances have different dimensions\"\n",
        "\n",
        "diffs = [mu_gen - mu_real for mu_gen, mu_real in zip(mus_gen, mus_real)]\n",
        "\n",
        "# Product might be almost singular\n",
        "covmeans = [linalg.sqrtm(sigmas_gen.dot(sigmas_real), disp=False)[0] for sigmas_gen, sigmas_real in zip(sigmas_gen, sigmas_real)]\n",
        "for covmean, sigma_gen, sigma_real in zip(covmeans, sigmas_gen, sigmas_real):\n",
        "  if not np.isfinite(covmean).all():\n",
        "    msg = (\n",
        "        \"fid calculation produces singular product; \"\n",
        "        \"adding %s to diagonal of cov estimates\"\n",
        "    ) % 1e-6\n",
        "    print(msg)\n",
        "    offset = np.eye(sigma_gen.shape[0]) * 1e-6\n",
        "    covmean = linalg.sqrtm((sigma_gen + offset).dot(sigma_real + offset))\n",
        "\n",
        "# Numerical error might give slight imaginary component\n",
        "for i, covmean in enumerate(covmeans):\n",
        "  if np.iscomplexobj(covmean):\n",
        "      if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
        "          m = np.max(np.abs(covmean.imag))\n",
        "          raise ValueError(\"Imaginary component {}\".format(m))\n",
        "      covmeans[i] = covmean.real\n",
        "\n",
        "tr_covmeans = [np.trace(covmean) for covmean in covmeans]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlYmUB0RXoCz"
      },
      "outputs": [],
      "source": [
        "fids = [diff.dot(diff) + np.trace(sigma_gen) + np.trace(sigma_real) - 2 * tr_covmean for diff, sigma_gen, sigma_real, tr_covmean in zip(diffs, sigmas_gen, sigmas_real, tr_covmeans)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UAzyULzXoCz"
      },
      "outputs": [],
      "source": [
        "fids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYo0rAs8XoCz"
      },
      "source": [
        "### Federado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3zljHPevm7I"
      },
      "source": [
        "CGAN duas classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1To3FRdBvm7I"
      },
      "outputs": [],
      "source": [
        "class Gen(nn.Module):\n",
        "    def __init__(self, dataset=\"mnist\", img_size=28, latent_dim=100):\n",
        "        super(Gen, self).__init__()\n",
        "        if dataset == \"mnist\":\n",
        "            self.classes = 10\n",
        "            self.channels = 1\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes)\n",
        "        self.adv_loss = torch.nn.BCELoss()\n",
        "\n",
        "        self.generator = nn.Sequential(\n",
        "            *self._create_layer_gen(self.latent_dim + self.classes, 128, False),\n",
        "            *self._create_layer_gen(128, 256),\n",
        "            *self._create_layer_gen(256, 512),\n",
        "            *self._create_layer_gen(512, 1024),\n",
        "            nn.Linear(1024, int(np.prod(self.img_shape))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def _create_layer_gen(self, size_in, size_out, normalize=True):\n",
        "        layers = [nn.Linear(size_in, size_out)]\n",
        "        if normalize:\n",
        "            layers.append(nn.BatchNorm1d(size_out))\n",
        "        layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return layers\n",
        "\n",
        "    def forward(self, input, labels):\n",
        "        z = torch.cat((self.label_embedding(labels), input), -1)\n",
        "        x = self.generator(z)\n",
        "        x = x.view(x.size(0), *self.img_shape) #Em\n",
        "        return x\n",
        "\n",
        "    def loss(self, output, label):\n",
        "        return self.adv_loss(output, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ob4HiiROvm7I"
      },
      "outputs": [],
      "source": [
        "class Disc(nn.Module):\n",
        "    def __init__(self, dataset=\"mnist\", img_size=28, latent_dim=100):\n",
        "        super(Disc, self).__init__()\n",
        "        if dataset == \"mnist\":\n",
        "            self.classes = 10\n",
        "            self.channels = 1\n",
        "        self.img_size = img_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_shape = (self.channels, self.img_size, self.img_size)\n",
        "        self.label_embedding = nn.Embedding(self.classes, self.classes)\n",
        "        self.adv_loss = torch.nn.BCELoss()\n",
        "\n",
        "        self.discriminator = nn.Sequential(\n",
        "            *self._create_layer_disc(self.classes + int(np.prod(self.img_shape)), 1024, False, True),\n",
        "            *self._create_layer_disc(1024, 512, True, True),\n",
        "            *self._create_layer_disc(512, 256, True, True),\n",
        "            *self._create_layer_disc(256, 128, False, False),\n",
        "            *self._create_layer_disc(128, 1, False, False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def _create_layer_disc(self, size_in, size_out, drop_out=True, act_func=True):\n",
        "        layers = [nn.Linear(size_in, size_out)]\n",
        "        if drop_out:\n",
        "            layers.append(nn.Dropout(0.4))\n",
        "        if act_func:\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        return layers\n",
        "\n",
        "    def forward(self, input, labels):\n",
        "        x = torch.cat((input.view(input.size(0), -1), self.label_embedding(labels)), -1)\n",
        "        return self.discriminator(x)\n",
        "\n",
        "    def loss(self, output, label):\n",
        "        return self.adv_loss(output, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jgO5dbyOX9IB",
        "outputId": "a3b2b562-b7db-4f9e-b6b9-306668fa6d8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flwr_datasets\n",
            "  Downloading flwr_datasets-0.5.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting datasets<=3.1.0,>=2.14.6 (from flwr_datasets)\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.7.5 in /usr/local/lib/python3.11/dist-packages (from flwr_datasets) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from flwr_datasets) (1.26.4)\n",
            "Requirement already satisfied: seaborn<0.14.0,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from flwr_datasets) (0.13.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from flwr_datasets) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr_datasets) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr_datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets<=3.1.0,>=2.14.6->flwr_datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr_datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr_datasets) (2.32.3)\n",
            "Collecting xxhash (from datasets<=3.1.0,>=2.14.6->flwr_datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets<=3.1.0,>=2.14.6->flwr_datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets<=3.1.0,>=2.14.6->flwr_datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr_datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr_datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr_datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets<=3.1.0,>=2.14.6->flwr_datasets) (6.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.5->flwr_datasets) (2.8.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr_datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr_datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr_datasets) (25.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr_datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr_datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr_datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets<=3.1.0,>=2.14.6->flwr_datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets<=3.1.0,>=2.14.6->flwr_datasets) (4.12.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<=3.1.0,>=2.14.6->flwr_datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets<=3.1.0,>=2.14.6->flwr_datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.7.5->flwr_datasets) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.14.6->flwr_datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.14.6->flwr_datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.14.6->flwr_datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.14.6->flwr_datasets) (2025.1.31)\n",
            "Downloading flwr_datasets-0.5.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.0/87.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets, flwr_datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 flwr_datasets-0.5.0 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install flwr_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBvMjRnOXoCz"
      },
      "outputs": [],
      "source": [
        "from flwr_datasets.partitioner import DirichletPartitioner, IidPartitioner\n",
        "from flwr_datasets import FederatedDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85htNladXoC0"
      },
      "outputs": [],
      "source": [
        "num_partitions = 4\n",
        "alpha_dir = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2Xjlca_XoC0"
      },
      "outputs": [],
      "source": [
        "partitioner = DirichletPartitioner(\n",
        "    num_partitions=num_partitions,\n",
        "    partition_by=\"label\",\n",
        "    alpha=alpha_dir,\n",
        "    min_partition_size=0,\n",
        "    self_balancing=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42jypjt9vm7J"
      },
      "outputs": [],
      "source": [
        "partitioner = IidPartitioner(num_partitions=num_partitions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "227p665iXoC0"
      },
      "outputs": [],
      "source": [
        "fds = FederatedDataset(\n",
        "    dataset=\"mnist\",\n",
        "    partitioners={\"train\": partitioner}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw5CezaqXoC0"
      },
      "outputs": [],
      "source": [
        "train_partitions = [fds.load_partition(i, split=\"train\") for i in range(num_partitions)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ05wNS_ZSi3"
      },
      "source": [
        "##### Rodar proxima celula somente se quiser testar com dataset reduzido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-DfNUiSXoC0"
      },
      "outputs": [],
      "source": [
        "num_samples = [int(len(train_partition)/10) for train_partition in train_partitions]\n",
        "train_partitions = [train_partition.select(range(n)) for train_partition, n in zip(train_partitions, num_samples)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkqcHp6eXoC1"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Compose, ToTensor, Normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIroIscqXoC1"
      },
      "outputs": [],
      "source": [
        "pytorch_transforms = Compose([\n",
        "    ToTensor(),\n",
        "    Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "def apply_transforms(batch):\n",
        "    batch[\"image\"] = [pytorch_transforms(img) for img in batch[\"image\"]]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPXZ9XAjXoC1"
      },
      "outputs": [],
      "source": [
        "train_partitions = [train_partition.with_transform(apply_transforms) for train_partition in train_partitions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF7BB2O-XoC1"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "trainloaders = [DataLoader(train_partition, batch_size=batch_size, shuffle=True) for train_partition in train_partitions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00vLeJqCXoC2"
      },
      "outputs": [],
      "source": [
        "models = [CGAN() for i in range(num_partitions)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2w3_MAnJvm7M"
      },
      "outputs": [],
      "source": [
        "models = [Disc() for i in range(num_partitions)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hg_QEZhIvm7M"
      },
      "outputs": [],
      "source": [
        "models = [Discriminator() for i in range(num_partitions)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qA2nQnS2vm7M"
      },
      "outputs": [],
      "source": [
        "optim_Ds = [\n",
        "    torch.optim.Adam(model.discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "    for model in models\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QELViKagvm7N"
      },
      "outputs": [],
      "source": [
        "optim_Ds = [\n",
        "    torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "    for model in models\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NZ6Ak66XoC4"
      },
      "outputs": [],
      "source": [
        "def generate_plot(net, device, round_number, client_id = None, examples_per_class: int=5, classes: int=10, latent_dim: int=100, server: bool=False):\n",
        "    \"\"\"Gera plot de imagens de cada classe\"\"\"\n",
        "    if server:\n",
        "        import matplotlib\n",
        "        matplotlib.use(\"Agg\")\n",
        "        import matplotlib.pyplot as plt\n",
        "    else:\n",
        "        import matplotlib.pyplot as plt\n",
        "\n",
        "    net_type = type(net).__name__\n",
        "    net.to(device)\n",
        "    net.eval()\n",
        "    batch_size = examples_per_class * classes\n",
        "\n",
        "    latent_vectors = torch.randn(batch_size, latent_dim, device=device)\n",
        "    labels = torch.tensor([i for i in range(classes) for _ in range(examples_per_class)], device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if net_type == \"Generator\":\n",
        "            labels_one_hot = torch.nn.functional.one_hot(labels, 10).float().to(device)\n",
        "            generated_images = net(torch.cat([latent_vectors, labels_one_hot], dim=1))\n",
        "        else:\n",
        "            generated_images = net(latent_vectors, labels).cpu()\n",
        "\n",
        "    # Criar uma figura com 10 linhas e 5 colunas de subplots\n",
        "    fig, axes = plt.subplots(classes, examples_per_class, figsize=(5, 9))\n",
        "\n",
        "    # Adiciona título no topo da figura\n",
        "    if client_id:\n",
        "        fig.text(0.5, 0.98, f\"Round: {round_number} | Client: {client_id}\", ha=\"center\", fontsize=12)\n",
        "    else:\n",
        "        fig.text(0.5, 0.98, f\"Round: {round_number}\", ha=\"center\", fontsize=12)\n",
        "\n",
        "    # Exibir as imagens nos subplots\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(generated_images[i, 0, :, :], cmap='gray')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "    # Ajustar o layout antes de calcular as posições\n",
        "    plt.tight_layout(rect=[0.05, 0, 1, 0.96])\n",
        "\n",
        "    # Reduzir espaço entre colunas\n",
        "    # plt.subplots_adjust(wspace=0.05)\n",
        "\n",
        "    # Adicionar os rótulos das classes corretamente alinhados\n",
        "    fig.canvas.draw()  # Atualiza a renderização para obter posições corretas\n",
        "    for row in range(classes):\n",
        "        # Obter posição do subplot em coordenadas da figura\n",
        "        bbox = axes[row, 0].get_window_extent(fig.canvas.get_renderer())\n",
        "        pos = fig.transFigure.inverted().transform([(bbox.x0, bbox.y0), (bbox.x1, bbox.y1)])\n",
        "        center_y = (pos[0, 1] + pos[1, 1]) / 2  # Centro exato da linha\n",
        "\n",
        "        # Adicionar o rótulo\n",
        "        fig.text(0.04, center_y, str(row), va='center', fontsize=12, color='black')\n",
        "\n",
        "    fig.savefig(f\"mnist_CGAN_r{round_number}_f2a.png\")\n",
        "    plt.close(fig)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZuTSmgYXoC4"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7L_24AOXoC5"
      },
      "outputs": [],
      "source": [
        "gen = CGAN().to(device)\n",
        "optim_G = torch.optim.Adam(gen.generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "\n",
        "# scheduler_D = torch.optim.lr_scheduler.StepLR(optim_D, step_size=5, gamma=0.9)\n",
        "# scheduler_G = torch.optim.lr_scheduler.StepLR(optim_G, step_size=5, gamma=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFIeuVnfvm7O"
      },
      "outputs": [],
      "source": [
        "net = Disc().to(device)\n",
        "optim_D = torch.optim.Adam(net.discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8SN_A1oXoC5"
      },
      "outputs": [],
      "source": [
        "net = CGAN().to(device)\n",
        "optim_D = torch.optim.Adam(net.discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "\n",
        "# scheduler_D = torch.optim.lr_scheduler.StepLR(optim_D, step_size=5, gamma=0.9)\n",
        "# scheduler_G = torch.optim.lr_scheduler.StepLR(optim_G, step_size=5, gamma=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iU4D1aZJvm7O"
      },
      "outputs": [],
      "source": [
        "gen = Gen().to(device)\n",
        "optim_G = torch.optim.Adam(gen.generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQpWdfVcvm7O"
      },
      "outputs": [],
      "source": [
        "gen = Generator().to(device)\n",
        "\n",
        "# Otimizadores\n",
        "#optim_D = torch.optim.Adam(D.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "optim_G = torch.optim.Adam(gen.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "\n",
        "# scheduler_D = torch.optim.lr_scheduler.StepLR(optim_D, step_size=5, gamma=0.9)\n",
        "# scheduler_G = torch.optim.lr_scheduler.StepLR(optim_G, step_size=5, gamma=0.9)\n",
        "\n",
        " # Função de perda Wasserstein\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    return fake_output.mean() - real_output.mean()\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return -fake_output.mean()\n",
        "\n",
        "# Função para calcular Gradient Penalty\n",
        "def gradient_penalty(D, real_samples, fake_samples):\n",
        "    alpha = torch.rand(real_samples.size(0), 1, 1, 1, device=device)\n",
        "    interpolated = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n",
        "    d_interpolated = D(interpolated)\n",
        "    gradients = torch.autograd.grad(outputs=d_interpolated, inputs=interpolated,\n",
        "                                    grad_outputs=torch.ones_like(d_interpolated),\n",
        "                                    create_graph=True, retain_graph=True)[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    return ((gradients.norm(2, dim=1) - 1) ** 2).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrMTGrznZNie"
      },
      "source": [
        "#### Treinamento Normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7fKR6J8vm7P"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "350e6b1230c84b1a9724475a2d8cd14d",
            "855d0234cfeb4fe6b20bb390bcf4a353",
            "bd268badb2df405cad98649d4b4bed6f",
            "c8f3364e3e694ab78458a950b52ac420",
            "bddcae3848b64bf29f052156140ada69",
            "f7fe07aa1a894123a4ee4775a6238c4a",
            "eacc44c7d4964fbb8a88a569ae07f5a7",
            "ae65cd77a47b4d80ae5ce44aff3128e0",
            "f11fce69d38646598ccca03bf1aa8bfa",
            "62e93158202347efb43623543e4ec2a4",
            "4e69dfbf244a42e0b6fe2399c2482cf0",
            "a06fe7e3b308445591272f9a70526bd6",
            "8e23fd2c4831446296cef5b206ef010d",
            "97eb7a74fa0c4c46aac6bf1713d83ce2"
          ]
        },
        "id": "eC41U1Iqvm7P",
        "outputId": "55708cf9-b090-48b8-ab83-0d4a0b457840"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "350e6b1230c84b1a9724475a2d8cd14d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Treinamento:   0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔹 Epoch 1/30\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "855d0234cfeb4fe6b20bb390bcf4a353",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 [100/469] loss_D_treino: 0.7172 loss_G_treino: 1.0355\n",
            "Epoch 0 [200/469] loss_D_treino: 0.5567 loss_G_treino: 1.0513\n",
            "Epoch 0 [300/469] loss_D_treino: 0.5390 loss_G_treino: 2.0415\n",
            "Epoch 0 [400/469] loss_D_treino: 0.5787 loss_G_treino: 1.0859\n",
            "\n",
            "🔹 Epoch 2/30\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd268badb2df405cad98649d4b4bed6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 [100/469] loss_D_treino: 0.4553 loss_G_treino: 1.3828\n",
            "Epoch 1 [200/469] loss_D_treino: 0.4056 loss_G_treino: 1.7168\n",
            "Epoch 1 [300/469] loss_D_treino: 0.4521 loss_G_treino: 1.1023\n",
            "Epoch 1 [400/469] loss_D_treino: 0.4181 loss_G_treino: 2.0259\n",
            "\n",
            "🔹 Epoch 3/30\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8f3364e3e694ab78458a950b52ac420",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 [100/469] loss_D_treino: 0.4117 loss_G_treino: 2.3528\n",
            "Epoch 2 [200/469] loss_D_treino: 0.4865 loss_G_treino: 2.4283\n",
            "Epoch 2 [300/469] loss_D_treino: 0.4765 loss_G_treino: 1.1877\n",
            "Epoch 2 [400/469] loss_D_treino: 0.3930 loss_G_treino: 1.3362\n",
            "\n",
            "🔹 Epoch 4/30\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bddcae3848b64bf29f052156140ada69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 [100/469] loss_D_treino: 0.3455 loss_G_treino: 1.4572\n",
            "Epoch 3 [200/469] loss_D_treino: 0.6152 loss_G_treino: 1.0659\n",
            "Epoch 3 [300/469] loss_D_treino: 0.5350 loss_G_treino: 1.2728\n",
            "Epoch 3 [400/469] loss_D_treino: 0.4074 loss_G_treino: 1.8394\n",
            "\n",
            "🔹 Epoch 5/30\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7fe07aa1a894123a4ee4775a6238c4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 [100/469] loss_D_treino: 0.4753 loss_G_treino: 1.1873\n",
            "Epoch 4 [200/469] loss_D_treino: 0.4004 loss_G_treino: 1.1077\n",
            "Epoch 4 [300/469] loss_D_treino: 0.4373 loss_G_treino: 1.4582\n",
            "Epoch 4 [400/469] loss_D_treino: 0.3777 loss_G_treino: 1.3204\n",
            "\n",
            "🔹 Epoch 6/30\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eacc44c7d4964fbb8a88a569ae07f5a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 [100/469] loss_D_treino: 0.3838 loss_G_treino: 1.2967\n",
            "Epoch 5 [200/469] loss_D_treino: 0.4419 loss_G_treino: 1.5179\n",
            "Epoch 5 [300/469] loss_D_treino: 0.5401 loss_G_treino: 2.0390\n",
            "Epoch 5 [400/469] loss_D_treino: 0.5145 loss_G_treino: 2.0209\n",
            "\n",
            "🔹 Epoch 7/30\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae65cd77a47b4d80ae5ce44aff3128e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 [100/469] loss_D_treino: 0.4938 loss_G_treino: 1.3961\n",
            "Epoch 6 [200/469] loss_D_treino: 0.5524 loss_G_treino: 1.5449\n",
            "Epoch 6 [300/469] loss_D_treino: 0.5913 loss_G_treino: 0.9399\n",
            "Epoch 6 [400/469] loss_D_treino: 0.5719 loss_G_treino: 1.4465\n",
            "\n",
            "🔹 Epoch 8/30\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f11fce69d38646598ccca03bf1aa8bfa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 [100/469] loss_D_treino: 0.5467 loss_G_treino: 1.4378\n",
            "Epoch 7 [200/469] loss_D_treino: 0.5788 loss_G_treino: 1.5506\n",
            "Epoch 7 [300/469] loss_D_treino: 0.5075 loss_G_treino: 1.6474\n",
            "Epoch 7 [400/469] loss_D_treino: 0.5595 loss_G_treino: 1.2396\n",
            "\n",
            "🔹 Epoch 9/30\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62e93158202347efb43623543e4ec2a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 [100/469] loss_D_treino: 0.6096 loss_G_treino: 1.4276\n",
            "Epoch 8 [200/469] loss_D_treino: 0.5336 loss_G_treino: 1.1822\n",
            "Epoch 8 [300/469] loss_D_treino: 0.5510 loss_G_treino: 1.5241\n",
            "Epoch 8 [400/469] loss_D_treino: 0.5710 loss_G_treino: 1.2522\n",
            "\n",
            "🔹 Epoch 10/30\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e69dfbf244a42e0b6fe2399c2482cf0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 [100/469] loss_D_treino: 0.5359 loss_G_treino: 1.3799\n",
            "Epoch 9 [200/469] loss_D_treino: 0.5499 loss_G_treino: 1.1218\n",
            "Epoch 9 [300/469] loss_D_treino: 0.6207 loss_G_treino: 1.0673\n",
            "Epoch 9 [400/469] loss_D_treino: 0.6025 loss_G_treino: 0.9652\n",
            "\n",
            "🔹 Epoch 11/30\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a06fe7e3b308445591272f9a70526bd6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 [100/469] loss_D_treino: 0.5971 loss_G_treino: 1.0946\n",
            "Epoch 10 [200/469] loss_D_treino: 0.5841 loss_G_treino: 1.1708\n",
            "Epoch 10 [300/469] loss_D_treino: 0.5977 loss_G_treino: 0.9976\n",
            "Epoch 10 [400/469] loss_D_treino: 0.5852 loss_G_treino: 1.0277\n",
            "\n",
            "🔹 Epoch 12/30\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e23fd2c4831446296cef5b206ef010d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 [100/469] loss_D_treino: 0.6285 loss_G_treino: 1.2069\n",
            "Epoch 11 [200/469] loss_D_treino: 0.5550 loss_G_treino: 1.1061\n",
            "Epoch 11 [300/469] loss_D_treino: 0.5619 loss_G_treino: 1.2196\n",
            "Epoch 11 [400/469] loss_D_treino: 0.5816 loss_G_treino: 1.2839\n",
            "\n",
            "🔹 Epoch 13/30\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97eb7a74fa0c4c46aac6bf1713d83ce2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[31], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m batch_bar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(trainloaders[\u001b[38;5;241m0\u001b[39m]), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatches\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     15\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 16\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_bar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\tqdm\\notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\datasets\\arrow_dataset.py:2766\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[1;34m(self, keys)\u001b[0m\n\u001b[0;32m   2764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys: List) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n\u001b[0;32m   2765\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2766\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2767\u001b[0m     n_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[0;32m   2768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\datasets\\arrow_dataset.py:2762\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2760\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[0;32m   2761\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\datasets\\arrow_dataset.py:2747\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, **kwargs)\u001b[0m\n\u001b[0;32m   2745\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m   2746\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[1;32m-> 2747\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[0;32m   2749\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\datasets\\formatting\\formatting.py:639\u001b[0m, in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    637\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\datasets\\formatting\\formatting.py:407\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\datasets\\formatting\\formatting.py:522\u001b[0m, in \u001b[0;36mCustomFormatter.format_batch\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    520\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_batch(pa_table)\n\u001b[0;32m    521\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_batch(batch)\n\u001b[1;32m--> 522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[14], line 7\u001b[0m, in \u001b[0;36mapply_transforms\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_transforms\u001b[39m(batch):\n\u001b[1;32m----> 7\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[43mpytorch_transforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\torchvision\\transforms\\functional.py:176\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    174\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "wgan = False\n",
        "epochs = 30\n",
        "g_losses_batch = []\n",
        "d_losses_batch = []\n",
        "g_losses_epoch = []\n",
        "d_losses_epoch = []\n",
        "\n",
        "epoch_bar = tqdm(range(epochs), desc=\"Treinamento\", leave=True, position=0)\n",
        "for epoch in epoch_bar:\n",
        "    print(f\"\\n🔹 Epoch {epoch+1}/{epochs}\")\n",
        "    epoch_g_loss = 0.0\n",
        "    epoch_d_loss = 0.0\n",
        "    num_batches = 0\n",
        "    batch_bar = tqdm(enumerate(trainloaders[0]), desc=\"Batches\", leave=False, position=1)\n",
        "    start_time = time.time()\n",
        "    for batch_idx, batch in batch_bar:\n",
        "        images, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "        batch_size = images.size(0)\n",
        "        real_ident = torch.full((batch_size, 1), 1., device=device)\n",
        "        fake_ident = torch.full((batch_size, 1), 0., device=device)\n",
        "\n",
        "        z_noise = torch.randn(batch_size, 100, device=device)\n",
        "        x_fake_labels = torch.randint(0, 10, (batch_size,), device=device)\n",
        "\n",
        "        optim_D.zero_grad()\n",
        "\n",
        "        if wgan:\n",
        "            labels = torch.nn.functional.one_hot(labels, 10).float().to(device)\n",
        "            x_fake_labels = torch.nn.functional.one_hot(x_fake_labels, 10).float()\n",
        "\n",
        "            # Adicionar labels ao images para treinamento do Discriminador\n",
        "            image_labels = labels.view(labels.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "            image_fake_labels = x_fake_labels.view(x_fake_labels.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "\n",
        "            images = torch.cat([images, image_labels], dim=1)\n",
        "\n",
        "            # Treinar Discriminador\n",
        "            z_noise = torch.cat([z_noise, x_fake_labels], dim=1)\n",
        "            fake_images = gen(z_noise).detach()\n",
        "            fake_images = torch.cat([fake_images, image_fake_labels], dim=1)\n",
        "\n",
        "            d_loss = discriminator_loss(D(images), D(fake_images)) + 10 * gradient_penalty(D, images, fake_images)\n",
        "\n",
        "        else:\n",
        "            # Train D\n",
        "            y_real = net(images, labels)\n",
        "            d_real_loss = net.loss(y_real, real_ident)\n",
        "            x_fake = gen(z_noise, x_fake_labels).detach()\n",
        "            y_fake_d = net(x_fake, x_fake_labels)\n",
        "            d_fake_loss = net.loss(y_fake_d, fake_ident)\n",
        "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        optim_D.step()\n",
        "\n",
        "        optim_G.zero_grad()\n",
        "\n",
        "        if wgan:\n",
        "            fake_images = gen(z_noise)\n",
        "            g_loss = generator_loss(D(torch.cat([fake_images, image_fake_labels], dim=1)))\n",
        "        else:\n",
        "            # Train G\n",
        "            x_fake = gen(z_noise, x_fake_labels)\n",
        "            y_fake_g = net(x_fake, x_fake_labels)\n",
        "            g_loss = gen.loss(y_fake_g, real_ident)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optim_G.step()\n",
        "\n",
        "        g_losses_batch.append(g_loss.item())\n",
        "        d_losses_batch.append(d_loss.item())\n",
        "\n",
        "        epoch_g_loss += g_loss.item()\n",
        "        epoch_d_loss += d_loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "        if batch_idx % 100 == 0 and batch_idx > 0:\n",
        "            print('Epoch {} [{}/{}] loss_D_treino: {:.4f} loss_G_treino: {:.4f}'.format(\n",
        "                        epoch, batch_idx, len(trainloaders[0]),\n",
        "                        d_loss.mean().item(),\n",
        "                        g_loss.mean().item()))\n",
        "\n",
        "    # Calcula médias da época\n",
        "    avg_g_loss = epoch_g_loss / num_batches\n",
        "    avg_d_loss = epoch_d_loss / num_batches\n",
        "\n",
        "    # Armazena as médias\n",
        "    g_losses_epoch.append(avg_g_loss)\n",
        "    d_losses_epoch.append(avg_d_loss)\n",
        "\n",
        "\n",
        "    figura = generate_plot(net=gen, device=device, round_number=epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqnZhxxUZaHM"
      },
      "source": [
        "#### Treinamento de Geradora única, após clientes treinarem Discriminadoras por todos os dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdhiGs-HXoC8",
        "outputId": "20f58c4e-2597-4359-fb3a-4f5a996b1e37"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[50], line 88\u001b[0m\n\u001b[1;32m     86\u001b[0m g_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     87\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(gen\u001b[38;5;241m.\u001b[39mgenerator\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m---> 88\u001b[0m \u001b[43moptim_G\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Acumula a perda\u001b[39;00m\n\u001b[1;32m     91\u001b[0m round_g_losses\u001b[38;5;241m.\u001b[39mappend(g_loss\u001b[38;5;241m.\u001b[39mitem())\n",
            "File \u001b[0;32m~/miniconda3/envs/gerafed/lib/python3.10/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/gerafed/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
            "File \u001b[0;32m~/miniconda3/envs/gerafed/lib/python3.10/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
            "File \u001b[0;32m~/miniconda3/envs/gerafed/lib/python3.10/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/gerafed/lib/python3.10/site-packages/torch/optim/adam.py:439\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    437\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "g_losses = []  # Perda média do gerador por rodada\n",
        "d_losses = []  # Perda média do discriminador por rodada\n",
        "num_discriminator_epochs = 1  # Épocas de treino do discriminador por rodada\n",
        "num_generator_epochs = 50       # Épocas de treino do gerador por rodada\n",
        "rounds = 50\n",
        "\n",
        "for r in range(rounds):  # 100 rodadas federadas\n",
        "    # ========================================================================\n",
        "    # Treino dos Discriminadores (clientes)\n",
        "    # ========================================================================\n",
        "    round_d_losses = []  # Armazena as perdas dos discriminadores nesta rodada\n",
        "\n",
        "    for i, (net, trainloader) in enumerate(zip(models, trainloaders)):\n",
        "        net.to(device)\n",
        "        optim_D = optim_Ds[i]\n",
        "\n",
        "        for e in range(num_discriminator_epochs):  # Épocas locais\n",
        "            epoch_d_loss = 0.0\n",
        "            num_batches = 0\n",
        "\n",
        "            for batch in trainloader:\n",
        "                images, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "                batch_size = images.size(0)\n",
        "                real_ident = torch.full((batch_size, 1), 1.0, device=device)\n",
        "                fake_ident = torch.full((batch_size, 1), 0.0, device=device)\n",
        "\n",
        "                # Treino do Discriminador\n",
        "                optim_D.zero_grad()\n",
        "\n",
        "                # Dados reais\n",
        "                y_real = net(images, labels)\n",
        "                d_real_loss = net.loss(y_real, real_ident)\n",
        "\n",
        "                # Dados falsos (gerados)\n",
        "                z_noise = torch.randn(batch_size, 100, device=device)\n",
        "                x_fake_labels = torch.randint(0, 10, (batch_size,), device=device)\n",
        "                x_fake = gen(z_noise, x_fake_labels).detach()  # Usa o gerador global\n",
        "                y_fake_d = net(x_fake, x_fake_labels)\n",
        "                d_fake_loss = net.loss(y_fake_d, fake_ident)\n",
        "\n",
        "                # Loss total e backprop\n",
        "                d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "                d_loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(net.discriminator.parameters(), max_norm=1.0)\n",
        "                optim_D.step()\n",
        "\n",
        "                # Acumula a perda\n",
        "                epoch_d_loss += d_loss.item()\n",
        "                num_batches += 1\n",
        "\n",
        "            # Média da perda do discriminador nesta época\n",
        "            epoch_d_loss /= num_batches\n",
        "            round_d_losses.append(epoch_d_loss)\n",
        "\n",
        "    # Média da perda dos discriminadores nesta rodada\n",
        "    avg_d_loss = sum(round_d_losses) / len(round_d_losses)\n",
        "    d_losses.append(avg_d_loss)\n",
        "\n",
        "    # ========================================================================\n",
        "    # Treino do Gerador (global)\n",
        "    # ========================================================================\n",
        "    round_g_losses = []  # Armazena as perdas do gerador nesta rodada\n",
        "\n",
        "    for e in range(num_generator_epochs):  # Épocas do gerador\n",
        "        optim_G.zero_grad()\n",
        "\n",
        "        # Gera dados falsos\n",
        "        z_noise = torch.randn(32, 100, device=device)\n",
        "        x_fake_labels = torch.randint(0, 10, (32,), device=device)\n",
        "        x_fake = gen(z_noise, x_fake_labels)\n",
        "\n",
        "        # Seleciona o melhor discriminador (Dmax)\n",
        "        y_fake_gs = [model(x_fake.detach(), x_fake_labels) for model in models]\n",
        "        real_ident = torch.full((32, 1), 1.0, device=device)\n",
        "        y_fake_g_means = [torch.mean(y).item() for y in y_fake_gs]\n",
        "        Dmax = models[y_fake_g_means.index(max(y_fake_g_means))]\n",
        "\n",
        "        # Calcula a perda do gerador\n",
        "        y_fake_g = Dmax(x_fake, x_fake_labels)\n",
        "        g_loss = gen.loss(y_fake_g, real_ident)\n",
        "        g_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(gen.generator.parameters(), max_norm=1.0)\n",
        "        optim_G.step()\n",
        "\n",
        "        # Acumula a perda\n",
        "        round_g_losses.append(g_loss.item())\n",
        "\n",
        "    # Média da perda do gerador nesta rodada\n",
        "    avg_g_loss = sum(round_g_losses) / len(round_g_losses)\n",
        "    g_losses.append(avg_g_loss)\n",
        "\n",
        "    # Gera a figura (opcional)\n",
        "    figura = generate_plot(net=gen, device=device, round_number=r)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgwSieOWZxdo"
      },
      "source": [
        "#### Treinamento de Geradora única, após cada batch em discriminadoras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4jz6hpA2dKW"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJPR2SUg12H2"
      },
      "outputs": [],
      "source": [
        "num_chunks = 5\n",
        "client_chunks = []\n",
        "for train_partition in train_partitions:\n",
        "  chunk_size = math.ceil(len(train_partition)/num_chunks)\n",
        "\n",
        "  chunks = []\n",
        "  for i in range(num_chunks):\n",
        "      start = i * chunk_size\n",
        "      end = min((i + 1) * chunk_size, len(train_partition))\n",
        "      chunks.append(Subset(train_partition, range(start, end)))\n",
        "\n",
        "  client_chunks.append(chunks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrHvGJVavm7S"
      },
      "outputs": [],
      "source": [
        "models = [Discriminator() for i in range(num_partitions)]\n",
        "optim_Ds = [\n",
        "    torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "    for model in models\n",
        "]\n",
        "gen = Generator(latent_dim=100).to(device)\n",
        "optim_G = torch.optim.Adam(gen.parameters(), lr=0.0001, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXJRD9Krvm7S"
      },
      "outputs": [],
      "source": [
        "models = [CGAN() for i in range(num_partitions)]\n",
        "optim_Ds = [\n",
        "    torch.optim.Adam(model.discriminator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "    for model in models\n",
        "]\n",
        "gen = CGAN().to(device)\n",
        "optim_G = torch.optim.Adam(gen.generator.parameters(), lr=0.0001, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXyYSytgvm7S"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Iterar sobre os clients_chunks\n",
        "for client_id, chunks in enumerate(client_chunks):\n",
        "    print(f\"Client {client_id}:\")\n",
        "    for chunk_id, chunk in enumerate(chunks):\n",
        "        # Contar as labels no chunk\n",
        "        labels = [example['label'] for example in chunk]\n",
        "        label_counts = Counter(labels)\n",
        "        print(f\"  Chunk {chunk_id}: {dict(label_counts)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "b01b8f2dff63418bad2fed88cbc4aad6"
          ]
        },
        "id": "b5QYQs60Zwwt",
        "outputId": "f8afa083-4d5e-4a3d-b7d6-03ff46159d6d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b01b8f2dff63418bad2fed88cbc4aad6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Treinamento:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Época 0 completa\n",
            "Época 1 completa\n",
            "Época 2 completa\n",
            "Época 3 completa\n",
            "Época 4 completa\n",
            "Época 5 completa\n",
            "Época 6 completa\n",
            "Época 7 completa\n",
            "Época 8 completa\n",
            "Época 9 completa\n",
            "Época 10 completa\n",
            "Época 11 completa\n",
            "Época 12 completa\n",
            "Época 13 completa\n",
            "Época 14 completa\n",
            "Época 15 completa\n",
            "Época 16 completa\n",
            "Época 17 completa\n",
            "Época 18 completa\n",
            "Época 19 completa\n",
            "Época 20 completa\n",
            "Época 21 completa\n",
            "Época 22 completa\n",
            "Época 23 completa\n",
            "Época 24 completa\n",
            "Época 25 completa\n",
            "Época 26 completa\n",
            "Época 27 completa\n",
            "Época 28 completa\n",
            "Época 29 completa\n",
            "Época 30 completa\n",
            "Época 31 completa\n",
            "Época 32 completa\n",
            "Época 33 completa\n",
            "Época 34 completa\n",
            "Época 35 completa\n",
            "Época 36 completa\n",
            "Época 37 completa\n",
            "Época 38 completa\n",
            "Época 39 completa\n",
            "Época 40 completa\n",
            "Época 41 completa\n",
            "Época 42 completa\n",
            "Época 43 completa\n",
            "Época 44 completa\n",
            "Época 45 completa\n",
            "Época 46 completa\n",
            "Época 47 completa\n",
            "Época 48 completa\n",
            "Época 49 completa\n",
            "Época 50 completa\n",
            "Época 51 completa\n",
            "Época 52 completa\n",
            "Época 53 completa\n",
            "Época 54 completa\n",
            "Época 55 completa\n",
            "Época 56 completa\n",
            "Época 57 completa\n",
            "Época 58 completa\n",
            "Época 59 completa\n",
            "Época 60 completa\n",
            "Época 61 completa\n",
            "Época 62 completa\n",
            "Época 63 completa\n",
            "Época 64 completa\n",
            "Época 65 completa\n",
            "Época 66 completa\n",
            "Época 67 completa\n",
            "Época 68 completa\n",
            "Época 69 completa\n",
            "Época 70 completa\n",
            "Época 71 completa\n",
            "Época 72 completa\n",
            "Época 73 completa\n",
            "Época 74 completa\n",
            "Época 75 completa\n",
            "Época 76 completa\n",
            "Época 77 completa\n",
            "Época 78 completa\n",
            "Época 79 completa\n",
            "Época 80 completa\n",
            "Época 81 completa\n",
            "Época 82 completa\n",
            "Época 83 completa\n",
            "Época 84 completa\n",
            "Época 85 completa\n",
            "Época 86 completa\n",
            "Época 87 completa\n",
            "Época 88 completa\n",
            "Época 89 completa\n",
            "Época 90 completa\n",
            "Época 91 completa\n",
            "Época 92 completa\n",
            "Época 93 completa\n",
            "Época 94 completa\n",
            "Época 95 completa\n",
            "Época 96 completa\n",
            "Época 97 completa\n",
            "Época 98 completa\n",
            "Época 99 completa\n",
            "Época 100 completa\n",
            "Época 101 completa\n",
            "Época 102 completa\n",
            "Época 103 completa\n",
            "Época 104 completa\n",
            "Época 105 completa\n",
            "Época 106 completa\n",
            "Época 107 completa\n",
            "Época 108 completa\n",
            "Época 109 completa\n",
            "Época 110 completa\n",
            "Época 111 completa\n",
            "Época 112 completa\n",
            "Época 113 completa\n",
            "Época 114 completa\n",
            "Época 115 completa\n",
            "Época 116 completa\n",
            "Época 117 completa\n",
            "Época 118 completa\n",
            "Época 119 completa\n",
            "Época 120 completa\n",
            "Época 121 completa\n",
            "Época 122 completa\n",
            "Época 123 completa\n",
            "Época 124 completa\n",
            "Época 125 completa\n",
            "Época 126 completa\n",
            "Época 127 completa\n",
            "Época 128 completa\n",
            "Época 129 completa\n",
            "Época 130 completa\n",
            "Época 131 completa\n",
            "Época 132 completa\n",
            "Época 133 completa\n",
            "Época 134 completa\n",
            "Época 135 completa\n",
            "Época 136 completa\n",
            "Época 137 completa\n",
            "Época 138 completa\n",
            "Época 139 completa\n",
            "Época 140 completa\n",
            "Época 141 completa\n",
            "Época 142 completa\n",
            "Época 143 completa\n",
            "Época 144 completa\n",
            "Época 145 completa\n",
            "Época 146 completa\n",
            "Época 147 completa\n",
            "Época 148 completa\n",
            "Época 149 completa\n",
            "Época 150 completa\n",
            "Época 151 completa\n",
            "Época 152 completa\n",
            "Época 153 completa\n",
            "Época 154 completa\n",
            "Época 155 completa\n",
            "Época 156 completa\n",
            "Época 157 completa\n",
            "Época 158 completa\n",
            "Época 159 completa\n",
            "Época 160 completa\n",
            "Época 161 completa\n",
            "Época 162 completa\n",
            "Época 163 completa\n",
            "Época 164 completa\n",
            "Época 165 completa\n",
            "Época 166 completa\n",
            "Época 167 completa\n",
            "Época 168 completa\n",
            "Época 169 completa\n",
            "Época 170 completa\n",
            "Época 171 completa\n",
            "Época 172 completa\n",
            "Época 173 completa\n",
            "Época 174 completa\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[24], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m gen\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     35\u001b[0m optim_D \u001b[38;5;241m=\u001b[39m optim_Ds[i]\n\u001b[1;32m---> 37\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:418\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices: List[\u001b[38;5;28mint\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[_T_co]:\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;66;03m# add batched sampling support when parent dataset supports it.\u001b[39;00m\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;66;03m# see torch.utils.data._utils.fetch._MapDatasetFetcher\u001b[39;00m\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[1;32m--> 418\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    420\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\datasets\\arrow_dataset.py:2766\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[1;34m(self, keys)\u001b[0m\n\u001b[0;32m   2764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys: List) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n\u001b[0;32m   2765\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2766\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2767\u001b[0m     n_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[0;32m   2768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\datasets\\arrow_dataset.py:2762\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2760\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[0;32m   2761\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\datasets\\arrow_dataset.py:2747\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, **kwargs)\u001b[0m\n\u001b[0;32m   2745\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m   2746\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[1;32m-> 2747\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[0;32m   2749\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\datasets\\formatting\\formatting.py:639\u001b[0m, in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    637\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\datasets\\formatting\\formatting.py:407\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\datasets\\formatting\\formatting.py:522\u001b[0m, in \u001b[0;36mCustomFormatter.format_batch\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    520\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_batch(pa_table)\n\u001b[0;32m    521\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_batch(batch)\n\u001b[1;32m--> 522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[13], line 7\u001b[0m, in \u001b[0;36mapply_transforms\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_transforms\u001b[39m(batch):\n\u001b[1;32m----> 7\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[43mpytorch_transforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\torchvision\\transforms\\functional.py:350\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\55199\\Mestrado\\gerafed_env312\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:928\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m std\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    927\u001b[0m     std \u001b[38;5;241m=\u001b[39m std\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 928\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdiv_(std)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "wgan = False\n",
        "epochs = 200\n",
        "g_losses_chunk = []\n",
        "d_losses_chunk = []\n",
        "g_losses_round = []\n",
        "d_losses_round = []\n",
        "\n",
        "epoch_bar = tqdm(range(epochs), desc=\"Treinamento\", leave=True, position=0)\n",
        "\n",
        "batch_size_gen = 2\n",
        "batch_tam = 128\n",
        "extra_g_e = 150\n",
        "\n",
        "for epoch in epoch_bar:\n",
        "  g_loss_c = 0.0\n",
        "  d_loss_c = 0.0\n",
        "  total_d_samples = 0  # Amostras totais processadas pelos discriminadores\n",
        "  total_g_samples = 0  # Amostras totais processadas pelo gerador\n",
        "\n",
        "  for chunk_idx in range(num_chunks):\n",
        "    # ====================================================================\n",
        "    # Treino dos Discriminadores (clientes) no bloco atual\n",
        "    # ====================================================================\n",
        "    d_loss_b = 0\n",
        "    total_chunk_samples = 0\n",
        "\n",
        "    for i, (net, chunks) in enumerate(zip(models, client_chunks)):\n",
        "      # Carregar o bloco atual do cliente\n",
        "      chunk_dataset = chunks[chunk_idx]\n",
        "      chunk_loader = DataLoader(chunk_dataset, batch_size=batch_tam, shuffle=True)\n",
        "\n",
        "      # Treinar o discriminador no bloco\n",
        "      net.to(device)\n",
        "      gen.to(device)\n",
        "      optim_D = optim_Ds[i]\n",
        "\n",
        "      for batch in chunk_loader:\n",
        "          images, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "          batch_size = images.size(0)\n",
        "          if batch_size == 1:\n",
        "            continue\n",
        "          real_ident = torch.full((batch_size, 1), 1., device=device)\n",
        "          fake_ident = torch.full((batch_size, 1), 0., device=device)\n",
        "\n",
        "          z_noise = torch.randn(batch_size, 100, device=device)\n",
        "          x_fake_labels = torch.randint(0, 10, (batch_size,), device=device)\n",
        "\n",
        "          # Train D\n",
        "          optim_D.zero_grad()\n",
        "\n",
        "          if wgan:\n",
        "            labels = torch.nn.functional.one_hot(labels, 10).float().to(device)\n",
        "            x_fake_labels = torch.nn.functional.one_hot(x_fake_labels, 10).float()\n",
        "\n",
        "            # Adicionar labels ao images para treinamento do Discriminador\n",
        "            image_labels = labels.view(labels.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "            image_fake_labels = x_fake_labels.view(x_fake_labels.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "\n",
        "            images = torch.cat([images, image_labels], dim=1)\n",
        "\n",
        "            # Treinar Discriminador\n",
        "            z_noise = torch.cat([z_noise, x_fake_labels], dim=1)\n",
        "            fake_images = gen(z_noise).detach()\n",
        "            fake_images = torch.cat([fake_images, image_fake_labels], dim=1)\n",
        "\n",
        "            d_loss = discriminator_loss(net(images), net(fake_images)) + 10 * gradient_penalty(net, images, fake_images)\n",
        "\n",
        "          else:\n",
        "            # Dados Reais\n",
        "            y_real = net(images, labels)\n",
        "            d_real_loss = net.loss(y_real, real_ident)\n",
        "\n",
        "            # Dados Falsos\n",
        "            z_noise = torch.randn(batch_size, 100, device=device)\n",
        "            x_fake_labels = torch.randint(0, 10, (batch_size,), device=device)\n",
        "            x_fake = gen(z_noise, x_fake_labels).detach()\n",
        "            y_fake_d = net(x_fake, x_fake_labels)\n",
        "            d_fake_loss = net.loss(y_fake_d, fake_ident)\n",
        "\n",
        "            # Loss total e backprop\n",
        "            d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "\n",
        "          d_loss.backward()\n",
        "          #torch.nn.utils.clip_grad_norm_(net.discriminator.parameters(), max_norm=1.0)\n",
        "          optim_D.step()\n",
        "          d_loss_b += d_loss.item()\n",
        "          total_chunk_samples += 1\n",
        "    # Média da perda dos discriminadores neste chunk\n",
        "    avg_d_loss_chunk = d_loss_b / total_chunk_samples if total_chunk_samples > 0 else 0.0\n",
        "    d_losses_chunk.append(avg_d_loss_chunk)\n",
        "    d_loss_c += avg_d_loss_chunk * total_chunk_samples\n",
        "    total_d_samples += total_chunk_samples\n",
        "\n",
        "    chunk_g_loss = 0.0\n",
        "    for g_epoch in range(extra_g_e):\n",
        "      # Train G\n",
        "      optim_G.zero_grad()\n",
        "\n",
        "      # Gera dados falsos\n",
        "      z_noise = torch.randn(batch_size_gen, 100, device=device)\n",
        "      x_fake_labels = torch.randint(0, 10, (batch_size_gen,), device=device)\n",
        "\n",
        "      if wgan:\n",
        "        x_fake_labels = torch.nn.functional.one_hot(x_fake_labels, 10).float()\n",
        "        z_noise = torch.cat([z_noise, x_fake_labels], dim=1)\n",
        "        fake_images = gen(z_noise)\n",
        "\n",
        "        # Seleciona o melhor discriminador (Dmax)\n",
        "        image_fake_labels = x_fake_labels.view(x_fake_labels.size(0), 10, 1, 1).expand(-1, -1, 28, 28)\n",
        "        fake_images = torch.cat([fake_images, image_fake_labels], dim=1)\n",
        "\n",
        "        y_fake_gs = [model(fake_images.detach()) for model in models]\n",
        "\n",
        "      else:\n",
        "        x_fake = gen(z_noise, x_fake_labels)\n",
        "\n",
        "        # Seleciona o melhor discriminador (Dmax)\n",
        "        y_fake_gs = [model(x_fake.detach(), x_fake_labels) for model in models]\n",
        "\n",
        "      y_fake_g_means = [torch.mean(y).item() for y in y_fake_gs]\n",
        "      Dmax = models[y_fake_g_means.index(max(y_fake_g_means))]\n",
        "\n",
        "      # Calcula a perda do gerador\n",
        "      real_ident = torch.full((batch_size_gen, 1), 1., device=device)\n",
        "      if wgan:\n",
        "        y_fake_g = Dmax(fake_images)\n",
        "        g_loss = generator_loss(y_fake_g)\n",
        "\n",
        "\n",
        "      else:\n",
        "        y_fake_g = Dmax(x_fake, x_fake_labels)  # Detach explícito\n",
        "        g_loss = gen.loss(y_fake_g, real_ident)\n",
        "\n",
        "      g_loss.backward()\n",
        "      #torch.nn.utils.clip_grad_norm_(gen.generator.parameters(), max_norm=1.0)\n",
        "      optim_G.step()\n",
        "\n",
        "      chunk_g_loss += g_loss.item()\n",
        "    g_losses_chunk.append(chunk_g_loss / extra_g_e)\n",
        "    g_loss_c += chunk_g_loss /extra_g_e\n",
        "\n",
        "  g_loss_e = g_loss_c/num_chunks\n",
        "  d_loss_e = d_loss_c / total_d_samples if total_d_samples > 0 else 0.0\n",
        "\n",
        "  g_losses_round.append(g_loss_e)\n",
        "  d_losses_round.append(d_loss_e)\n",
        "\n",
        "  figura = generate_plot(net=gen, device=\"cpu\", round_number=epoch, latent_dim=100)\n",
        "  print(f\"Época {epoch} completa\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBWFA3seZ_-U"
      },
      "source": [
        "#### Plot losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38ycqSVjaT4q"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0_nwm1SXoC9"
      },
      "outputs": [],
      "source": [
        "def loss_graph(g_losses: int, d_losses: int) -> None:\n",
        "    \"\"\"Funcao para gerar grafico de evolucao das perdas da geradora e discriminadora\"\"\"\n",
        "\n",
        "    # Número de iterações/épocas para cada lista\n",
        "    epochs_g = range(len(g_losses))  # Eixo x para o gerador\n",
        "    epochs_d = range(len(d_losses))  # Eixo x para o discriminador\n",
        "\n",
        "    # Criar o gráfico\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(epochs_g, g_losses, label='Generator Loss')\n",
        "    plt.plot(epochs_d, d_losses, label='Discriminator Loss')\n",
        "\n",
        "    # Adicionar título e rótulos aos eixos\n",
        "    plt.title('Generator and Discriminator Losses Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Mostrar o gráfico\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "leK6Jt3Manph",
        "outputId": "dbf9d258-2d79-407f-f1e7-6416fec950df"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "loss_graph(g_losses=g_losses_round, d_losses=d_losses_round)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd2fQWWzXoC_"
      },
      "outputs": [],
      "source": [
        "optim_G = torch.optim.Adam(gen.generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "gen.zero_grad()\n",
        "z_noise = torch.randn(128, 100, device=device)\n",
        "x_fake_labels = torch.randint(0, 10, (128,), device=device)\n",
        "x_fake = gen(z_noise, x_fake_labels)\n",
        "y_fake_gs = [model(x_fake.detach(), x_fake_labels) for model in models]\n",
        "real_ident = torch.full((128, 1), 1., device=device)\n",
        "y_fake_g_means = [torch.mean(y).item() for y in y_fake_gs]\n",
        "Dmax = models[y_fake_g_means.index(max(y_fake_g_means))]\n",
        "y_fake_g = Dmax(x_fake, x_fake_labels)\n",
        "g_loss = gen.loss(y_fake_g, real_ident)\n",
        "g_loss.backward()\n",
        "optim_G.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjrUZkoAXoDD"
      },
      "outputs": [],
      "source": [
        "optim_G = torch.optim.Adam(gen.generator.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "gen.zero_grad()\n",
        "z_noise = torch.randn(128, 100, device=device)\n",
        "x_fake_labels = torch.randint(0, 10, (128,), device=device)\n",
        "x_fake = gen(z_noise, x_fake_labels)\n",
        "y_fake_gs = [model(x_fake, x_fake_labels) for model in models]\n",
        "real_ident = torch.full((128, 1), 1., device=device)\n",
        "y_fake_g_means = [torch.mean(y).item() for y in y_fake_gs]\n",
        "max_idx = y_fake_g_means.index(max(y_fake_g_means))\n",
        "g_loss = gen.loss(y_fake_gs[max_idx], real_ident)\n",
        "g_loss.backward()\n",
        "optim_G.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_mj5MokXoDM"
      },
      "outputs": [],
      "source": [
        "from flwr.server.client_proxy import ClientProxy\n",
        "from flwr.common import FitRes, Status, Code, ndarrays_to_parameters, parameters_to_ndarrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDEMtyGKXoDM"
      },
      "outputs": [],
      "source": [
        "params = [[val.cpu().numpy() for _, val in net.state_dict().items()] for net in models]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72r92dCPXoDM"
      },
      "outputs": [],
      "source": [
        "params_converted = [ndarrays_to_parameters(param) for param in params]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Is3LfQQLXoDM"
      },
      "outputs": [],
      "source": [
        "results = [(i, FitRes(status=Status(code=Code.OK, message=\"Success\"), parameters=param, num_examples=len(train_partition), metrics={})) for i, param, train_partition in zip(range(num_partitions), params_converted, train_partitions)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxj1CVhoXoDN"
      },
      "outputs": [],
      "source": [
        "from flwr.server.strategy.aggregate import aggregate_inplace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvmLuOmPXoDN"
      },
      "outputs": [],
      "source": [
        "aggregated_ndarrays = aggregate_inplace(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-e-StinXoDN"
      },
      "outputs": [],
      "source": [
        "parameters_aggregated_gen = ndarrays_to_parameters(aggregated_ndarrays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTzi5zSvXoDP"
      },
      "outputs": [],
      "source": [
        "# Cria uma instância do modelo\n",
        "model = CGAN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Wj3iAxHXoDQ"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7ia1SieXoFS",
        "outputId": "bee573da-6d62-4eb0-9314-00c09c3d92f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = next(model.parameters()).device\n",
        "params_dict = zip(model.state_dict().keys(), aggregated_ndarrays)\n",
        "state_dict = OrderedDict({k: torch.tensor(v).to(device) for k, v in params_dict})\n",
        "model.load_state_dict(state_dict, strict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDTkH5S6XoFT"
      },
      "outputs": [],
      "source": [
        "def train_G(net: CGAN, device: str, lr: float, epochs: int, batch_size: int, latent_dim: int):\n",
        "    net.to(device)  # move model to GPU if available\n",
        "    optim_G = torch.optim.Adam(net.generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Train G\n",
        "        net.zero_grad()\n",
        "        z_noise = torch.randn(batch_size, latent_dim, device=device)\n",
        "        x_fake_labels = torch.randint(0, 10, (batch_size,), device=device)\n",
        "        x_fake = net(z_noise, x_fake_labels)\n",
        "        y_fake_g = net(x_fake, x_fake_labels)\n",
        "        real_ident = torch.full((batch_size, 1), 1., device=device)\n",
        "        g_loss = net.loss(y_fake_g, real_ident)\n",
        "        g_loss.backward()\n",
        "        optim_G.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iwNpLftXoFT"
      },
      "outputs": [],
      "source": [
        "train_G(net=model,\n",
        "        device=device,\n",
        "        lr=0.0001,\n",
        "        epochs=2,\n",
        "        batch_size=128,\n",
        "        latent_dim=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoZsab-tXoFU",
        "outputId": "d9cc408c-5563-4d41-bd07-718c97ff8f99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "flwr.common.typing.Parameters"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(parameters_aggregated_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4knrQHgXoFV"
      },
      "outputs": [],
      "source": [
        "params = [val.cpu().numpy() for _, val in model.state_dict().items()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZdf9fw0XoFV"
      },
      "outputs": [],
      "source": [
        "param = ndarrays_to_parameters(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnpXx2j_XoFV",
        "outputId": "dcffe647-d5a4-40ea-90b0-390885be8d28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "flwr.common.typing.Parameters"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(param)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gerafed_env312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}